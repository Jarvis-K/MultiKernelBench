{
  "爬取时间": "2025-08-27 07:51:31",
  "总计API数量": 308,
  "成功爬取": 308,
  "失败页面数": 2,
  "爬取统计": {
    "有函数原型": 89,
    "有参数说明": 85,
    "有调用示例": 92,
    "有功能说明": 94
  },
  "APIs": [
    {
      "API名称": "Ascend C API列表-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0003.html",
      "功能说明": "Ascend C提供一组类库API，开发者使用标准C++语法和类库API进行编程。Ascend C编程类库API示意图如下所示，分为：",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [
        "ScalarGetCountOfValue",
        "ScalarCountLeadingZero",
        "ScalarCast",
        "CountBitsCntSameAsSignBit",
        "ScalarGetSFFValue",
        "ToBfloat16",
        "ToFloat",
        "Exp",
        "Ln",
        "Abs"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "GetICachePreloadStatus(ISASI)-缓存处理-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0277.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GeGLU-GeGLU-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0786.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "FusedMulAddRelu-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0051.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "DataCacheCleanAndInvalid-缓存处理-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0177.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ICPU_SET_TILING_KEY-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1209.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "RmsNorm-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0804.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "CreateVecIndex-数据填充-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0090.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "WholeReduceMin-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0080.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LoadImageToLocal-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0241.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "TilingData结构注册-Tiling数据结构注册-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1006.html",
      "功能说明": "注册定义的TilingData结构体并和自定义算子绑定。具体使用说明请参考调用示例。 注册定义的TilingData结构体并和自定义算子绑定。具体使用说明请参考调用示例。 表1 参数说明参数 输入/输出 说明 op_type 输入 注册的算子名 struct_name 输入 tiling结构体名，与c++变量命名要求一致",
      "函数原型": "注册算子tilingdata类到对应的AddCustom算子 REGISTER_TILING_DATA_CLASS(AddCustom, AddCustomTilingData)",
      "参数说明": [
        {
          "参数名": "op_type",
          "类型": "输入",
          "说明": "注册的算子名"
        },
        {
          "参数名": "struct_name",
          "类型": "输入",
          "说明": "tiling结构体名，与c++变量命名要求一致"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12\n1 2 3 4 5 6 7 8 9 10 11 12",
      "约束限制": "",
      "相关接口": [
        "Tiling数据结构注册"
      ],
      "版本信息": ""
    },
    {
      "API名称": "ReadSpmBuffer-SPM Buffer-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0168.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Ln-单目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0026.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SoftMax-SoftMax-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0754.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "WaitPreBlock-核间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0207.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ScalarGetSFFValue-标量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0020.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "min-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10054.html",
      "功能说明": "比较相同数据类型的两个数，返回最小值。 比较相同数据类型的两个数，返回最小值。 表1 模板参数说明参数名 含义 T 输入数据src0的数据类型。当前支持的数据类型为int8_t/uint8_t/int16_t/uint16_t/int32_t/uint32_t/float/int64_t/uint64_t。 U 输入数据src1的数据类型。当前支持的数据类型为int8_t/uint8_t/int16_t/uint16_t/int32_t/uint32_t/float/int64_t/uint64_t。 预留类型，当前必须与T保持一致。 表2 接口参数说明参数名 输入/输出 含义 src0 输入 源操作数。参与比较的输入。 src1 输入 源操作数。参与比较的输入。 两个源操作数的数据类型必须相同。 两个输入数据中的最小值。",
      "函数原型": "template <typename T, typename U> __aicore__ inline T min(const T src0, const U src1)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "输入数据src0的数据类型。当前支持的数据类型为int8_t/uint8_t/int16_t/uint16_t/int32_t/uint32_t/float/int64_t/uint64_t。"
        },
        {
          "参数名": "U",
          "类型": "",
          "说明": "输入数据src1的数据类型。当前支持的数据类型为int8_t/uint8_t/int16_t/uint16_t/int32_t/uint32_t/float/int64_t/uint64_t。 预留类型，当前必须与T保持一致。"
        },
        {
          "参数名": "src0",
          "类型": "输入",
          "说明": "源操作数。参与比较的输入。"
        },
        {
          "参数名": "src1",
          "类型": "输入",
          "说明": "源操作数。参与比较的输入。"
        }
      ],
      "返回值": "两个输入数据中的最小值。",
      "调用示例": "template <typename T, typename U> __aicore__ inline T min(const T src0, const U src1)\nint64_t src0 = 1; int64_t src1 = 2; int64_t result = AscendC::Std::min(src0, src1); // result: 1",
      "约束限制": "两个源操作数的数据类型必须相同。",
      "相关接口": [
        "模板库函数"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "CompareScalar-比较指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0068.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "MulAddDst-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0048.html",
      "功能说明": "按元素将src0Local和src1Local相乘并和dstLocal相加，将最终结果存放进dstLocal中。计算公式如下： 按元素将src0Local和src1Local相乘并和dstLocal相加，将最终结果存放进dstLocal中。计算公式如下： 表1 模板参数说明 参数名 描述 T 目的操作数数据类型。目的操作数和源操作数的数据类型约束请参考表3。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float U 源操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。源操作数数据类型和目的操作数数据类型可以不一致。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。 表3 数据类型约束 src0Local数据类型 src1Local数据类型 dstLocal数据类型 PAR 支持的型号 half half half 128 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 Atlas 推理系列产品 AI Core Atlas 200I/500 A2 推理产品 float float float 64 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 Atlas 推理系列产品 AI Core Atlas 200I/500 A2 推理产品 half half float 64 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 Atlas 推理系列产品 AI Core int16_t int16_t int16_t 128 Atlas 200I/500 A2 推理产品 uint16_t uint16_t uint16_t 128 Atlas 200I/500 A2 推理产品 int32_t int32_t int32_t 64 Atlas 200I/500 A2 推理产品 uint32_t uint32_t uint32_t 64 Atlas 200I/500 A2 推理产品",
      "函数原型": "template <typename T, typename U, bool isSetMask = true> __aicore__ inline void MulAddDst(const LocalTensor<T>& dstLocal, const LocalTensor<U>& src0Local, const LocalTensor<U>& src1Local, const uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "目的操作数数据类型。目的操作数和源操作数的数据类型约束请参考表3。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float"
        },
        {
          "参数名": "U",
          "类型": "",
          "说明": "源操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。源操作数数据类型和目的操作数数据类型可以不一致。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T, typename U> __aicore__ inline void MulAddDst(const LocalTensor<T>& dstLocal, const LocalTensor<U>& src0Local, const LocalTensor<U>& src1Local, const int32_t& calCount)\ntemplate <typename T, typename U, bool isSetMask = true> __aicore__ inline void MulAddDst(const LocalTensor<T>& dstLocal, const LocalTensor<U>& src0Local, const LocalTensor<U>& src1Local, const uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\ntemplate <typename T, typename U, bool isSetMask = true> __aicore__ inline void MulAddDst(const LocalTensor<T>& dstLocal, const LocalTensor<U>& src0Local, const LocalTensor<U>& src1Local, uint64_t mask, const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\nuint64_t mask = 64; // repeatTimes = 4, 一次迭代计算64个数, 共计算256个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride = 8, src0RepStride, src1RepStride = 4, 相邻迭代间数据连续读取和写入 AscendC::MulAddDst(dstLocal, src0Local, src1Local, 64, 4, { 1, 1, 1, 8, 4, 4 });\nuint64_t mask[2] = { UINT64_MAX, 0 }; // repeatTimes = 4, 一次迭代计算64个数, 共计算256个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride = 8, src0RepStride, src1RepStride = 4, 相邻迭代间数据连续读取和写入 AscendC::MulAddDst(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 4, 4 });\nAscendC::MulAddDst(dstLocal, src0Local, src1Local, 256);\n输入数据(src0Local): [-83. 58.2 -14.28 -43.12 20.72 -79.9 54.16 31.56 -1.464 68.25 -28.31 -93.5 -4.2 -46.56 -22.23 78.5 -69.56 -37.03 -53.12 58.28 -71.56 -34.44 85.94 96.3 66.06 99.94 -45.94 8.75 -93.9 35.56 82.56 -70.8 -68.75 -35.4 95.3 -49.1 -56.34 86.75 90.25 24.17 79.06 -49.66 -95.3 -6.965 -63.72 -33.16 -15.56 -43.28 51.28 40.1 83.25 49.72 55.47 -53.7 17.55 -36.06 63. 59.16 -66.8 -9.01 25.56 44.28 22.12 -33.84 -31.9 -74.2 79.94 -34.94 1.119 18.45 -92.75 -83.25 42.66 -77.6 33.28 0.709 -19.3 44.44 45.28 -33.4 -55.94 -42.22 -37.72 39.4 87.25 23.19 34.16 51.3 -22.16 15.234 59. -20.45 -63.9 41.84 -14.63 -80.94 47.8 -36.84 8.47 -60.66 -26.06 -42.78 30.5 -91.3 55.84 -85.44 -99.44 68.2 -71.7 27.45 -11.48 -48.03 71. 71.5 -59.2 14.67 79.25 32.7 -54.22 6.17 -69.94 -49.22 87.7 -61.53 36.25 -57.84 -81.75 -24.84 -35. -62.44 -47.22 19.95 21.16 -31.56 13.38 72.4 -64.06 -89.75 -28.17 34.4 -68.06 -46.94 16.06 65.56 3.16 -59.88 -32.97 30.69 89.5 16.66 25.05 -1.988 5.27 -23.14 -26.89 -24.72 1.427 -14.46 81.9 -59.94 68.7 -83.2 -75.44 88.6 27.62 -58.06 -36.1 -49.53 27.73 89.5 -51.5 90. 67.94 -70.8 24.2 -75.8 -96.75 -22.66 33.03 6.293 -87.5 36.56 36.06 -76.8 1.786 82.9 87.6 -63.94 -4.51 -89.06 -56.06 75.2 -31.89 27.44 35.22 -27.19 37.53 96.94 -83.25 -49.6 31.78 -50.25 65.2 69.9 63.03 53. -70.1 -57.22 -11.99 -23.14 44.28 -77.3 77.25 10.805 16.3 -96.6 -94.9 34.1 -40.25 -99.7 -6.156 44.97 82.7 51.1 -53.28 85.44 -80.94 -47. -53.47 -35.22 76.75 -28.38 26.48 -67.06 34.28 -54.6 21.52 -38.9 79.75 51.7 -39.44 48.56 -91.7 -44.06 92.9 11.79 8.98 -5.074 12.375 -24.77 -27.31 76.2 39.8 -5.46 25.17 47. ] 输入数据(src1Local): [-57.97 43.5 8.08 72.4 -81.44 -52. 69.1 -84.25 31.12 34.34 74.75 83.56 -83. 80.1 42.84 -31.6 88.56 47.34 18.89 -95.25 16.88 -85.75 76.75 -17.19 23.39 92.56 22.81 77.94 38.62 -55.8 38.22 -88.6 -99.4 -66.75 90.44 80.56 12.78 -12.6 -68.4 2.816 27.45 -60.88 70. 61.78 -90.56 -99.25 38.25 -14.49 -35.88 38.1 13. 29.22 -57.06 -44.7 6.535 -44.6 -76.3 91.7 36.66 83.9 66. -81.25 -50.06 68. 2.705 -51.72 66.9 49.03 15.76 9.37 33.2 99.56 -20.55 83.3 -57.1 37.06 68.94 -91.9 -46.06 -92.7 64.4 8.164 8.98 10.76 -75.6 26.94 46.8 62. 8.734 -69.25 -70.2 -59. 67.25 87.6 48.72 60.16 19.39 48.62 21.64 25.06 1.013 -36.6 -46.28 -29.14 67.44 56.7 32.03 -28.81 -94.44 49.6 0.583 -84.4 -51.53 -43. 66. -68. 77.44 -50.16 -90.4 -46.22 90.25 88. 79.25 -40.84 -71.7 -27.03 19.53 85.44 45.06 60.72 19.22 -28.95 -47.72 97.8 -51.6 31.42 31.75 -21.84 -71.4 77.9 43.12 35.66 -50.84 -52. -48.84 -53.97 -59.56 31.2 -64.3 -10.47 86.25 -84.44 -56.4 -63.03 -99.9 54.44 40.72 74.94 8.305 18.52 -47.34 -74.06 79.1 92.44 84.94 -98.7 -41.06 -80.2 -71.06 89.06 96.2 -19.83 -51.03 -92. 82.25 -75.75 58.66 22.72 -89.06 -83.06 -73.5 18.75 -0.939 -96.4 50.12 -73.9 -56.97 52.34 -95.56 11.02 -46.3 -52.2 -8.46 80.56 77. -51.72 38.8 -66.44 -69. -30.33 -53.3 5.406 74.8 52.25 -35.88 92.5 51.38 40.47 43.94 -29.05 89.7 -74.5 -83.5 81.75 -56.6 -13.625 86.9 -4.58 -67.5 -6.67 -59.53 -30.4 -91.75 -84.3 -66.6 -28.61 -13.79 -70.75 -90.2 -47.94 59.56 84.2 0.7085 -57.44 -24.94 -11.875 -90.4 54.22 -44.16 -36.34 -31.64 72.1 -81.25 75.8 93.9 -28.28 -20.53 90.2 -58.97 -95.7 59.22 -37.8 94.9 -86.7 36.16 26.47 ] 输入数据(dstLocal): [-97.94773 -61.303955 32.56878 -87.50743 -78.92147 59.20739 50.336506 49.039738 -76.2525 0.25441223 -71.73807 6.481831 -55.5052 -51.057415 31.403702 63.285076 98.1897 86.71727 -50.16466 88.94256 72.111435 8.4164915 34.524082 73.14016 4.838548 69.67902 -97.855736 90.358696 9.051491 37.595695 -66.01661 -97.110634 82.84477 69.46122 25.561102 47.926853 -10.202202 78.2545 31.339691 12.940468 -31.499294 -3.351652 62.46355 45.0427 -86.02812 -43.48385 -62.274956 -36.077827 51.81446 32.47797 59.10228 68.18655 9.3604145 -76.47674 -50.29268 94.496346 30.837933 -48.315712 -44.92399 -62.369625 47.578724 84.84092 -66.64584 88.376434 95.05615 -92.37309 3.0038757 85.21814 -6.688882 97.74142 20.733965 -5.62451 69.6166 -64.435455 94.09325 -63.13334 89.150345 -17.61865 32.776333 27.28345 31.288876 -9.983517 -46.39662 -37.025536 47.853374 -30.384796 -79.801544 -11.131944 -36.417023 84.25002 -74.19904 -86.72338 -6.5878353 26.253004 -28.112898 -64.88305 -40.56897 -65.849686 22.276798 -3.356709 -78.41364 -67.26924 -10.346288 -43.172684 10.149812 -22.575602 -28.780804 -64.24396 -14.579756 -30.369322 -59.28742 -37.098255 31.078829 29.901808 50.531147 -88.35735 -45.65366 -6.7495203 6.8026304 56.172153 -0.8727364 9.618746 89.294815 75.4403 81.63827 -61.722088 -72.85743 9.296161 -69.17855 2.3497865 20.234892 -13.279363 -44.531677 55.188084 -45.736256 -30.018398 27.09971 28.841034 35.764072 21.457811 -15.206495 94.05271 79.9942 -36.39198 38.40136 5.2365685 -11.435508 67.15551 87.03286 7.9285994 78.32062 97.863335 -28.68556 -72.658554 -79.39075 -82.65206 39.52689 -22.053177 30.602457 -26.158005 49.83525 -72.24563 -97.10148 54.803936 65.070786 -57.019573 35.972733 6.694148 -74.88097 -71.13884 -84.549545 -26.875593 -3.2775877 -8.592472 -5.248627 -22.2127 98.26377 -51.741936 -69.48398 -47.230175 92.72371 18.192408 -39.66745 44.556633 -21.733562 15.191482 5.9535656 41.23602 89.30139 -32.57541 -47.595608 -50.371124 -87.899666 57.644466 38.85747 47.65093 49.42874 -32.424126 -22.5012 78.78245 -70.6598 -87.218544 50.347565 55.945244 -3.4658287 17.902784 -30.977674 53.424767 -82.00753 2.9060571 -1.010124 -94.316765 13.186674 -52.089214 58.975357 48.281635 26.436571 -27.11565 89.21593 -10.962796 49.347828 21.556795 78.163956 35.06028 10.803711 53.231297 -44.78757 -0.6473386 26.717777 63.757347 -4.90904 21.724916 37.443634 -89.250656 62.98874 72.13095 -12.19138 84.16487 71.54008 -73.41178 -97.612564 39.947853 -1.3887504 -5.6196795 -54.509125 -28.877354 26.259935 42.28702 -38.848114 -76.46558 -91.69401 71.27111 89.36143 -65.70425 -31.810083 82.811226 ] 输出数据(dstLocal): [ 4.71345850e+03 2.46985229e+03 -8.27969437e+01 -3.20867920e+03 -1.76620471e+03 4.21270752e+03 3.79388721e+03 -2.61010083e+03 -1.21815369e+02 2.34421533e+03 -2.18809741e+03 -7.80661182e+03 2.93029968e+02 -3.78187769e+03 -9.21200317e+02 -2.41682422e+03 -6.06243945e+03 -1.66648096e+03 -1.05372913e+03 -5.46234668e+03 -1.13550574e+03 2.96143213e+03 6.63022705e+03 -1.58223096e+03 1.55008167e+03 9.32014355e+03 -1.14580493e+03 7.72311829e+02 -3.61687036e+03 -1.94723633e+03 3.08941895e+03 6.17864697e+03 6.91487598e+03 2.43282837e+03 8.64538574e+03 -3.90718848e+03 -7.30345764e+02 -1.01493103e+03 -6.13950391e+03 8.10182877e+01 2.13901343e+03 3.01947266e+03 -6.60941162e+03 -3.85254059e+02 5.68450098e+03 3.24727393e+03 -6.57540588e+02 5.91162170e+02 -1.78790039e+03 1.55979932e+03 1.14135229e+03 1.52090625e+03 -3.15582520e+03 2.32268335e+03 6.43788910e+01 1.70265845e+03 -4.77684961e+03 5.37557275e+03 -2.49401978e+03 -8.17899902e+02 1.73470374e+03 -3.51301074e+03 -1.17427869e+03 -2.21299854e+03 8.74725342e+00 3.74451172e+03 5.34882422e+03 -1.62781116e+03 1.09463263e+01 2.70595306e+02 -3.05740674e+03 -8.29420215e+03 -8.06836060e+02 -6.53156836e+03 -1.80605811e+03 -3.68566055e+01 -1.24112793e+03 -4.10031396e+03 -2.05299121e+03 3.12362524e+03 -3.56968774e+03 -3.54660034e+02 -3.84981323e+02 3.86899506e+02 -6.55042773e+03 5.94228516e+02 1.51913794e+03 3.17024316e+03 -2.29938019e+02 -9.70730469e+02 -4.21526172e+03 1.12001099e+03 -4.30428320e+03 3.69281152e+03 -7.41005249e+02 -4.93377930e+03 8.86545288e+02 -1.85737708e+03 2.05545837e+02 -1.52355396e+03 -1.04807014e+02 1.49825708e+03 -1.42192444e+03 2.61773071e+03 3.77611279e+03 -4.86581396e+03 -3.21388818e+03 -2.02889624e+03 6.75540869e+03 1.33113416e+03 -6.59783478e+01 4.01553857e+03 -3.62763989e+03 -3.04459814e+03 -3.85584375e+03 -1.08604480e+03 6.09126807e+03 -1.64623193e+03 4.90682227e+03 -2.29084198e+02 -6.31273193e+03 -4.32163135e+03 7.03852930e+03 2.58860718e+03 -2.51703369e+03 1.50186682e+03 -1.66953711e+03 -2.11329175e+03 -1.64636609e+03 -3.78877710e+03 -8.87250488e+02 -5.90984680e+02 -1.05408154e+03 -3.03201904e+03 -7.36205750e+02 2.24413989e+03 -2.00688464e+03 1.98931763e+03 2.04653162e+03 2.70084448e+03 -2.95040186e+03 -1.57956250e+03 -7.36683533e+02 -3.44564209e+03 -1.15952522e+02 3.23661548e+03 1.95226562e+03 1.02470142e+03 -5.66893604e+03 -1.66441513e+02 2.23861353e+03 2.65748840e+02 -3.25920044e+02 1.38592395e+03 2.60631055e+03 -1.42827905e+03 9.76226807e+01 -1.10571973e+03 7.10548767e+02 -1.13593823e+03 -3.20208862e+03 6.08882861e+03 -6.06609375e+03 8.24707715e+03 2.41146924e+03 5.67302344e+03 1.51807239e+03 3.97848120e+03 -2.04575500e+03 7.89995508e+03 -5.03820557e+03 -1.81140686e+03 -3.47021313e+03 6.50615771e+03 1.98545837e+03 5.72058398e+03 -5.57672852e+03 -5.66463623e+02 -3.01132959e+03 -5.69939880e+02 6.52397363e+03 7.03739258e+02 -7.35288696e+01 7.44736133e+03 6.77963409e+01 -6.10719922e+03 -4.98593311e+03 -3.30549243e+03 5.20452515e+02 -1.01435034e+03 2.54879883e+03 -3.97421875e+03 1.81924927e+02 2.26807812e+03 2.75070117e+03 1.45375439e+03 1.50611035e+03 -6.47270947e+03 5.72174902e+03 1.58286792e+03 -1.76499768e+03 -3.58882599e+02 4.92718750e+03 3.70691406e+03 -2.26471191e+03 4.92040283e+03 -3.63364966e+03 -2.26214648e+03 -6.08914246e+02 6.75068909e+02 3.97046460e+03 5.66546436e+03 -6.43718848e+03 8.31193970e+02 -8.63325928e+02 1.36479724e+03 -8.21582910e+03 -1.83201096e+02 2.80609082e+03 6.54139771e+02 4.15837097e+02 -1.34577429e+03 -7.50841406e+03 -4.27278174e+03 3.56066699e+03 -2.39108228e+03 1.07126465e+03 3.32460278e+03 4.84893066e+03 1.75205615e+03 4.56651270e+03 -2.36709546e+03 5.62077103e+01 3.76265161e+03 -7.91899902e+02 7.20431763e+02 -1.95666602e+03 -2.02528333e+03 -3.44992090e+03 -1.95192932e+03 1.15021460e+03 3.54251807e+03 7.44822070e+03 -3.34610791e+03 8.66413184e+03 -3.62286774e+02 -1.58040115e+02 -4.15344086e+02 -7.68586426e+02 2.29329517e+03 -1.70910608e+03 -2.80956885e+03 3.86657227e+03 4.07690765e+02 8.78310547e+02 1.32684253e+03]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "BinaryRepeatParams",
        "通用约束",
        "更多样例",
        "双目指令"
      ],
      "版本信息": "58.2"
    },
    {
      "API名称": "ReduceMin-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0077.html",
      "功能说明": "在所有的输入数据中找出最小值及最小值对应的索引位置。归约指令的总体介绍请参考如何使用归约指令。ReduceMin计算原理参考ReduceMax。 在所有的输入数据中找出最小值及最小值对应的索引位置。归约指令的总体介绍请参考如何使用归约指令。ReduceMin计算原理参考ReduceMax。 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float 表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证4字节对齐（针对half数据类型），8字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 workLocal 输入 API执行期间，部分硬件型号需要一块空间用于存储中间结果，空间大小需要满足最小所需空间的要求，具体计算方法可参考ReduceMax计算示意图中的介绍。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，需要使用workLocal。 Atlas 推理系列产品 AI Core，需要使用workLocal Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，需要使用workLocal。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，需要使用workLocal。 Atlas 200I/500 A2 推理产品 ，需要使用workLocal。 count 输入 参与计算的元素个数。 参数取值范围和操作数的数据类型有关，数据类型不同，能够处理的元素个数最大值不同，最大处理的数据量不能超过UB大小限制。 calIndex 输入 指定是否获取最小值的索引，bool类型，默认值为false，取值： true：同时获取最小值和最小值索引。 false：不获取索引，只获取最小值。 mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 迭代次数。与通用参数说明中不同的是，支持更大的取值范围，保证不超过int32_t最大值的范围即可。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考repeatStride。",
      "函数原型": "template <typename T> __aicore__ inline void ReduceMin(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<T>& workLocal, const uint64_t mask[], const int32_t repeatTimes, const int32_t srcRepStride, bool calIndex = 0)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证4字节对齐（针对half数据类型），8字节对齐（针对float数据类型）。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "workLocal",
          "类型": "输入",
          "说明": "API执行期间，部分硬件型号需要一块空间用于存储中间结果，空间大小需要满足最小所需空间的要求，具体计算方法可参考ReduceMax计算示意图中的介绍。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，需要使用workLocal。 Atlas 推理系列产品 AI Core，需要使用workLocal Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，需要使用workLocal。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，需要使用workLocal。 Atlas 200I/500 A2 推理产品 ，需要使用workLocal。"
        },
        {
          "参数名": "count",
          "类型": "输入",
          "说明": "参与计算的元素个数。 参数取值范围和操作数的数据类型有关，数据类型不同，能够处理的元素个数最大值不同，最大处理的数据量不能超过UB大小限制。"
        },
        {
          "参数名": "calIndex",
          "类型": "输入",
          "说明": "指定是否获取最小值的索引，bool类型，默认值为false，取值： true：同时获取最小值和最小值索引。 false：不获取索引，只获取最小值。"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "迭代次数。与通用参数说明中不同的是，支持更大的取值范围，保证不超过int32_t最大值的范围即可。"
        },
        {
          "参数名": "srcRepStride",
          "类型": "输入",
          "说明": "源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考repeatStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void ReduceMin(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<T>& workLocal, const int32_t count, bool calIndex = 0)\ntemplate <typename T> __aicore__ inline void ReduceMin(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<T>& workLocal, const uint64_t mask[], const int32_t repeatTimes, const int32_t srcRepStride, bool calIndex = 0)\ntemplate <typename T> __aicore__ inline void ReduceMin(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<T>& workLocal, const int32_t mask, const int32_t repeatTimes, const int32_t srcRepStride, bool calIndex = 0)\nfloat minIndex = dst.GetValue(1); uint32_t realIndex = *reinterpret_cast<uint32_t*>(&minIndex);\n#include \"kernel_operator.h\" class KernelReduce { public: __aicore__ inline KernelReduce() {} __aicore__ inline void Init(__gm__ uint8_t* src, __gm__ uint8_t* dstGm) { srcGlobal.SetGlobalBuffer((__gm__ half*)src); dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm); repeat = srcDataSize / mask; pipe.InitBuffer(inQueueSrc, 1, srcDataSize * sizeof(half)); pipe.InitBuffer(workQueue, 1, 32 * sizeof(half)); // 此处按照公式计算所需的最小work空间为32，也就是64Bytes pipe.InitBuffer(outQueueDst, 1, dstDataSize * sizeof(half)); } __aicore__ inline void Process() { CopyIn(); Compute(); CopyOut(); } private: __aicore__ inline void CopyIn() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>(); AscendC::DataCopy(srcLocal, srcGlobal, srcDataSize); inQueueSrc.EnQue(srcLocal); } __aicore__ inline void Compute() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>(); AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>(); AscendC::LocalTensor<half> workLocal = workQueue.AllocTensor<half>(); AscendC::ReduceMin<half>(dstLocal, srcLocal, workLocal, mask, repeat, repStride, true); outQueueDst.EnQue<half>(dstLocal); inQueueSrc.FreeTensor(srcLocal); workQueue.FreeTensor(workLocal); } __aicore__ inline void CopyOut() { AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>(); AscendC::DataCopy(dstGlobal, dstLocal, srcDataSize); outQueueDst.FreeTensor(dstLocal); } private: AscendC::TPipe pipe; AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc; AscendC::TQue<AscendC::TPosition::VECOUT, 1> workQueue; AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst; AscendC::GlobalTensor<half> srcGlobal, dstGlobal; int srcDataSize = 512; int dstDataSize = 512; int mask = 128; int repStride = 8; int repeat = 0; }; extern \"C\" __global__ __aicore__ void kernel_ReduceMin_lv0_half_512(__gm__ uint8_t* src, __gm__ uint8_t* dstGm) { KernelReduce op; op.Init(src, dstGm); op.Process(); }\n输入数据(src_gm): [0.769 0.8584 0.1082 0.2715 0.1759 0.7646 0.6406 0.2944 0.4255 0.927 0.8022 0.04507 0.9688 0.919 0.3008 0.7144 0.3206 0.6753 0.8276 0.3374 0.4636 0.3591 0.112 0.93 0.822 0.7314 0.01165 0.31 0.5586 0.2808 0.3997 0.04544 0.0931 0.8438 0.612 0.03052 0.3652 0.1153 0.06213 0.12103 0.4421 0.8003 0.1583 0.845 0.125 0.6934 0.4592 0.871 0.573 0.4133 0.885 0.6875 0.2854 0.7007 0.1294 0.2092 0.3794 0.7534 0.5923 0.03888 0.2412 0.8584 0.6704 0.429 0.77 0.427 0.6323 0.524 0.0519 0.514 0.2408 0.09357 0.1702 0.3694 0.665 0.2651 0.9507 0.661 0.459 0.1317 0.7334 0.289 0.0325 0.1187 0.6626 0.2769 0.3083 0.923 0.826 0.7275 0.976 0.4854 0.724 0.7783 0.8022 0.677 0.2401 0.377 0.839 0.2297 0.54 0.743 0.511 0.1346 0.7183 0.4775 0.3442 0.561 0.2935 0.04065 0.1001 0.753 0.6816 0.8955 0.07324 0.5947 0.508 0.2229 0.468 0.3135 0.0898 0.5625 0.7407 0.803 0.1071 0.6724 0.797 0.8296 0.807 0.8604 0.7437 0.967 0.4307 0.3833 0.03394 0.02478 0.9385 0.3105 0.43 0.0706 0.4363 0.05832 0.0812 0.2418 0.03967 0.557 0.2705 0.963 0.8125 0.342 0.8853 0.3047 0.7197 0.7173 0.02887 0.7695 0.4304 0.691 0.4285 0.9917 0.3994 0.19 0.3984 0.1888 0.83 0.0644 0.9766 0.857 0.09784 0.831 0.224 0.8228 0.8975 0.1775 0.725 0.882 0.7188 0.3257 0.05347 0.1026 0.05902 0.9697 0.445 0.728 0.626 0.3577 0.711 0.2343 0.3865 0.03888 0.3318 0.855 0.891 0.3647 0.9297 0.5083 0.7163 0.5737 0.2155 0.804 0.2118 0.525 0.1116 0.558 0.05203 0.6343 0.5796 0.5605 0.449 0.4475 0.3713 0.3708 0.11017 0.2048 0.087 0.265 0.937 0.933 0.4683 0.5884 0.4312 0.9326 0.839 0.592 0.566 0.4229 0.05493 0.4578 0.353 0.2915 0.8345 0.888 0.8394 0.8774 0.3582 0.2913 0.798 0.87 0.3372 0.6914 0.9185 0.4368 0.3276 0.8125 0.782 0.885 0.6543 0.1626 0.0965 0.8247 0.03952 0.459 0.5596 0.694 0.59 0.02153 0.3762 0.2428 0.9727 0.3672 0.732 0.2676 0.2102 0.128 0.5957 0.988 0.583 0.9097 0.144 0.3845 0.2151 0.327 0.2925 0.974 0.771 0.9224 0.147 0.6206 0.1774 0.1415 0.7637 0.573 0.9736 0.183 0.837 0.0753 0.098 0.8184 0.08527 0.889 0.528 0.2207 0.1852 0.5903 0.594 0.04865 0.5806 0.6006 0.2048 0.4934 0.1302 0.7217 0.949 0.04105 0.6875 0.3975 0.845 0.6045 0.4077 0.01927 0.1505 0.4407 0.8457 0.9614 0.4504 0.7134 0.07837 0.3557 0.521 0.545 0.02188 0.581 0.3215 0.4458 0.853 0.4656 0.928 0.2927 0.3467 0.3516 0.1686 0.88 0.1509 0.2993 0.4006 0.611 0.1251 0.0887 0.896 0.2651 0.5596 0.0359 0.6895 0.3494 0.871 0.673 0.1486 0.7812 0.0925 0.434 0.09985 0.02402 0.2932 0.01034 0.744 0.6357 0.658 0.1487 0.3416 0.1171 0.3088 0.557 0.837 0.10944 0.7036 0.9097 0.3706 0.73 0.2844 0.78 0.5117 0.5537 0.776 0.6553 0.128 0.3184 0.8022 0.686 0.1785 0.2212 0.74 0.8955 0.4773 0.6084 0.7827 0.239 0.4849 0.1816 0.2854 0.166 0.012505 0.4421 0.2179 0.06094 0.2124 0.409 0.641 0.1841 0.776 0.4685 0.2334 0.4094 0.3447 0.6836 0.434 0.10516 0.514 0.8345 0.371 0.8555 0.5396 0.844 0.7554 0.171 0.749 0.7344 0.05936 0.4482 0.9873 0.3137 0.7627 0.871 0.5503 0.956 0.2607 0.0904 0.535 0.3079 0.762 0.793 0.545 0.889 0.8936 0.6094 0.6533 0.5737 0.945 0.4434 0.2686 0.05872 0.0776 0.0915 0.5386 0.6777 0.3164 0.8955 0.3398 0.3801 0.3784 0.3904 0.4849 0.816 0.962 0.335 0.705 0.1871 0.3643 0.7163 0.6484 0.4526 0.8096 0.2408 0.608 0.0215 0.7246 0.412 0.609 0.03342 0.653 0.0424 0.672 0.627 0.3025 0.9424 0.3784 0.1012 0.4192 0.7695 0.7383 0.9395 0.06494 0.3027 0.11523 0.6035 0.1727 0.4048 0.932 0.4053 0.3528 0.8193 0.0355 0.01953 0.574 0.509 0.1443 0.0848 0.568 0.8716 0.968 0.613 0.535 0.0389 0.84 0.0655 0.127 0.06104 0.526 0.504 0.4175 0.8027 0.482 0.304 ] 输出数据(dst_gm): [0.01034, 2.104e-05], 2.104e-05需要使用reinterpret_cast方法转换得到索引值353\n#include \"kernel_operator.h\" class KernelReduce { public: __aicore__ inline KernelReduce() {} __aicore__ inline void Init(__gm__ uint8_t* src, __gm__ uint8_t* dstGm) { srcGlobal.SetGlobalBuffer((__gm__ half*)src); dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm); repeat = srcDataSize / mask; pipe.InitBuffer(inQueueSrc, 1, srcDataSize * sizeof(half)); pipe.InitBuffer(workQueue, 1, 32 * sizeof(half)); // 此处按照公式计算所需的最小work空间为32,也就是64Bytes pipe.InitBuffer(outQueueDst, 1, dstDataSize * sizeof(half)); } __aicore__ inline void Process() { CopyIn(); Compute(); CopyOut(); } private: __aicore__ inline void CopyIn() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>(); AscendC::DataCopy(srcLocal, srcGlobal, srcDataSize); inQueueSrc.EnQue(srcLocal); } __aicore__ inline void Compute() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>(); AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>(); AscendC::LocalTensor<half> workLocal = workQueue.AllocTensor<half>(); // level2 AscendC::ReduceMin<half>(dstLocal, srcLocal, workLocal, srcDataSize, true); outQueueDst.EnQue<half>(dstLocal); inQueueSrc.FreeTensor(srcLocal); workQueue.FreeTensor(workLocal); } __aicore__ inline void CopyOut() { AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>(); AscendC::DataCopy(dstGlobal, dstLocal, dstDataSize); outQueueDst.FreeTensor(dstLocal); } private: AscendC::TPipe pipe; AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc; AscendC::TQue<AscendC::TPosition::VECOUT, 1> workQueue; AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst; AscendC::GlobalTensor<half> srcGlobal, dstGlobal; int srcDataSize = 288; int dstDataSize = 16; int mask = 128; int repStride = 8; int repeat = 0; }; extern \"C\" __global__ __aicore__ void kernel_ReduceMin_lv2_half_288(__gm__ uint8_t* src, __gm__ uint8_t* dstGm) { KernelReduce op; op.Init(src, dstGm); op.Process(); }\n示例结果 输入数据(src_gm): [0.556 0.5225 0.3623 0.214 0.556 0.0643 0.769 0.594 0.261 0.3652 0.911 0.924 0.386 0.3696 0.2296 0.5957 0.1709 0.79 0.8516 0.341 0.705 0.728 0.8135 0.7534 0.5874 0.771 0.05835 0.7456 0.1049 0.3105 0.1729 0.9253 0.8003 0.918 0.5005 0.7744 0.688 0.6807 0.1456 0.4136 0.1055 0.12054 0.275 0.3848 0.08405 0.3843 0.3218 0.6904 0.878 0.3706 0.3586 0.3518 0.429 0.7275 0.6123 0.8096 0.563 0.54 0.8857 0.8594 0.4143 0.525 0.2744 0.1376 0.382 0.6406 0.1534 0.134 0.2993 0.365 0.8843 0.2986 0.00393 0.6577 0.313 0.8164 0.8706 0.7686 0.873 0.3286 0.03787 0.8145 0.4656 0.66 0.1362 0.1075 0.1376 0.9097 0.9214 0.833 0.3657 0.8438 0.006973 0.2408 0.801 0.1862 0.864 0.8745 0.1805 0.4324 0.8647 0.844 0.8936 0.8496 0.311 0.0334 0.3967 0.579 0.43 0.2332 0.5366 0.3557 0.3542 0.945 0.9336 0.252 0.4375 0.9727 0.859 0.6294 0.6787 0.8887 0.1884 0.524 0.787 0.04755 0.3984 0.0508 0.4065 0.716 0.3184 0.21 0.10645 0.7544 0.2827 0.7856 0.4878 0.5903 0.12146 0.6426 0.8438 0.063 0.7617 0.6396 0.1995 0.6475 0.1464 0.7617 0.514 0.3506 0.2708 0.8643 0.1204 0.04337 0.21 0.528 0.0644 0.2133 0.0643 0.0125 0.602 0.654 0.866 0.225 0.9473 0.408 0.4597 0.2793 0.11145 0.293 0.04156 0.7705 0.3555 0.3977 0.7485 0.76 0.9824 0.2832 0.1239 0.4915 0.878 0.5986 0.7217 0.832 0.6206 0.6455 0.0639 0.772 0.01854 0.7437 0.1962 0.485 0.5483 0.414 0.9253 0.2452 0.2942 0.9478 0.879 0.586 0.659 0.635 0.7197 0.933 0.08905 0.02892 0.74 0.499 0.02054 0.2241 0.5137 0.8325 0.185 0.6196 0.949 0.935 0.5605 0.04108 0.3672 0.5566 0.3958 0.4565 0.8135 0.3015 0.46 0.1196 0.5044 0.54 0.05203 0.687 0.8525 0.501 0.3464 0.307 0.804 0.0926 0.202 0.999 0.955 0.581 0.06216 0.271 0.9365 0.854 0.4202 0.269 0.985 0.04547 1. 0.1208 0.5225 0.00935 0.4128 0.644 0.3826 0.6963 0.2942 0.007626 0.7144 0.609 0.3206 0.694 0.393 0.6265 0.6904 0.2487 0.9478 0.798 0.891 0.8867 0.9414 0.395 0.11285 0.515 0.919 0.013855 0.749 0.5527 0.465 0.451 0.1458 0.59 0.893 0.0146 0.062 0.06604 0.934 0.2242 ] 输出数据(dst_gm): [0.00393, 4.3e-06], 4.3e-06需要使用reinterpret_cast方法转换得到索引值72",
      "约束限制": "",
      "相关接口": [
        "ReduceMax",
        "LocalTensor",
        "归约指令"
      ],
      "版本信息": "0.01034"
    },
    {
      "API名称": "Sort-Sort-排序-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0842.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SwiGLU-SwiGLU-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0776.html",
      "功能说明": "SwiGLU是采用Swish作为激活函数的GLU变体。具体计算公式如下： 其中Swish激活函数的计算公式如下（β为常量）： SwiGLU是采用Swish作为激活函数的GLU变体。具体计算公式如下： 其中Swish激活函数的计算公式如下（β为常量）： 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor0/srcTensor1 输入 源操作数。 源操作数的数据类型需要与目的操作数保持一致。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 scalarValue 输入 激活函数中的β参数。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于SwiGLU内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetSwiGLUMaxMinTmpSize。 calCount 输入 实际计算数据元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void SwiGLU(LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor0, const LocalTensor<T>& srcTensor1, const float& scalarValue, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor0/srcTensor1",
          "类型": "输入",
          "说明": "源操作数。 源操作数的数据类型需要与目的操作数保持一致。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "scalarValue",
          "类型": "输入",
          "说明": "激活函数中的β参数。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于SwiGLU内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetSwiGLUMaxMinTmpSize。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "实际计算数据元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84",
      "约束限制": "",
      "相关接口": [
        "GetSwiGLUMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "SwiGLU"
      ],
      "版本信息": "0.4065"
    },
    {
      "API名称": "SetMaskNorm-掩码操作-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0095.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "make_tuple-容器函数-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10110.html",
      "功能说明": "make_tuple是一个实用的函数模板，其作用在于便捷地创建tuple对象。它可以自动推断元素的类型，使代码更简洁，也可以构造元素列表。 make_tuple是一个实用的函数模板，其作用在于便捷地创建tuple对象。它可以自动推断元素的类型，使代码更简洁，也可以构造元素列表。 表1 模板参数说明参数名 含义 Tps... Tps...为传入tuple的模板参数包，代表传递给make_tuple的参数类型，参数个数范围为[0, 64]。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor args args...是函数参数包，代表传递给make_tuple的实际参数，参数个数范围为[0, 64]。 一个tuple对象，此对象包含传递的参数副本。",
      "函数原型": "template <typename ...Tps> __aicore__ inline constexpr tuple<unwrap_decay_t<Tps>...> make_tuple(Tps&& ...args)",
      "参数说明": [
        {
          "参数名": "Tps...",
          "类型": "",
          "说明": "Tps...为传入tuple的模板参数包，代表传递给make_tuple的参数类型，参数个数范围为[0, 64]。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor"
        },
        {
          "参数名": "args",
          "类型": "",
          "说明": "args...是函数参数包，代表传递给make_tuple的实际参数，参数个数范围为[0, 64]。"
        }
      ],
      "返回值": "一个tuple对象，此对象包含传递的参数副本。",
      "调用示例": "template <typename ...Tps> __aicore__ inline constexpr tuple<unwrap_decay_t<Tps>...> make_tuple(Tps&& ...args);\nAscendC::Std::tuple<uint32_t, float, bool> test = AscendC::Std::make_tuple(22, 3.3, true);",
      "约束限制": "",
      "相关接口": [
        "容器函数"
      ],
      "版本信息": "3.3"
    },
    {
      "API名称": "Erfc-Erfc-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0548.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetReduceMaxMinCount(ISASI)-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0226.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LoadDataWithSparse-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0244.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Sum-Sum-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0826.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Gelu-Gelu-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0771.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Trap-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0196.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ConfusionTranspose-变形-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0865.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetFmatrix-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0245.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Div-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0038.html",
      "功能说明": "按元素求商，公式表达如下： 按元素求商，公式表达如下： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void Div(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "BinaryRepeatParams",
        "通用约束",
        "双目指令"
      ],
      "版本信息": "1.0"
    },
    {
      "API名称": "ResetMask-掩码操作-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0097.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ShiftRight-标量双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0059.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "AddRelu-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0043.html",
      "功能说明": "按元素求和，再进行Relu计算（结果和0对比取较大值）。计算公式如下： 按元素求和，再进行Relu计算（结果和0对比取较大值）。计算公式如下： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 接口参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。 calCount 输入 参与计算的元素个数。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void AddRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为：half/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void AddRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void AddRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void AddRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask, const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\nuint64_t mask = 128; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::AddRelu(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::AddRelu(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nAscendC::AddRelu(dstLocal, src0Local, src1Local, 512);\n输入数据(src0Local): [1 -2 3 ... -6] 输入数据(src1Local): [1 3 -4 ... 5] 输出数据(dstLocal): [2 1 0 ... 0]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "BinaryRepeatParams",
        "通用约束",
        "更多样例",
        "双目指令"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "Or-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0042.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ReduceAll-ReduceAll-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10145.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetVectorMask-掩码操作-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0096.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ProposalConcat-排序组合(ISASI)-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0227.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Tan-Tan-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0532.html",
      "功能说明": "按元素做正切函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： Tan(x)的泰勒展开式为： 其中B2n是伯努利数。 按元素做正切函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： Tan(x)的泰勒展开式为： 其中B2n是伯努利数。 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考GetTanMaxMinTmpSize。 calCount 输入 参与计算的元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void Tan(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考GetTanMaxMinTmpSize。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6\n1 2 3 4 5 6",
      "约束限制": "",
      "相关接口": [
        "GetTanMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "Tan"
      ],
      "版本信息": "65504.0"
    },
    {
      "API名称": "Compare（结果存入寄存器）-比较指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0067.html",
      "功能说明": "逐元素比较两个tensor大小，如果比较后的结果为真，则输出结果的对应比特位为1，否则为0。Compare接口需要mask参数时，可以使用此接口。计算结果存放入寄存器中。 支持多种比较模式： 逐元素比较两个tensor大小，如果比较后的结果为真，则输出结果的对应比特位为1，否则为0。Compare接口需要mask参数时，可以使用此接口。计算结果存放入寄存器中。 支持多种比较模式： 表1 模板参数说明 参数名 描述 T 源操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 接口参数说明 参数名称 输入/输出 含义 src0Local、src1Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 cmpMode 输入 CMPMODE类型，表示比较模式，包括EQ，NE，GE，LE，GT，LT。 LT： src0小于（less than）src1 GT： src0大于（greater than）src1 GE：src0大于或等于（greater than or equal to）src1 EQ：src0等于（equal to）src1 NE：src0不等于（not equal to）src1 LE：src0小于或等于（less than or equal to）src1 mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatParams 输入 控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void Compare(const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, CMPMODE cmpMode, const uint64_t mask[], const BinaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "源操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "cmpMode",
          "类型": "输入",
          "说明": "CMPMODE类型，表示比较模式，包括EQ，NE，GE，LE，GT，LT。 LT： src0小于（less than）src1 GT： src0大于（greater than）src1 GE：src0大于或等于（greater than or equal to）src1 EQ：src0等于（equal to）src1 NE：src0不等于（not equal to）src1 LE：src0小于或等于（less than or equal to）src1"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T, bool isSetMask = true> __aicore__ inline void Compare(const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, CMPMODE cmpMode, const uint64_t mask[], const BinaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Compare(const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, CMPMODE cmpMode, const uint64_t mask, const BinaryRepeatParams& repeatParams)\nuint64_t mask = 256 / sizeof(float); // 256为每个迭代处理的字节数 AscendC::BinaryRepeatParams repeatParams = { 1, 1, 1, 8, 8, 8 }; // dstBlkStride, src0BlkStride, src1BlkStride = 1, no gap between blocks in one repeat // dstRepStride, src0RepStride, src1RepStride = 8, no gap between repeats AscendC::Compare(src0Local, src1Local, AscendC::CMPMODE::LT, mask, repeatParams);\nuint64_t mask[2] = { UINT64_MAX, 0}; AscendC::BinaryRepeatParams repeatParams = { 1, 1, 1, 8, 8, 8 }; // srcBlkStride, = 1, no gap between blocks in one repeat // dstRepStride, srcRepStride = 8, no gap between repeats AscendC::Compare(src0Local, src1Local, AscendC::CMPMODE::LT, mask, repeatParams);\n输入数据(src0_gm): [ 86.72287 9.413112 17.033222 -64.10005 -66.2691 -65.57659 15.898049 94.61241 -68.920685 -36.16883 15.62852 68.078514 -59.724575 -9.4302225 -64.770935 66.55523 -84.60122 57.331 60.42026 -86.78856 37.25265 8.356797 -48.544407 16.73616 15.28083 -21.889254 -67.93181 -41.01825 -68.79465 20.169441 44.11346 -27.419518 30.452742 -89.30283 -18.590672 32.45831 8.392082 -57.198048 98.76846 -81.73067 -38.274437 -83.84363 64.30617 6.028703 -20.77164 93.71867 54.190437 94.98172 -47.447758 -65.77461 82.21715 59.953922 23.599781 -77.29708 26.963976 -63.468987 79.97712 -70.47842 39.00433 52.36555 -63.94925 -65.77033 26.17237 -71.904884 ] 输入数据(src1_gm): [ 2.2989323 51.8879 -81.49718 41.189415 6.4081917 92.566666 53.205498 -94.47063 -75.38387 36.464787 85.60772 -28.70681 42.58504 -76.15293 38.723816 10.006577 74.53035 -78.38537 71.945404 -4.060528 -14.501523 28.229202 96.87876 41.558033 -92.623215 43.318684 35.387154 -16.029816 61.544827 3.3527017 55.806778 -93.242096 22.86275 -87.506584 35.29523 8.405956 91.03445 -85.29485 34.30078 -3.8019252 93.40503 15.459968 -57.99712 -74.39948 -59.900818 -43.132637 -13.123036 41.246174 -93.01083 75.476875 -45.437893 -99.19293 13.543604 76.23386 46.192528 -39.23934 75.9787 -38.38979 9.807722 -60.610104 -23.062874 48.1669 89.913376 73.78631 ] 输出数据(dst_gm): [122 86 237 94 150 3 226 242]\n#include \"kernel_operator.h\" template <typename T> class KernelCmpCmpmask { public: __aicore__ inline KernelCmpCmpmask() {} __aicore__ inline void Init(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm, uint32_t dataSize, AscendC::CMPMODE mode) { srcDataSize = dataSize; dstDataSize = 32; cmpMode = mode; src0Global.SetGlobalBuffer((__gm__ T*)src0Gm); src1Global.SetGlobalBuffer((__gm__ T*)src1Gm); dstGlobal.SetGlobalBuffer((__gm__ uint8_t*)dstGm); pipe.InitBuffer(inQueueSrc0, 1, srcDataSize * sizeof(T)); pipe.InitBuffer(inQueueSrc1, 1, srcDataSize * sizeof(T)); pipe.InitBuffer(outQueueDst, 1, dstDataSize * sizeof(uint8_t)); } __aicore__ inline void Process() { CopyIn(); Compute(); CopyOut(); } private: __aicore__ inline void CopyIn() { AscendC::LocalTensor<T> src0Local = inQueueSrc0.AllocTensor<T>(); AscendC::LocalTensor<T> src1Local = inQueueSrc1.AllocTensor<T>(); AscendC::DataCopy(src0Local, src0Global, srcDataSize); AscendC::DataCopy(src1Local, src1Global, srcDataSize); inQueueSrc0.EnQue(src0Local); inQueueSrc1.EnQue(src1Local); } __aicore__ inline void Compute() { AscendC::LocalTensor<T> src0Local = inQueueSrc0.DeQue<T>(); AscendC::LocalTensor<T> src1Local = inQueueSrc1.DeQue<T>(); AscendC::LocalTensor<uint8_t> dstLocal = outQueueDst.AllocTensor<uint8_t>(); AscendC::Duplicate(dstLocal.ReinterpretCast<float>(), static_cast<float>(0), 8); AscendC::BinaryRepeatParams repeatParams; uint32_t mask = 256 / sizeof(T); AscendC::Compare(src0Local, src1Local, cmpMode, mask, repeatParams); AscendC::PipeBarrier<PIPE_V>(); AscendC::GetCmpMask(dstLocal); outQueueDst.EnQue<uint8_t>(dstLocal); inQueueSrc0.FreeTensor(src0Local); inQueueSrc1.FreeTensor(src1Local); } __aicore__ inline void CopyOut() { AscendC::LocalTensor<uint8_t> dstLocal = outQueueDst.DeQue<uint8_t>(); AscendC::DataCopy(dstGlobal, dstLocal, dstDataSize); outQueueDst.FreeTensor(dstLocal); } private: AscendC::TPipe pipe; AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc0, inQueueSrc1; AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst; AscendC::GlobalTensor<T> src0Global, src1Global; AscendC::GlobalTensor<uint8_t> dstGlobal; uint32_t srcDataSize = 0; uint32_t dstDataSize = 0; AscendC::CMPMODE cmpMode; }; template <typename T> __aicore__ void main_cpu_cmp_cmpmask_demo(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm, uint32_t dataSize, AscendC::CMPMODE mode) { KernelCmpCmpmask<T> op; op.Init(src0Gm, src1Gm, dstGm, dataSize, mode); op.Process(); } extern \"C\" __global__ __aicore__ void kernel_vec_compare_cmpmask_64_LT_float(GM_ADDR src0_gm, GM_ADDR src1_gm, GM_ADDR dst_gm) { main_cpu_cmp_cmpmask_demo<float>(src0_gm, src1_gm, dst_gm, 64, AscendC::CMPMODE::LT); }",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "BinaryRepeatParams",
        "通用约束",
        "GetCmpMask",
        "比较指令"
      ],
      "版本信息": "86.72287"
    },
    {
      "API名称": "CountBitsCntSameAsSignBit-标量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0019.html",
      "功能说明": "计算一个int64_t类型数字的二进制中，从最高数值位开始与符号位相同的连续比特位的个数。 当输入是-1（比特位全1）或者0（比特位全0）时，返回-1。 计算一个int64_t类型数字的二进制中，从最高数值位开始与符号位相同的连续比特位的个数。 当输入是-1（比特位全1）或者0（比特位全0）时，返回-1。 表1 参数说明参数名 输入/输出 描述 valueIn 输入 输入数据，数据类型int64_t。",
      "函数原型": "__aicore__ inline int64_t CountBitsCntSameAsSignBit(int64_t valueIn)",
      "参数说明": [
        {
          "参数名": "valueIn",
          "类型": "输入",
          "说明": "输入数据，数据类型int64_t。"
        }
      ],
      "返回值": "返回从最高数值位开始和符号位相同的连续比特位的个数。",
      "调用示例": "__aicore__ inline int64_t CountBitsCntSameAsSignBit(int64_t valueIn)\nint64_t valueIn = 0x0f00000000000000; // 输出数据(ans): 3 int64_t ans = AscendC::CountBitsCntSameAsSignBit(valueIn);",
      "约束限制": "",
      "相关接口": [
        "标量计算"
      ],
      "版本信息": ""
    },
    {
      "API名称": "CumSum-CumSum-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0605.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Compare-比较指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0066.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Gather-数据分散/数据收集-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0092.html",
      "功能说明": "给定输入的张量和一个地址偏移张量，本接口根据偏移地址将输入张量按元素收集到结果张量中。 给定输入的张量和一个地址偏移张量，本接口根据偏移地址将输入张量按元素收集到结果张量中。 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/float/half/bfloat16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/float/half/bfloat16_t Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/float/half Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/uint32_t/int32_t/float 表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型和dstLocal保持一致。 srcOffsetLocal 输入 每个元素在src中对应的地址偏移。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 该偏移量相对于src的起始基地址而言。单位为Bytes。地址偏移要大于等于0，取值应保证src元素类型位宽对齐，否则会导致非预期行为；同时需要保证偏移地址后不能超出UB大小数据的范围。 针对以下型号，地址偏移的取值范围不超出uint32_t的范围即可。 Atlas 推理系列产品 AI Core Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 针对以下型号，地址偏移的取值范围如下：当操作数为8位时，取值范围为[0, 216-1]；当操作数为16位时，取值范围为[0, 217-1]，当操作数为32位或者64位时，不超过uint32_t的范围即可，超出取值范围可能导致非预期输出。 Atlas 200I/500 A2 推理产品 srcBaseAddr 输入 srcLocal的起始基地址，单位为Bytes。取值应保证src元素类型位宽对齐，否则会导致非预期行为。 count 输入 执行处理的数据个数。 mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。参数类型为长度为2的uint64_t类型数组。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 参数取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，mask[1]为0，mask[0]∈(0, 264-1]；当操作数为64位时，mask[1]为0，mask[0]∈(0, 232-1]。 repeatTimes 输入 指令迭代次数，每次迭代完成8个datablock（32Bytes）的数据收集，数据范围：repeatTimes∈[0,255]。 特别地，针对以下型号： Atlas 200I/500 A2 推理产品 操作数为8位时，每次迭代完成4个datablock（32Bytes）的数据收集。 dstRepStride 输入 相邻迭代间的地址步长，单位是datablock（32Bytes）。",
      "函数原型": "template <typename T> __aicore__ inline void Gather(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<uint32_t>& srcOffsetLocal, const uint32_t srcBaseAddr, const uint64_t mask[], const uint8_t repeatTimes, const uint16_t dstRepStride)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/float/half/bfloat16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/float/half/bfloat16_t Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/float/half Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/uint32_t/int32_t/float"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型和dstLocal保持一致。"
        },
        {
          "参数名": "srcOffsetLocal",
          "类型": "输入",
          "说明": "每个元素在src中对应的地址偏移。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 该偏移量相对于src的起始基地址而言。单位为Bytes。地址偏移要大于等于0，取值应保证src元素类型位宽对齐，否则会导致非预期行为；同时需要保证偏移地址后不能超出UB大小数据的范围。 针对以下型号，地址偏移的取值范围不超出uint32_t的范围即可。 Atlas 推理系列产品 AI Core Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 针对以下型号，地址偏移的取值范围如下：当操作数为8位时，取值范围为[0, 216-1]；当操作数为16位时，取值范围为[0, 217-1]，当操作数为32位或者64位时，不超过uint32_t的范围即可，超出取值范围可能导致非预期输出。 Atlas 200I/500 A2 推理产品"
        },
        {
          "参数名": "srcBaseAddr",
          "类型": "输入",
          "说明": "srcLocal的起始基地址，单位为Bytes。取值应保证src元素类型位宽对齐，否则会导致非预期行为。"
        },
        {
          "参数名": "count",
          "类型": "输入",
          "说明": "执行处理的数据个数。"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。参数类型为长度为2的uint64_t类型数组。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 参数取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，mask[1]为0，mask[0]∈(0, 264-1]；当操作数为64位时，mask[1]为0，mask[0]∈(0, 232-1]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "指令迭代次数，每次迭代完成8个datablock（32Bytes）的数据收集，数据范围：repeatTimes∈[0,255]。 特别地，针对以下型号： Atlas 200I/500 A2 推理产品 操作数为8位时，每次迭代完成4个datablock（32Bytes）的数据收集。"
        },
        {
          "参数名": "dstRepStride",
          "类型": "输入",
          "说明": "相邻迭代间的地址步长，单位是datablock（32Bytes）。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "通用约束",
        "数据分散/数据收集"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Mul-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0037.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SoftmaxGradFront-SoftMax-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0759.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Sub-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0036.html",
      "功能说明": "按元素求差，计算公式如下： 按元素求差，计算公式如下： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/int32_t/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/int16_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/int32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void Sub(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/int32_t/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/int16_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/int32_t/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void Sub(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Sub(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Sub(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask, const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\nuint64_t mask = 128; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::Sub(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::Sub(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nAscendC::Sub(dstLocal, src0Local, src1Local, 512);\n输入数据(src0Local): [1 2 3 ... 512] 输入数据(src1Local): [513 514 515 ... 1024] 输出数据(dstLocal): [-512 -512 -512 ... -512]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "BinaryRepeatParams",
        "通用约束",
        "更多样例",
        "双目指令"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "SoftmaxGrad-SoftMax-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0757.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "MrgSort4-排序组合(ISASI)-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0230.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "原型注册接口（OP_ADD）-原型注册与管理-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0945.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "PipeBarrier(ISASI)-核内同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0271.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "InitGlobalMemory-工具类-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0891.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetAccVal(ISASI)-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0225.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SubReluCast-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0047.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "简介-TQueBind-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0146.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "AdjustSoftMaxRes-SoftMax-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0760.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetAtomicNone-原子操作-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0212.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Sin-Sin-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0500.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Not-单目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0031.html",
      "功能说明": "按元素做按位取反，计算公式如下 : 按元素做按位取反，计算公式如下 : 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int16_t/uint16_t isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。UnaryRepeatParams类型，包含操作数相邻迭代间相同DataBlock的地址步长，操作数同一迭代内不同DataBlock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void Not(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint64_t mask[], const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int16_t/uint16_t"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。UnaryRepeatParams类型，包含操作数相邻迭代间相同DataBlock的地址步长，操作数同一迭代内不同DataBlock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void Not(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Not(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint64_t mask[], const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Not(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint64_t mask, const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)\nuint64_t mask = 256 / sizeof(int16_t); // repeatTimes = 4, 128 elements one repeat, 512 elements total // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat // dstRepStride, srcRepStride = 8, no gap between repeats AscendC::Not(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 4, 128 elements one repeat, 512 elements total // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat // dstRepStride, srcRepStride = 8, no gap between repeats AscendC::Not(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });\nAscendC::Not(dstLocal, srcLocal, 512);\n输入数据(srcLocal): [9 -2 8 ... 9 0] 输出数据(dstLocal): [-10 1 -9 ... -10 -1]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "UnaryRepeatParams",
        "通用约束",
        "单目指令"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Acos-Acos-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0504.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GET_TILING_DATA_WITH_STRUCT-Kernel Tiling-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0215.html",
      "功能说明": "使用该接口指定结构体名称，可获取指定的tiling信息，并填入对应的Tiling结构体中，此函数会以宏展开的方式进行编译。与GET_TILING_DATA的区别是：GET_TILING_DATA只能获取默认注册的结构体，该接口可以根据指定的结构体名称获取对应的结构体，常用于针对不同的TilingKey注册了不同结构体的情况下。 使用该接口指定结构体名称，可获取指定的tiling信息，并填入对应的Tiling结构体中，此函数会以宏展开的方式进行编译。与GET_TILING_DATA的区别是：GET_TILING_DATA只能获取默认注册的结构体，该接口可以根据指定的结构体名称获取对应的结构体，常用于针对不同的TilingKey注册了不同结构体的情况下。 参数 输入/输出 说明 struct_name 输入 指定的结构体名称。 tiling_data 输出 返回指定Tiling结构体变量。 tiling_arg 输入 此参数为算子入口函数处传入的tiling参数。",
      "函数原型": "void add_custom(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *z, __gm__ uint8_t *tiling) {",
      "参数说明": [
        {
          "参数名": "struct_name",
          "类型": "输入",
          "说明": "指定的结构体名称。"
        },
        {
          "参数名": "tiling_data",
          "类型": "输出",
          "说明": "返回指定Tiling结构体变量。"
        },
        {
          "参数名": "tiling_arg",
          "类型": "输入",
          "说明": "此参数为算子入口函数处传入的tiling参数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18",
      "约束限制": "",
      "相关接口": [
        "GET_TILING_DATA",
        "Kernel Tiling"
      ],
      "版本信息": ""
    },
    {
      "API名称": "普通数据搬运-DataCopy-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0101.html",
      "功能说明": "普通数据搬运接口，适用于连续和不连续数据搬运。 普通数据搬运接口，适用于连续和不连续数据搬运。 表5 模板参数说明参数名 描述 T 源操作数和目的操作数的数据类型。 dst_T 目的操作数的数据类型。 src_T 源操作数的数据类型。 表6 普通数据搬运接口参数说明参数名称 输入/输出 含义 dstLocal，dstGlobal 输出 目的操作数，类型为LocalTensor或GlobalTensor。 dstLocal位于C2时，起始地址要求64B对齐；dstLocal位于C2PIPE2GM时，起始地址要求128B对齐；其他情况均要求32字节对齐。 dstGlobal的起始地址要求按照对应数据类型所占字节数对齐。 srcLocal，srcGlobal 输入 源操作数，类型为LocalTensor或GlobalTensor。 srcLocal的起始地址要求32字节对齐。 srcGlobal的起始地址要求按照对应数据类型所占字节数对齐。 repeatParams 输入 搬运参数，DataCopyParams类型，参数说明请参考表7。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_data_copy.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 calCount 输入 参与搬运的元素个数。 说明： DataCopy的搬运量要求为32byte的倍数，因此使用普通数据搬运接口（连续数据搬运，包含calCount参数）时，calCount * sizeof(T)需要32byte对齐，若不对齐，搬运量将对32byte做向下取整。 表7 DataCopyParams结构体参数定义参数名称 含义 blockCount 指定该指令包含的连续传输数据块个数，取值范围：blockCount∈[1, 4095]。 blockLen 指定该指令每个连续传输数据块长度，单位为datablock(32B)。取值范围：blockLen∈[1, 65535]。 特别的，当dstLocal位于C2PIPE2GM时，单位为128B；当dstLocal位于C2时，表示源操作数的连续传输数据块长度，单位为64B。 srcStride 源操作数，相邻连续数据块的间隔（前面一个数据块的尾与后面数据块的头的间隔），单位为datablock(32B)。数据类型为uint16_t，srcStride不要超出该数据类型的取值范围。 dstStride 目的操作数，相邻连续数据块间的间隔（前面一个数据块的尾与后面数据块的头的间隔），单位为datablock(32B)。数据类型为uint16_t，dstStride不要超出该数据类型的取值范围。 特别的，当dstLocal位于C2PIPE2GM时，单位为128B；当dstLocal位于C2时，单位为64B。 下面的样例呈现了DataCopyParams结构体参数的使用方法，样例中完成了2个连续传输数据块的搬运，每个数据块含有8个datablock，源操作数相邻数据块之间无间隔，目的操作数相邻数据块尾与头之间间隔1个datablock。",
      "函数原型": "template <typename dst_T, typename src_T> __aicore__ inline void DataCopy(const LocalTensor<dst_T>& dstLocal, const LocalTensor<src_T>& srcLocal, const DataCopyParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "源操作数和目的操作数的数据类型。"
        },
        {
          "参数名": "dst_T",
          "类型": "",
          "说明": "目的操作数的数据类型。"
        },
        {
          "参数名": "src_T",
          "类型": "",
          "说明": "源操作数的数据类型。"
        },
        {
          "参数名": "dstLocal，dstGlobal",
          "类型": "输出",
          "说明": "目的操作数，类型为LocalTensor或GlobalTensor。 dstLocal位于C2时，起始地址要求64B对齐；dstLocal位于C2PIPE2GM时，起始地址要求128B对齐；其他情况均要求32字节对齐。 dstGlobal的起始地址要求按照对应数据类型所占字节数对齐。"
        },
        {
          "参数名": "srcLocal，srcGlobal",
          "类型": "输入",
          "说明": "源操作数，类型为LocalTensor或GlobalTensor。 srcLocal的起始地址要求32字节对齐。 srcGlobal的起始地址要求按照对应数据类型所占字节数对齐。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "搬运参数，DataCopyParams类型，参数说明请参考表7。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_data_copy.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与搬运的元素个数。 说明： DataCopy的搬运量要求为32byte的倍数，因此使用普通数据搬运接口（连续数据搬运，包含calCount参数）时，calCount * sizeof(T)需要32byte对齐，若不对齐，搬运量将对32byte做向下取整。"
        },
        {
          "参数名": "blockCount",
          "类型": "",
          "说明": "指定该指令包含的连续传输数据块个数，取值范围：blockCount∈[1, 4095]。"
        },
        {
          "参数名": "blockLen",
          "类型": "",
          "说明": "指定该指令每个连续传输数据块长度，单位为datablock(32B)。取值范围：blockLen∈[1, 65535]。 特别的，当dstLocal位于C2PIPE2GM时，单位为128B；当dstLocal位于C2时，表示源操作数的连续传输数据块长度，单位为64B。"
        },
        {
          "参数名": "srcStride",
          "类型": "",
          "说明": "源操作数，相邻连续数据块的间隔（前面一个数据块的尾与后面数据块的头的间隔），单位为datablock(32B)。数据类型为uint16_t，srcStride不要超出该数据类型的取值范围。"
        },
        {
          "参数名": "dstStride",
          "类型": "",
          "说明": "目的操作数，相邻连续数据块间的间隔（前面一个数据块的尾与后面数据块的头的间隔），单位为datablock(32B)。数据类型为uint16_t，dstStride不要超出该数据类型的取值范围。 特别的，当dstLocal位于C2PIPE2GM时，单位为128B；当dstLocal位于C2时，单位为64B。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57",
      "约束限制": "",
      "相关接口": [
        "PipeBarrier(ISASI)",
        "DataCopy"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "TRACE_START-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1212.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GmAlloc-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1207.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LayerNormGradBeta-LayerNorm-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0799.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Silu-Silu-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0780.html",
      "功能说明": "按元素做Silu运算，计算公式如下： 按元素做Silu运算，计算公式如下： 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 dataSize 输入 实际计算数据元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void Silu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint32_t dataSize)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "dataSize",
          "类型": "输入",
          "说明": "实际计算数据元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "通用约束",
        "Silu"
      ],
      "版本信息": "3.304723"
    },
    {
      "API名称": "DataCopyPad(ISASI)-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0265.html",
      "功能说明": "该接口提供数据非对齐搬运的功能，其中从Global Memory搬运数据至Local Memory时，可以根据开发者的需要自行填充数据。 该接口提供数据非对齐搬运的功能，其中从Global Memory搬运数据至Local Memory时，可以根据开发者的需要自行填充数据。 表2 模板参数说明参数名 描述 T 操作数以及paddingValue（待填充数据值）的数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t/int16_t/uint16_t/float/int32_t/uint32_t/int8_t/uint8_t/int64_t/uint64_t/double Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t/int16_t/uint16_t/float/int32_t/uint32_t/int8_t/uint8_t/int64_t/uint64_t/double Atlas 200I/500 A2 推理产品，支持的数据类型为：int8_t/uint8_t/half/bfloat16_t/int16_t/uint16_t/float/int32_t/uint32_t 表3 接口参数说明参数名 输入/输出 描述 dstLocal/dstGlobal 输出 目的操作数，类型为LocalTensor或GlobalTensor。 LocalTensor的起始地址需要保证32字节对齐。 GlobalTensor的起始地址无地址对齐约束。 srcLocal/srcGlobal 输入 源操作数，类型为LocalTensor或GlobalTensor。 LocalTensor的起始地址需要保证32字节对齐。 GlobalTensor的起始地址无地址对齐约束。 dataCopyParams 输入 搬运参数。 DataCopyExtParams类型，具体参数说明请参考表4。DataCopyParams类型，具体参数说明请参考表5。 padParams 输入 从Global Memory搬运数据至Local Memory时，可以根据开发者需要，在搬运数据左边或右边填充数据。padParams是用于控制数据填充过程的参数。 DataCopyPadExtParams类型，具体参数请参考表6。DataCopyPadParams类型，具体参数请参考表7。 nd2nzParams 输入 从VECIN/VECOUT->TSCM进行数据搬运时，可以进行ND到NZ的数据格式转换。nd2nzParams是用于控制数据格式转换的参数，Nd2NzParams类型，具体参数请参考表8。 注意：Nd2NzParams的ndNum仅支持设置为1。 下文表格中列出的结构体参数定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_data_copy.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 表4 DataCopyExtParams结构体参数定义参数名称 含义 blockCount 指定该指令包含的连续传输数据块个数，数据类型为uint16_t，取值范围：blockCount∈[1, 4095]。 blockLen 指定该指令每个连续传输数据块长度，该指令支持非对齐搬运，每个连续传输数据块长度单位为Byte。数据类型为uint32_t，取值范围：blockLen∈[1, 2097151]。 srcStride 源操作数，相邻连续数据块的间隔（前面一个数据块的尾与后面数据块的头的间隔）。 如果源操作数的逻辑位置为VECIN/VECOUT，则单位为dataBlock(32Bytes)。如果源操作数的逻辑位置为GM，则单位为Byte。 数据类型为uint32_t，srcStride不要超出该数据类型的取值范围。 dstStride 目的操作数，相邻连续数据块间的间隔（前面一个数据块的尾与后面数据块的头的间隔）。 如果目的操作数的逻辑位置为VECIN/VECOUT，则单位为dataBlock(32Bytes)，如果目的操作数的逻辑位置为GM，则单位为Byte。 数据类型为uint32_t，dstStride不要超出该数据类型的取值范围。 rsv 保留字段。 表5 DataCopyParams结构体参数定义参数名称 含义 blockCount 指定该指令包含的连续传输数据块个数，数据类型为uint16_t，取值范围：blockCount∈[1, 4095]。 blockLen 指定该指令每个连续传输数据块长度，该指令支持非对齐搬运，每个连续传输数据块长度单位为Byte。数据类型为uint16_t，blockLen不要超出该数据类型的取值范围。 srcStride 源操作数，相邻连续数据块的间隔（前面一个数据块的尾与后面数据块的头的间隔），如果源操作数的逻辑位置为VECIN/VECOUT，则单位为dataBlock(32Bytes)。如果源操作数的逻辑位置为GM，则单位为Byte。数据类型为uint16_t，srcStride不要超出该数据类型的取值范围。 dstStride 目的操作数，相邻连续数据块间的间隔（前面一个数据块的尾与后面数据块的头的间隔），如果目的操作数的逻辑位置为VECIN/VECOUT，则单位为dataBlock(32Bytes)，如果目的操作数的逻辑位置为GM，则单位为Byte。数据类型为uint16_t，dstStride不要超出该数据类型的取值范围。 leftPadding、rightPadding的字节数均不能超过32Bytes。",
      "函数原型": "template <typename T> __aicore__ inline void DataCopyPad(const LocalTensor<T> &dstLocal, const GlobalTensor<T> &srcGlobal, const DataCopyExtParams &dataCopyParams, const DataCopyPadExtParams<T> &padParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数以及paddingValue（待填充数据值）的数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t/int16_t/uint16_t/float/int32_t/uint32_t/int8_t/uint8_t/int64_t/uint64_t/double Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t/int16_t/uint16_t/float/int32_t/uint32_t/int8_t/uint8_t/int64_t/uint64_t/double Atlas 200I/500 A2 推理产品，支持的数据类型为：int8_t/uint8_t/half/bfloat16_t/int16_t/uint16_t/float/int32_t/uint32_t"
        },
        {
          "参数名": "dstLocal/dstGlobal",
          "类型": "输出",
          "说明": "目的操作数，类型为LocalTensor或GlobalTensor。 LocalTensor的起始地址需要保证32字节对齐。 GlobalTensor的起始地址无地址对齐约束。"
        },
        {
          "参数名": "srcLocal/srcGlobal",
          "类型": "输入",
          "说明": "源操作数，类型为LocalTensor或GlobalTensor。 LocalTensor的起始地址需要保证32字节对齐。 GlobalTensor的起始地址无地址对齐约束。"
        },
        {
          "参数名": "dataCopyParams",
          "类型": "输入",
          "说明": "搬运参数。 DataCopyExtParams类型，具体参数说明请参考表4。DataCopyParams类型，具体参数说明请参考表5。"
        },
        {
          "参数名": "padParams",
          "类型": "输入",
          "说明": "从Global Memory搬运数据至Local Memory时，可以根据开发者需要，在搬运数据左边或右边填充数据。padParams是用于控制数据填充过程的参数。 DataCopyPadExtParams类型，具体参数请参考表6。DataCopyPadParams类型，具体参数请参考表7。"
        },
        {
          "参数名": "nd2nzParams",
          "类型": "输入",
          "说明": "从VECIN/VECOUT->TSCM进行数据搬运时，可以进行ND到NZ的数据格式转换。nd2nzParams是用于控制数据格式转换的参数，Nd2NzParams类型，具体参数请参考表8。 注意：Nd2NzParams的ndNum仅支持设置为1。"
        },
        {
          "参数名": "blockCount",
          "类型": "",
          "说明": "指定该指令包含的连续传输数据块个数，数据类型为uint16_t，取值范围：blockCount∈[1, 4095]。"
        },
        {
          "参数名": "blockLen",
          "类型": "",
          "说明": "指定该指令每个连续传输数据块长度，该指令支持非对齐搬运，每个连续传输数据块长度单位为Byte。数据类型为uint32_t，取值范围：blockLen∈[1, 2097151]。"
        },
        {
          "参数名": "srcStride",
          "类型": "",
          "说明": "源操作数，相邻连续数据块的间隔（前面一个数据块的尾与后面数据块的头的间隔）。 如果源操作数的逻辑位置为VECIN/VECOUT，则单位为dataBlock(32Bytes)。如果源操作数的逻辑位置为GM，则单位为Byte。 数据类型为uint32_t，srcStride不要超出该数据类型的取值范围。"
        },
        {
          "参数名": "dstStride",
          "类型": "",
          "说明": "目的操作数，相邻连续数据块间的间隔（前面一个数据块的尾与后面数据块的头的间隔）。 如果目的操作数的逻辑位置为VECIN/VECOUT，则单位为dataBlock(32Bytes)，如果目的操作数的逻辑位置为GM，则单位为Byte。 数据类型为uint32_t，dstStride不要超出该数据类型的取值范围。"
        },
        {
          "参数名": "rsv",
          "类型": "",
          "说明": "保留字段。"
        },
        {
          "参数名": "blockCount",
          "类型": "",
          "说明": "指定该指令包含的连续传输数据块个数，数据类型为uint16_t，取值范围：blockCount∈[1, 4095]。"
        },
        {
          "参数名": "blockLen",
          "类型": "",
          "说明": "指定该指令每个连续传输数据块长度，该指令支持非对齐搬运，每个连续传输数据块长度单位为Byte。数据类型为uint16_t，blockLen不要超出该数据类型的取值范围。"
        },
        {
          "参数名": "srcStride",
          "类型": "",
          "说明": "源操作数，相邻连续数据块的间隔（前面一个数据块的尾与后面数据块的头的间隔），如果源操作数的逻辑位置为VECIN/VECOUT，则单位为dataBlock(32Bytes)。如果源操作数的逻辑位置为GM，则单位为Byte。数据类型为uint16_t，srcStride不要超出该数据类型的取值范围。"
        },
        {
          "参数名": "dstStride",
          "类型": "",
          "说明": "目的操作数，相邻连续数据块间的间隔（前面一个数据块的尾与后面数据块的头的间隔），如果目的操作数的逻辑位置为VECIN/VECOUT，则单位为dataBlock(32Bytes)，如果目的操作数的逻辑位置为GM，则单位为Byte。数据类型为uint16_t，dstStride不要超出该数据类型的取值范围。"
        },
        {
          "参数名": "isPad",
          "类型": "",
          "说明": "是否需要填充用户自定义的数据，取值范围：true，false。 true：填充padding value。 false：表示用户不需要指定填充值，会默认填充随机值。"
        },
        {
          "参数名": "leftPadding",
          "类型": "",
          "说明": "连续搬运数据块左侧需要补充的数据范围，单位为元素个数。 leftPadding、rightPadding所占的字节数均不能超过32Bytes。"
        },
        {
          "参数名": "rightPadding",
          "类型": "",
          "说明": "连续搬运数据块右侧需要补充的数据范围，单位为元素个数。 leftPadding、rightPadding所占的字节数均不能超过32Bytes。"
        },
        {
          "参数名": "paddingValue",
          "类型": "",
          "说明": "左右两侧需要填充的数据值，需要保证在数据占用字节范围内。 数据类型和源操作数保持一致，T数据类型。 当数据类型长度为64位时，该参数只能设置为0。"
        },
        {
          "参数名": "isPad",
          "类型": "",
          "说明": "是否需要填充用户自定义的数据，取值范围：true，false。 true：填充padding value。 false：表示用户不需要指定填充值，会默认填充随机值。"
        },
        {
          "参数名": "leftPadding",
          "类型": "",
          "说明": "连续搬运数据块左侧需要补充的数据范围，单位为元素个数。 leftPadding、rightPadding所占的字节数均不能超过32Bytes。"
        },
        {
          "参数名": "rightPadding",
          "类型": "",
          "说明": "连续搬运数据块右侧需要补充的数据范围，单位为元素个数。 leftPadding、rightPadding所占的字节数均不能超过32Bytes。"
        },
        {
          "参数名": "paddingValue",
          "类型": "",
          "说明": "左右两侧需要填充的数据值，需要保证在数据占用字节范围内。 uint64_t数据类型，要求源操作数为uint64_t数据类型，且该参数只能设置为0。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59",
      "约束限制": "leftPadding、rightPadding的字节数均不能超过32Bytes。",
      "相关接口": [
        "数据搬运"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "MrgSort-排序组合(ISASI)-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0232.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "CrossCoreSetFlag(ISASI)-核间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0273.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Input-OpDef-原型注册与管理-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0946.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ICPU_RUN_KF-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1208.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ClampMax-Clamp-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0576.html",
      "功能说明": "将srcTensor中大于scalar的数替换为scalar，小于等于scalar的数保持不变，作为dstTensor输出。 将srcTensor中大于scalar的数替换为scalar，小于等于scalar的数保持不变，作为dstTensor输出。 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于ClampMax内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetClampMaxMinTmpSize。 scalar 输入 scalar数据，数据类型与srcTensor一致，支持数据类型为：half/float。 calCount 输入 参与计算的元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void ClampMax(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const T scalar, const uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于ClampMax内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetClampMaxMinTmpSize。"
        },
        {
          "参数名": "scalar",
          "类型": "输入",
          "说明": "scalar数据，数据类型与srcTensor一致，支持数据类型为：half/float。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6\n1 2 3 4 5 6",
      "约束限制": "",
      "相关接口": [
        "GetClampMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "更多样例",
        "Clamp"
      ],
      "版本信息": ""
    },
    {
      "API名称": "SetFixpipeNz2ndFlag(ISASI)-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0253.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Tanh-Tanh-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0492.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Min-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0040.html",
      "功能说明": "按元素求最小值，公式表达如下： 按元素求最小值，公式表达如下： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/int32_t/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/int16_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/int32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void Min(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/int32_t/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/int16_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/int32_t/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void Min(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Min(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Min(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask, const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\nuint64_t mask = 128; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::Min(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::Min(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nAscendC::Min(dstLocal, src0Local, src1Local, 512);\n输入数据(src0Local): [1 2 3 ... 512] 输入数据(src1Local): [513 512 511 ... 2] 输出数据(dstLocal): [1 2 3 ... 2]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "BinaryRepeatParams",
        "通用约束",
        "更多样例",
        "双目指令"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "SetMaskCount-掩码操作-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0094.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "昇腾AI原生创新算子挑战赛-昇腾社区",
      "API文档URL": "https://www.hiascend.com/developer/ops",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Fixpipe-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0251.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "模板参数定义-Tiling数据结构注册-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00011.html",
      "功能说明": "通过以下函数原型进行模板参数ASCENDC_TPL_ARGS_DECL和模板参数组合ASCENDC_TPL_ARGS_SEL（即可使用的模板）的定义。详细内容请参考Tiling模板编程。 通过以下函数原型进行模板参数ASCENDC_TPL_ARGS_DECL和模板参数组合ASCENDC_TPL_ARGS_SEL（即可使用的模板）的定义。详细内容请参考Tiling模板编程。 表1 Tiling模板参数定义说明 宏 功能描述 参数解释 ASCENDC_TPL_ARGS_DECL(args0, ...) 用于定义算子的模板参数。 args0：表示算子Optype。 args1-argsn：后续为若干个DTYPE、FORMAT、UINT、BOOL的模板参数定义，分别通过ASCENDC_TPL_DTYPE_DECL、ASCENDC_TPL_FORMAT_DECL、ASCENDC_TPL_UINT_DECL、ASCENDC_TPL_BOOL_DECL进行定义。 ASCENDC_TPL_DTYPE_DECL(args0, ...) DataType类型的模板参数定义。 args0：参数名。 args1-argsn：后续若干个参数为穷举的DataType枚举值。 ASCENDC_TPL_FORMAT_DECL(args0, ...) Format类型的模板参数定义。 args0：参数名。 args1-argsn：后续若干个参数为穷举的Format枚举值。 ASCENDC_TPL_UINT_DECL(args0, args1, args2, ...) 自定义UINT类型（无符号整形）的模板参数定义。 args0：参数名。 args1：最大位宽，模板参数的个数不能超过最大位宽。 args2：参数定义的模式。支持以下三种模式： ASCENDC_TPL_UI_RANGE：范围模式，设置该模式，后续紧跟着第一个值表示范围个数，第一个值后面的每两个数值为一组分别表示该范围的起、终位置；注意定义的范围个数要和后续的组数保持一致。 举例：ASCENDC_TPL_UINT_DECL(args0, args1,ASCENDC_TPL_UI_RANGE,2,0,2,3,5)表示2组参数，这2组参数范围为{0, 2}，{3, 5}，因此该参数定义的UINT参数合法值为{0, 1, 2, 3, 4, 5}。 ASCENDC_TPL_UI_LIST：穷举模式，设置该模式，则表示后续将穷举出所有的参数值。 举例：ASCENDC_TPL_UINT_DECL(args0, args1,ASCENDC_TPL_UI_LIST,10,12,13,9,8,7,6)表示1组穷举参数，[10, 12, 13, 9, 8, 7, 6]为穷举值，因此该参数定义的UINT参数合法值为{10, 12, 13, 9, 8, 7, 6}。 ASCENDC_TPL_UI_MIX：混合模式，设置该模式，则表示前n个数值为范围模式的参数定义，后m个数值为穷举模式的参数定义。 举例： ASCENDC_TPL_UINT_DECL(args0, args1,ASCENDC_TPL_UI_MIX,2,0,2,3, 5, 10, 12, 13, 9, 8)表示2组穷举参数，这2组范围为{0, 2}, {3, 5}，[10, 12, 13, 9, 8]为穷举值，因此该参数定义的UINT参数合法值为{0, 1, 2, 3, 4, 5, 10, 12, 13, 9, 8}。 args3-argsn：对应不同范围模式的参数数值。 ASCENDC_TPL_BOOL_DECL(args0, ...) 自定义bool类型的模板参数定义。 args0：参数名。 args1-args2：取值范围0，1。 表2 Tiling模板参数组合定义 宏 功能描述 参数解释 ASCENDC_TPL_SEL(...) 算子的模板参数整体组合。 包含多个算子的模板参数组合。 ASCENDC_TPL_ARGS_DSEL(...) 算子的模板参数组合。 一个算子的模板参数组合。 ASCENDC_TPL_DTYPE_SEL(args0, ...) DataType类型的模板参数组合。 args0：表示参数名。 args1-argsn ：后续若干个参数为ASCENDC_TPL_DTYPE_DECL中定义的参数范围子集。 ASCENDC_TPL_FORMAT_SEL(args0, ...) Format类型的模板参数组合。 args0：表示参数名。 args1-argsn：后续若干个参数为ASCENDC_TPL_FORMAT_DECL中定义的参数范围子集。 ASCENDC_TPL_UINT_SEL(args0, args1, args2, ...) UINT类型的模板参数组合。 args0：表示参数名。 args1：参数定义的模式。支持如下取值： ASCENDC_TPL_UI_RANGE：范围模式。 ASCENDC_TPL_UI_LIST：穷举模式。 ASCENDC_TPL_UI_MIX：混合模式。 args2-argsn：后续若干个参数为ASCENDC_TPL_UINT_DECL中定义的参数范围子集。 模式和参数的配置方式参考ASCENDC_TPL_UINT_DECL(args0, args1, args2, ...)。 ASCENDC_TPL_BOOL_SEL(args0, ...) bool类型的模板参数组合。 args0：表示参数名。 args1-args2 ：后续若干个参数为ASCENDC_TPL_BOOL_DECL定义的参数范围子集。 对模板参数定义的取值进行修改或新增后，需要重新编译自定义算子包，不能再继续使用之前的算子二进制。",
      "函数原型": "define ASCENDC_TPL_UINT_DECL(x, bw, ...)",
      "参数说明": [
        {
          "参数名": "ASCENDC_TPL_ARGS_DECL(args0, ...)",
          "类型": "用于定义算子的模板参数。",
          "说明": "args0：表示算子Optype。 args1-argsn：后续为若干个DTYPE、FORMAT、UINT、BOOL的模板参数定义，分别通过ASCENDC_TPL_DTYPE_DECL、ASCENDC_TPL_FORMAT_DECL、ASCENDC_TPL_UINT_DECL、ASCENDC_TPL_BOOL_DECL进行定义。"
        },
        {
          "参数名": "ASCENDC_TPL_DTYPE_DECL(args0, ...)",
          "类型": "DataType类型的模板参数定义。",
          "说明": "args0：参数名。 args1-argsn：后续若干个参数为穷举的DataType枚举值。"
        },
        {
          "参数名": "ASCENDC_TPL_FORMAT_DECL(args0, ...)",
          "类型": "Format类型的模板参数定义。",
          "说明": "args0：参数名。 args1-argsn：后续若干个参数为穷举的Format枚举值。"
        },
        {
          "参数名": "ASCENDC_TPL_UINT_DECL(args0, args1, args2, ...)",
          "类型": "自定义UINT类型（无符号整形）的模板参数定义。",
          "说明": "args0：参数名。 args1：最大位宽，模板参数的个数不能超过最大位宽。 args2：参数定义的模式。支持以下三种模式： ASCENDC_TPL_UI_RANGE：范围模式，设置该模式，后续紧跟着第一个值表示范围个数，第一个值后面的每两个数值为一组分别表示该范围的起、终位置；注意定义的范围个数要和后续的组数保持一致。 举例：ASCENDC_TPL_UINT_DECL(args0, args1,ASCENDC_TPL_UI_RANGE,2,0,2,3,5)表示2组参数，这2组参数范围为{0, 2}，{3, 5}，因此该参数定义的UINT参数合法值为{0, 1, 2, 3, 4, 5}。 ASCENDC_TPL_UI_LIST：穷举模式，设置该模式，则表示后续将穷举出所有的参数值。 举例：ASCENDC_TPL_UINT_DECL(args0, args1,ASCENDC_TPL_UI_LIST,10,12,13,9,8,7,6)表示1组穷举参数，[10, 12, 13, 9, 8, 7, 6]为穷举值，因此该参数定义的UINT参数合法值为{10, 12, 13, 9, 8, 7, 6}。 ASCENDC_TPL_UI_MIX：混合模式，设置该模式，则表示前n个数值为范围模式的参数定义，后m个数值为穷举模式的参数定义。 举例： ASCENDC_TPL_UINT_DECL(args0, args1,ASCENDC_TPL_UI_MIX,2,0,2,3, 5, 10, 12, 13, 9, 8)表示2组穷举参数，这2组范围为{0, 2}, {3, 5}，[10, 12, 13, 9, 8]为穷举值，因此该参数定义的UINT参数合法值为{0, 1, 2, 3, 4, 5, 10, 12, 13, 9, 8}。 args3-argsn：对应不同范围模式的参数数值。"
        },
        {
          "参数名": "ASCENDC_TPL_BOOL_DECL(args0, ...)",
          "类型": "自定义bool类型的模板参数定义。",
          "说明": "args0：参数名。 args1-args2：取值范围0，1。"
        },
        {
          "参数名": "ASCENDC_TPL_SEL(...)",
          "类型": "算子的模板参数整体组合。",
          "说明": "包含多个算子的模板参数组合。"
        },
        {
          "参数名": "ASCENDC_TPL_ARGS_DSEL(...)",
          "类型": "算子的模板参数组合。",
          "说明": "一个算子的模板参数组合。"
        },
        {
          "参数名": "ASCENDC_TPL_DTYPE_SEL(args0, ...)",
          "类型": "DataType类型的模板参数组合。",
          "说明": "args0：表示参数名。 args1-argsn ：后续若干个参数为ASCENDC_TPL_DTYPE_DECL中定义的参数范围子集。"
        },
        {
          "参数名": "ASCENDC_TPL_FORMAT_SEL(args0, ...)",
          "类型": "Format类型的模板参数组合。",
          "说明": "args0：表示参数名。 args1-argsn：后续若干个参数为ASCENDC_TPL_FORMAT_DECL中定义的参数范围子集。"
        },
        {
          "参数名": "ASCENDC_TPL_UINT_SEL(args0, args1, args2, ...)",
          "类型": "UINT类型的模板参数组合。",
          "说明": "args0：表示参数名。 args1：参数定义的模式。支持如下取值： ASCENDC_TPL_UI_RANGE：范围模式。 ASCENDC_TPL_UI_LIST：穷举模式。 ASCENDC_TPL_UI_MIX：混合模式。 args2-argsn：后续若干个参数为ASCENDC_TPL_UINT_DECL中定义的参数范围子集。 模式和参数的配置方式参考ASCENDC_TPL_UINT_DECL(args0, args1, args2, ...)。"
        },
        {
          "参数名": "ASCENDC_TPL_BOOL_SEL(args0, ...)",
          "类型": "bool类型的模板参数组合。",
          "说明": "args0：表示参数名。 args1-args2 ：后续若干个参数为ASCENDC_TPL_BOOL_DECL定义的参数范围子集。"
        }
      ],
      "返回值": "无",
      "调用示例": "// ParamStruct是存放用户设置的模板参数ASCENDC_TPL_ARGS_DECL和模板参数组合ASCENDC_TPL_ARGS_SEL的结构体，用作后续的Tilingkey与模板参数之间的编解码，用户无需关注 struct ParamStruct { const char* name; uint32_t paramType; uint8_t bitWidth; std::vector<uint64_t> vals; const char* macroType; ParamStruct(const char* inName, uint32_t inParamType, uint8_t inBitWidth, std::vector<uint64_t> inVals, const char* inMacroType): name(inName), paramType(inParamType), bitWidth(inBitWidth), vals(std::move(inVals)), macroType(inMacroType) {} }; using TilingDeclareParams = std::vector<ParamStruct>; using TilingSelectParams = std::vector<std::vector<ParamStruct>>; // 模板参数定义相关接口 #define ASCENDC_TPL_DTYPE_DECL(x, ...) ParamStruct{#x, ASCENDC_TPL_DTYPE, ASCENDC_TPL_8_BW, {__VA_ARGS__}, \"DECL\"} #define ASCENDC_TPL_FORMAT_DECL(x, ...) ParamStruct{#x, ASCENDC_TPL_FORMAT, ASCENDC_TPL_8_BW, {__VA_ARGS__}, \"DECL\"} #define ASCENDC_TPL_UINT_DECL(x, bw, ...) ParamStruct{#x, ASCENDC_TPL_UINT, bw, {__VA_ARGS__}, \"DECL\"} #define ASCENDC_TPL_BOOL_DECL(x, ...) ParamStruct{#x, ASCENDC_TPL_BOOL, ASCENDC_TPL_1_BW, {__VA_ARGS__}, \"DECL\"} #define ASCENDC_TPL_DTYPE_SEL(x, ...) ParamStruct{#x, ASCENDC_TPL_DTYPE, ASCENDC_TPL_8_BW, {__VA_ARGS__}, \"SEL\"} #define ASCENDC_TPL_FORMAT_SEL(x, ...) ParamStruct{#x, ASCENDC_TPL_FORMAT, ASCENDC_TPL_8_BW, {__VA_ARGS__}, \"SEL\"} #define ASCENDC_TPL_UINT_SEL(x, ...) ParamStruct{#x, ASCENDC_TPL_UINT, 0, {__VA_ARGS__}, \"SEL\"} #define ASCENDC_TPL_BOOL_SEL(x, ...) ParamStruct{#x, ASCENDC_TPL_BOOL, ASCENDC_TPL_1_BW, {__VA_ARGS__}, \"SEL\"} #define ASCENDC_TPL_ARGS_DECL(x, ...) static TilingDeclareParams g_tilingDeclareParams{ __VA_ARGS__ } #define ASCENDC_TPL_ARGS_SEL(...) { __VA_ARGS__} #define ASCENDC_TPL_SEL(...) static TilingSelectParams g_tilingSelectParams{ __VA_ARGS__ }",
      "约束限制": "对模板参数定义的取值进行修改或新增后，需要重新编译自定义算子包，不能再继续使用之前的算子二进制。",
      "相关接口": [
        "Tiling数据结构注册"
      ],
      "版本信息": ""
    },
    {
      "API名称": "PairReduceSum-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0085.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "DropOut-数据过滤-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0862.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GmFree-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1210.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Reciprocal-单目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0028.html",
      "功能说明": "按元素取倒数，计算公式如下： 按元素取倒数，计算公式如下： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。Vector计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。UnaryRepeatParams类型，包含操作数相邻迭代间相同DataBlock的地址步长，操作数同一迭代内不同DataBlock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void Reciprocal(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint64_t mask[], const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。Vector计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。UnaryRepeatParams类型，包含操作数相邻迭代间相同DataBlock的地址步长，操作数同一迭代内不同DataBlock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void Reciprocal(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Reciprocal(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint64_t mask[], const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Reciprocal(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint64_t mask, const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)\nuint64_t mask = 256 / sizeof(half); // repeatTimes = 4, 128 elements one repeat, 512 elements total // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat // dstRepStride, srcRepStride = 8, no gap between repeats AscendC::Reciprocal(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 4, 128 elements one repeat, 512 elements total // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat // dstRepStride, srcRepStride = 8, no gap between repeats AscendC::Reciprocal(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });\nAscendC::Reciprocal(dstLocal, srcLocal, 512);\n输入数据(srcLocal): [-7.152 -7.24 1.771 ... -1.339 4.473] 输出数据(dstLocal): [-0.1396 -0.1382 0.5645 ... -0.748 0.2231]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "UnaryRepeatParams",
        "通用约束",
        "单目指令"
      ],
      "版本信息": "7.152"
    },
    {
      "API名称": "Max-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0039.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SoftmaxFlashV3-SoftMax-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10001.html",
      "功能说明": "SoftmaxFlash增强版本，对应Softmax PASA算法。将输入tensor[m0, m1, ..., mt, n]（t大于或等于0）的非尾轴长度m0, m1, ..., mt相乘的结果看作m，则输入tensor的shape看作[m, n]。对输入tensor x的尾轴进行切分，分块个数为splitMeanCnt，切分后的tensor为x_cnti。按如下公式进行计算，其中x、inmax、insum、inmean为输入，M、S、E均为输出。 本接口当前只支持ND格式的输入，内部的reduce过程按last轴处理。 为方便理解，通过Python伪代码实现的方式，表达其计算公式如下。其中，repeatSize为64，elementNumPerBlk/BlkcntPerRepeat为8，splitMeanCnt为8，src、inmean、inmax、 insum、update为输入，dst、x_mean、x_sum、x_max、exp_max为输出。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40def softmax_flash_3(src, height, width, loopCnt, alpha, baseK, inmax=None, insum=None, inmean=None, update=False): scalar = alpha / (1 - alpha) #(m,n)->(m,64) tmpbuffer0 = BlockReduceSum(repeatSize, repeatSize, elementNumPerBlk) remain = int(width / repeatSize - BlkcntPerRepeat) tmpbuffer0 = Add(tmpbuffer0, src, remain, repeatSize * elementNumPerBlk, width) #(m,64)->(m,8) tmpbuffer0 = BlockReduceSum(1, elementNumPerBlk, elementNumPerBlk) #width = baseK * splitMeanCnt rowMeanLocal = tmpbuffer0 / baseK rowMeanGlobal = np.mean(src, axis=(-1), keepdims=True) rowMeanGlobalTmp = (rowMeanGlobal - rowMeanLocal) * scalar src = src - rowMeanGlobalTmp if update == False: x_mean = rowMeanGlobal maxTmp = np.max(src, axis=-1, keepdims=True) shiftCurr = (rowMeanGlobal - x_mean) * scalar x_max = shiftCurr + maxTmp maxTmp = x_max - shiftCurr x_sub = src - maxTmp dst = np.exp(x_sub) x_sum = np.sum(dst, axis=-1, keepdims=True) exp_max = None return dst, x_max, x_sum, x_mean, exp_max else: x_mean = (rowMeanGlobal + inmean * (loopCnt - 1)) / loopCnt maxTmp = np.max(src, axis=-1, keepdims=True) shiftCurr = (rowMeanGlobal - x_mean) * scalar shiftPrev = (inmean - x_mean) * scalar x_max = shiftCurr + maxTmp maxTmp = shiftPrev + inmax x_max = np.max(np.concatenate((x_max, maxTmp), axis=(-1)), axis=(-1), keepdims=True) maxTmp = x_max - shiftCurr x_sub = src - maxTmp dst = np.exp(x_sub) exp_max = np.exp(inmax - x_max + shiftPrev) x_sum = np.sum(x_exp, axis=-1, keepdims=True) x_sum = exp_max * insum + x_sum return x_exp, x_max, x_sum, x_mean, exp_max SoftmaxFlash增强版本，对应Softmax PASA算法。将输入tensor[m0, m1, ..., mt, n]（t大于或等于0）的非尾轴长度m0, m1, ..., mt相乘的结果看作m，则输入tensor的shape看作[m, n]。对输入tensor x的尾轴进行切分，分块个数为splitMeanCnt，切分后的tensor为x_cnti。按如下公式进行计算，其中x、inmax、insum、inmean为输入，M、S、E均为输出。 本接口当前只支持ND格式的输入，内部的reduce过程按last轴处理。 为方便理解，通过Python伪代码实现的方式，表达其计算公式如下。其中，repeatSize为64，elementNumPerBlk/BlkcntPerRepeat为8，splitMeanCnt为8，src、inmean、inmax、 insum、update为输入，dst、x_mean、x_sum、x_max、exp_max为输出。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40def softmax_flash_3(src, height, width, loopCnt, alpha, baseK, inmax=None, insum=None, inmean=None, update=False): scalar = alpha / (1 - alpha) #(m,n)->(m,64) tmpbuffer0 = BlockReduceSum(repeatSize, repeatSize, elementNumPerBlk) remain = int(width / repeatSize - BlkcntPerRepeat) tmpbuffer0 = Add(tmpbuffer0, src, remain, repeatSize * elementNumPerBlk, width) #(m,64)->(m,8) tmpbuffer0 = BlockReduceSum(1, elementNumPerBlk, elementNumPerBlk) #width = baseK * splitMeanCnt rowMeanLocal = tmpbuffer0 / baseK rowMeanGlobal = np.mean(src, axis=(-1), keepdims=True) rowMeanGlobalTmp = (rowMeanGlobal - rowMeanLocal) * scalar src = src - rowMeanGlobalTmp if update == False: x_mean = rowMeanGlobal maxTmp = np.max(src, axis=-1, keepdims=True) shiftCurr = (rowMeanGlobal - x_mean) * scalar x_max = shiftCurr + maxTmp maxTmp = x_max - shiftCurr x_sub = src - maxTmp dst = np.exp(x_sub) x_sum = np.sum(dst, axis=-1, keepdims=True) exp_max = None return dst, x_max, x_sum, x_mean, exp_max else: x_mean = (rowMeanGlobal + inmean * (loopCnt - 1)) / loopCnt maxTmp = np.max(src, axis=-1, keepdims=True) shiftCurr = (rowMeanGlobal - x_mean) * scalar shiftPrev = (inmean - x_mean) * scalar x_max = shiftCurr + maxTmp maxTmp = shiftPrev + inmax x_max = np.max(np.concatenate((x_max, maxTmp), axis=(-1)), axis=(-1), keepdims=True) maxTmp = x_max - shiftCurr x_sub = src - maxTmp dst = np.exp(x_sub) exp_max = np.exp(inmax - x_max + shiftPrev) x_sum = np.sum(x_exp, axis=-1, keepdims=True) x_sum = exp_max * insum + x_sum return x_exp, x_max, x_sum, x_mean, exp_max 表1 模板参数说明参数名 描述 T 输入srcTensor及输出dstTensor、expMaxTensor操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half U 输入inMeanTensor、inExpSumTensor、inMaxTensor及输出meanTensor、expSumTensor、maxTensor操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：float isUpdate 是否使能update为true的计算。 isReuseSource 该参数预留，传入默认值false即可。 isBasicBlock 该参数预留，传入默认值false即可。 isDataFormatNZ 该参数预留，传入默认值false即可。 config 该参数预留，传入默认值SOFTMAX_DEFAULT_CFG即可。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 dstTensor的shape和源操作数srcTensor一致。 meanTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于保存softmax计算过程中平均值的结果。 meanTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的reducesum求平均后的值。非last轴的长度与dstTensor保持一致。 expSumTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于保存softmax计算过程中reducesum的结果。 expSumTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的reducesum的值。非last轴的长度与dstTensor保持一致。 maxTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于保存softmax计算过程中reducemax的结果。 maxTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的reducemax的值。非last轴的长度与dstTensor保持一致。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 last轴长度需要32Byte对齐。 expMaxTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 expMaxTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如half数据类型下，该datablock中的16个数均为相同的值。非last轴的长度需要与dstTensor保持一致。 inMeanTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 softmax计算所需要的mean值。 inMeanTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的值。非last轴的长度需要与dstTensor保持一致。 inExpSumTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 softmax计算所需要的sum值。 inExpSumTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的值。非last轴的长度需要与dstTensor保持一致。 inMaxTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 softmax计算所需要的max值。 inMaxTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的值。非last轴的长度需要与dstTensor保持一致。 sharedTmpBuffer 输入 临时空间。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 该操作数的数据类型固定uint8_t。 接口内部复杂计算时用于存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考SoftmaxFlashV3 Tiling接口。 tiling 输入 SoftmaxFlashV3接口计算所需Tiling信息，Tiling信息的获取请参考SoftmaxFlashV3 Tiling接口。 params 输入 srcTensor的shape信息和计算相关参数。SoftMaxParams类型，具体定义如下： 1 2 3 4 5 6 7 8 9struct SoftMaxParams { uint32_t srcM; // 非尾轴长度的乘积 uint32_t srcK; // 尾轴长度，必须32Byte对齐 uint32_t oriSrcM; // 原始非尾轴长度的乘积 uint32_t oriSrcK; // 原始尾轴长度 uint32_t loopCnt; // update为true时，公式中的循环次数loopCnt，该参数大于等于1 uint32_t splitMeanCnt; // 公式中计算每一行平均值时的分块个数，当前该参数仅支持取值为8 float alpha; // 公式中的计算参数，推荐取值0.9375、0.96889、0.984497 }; 注意，当前本接口不支持非对齐场景，因此参数srcM与oriSrcM相等，参数srcK与oriSrcK相等。",
      "函数原型": "template <typename T, typename U, bool isUpdate = false, bool isReuseSource = false, bool isBasicBlock = false, bool isDataFormatNZ = false, const SoftmaxConfig& config = SOFTMAX_DEFAULT_CFG> __aicore__ inline void SoftmaxFlashV3(const LocalTensor<T>& dstTensor, const LocalTensor<U>& meanTensor,const LocalTensor<U>& expSumTensor, const LocalTensor<U>& maxTensor, const LocalTensor<T>& srcTensor,const LocalTensor<T>& expMaxTensor, const LocalTensor<U>& inMeanTensor, const LocalTensor<U>& inExpSumTensor, const LocalTensor<U>& inMaxTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const SoftMaxTiling& tiling, const SoftMaxParams& params)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "输入srcTensor及输出dstTensor、expMaxTensor操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half"
        },
        {
          "参数名": "U",
          "类型": "",
          "说明": "输入inMeanTensor、inExpSumTensor、inMaxTensor及输出meanTensor、expSumTensor、maxTensor操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：float"
        },
        {
          "参数名": "isUpdate",
          "类型": "",
          "说明": "是否使能update为true的计算。"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "isBasicBlock",
          "类型": "",
          "说明": "该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "isDataFormatNZ",
          "类型": "",
          "说明": "该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "config",
          "类型": "",
          "说明": "该参数预留，传入默认值SOFTMAX_DEFAULT_CFG即可。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 dstTensor的shape和源操作数srcTensor一致。"
        },
        {
          "参数名": "meanTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于保存softmax计算过程中平均值的结果。 meanTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的reducesum求平均后的值。非last轴的长度与dstTensor保持一致。"
        },
        {
          "参数名": "expSumTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于保存softmax计算过程中reducesum的结果。 expSumTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的reducesum的值。非last轴的长度与dstTensor保持一致。"
        },
        {
          "参数名": "maxTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于保存softmax计算过程中reducemax的结果。 maxTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的reducemax的值。非last轴的长度与dstTensor保持一致。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 last轴长度需要32Byte对齐。"
        },
        {
          "参数名": "expMaxTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 expMaxTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如half数据类型下，该datablock中的16个数均为相同的值。非last轴的长度需要与dstTensor保持一致。"
        },
        {
          "参数名": "inMeanTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 softmax计算所需要的mean值。 inMeanTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的值。非last轴的长度需要与dstTensor保持一致。"
        },
        {
          "参数名": "inExpSumTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 softmax计算所需要的sum值。 inExpSumTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的值。非last轴的长度需要与dstTensor保持一致。"
        },
        {
          "参数名": "inMaxTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 softmax计算所需要的max值。 inMaxTensor的last轴长度固定为32Byte，即一个datablock长度。该datablock中的所有数据为同一个值。比如float数据类型下，该datablock中的8个数均为相同的值。非last轴的长度需要与dstTensor保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时空间。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 该操作数的数据类型固定uint8_t。 接口内部复杂计算时用于存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考SoftmaxFlashV3 Tiling接口。"
        },
        {
          "参数名": "tiling",
          "类型": "输入",
          "说明": "SoftmaxFlashV3接口计算所需Tiling信息，Tiling信息的获取请参考SoftmaxFlashV3 Tiling接口。"
        },
        {
          "参数名": "params",
          "类型": "输入",
          "说明": "srcTensor的shape信息和计算相关参数。SoftMaxParams类型，具体定义如下： 1 2 3 4 5 6 7 8 9struct SoftMaxParams { uint32_t srcM; // 非尾轴长度的乘积 uint32_t srcK; // 尾轴长度，必须32Byte对齐 uint32_t oriSrcM; // 原始非尾轴长度的乘积 uint32_t oriSrcK; // 原始尾轴长度 uint32_t loopCnt; // update为true时，公式中的循环次数loopCnt，该参数大于等于1 uint32_t splitMeanCnt; // 公式中计算每一行平均值时的分块个数，当前该参数仅支持取值为8 float alpha; // 公式中的计算参数，推荐取值0.9375、0.96889、0.984497 }; 注意，当前本接口不支持非对齐场景，因此参数srcM与oriSrcM相等，参数srcK与oriSrcK相等。"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9",
          "类型": "",
          "说明": "struct SoftMaxParams { uint32_t srcM; // 非尾轴长度的乘积 uint32_t srcK; // 尾轴长度，必须32Byte对齐 uint32_t oriSrcM; // 原始非尾轴长度的乘积 uint32_t oriSrcK; // 原始尾轴长度 uint32_t loopCnt; // update为true时，公式中的循环次数loopCnt，该参数大于等于1 uint32_t splitMeanCnt; // 公式中计算每一行平均值时的分块个数，当前该参数仅支持取值为8 float alpha; // 公式中的计算参数，推荐取值0.9375、0.96889、0.984497 };"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99",
      "约束限制": "",
      "相关接口": [
        "SoftmaxFlashV3 Tiling接口",
        "LocalTensor",
        "通用约束",
        "SoftMax"
      ],
      "版本信息": "0.9375"
    },
    {
      "API名称": "GetTPipePtr-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0120.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetPadValue(ISASI)-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0266.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LoadUnzipIndex-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0242.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "使用说明-Matmul-Matmul-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0613.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "printf-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0193.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ClampMin-Clamp-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0577.html",
      "功能说明": "将srcTensor中小于scalar的数替换为scalar，大于等于scalar的数保持不变，作为dstTensor输出。 将srcTensor中小于scalar的数替换为scalar，大于等于scalar的数保持不变，作为dstTensor输出。 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于ClampMin内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetClampMaxMinTmpSize。 scalar 输入 scalar数据，数据类型与srcTensor一致，支持数据类型为：half/float。 calCount 输入 参与计算的元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void ClampMin(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const T scalar, const uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于ClampMin内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetClampMaxMinTmpSize。"
        },
        {
          "参数名": "scalar",
          "类型": "输入",
          "说明": "scalar数据，数据类型与srcTensor一致，支持数据类型为：half/float。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6\n1 2 3 4 5 6",
      "约束限制": "",
      "相关接口": [
        "GetClampMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "更多样例",
        "Clamp"
      ],
      "版本信息": ""
    },
    {
      "API名称": "MrgSort-Sort-排序-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0847.html",
      "功能说明": "将已经排好序的最多4条队列，合并排列成1条队列，结果按照score域由大到小排序，排布方式如下： Atlas A3 训练系列产品/Atlas A3 推理系列产品采用方式一 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件采用方式一 Atlas 推理系列产品AI Core采用方式二 将已经排好序的最多4条队列，合并排列成1条队列，结果按照score域由大到小排序，排布方式如下： Atlas A3 训练系列产品/Atlas A3 推理系列产品采用方式一 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件采用方式一 Atlas 推理系列产品AI Core采用方式二 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isExhaustedSuspension 某条队列耗尽（即该队列已经全部排序到目的操作数）后，是否需要停止合并。类型为bool，参数取值如下： false：直到所有队列耗尽完才停止合并。true：某条队列耗尽后，停止合并。 默认值为false。 表2 接口参数说明参数名 输入/输出 描述 dstLocal 输出 目的操作数，存储经过排序后的数据。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 sortList 输入 源操作数，支持2-4个队列，并且每个队列都已经排好序，类型为MrgSortSrcList结构体，具体请参考表3。MrgSortSrcList中传入要合并的队列。 1 2 3 4 5 6 7template <typename T> struct MrgSortSrcList { LocalTensor<T> src1; LocalTensor<T> src2; LocalTensor<T> src3; // 当要合并的队列个数小于3，可以为空tensor LocalTensor<T> src4; // 当要合并的队列个数小于4，可以为空tensor }; elementCountList 输入 四个源队列的长度（8Bytes结构的数目），类型为长度为4的uint16_t数据类型的数组，理论上每个元素取值范围[0, 4095]，但不能超出UB的存储空间。 sortedNum 输出 耗尽模式下（即isExhaustedSuspension为true时），停止合并时每个队列已排序的元素个数。 validBit 输入 有效队列个数，取值如下：0b11：前两条队列有效0b111：前三条队列有效0b1111：四条队列全部有效 repeatTimes 输入 迭代次数，每一次源操作数和目的操作数跳过四个队列总长度。取值范围：repeatTimes∈[1,255]。 repeatTimes参数生效是有条件的，需要同时满足以下四个条件：srcLocal包含四条队列并且validBit=15四个源队列的长度一致四个源队列连续存储isExhaustedSuspension为false 表3 MrgSortSrcList参数说明参数名称 输入/输出 含义 src1 输入 源操作数，第一个已经排好序的队列。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 数据类型与目的操作数保持一致。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float src2 输入 源操作数，第二个已经排好序的队列。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 数据类型与目的操作数保持一致。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float src3 输入 源操作数，第三个已经排好序的队列。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 数据类型与目的操作数保持一致。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float src4 输入 源操作数，第四个已经排好序的队列。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 数据类型与目的操作数保持一致。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float",
      "函数原型": "template <typename T, bool isExhaustedSuspension = false> __aicore__ inline void MrgSort(const LocalTensor<T> &dstLocal, const MrgSortSrcList<T> &sortList, const uint16_t elementCountList[4], uint32_t sortedNum[4], uint16_t validBit, const int32_t repeatTimes)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isExhaustedSuspension",
          "类型": "",
          "说明": "某条队列耗尽（即该队列已经全部排序到目的操作数）后，是否需要停止合并。类型为bool，参数取值如下： false：直到所有队列耗尽完才停止合并。true：某条队列耗尽后，停止合并。 默认值为false。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数，存储经过排序后的数据。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "sortList",
          "类型": "输入",
          "说明": "源操作数，支持2-4个队列，并且每个队列都已经排好序，类型为MrgSortSrcList结构体，具体请参考表3。MrgSortSrcList中传入要合并的队列。 1 2 3 4 5 6 7template <typename T> struct MrgSortSrcList { LocalTensor<T> src1; LocalTensor<T> src2; LocalTensor<T> src3; // 当要合并的队列个数小于3，可以为空tensor LocalTensor<T> src4; // 当要合并的队列个数小于4，可以为空tensor };"
        },
        {
          "参数名": "1 2 3 4 5 6 7",
          "类型": "",
          "说明": "template <typename T> struct MrgSortSrcList { LocalTensor<T> src1; LocalTensor<T> src2; LocalTensor<T> src3; // 当要合并的队列个数小于3，可以为空tensor LocalTensor<T> src4; // 当要合并的队列个数小于4，可以为空tensor };"
        },
        {
          "参数名": "elementCountList",
          "类型": "输入",
          "说明": "四个源队列的长度（8Bytes结构的数目），类型为长度为4的uint16_t数据类型的数组，理论上每个元素取值范围[0, 4095]，但不能超出UB的存储空间。"
        },
        {
          "参数名": "sortedNum",
          "类型": "输出",
          "说明": "耗尽模式下（即isExhaustedSuspension为true时），停止合并时每个队列已排序的元素个数。"
        },
        {
          "参数名": "validBit",
          "类型": "输入",
          "说明": "有效队列个数，取值如下：0b11：前两条队列有效0b111：前三条队列有效0b1111：四条队列全部有效"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "迭代次数，每一次源操作数和目的操作数跳过四个队列总长度。取值范围：repeatTimes∈[1,255]。 repeatTimes参数生效是有条件的，需要同时满足以下四个条件：srcLocal包含四条队列并且validBit=15四个源队列的长度一致四个源队列连续存储isExhaustedSuspension为false"
        },
        {
          "参数名": "src1",
          "类型": "输入",
          "说明": "源操作数，第一个已经排好序的队列。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 数据类型与目的操作数保持一致。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "src2",
          "类型": "输入",
          "说明": "源操作数，第二个已经排好序的队列。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 数据类型与目的操作数保持一致。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "src3",
          "类型": "输入",
          "说明": "源操作数，第三个已经排好序的队列。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 数据类型与目的操作数保持一致。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "src4",
          "类型": "输入",
          "说明": "源操作数，第四个已经排好序的队列。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 数据类型与目的操作数保持一致。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111",
      "约束限制": "",
      "相关接口": [
        "Sort",
        "LocalTensor",
        "通用约束"
      ],
      "版本信息": "rc1"
    },
    {
      "API名称": "Sign-Sign-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0552.html",
      "功能说明": "按元素执行Sign操作，Sign是指返回输入数据的符号，如果为0则返回0，如果为正数则返回1，如果为负数则返回-1。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 按元素执行Sign操作，Sign是指返回输入数据的符号，如果为0则返回0，如果为正数则返回1，如果为负数则返回-1。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Sign内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetSignMaxMinTmpSize。 calCount 输入 参与计算的元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void Sign(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Sign内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetSignMaxMinTmpSize。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10\n1 2 3 4 5 6 7 8 9 10",
      "约束限制": "",
      "相关接口": [
        "GetSignMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "更多样例",
        "Sign"
      ],
      "版本信息": "2.0"
    },
    {
      "API名称": "ScalarCast-标量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0018.html",
      "功能说明": "将一个scalar的类型转换为指定的类型。 将一个scalar的类型转换为指定的类型。 表1 模板参数说明参数名 描述 srcT valueIn的数据类型，支持float。 dstT 转换后的数据类型，支持half、int32_t。 roundMode 精度转换处理模式，类型是RoundMode。 RoundMode为枚举类型，用以控制精度转换处理模式，具体定义为： 1 2 3 4 5 6 7 8 9enum class RoundMode { CAST_NONE = 0, // 在转换有精度损失时表示CAST_RINT模式，不涉及精度损失时表示不取整 CAST_RINT, // rint，四舍六入五成双取整 CAST_FLOOR, // floor，向负无穷取整 CAST_CEIL, // ceil，向正无穷取整 CAST_ROUND, // round，四舍五入取整 CAST_TRUNC, // trunc，向零取整 CAST_ODD, // Von Neumann rounding，最近邻奇数舍入 }; 对于ScalarCast，转换类型仅支持float转half(f322f16)与float转int32_t(f322s32)，相应支持的RoundMode如下： f322f16：CAST_ODD f322s32：CAST_ROUND、CAST_CEIL、CAST_FLOOR、CAST_RINT ScalarCast的精度转换规则与Cast保持一致，具体可参考表1。 表2 参数说明参数名 输入/输出 描述 valueIn 输入 被转换数据类型的Scalar。",
      "函数原型": "template <typename srcT, typename dstT, RoundMode roundMode> __aicore__ inline dstT ScalarCast(srcT valueIn)",
      "参数说明": [
        {
          "参数名": "srcT",
          "类型": "",
          "说明": "valueIn的数据类型，支持float。"
        },
        {
          "参数名": "dstT",
          "类型": "",
          "说明": "转换后的数据类型，支持half、int32_t。"
        },
        {
          "参数名": "roundMode",
          "类型": "精度转换处理模式，类型是RoundMode。 RoundMode为枚举类型，用以控制精度转换处理模式，具体定义为： 1 2 3 4 5 6 7 8 9enum class RoundMode { CAST_NONE = 0, // 在转换有精度损失时表示CAST_RINT模式，不涉及精度损失时表示不取整 CAST_RINT, // rint，四舍六入五成双取整 CAST_FLOOR, // floor，向负无穷取整 CAST_CEIL, // ceil，向正无穷取整 CAST_ROUND, // round，四舍五入取整 CAST_TRUNC, // trunc，向零取整 CAST_ODD, // Von Neumann rounding，最近邻奇数舍入 }; 对于ScalarCast，转换类型仅支持float转half(f322f16)与float转int32_t(f322s32)，相应支持的RoundMode如下： f322f16：CAST_ODD f322s32：CAST_ROUND、CAST_CEIL、CAST_FLOOR、CAST_RINT ScalarCast的精度转换规则与Cast保持一致，具体可参考表1。",
          "说明": "1 2 3 4 5 6 7 8 9"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9",
          "类型": "",
          "说明": "enum class RoundMode { CAST_NONE = 0, // 在转换有精度损失时表示CAST_RINT模式，不涉及精度损失时表示不取整 CAST_RINT, // rint，四舍六入五成双取整 CAST_FLOOR, // floor，向负无穷取整 CAST_CEIL, // ceil，向正无穷取整 CAST_ROUND, // round，四舍五入取整 CAST_TRUNC, // trunc，向零取整 CAST_ODD, // Von Neumann rounding，最近邻奇数舍入 };"
        },
        {
          "参数名": "valueIn",
          "类型": "输入",
          "说明": "被转换数据类型的Scalar。"
        }
      ],
      "返回值": "dstT类型的valueIn。",
      "调用示例": "template <typename srcT, typename dstT, RoundMode roundMode> __aicore__ inline dstT ScalarCast(srcT valueIn)\nfloat valueIn = 2.5; // 输出数据(valueOut): 3 int32_t valueOut = AscendC::ScalarCast<float, int32_t, AscendC::RoundMode::CAST_ROUND>(valueIn);",
      "约束限制": "",
      "相关接口": [
        "标量计算"
      ],
      "版本信息": "2.5"
    },
    {
      "API名称": "GET_TILING_DATA-Kernel Tiling-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0214.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SelectWithBytesMask-比较选择-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0859.html",
      "功能说明": "给定两个源操作数src0和src1，根据maskTensor相应位置的值（非bit位）选取元素，得到目的操作数dst。选择的规则为：当Mask的值为0时，从src0中选取，否则从src1选取。 该接口支持多维Shape，需满足maskTensor和源操作数Tensor的前轴（非尾轴）元素个数相同，且maskTensor尾轴元素个数大于等于源操作数尾轴元素个数，maskTensor多余部分丢弃不参与计算。 如下图样例，源操作数src0为Tensor，shape为(2,16)，数据类型为half，尾轴长度满足32字节对齐；源操作数src1为scalar，数据类型为half；maskTensor的数据类型为bool，为满足对齐要求shape为(2,32)，仅有图中蓝色部分的mask掩码生效，灰色部分不参与计算。输出目的操作数dstTensor如下图所示。 给定两个源操作数src0和src1，根据maskTensor相应位置的值（非bit位）选取元素，得到目的操作数dst。选择的规则为：当Mask的值为0时，从src0中选取，否则从src1选取。 该接口支持多维Shape，需满足maskTensor和源操作数Tensor的前轴（非尾轴）元素个数相同，且maskTensor尾轴元素个数大于等于源操作数尾轴元素个数，maskTensor多余部分丢弃不参与计算。 如下图样例，源操作数src0为Tensor，shape为(2,16)，数据类型为half，尾轴长度满足32字节对齐；源操作数src1为scalar，数据类型为half；maskTensor的数据类型为bool，为满足对齐要求shape为(2,32)，仅有图中蓝色部分的mask掩码生效，灰色部分不参与计算。输出目的操作数dstTensor如下图所示。 表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float U 掩码Tensor mask的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：bool/uint8_t/int8_t/uint16_t/int16_t/uint32_t/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：bool/uint8_t/int8_t/uint16_t/int16_t/uint32_t/int32_t Atlas 推理系列产品 AI Core，支持的数据类型为：bool/uint8_t/int8_t/uint16_t/int16_t/uint32_t/int32_t isReuseMask 是否允许修改maskTensor。默认为true。 取值为true时，仅在maskTensor尾轴元素个数和srcTensor尾轴元素个数不同的情况下，maskTensor可能会被修改；其余场景，maskTensor不会修改。 取值为false时，任意场景下，maskTensor均不会修改，但可能会需要更多的临时空间。 表2 接口参数说明 参数名称 输入/输出 含义 dst 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 src0(srcTensor) src1(srcTensor) 输入 源操作数。源操作数Tensor尾轴需32字节对齐。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 src1(srcScalar) src0(srcScalar) 输入 源操作数。类型为scalar。 mask 输入 掩码Tensor。用于描述如何选择srcTensor和srcScalar之间的值。maskTensor尾轴需32字节对齐且元素个数为16的倍数。 src0为srcTensor（tensor类型），src1为srcScalar（scalar类型） 若mask的值为0，选择srcTensor相应的值放入dstLocal，否则选择srcScalar的值放入dstLocal。 src0为srcScalar（scalar类型），src1为srcTensor（tensor类型） 若mask的值为0，选择srcScalar的值放入dstLocal，否则选择srcTensor相应的值放入dstLocal。 sharedTmpBuffer 输入 该API用于计算的临时空间，所需空间大小根据GetSelectWithBytesMaskMaxMinTmpSize获取。 info 输入 描述SrcTensor和maskTensor的shape信息。SelectWithBytesMaskShapeInfo类型，定义如下： 1 2 3 4 5 6 struct SelectWithBytesMaskShapeInfo { __aicore__ SelectWithBytesMaskShapeInfo(){}; uint32_t firstAxis = 0; // srcLocal/maskTensor的前轴元素个数 uint32_t srcLastAxis = 0; // srcLocal的尾轴元素个数 uint32_t maskLastAxis = 0;// maskTensor的尾轴元素个数 }; 需要满足srcTensor和maskTensor的前轴元素个数相同，均为firstAxis。 需要满足firstAxis * srcLastAxis = srcTensor.GetSize() ；firstAxis * maskLastAxis = maskTensor.GetSize()。 maskTensor尾轴的元素个数大于等于srcTensor尾轴的元素个数，计算时会丢弃maskTensor多余部分，不参与计算。",
      "函数原型": "template <typename T, typename U, bool isReuseMask = true> __aicore__ inline void SelectWithBytesMask(const LocalTensor<T> &dst, const LocalTensor<T> &src0, T src1, const LocalTensor<U> &mask, const LocalTensor<uint8_t> &sharedTmpBuffer, const SelectWithBytesMaskShapeInfo &info)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "U",
          "类型": "",
          "说明": "掩码Tensor mask的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：bool/uint8_t/int8_t/uint16_t/int16_t/uint32_t/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：bool/uint8_t/int8_t/uint16_t/int16_t/uint32_t/int32_t Atlas 推理系列产品 AI Core，支持的数据类型为：bool/uint8_t/int8_t/uint16_t/int16_t/uint32_t/int32_t"
        },
        {
          "参数名": "isReuseMask",
          "类型": "",
          "说明": "是否允许修改maskTensor。默认为true。 取值为true时，仅在maskTensor尾轴元素个数和srcTensor尾轴元素个数不同的情况下，maskTensor可能会被修改；其余场景，maskTensor不会修改。 取值为false时，任意场景下，maskTensor均不会修改，但可能会需要更多的临时空间。"
        },
        {
          "参数名": "dst",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "src0(srcTensor) src1(srcTensor)",
          "类型": "输入",
          "说明": "源操作数。源操作数Tensor尾轴需32字节对齐。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "src1(srcScalar) src0(srcScalar)",
          "类型": "输入",
          "说明": "源操作数。类型为scalar。"
        },
        {
          "参数名": "mask",
          "类型": "输入",
          "说明": "掩码Tensor。用于描述如何选择srcTensor和srcScalar之间的值。maskTensor尾轴需32字节对齐且元素个数为16的倍数。 src0为srcTensor（tensor类型），src1为srcScalar（scalar类型） 若mask的值为0，选择srcTensor相应的值放入dstLocal，否则选择srcScalar的值放入dstLocal。 src0为srcScalar（scalar类型），src1为srcTensor（tensor类型） 若mask的值为0，选择srcScalar的值放入dstLocal，否则选择srcTensor相应的值放入dstLocal。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "该API用于计算的临时空间，所需空间大小根据GetSelectWithBytesMaskMaxMinTmpSize获取。"
        },
        {
          "参数名": "info",
          "类型": "输入",
          "说明": "描述SrcTensor和maskTensor的shape信息。SelectWithBytesMaskShapeInfo类型，定义如下： 1 2 3 4 5 6 struct SelectWithBytesMaskShapeInfo { __aicore__ SelectWithBytesMaskShapeInfo(){}; uint32_t firstAxis = 0; // srcLocal/maskTensor的前轴元素个数 uint32_t srcLastAxis = 0; // srcLocal的尾轴元素个数 uint32_t maskLastAxis = 0;// maskTensor的尾轴元素个数 }; 需要满足srcTensor和maskTensor的前轴元素个数相同，均为firstAxis。 需要满足firstAxis * srcLastAxis = srcTensor.GetSize() ；firstAxis * maskLastAxis = maskTensor.GetSize()。 maskTensor尾轴的元素个数大于等于srcTensor尾轴的元素个数，计算时会丢弃maskTensor多余部分，不参与计算。"
        },
        {
          "参数名": "1 2 3 4 5 6",
          "类型": "",
          "说明": "struct SelectWithBytesMaskShapeInfo { __aicore__ SelectWithBytesMaskShapeInfo(){}; uint32_t firstAxis = 0; // srcLocal/maskTensor的前轴元素个数 uint32_t srcLastAxis = 0; // srcLocal的尾轴元素个数 uint32_t maskLastAxis = 0;// maskTensor的尾轴元素个数 };"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9\n1 2 3 4 5 6 7 8 9",
      "约束限制": "",
      "相关接口": [
        "GetSelectWithBytesMaskMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "比较选择"
      ],
      "版本信息": "84.6"
    },
    {
      "API名称": "get-容器函数-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10109.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetLoadDataPaddingValue-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0248.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "简介-TQue-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0136.html",
      "功能说明": "流水任务之间通过队列（Queue）完成任务间通信和同步。TQue是用来执行队列相关操作、管理相关资源的数据结构。TQue继承自TQueBind父类，继承关系如下：",
      "函数原型": "__aicore__ constexpr AscendC::TQueConfig GetMyTQueConfig(bool nd2nzIn, bool nz2ndIn, bool scmBlockGroupIn, uint32_t bufferLenIn, uint32_t bufferNumberIn, uint32_t consumerSizeIn, const AscendC::TPosition consumerIn[]) { return { .nd2nz = nd2nzIn, .nz2nd = nz2ndIn, .scmBlockGroup = scmBlockGroupIn, .bufferLen = bufferLenIn, .bufferNumber = bufferNumberIn, .consumerSize = consumerSizeIn, .consumer = {consumerIn[0], consumerIn[1], consumerIn[2], consumerIn[3], consumerIn[4], consumerIn[5], consumerIn[6], consumerIn[7]} }; } static constexpr AscendC::TPosition tp[8] = {AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX}; static constexpr AscendC::TQueConfig conf = GetMyTQueConfig(false, false, false, 0, 1, 0, tp); template <typename srcType> class KernelAscendQuant { public: __aicore__ inline KernelAscendQuant()",
      "参数说明": [
        {
          "参数名": "pos",
          "类型": "",
          "说明": "队列逻辑位置，可以为VECIN、VECOUT、A1、A2、B1、B2、CO1、CO2。关于TPosition的具体介绍请参考TPosition。"
        },
        {
          "参数名": "depth",
          "类型": "队列的深度表示该队列可以连续进行入队/出队的次数，在代码运行时，对同一个队列有n次连续的EnQue（中间没有DeQue），那么该队列的深度就需要设置为n。 注意，这里的队列深度和double buffer无关，队列机制用于实现流水线并行，double buffer在此基础上进一步提高流水线的利用率。即使队列的深度为1，仍可以开启double buffer。 非Tensor原地操作的场景下，队列的深度设置为1时，编译器对这种场景做了特殊优化，性能通常更好，推荐设置为1。 Tensor原地操作的场景下，需要设置为0。 如下样例中队列没有连续入队，队列的深度设置为1。 1 2 3 4 a1 = que.AllocTensor(); que.EnQue(a1); a1 = que.DeQue(); que.FreeTensor(a1); 如下样例中队列连续2次入队，队列的深度应设置为2，仅在极少数preload场景（比如连续搬入两份数据，计算处理一份，完成后再搬入一份，然后计算处理提前搬入的一份...）可能会使用。其他情况下均不推荐depth >= 2 。 1 2 3 4 5 6 7 8 a1 = que.AllocTensor(); a2 = que.AllocTensor(); que.EnQue(a1); que.EnQue(a2); a1 = que.DeQue(); a2 = que.DeQue(); que.FreeTensor(a1); que.FreeTensor(a2);",
          "说明": "1 2 3 4"
        },
        {
          "参数名": "1 2 3 4",
          "类型": "",
          "说明": "a1 = que.AllocTensor(); que.EnQue(a1); a1 = que.DeQue(); que.FreeTensor(a1);"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8",
          "类型": "",
          "说明": "a1 = que.AllocTensor(); a2 = que.AllocTensor(); que.EnQue(a1); que.EnQue(a2); a1 = que.DeQue(); a2 = que.DeQue(); que.FreeTensor(a1); que.FreeTensor(a2);"
        },
        {
          "参数名": "mask",
          "类型": "mask是int类型时，采用比特位表达信息： bit 0位为1表示，数据格式从ND转换为NZ，TPosition仅支持A1或B1； bit 1位为1表示，数据格式从NZ转换为ND，TPosition仅支持CO2。 支持的型号如下： Atlas 推理系列产品 AI Core mask是const TQueConfig*类型时，TQueConfig结构定义和参数说明如下，调用示例见调用示例: 1 2 3 4 5 6 7 8 9 10 11 struct TQueConfig { bool nd2nz = false; // true代表数据格式从ND转换为NZ，仅支持TPosition为A1或B1，默认为false bool nz2nd = false; // true代表数据格式从NZ转换为ND，仅支持TPosition为CO2，默认为false bool scmBlockGroup = false; // TSCM相关参数，预留参数，默认为false uint32_t bufferLen = 0; // 与InitBuffer时输入的len参数保持一致，可以在编译期做性能优化，传0表示在InitBuffer时做资源分配。 uint32_t bufferNumber = 0; // 与InitBuffer时输入的num参数保持一致，可以在编译期做性能优化，传0表示在InitBuffer时做资源分配。 uint32_t consumerSize = 0; // 预留参数 TPosition consumer[8] = {}; // 预留参数 bool enableStaticEvtId = false; // 预留参数 bool enableLoopQueue = false; // 预留参数 }; 上述ND、NZ格式转换相关参数支持的型号如下： Atlas 推理系列产品 AI Core",
          "说明": "1 2 3 4 5 6 7 8 9 10 11"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9 10 11",
          "类型": "",
          "说明": "struct TQueConfig { bool nd2nz = false; // true代表数据格式从ND转换为NZ，仅支持TPosition为A1或B1，默认为false bool nz2nd = false; // true代表数据格式从NZ转换为ND，仅支持TPosition为CO2，默认为false bool scmBlockGroup = false; // TSCM相关参数，预留参数，默认为false uint32_t bufferLen = 0; // 与InitBuffer时输入的len参数保持一致，可以在编译期做性能优化，传0表示在InitBuffer时做资源分配。 uint32_t bufferNumber = 0; // 与InitBuffer时输入的num参数保持一致，可以在编译期做性能优化，传0表示在InitBuffer时做资源分配。 uint32_t consumerSize = 0; // 预留参数 TPosition consumer[8] = {}; // 预留参数 bool enableStaticEvtId = false; // 预留参数 bool enableLoopQueue = false; // 预留参数 };"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62",
      "约束限制": "由于TQue分配的Buffer存储着同步事件eventID，故同一个TPosition上TQue Buffer的数量与硬件的同步事件eventID有关。 针对 Atlas 训练系列产品 ，eventID的数量为4 Atlas 推理系列产品 AI Core，eventID的数量为8 Atlas 推理系列产品 Vector Core，eventID的数量为8 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，eventID的数量为8",
      "相关接口": [
        "TPosition",
        "TQue"
      ],
      "版本信息": ""
    },
    {
      "API名称": "PlatformAscendCManager-平台信息获取-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1039.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "IBSet-核间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0202.html",
      "功能说明": "当不同核之间操作同一块全局内存且可能存在读后写、写后读以及写后写等数据依赖问题时，通过调用该函数来插入同步语句来避免上述数据依赖时可能出现的数据读写错误问题。调用IBSet设置某一个核的标志位，与IBWait成对出现配合使用，表示核之间的同步等待指令，等待某一个核操作完成。 当不同核之间操作同一块全局内存且可能存在读后写、写后读以及写后写等数据依赖问题时，通过调用该函数来插入同步语句来避免上述数据依赖时可能出现的数据读写错误问题。调用IBSet设置某一个核的标志位，与IBWait成对出现配合使用，表示核之间的同步等待指令，等待某一个核操作完成。 表1 模板参数说明参数名 描述 isAIVOnly 控制是否为AIVOnly模式，默认为true。 表2 接口参数说明参数名 输入/输出 描述 gmWorkspace 输出 外部存储核状态的公共缓存，类型为GlobalTensor。GlobalTensor数据结构的定义请参考GlobalTensor。 ubWorkspace 输入 存储当前核状态的公共缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 blockIdx 输入 表示等待核的idx号，取值范围：[0, 核数-1]。 eventID 输入 用来控制当前核的set、wait事件。",
      "函数原型": "template <bool isAIVOnly = true> __aicore__ inline void IBSet(const GlobalTensor<int32_t>& gmWorkspace, const LocalTensor<int32_t>& ubWorkspace, int32_t blockIdx, int32_t eventID)",
      "参数说明": [
        {
          "参数名": "isAIVOnly",
          "类型": "",
          "说明": "控制是否为AIVOnly模式，默认为true。"
        },
        {
          "参数名": "gmWorkspace",
          "类型": "输出",
          "说明": "外部存储核状态的公共缓存，类型为GlobalTensor。GlobalTensor数据结构的定义请参考GlobalTensor。"
        },
        {
          "参数名": "ubWorkspace",
          "类型": "输入",
          "说明": "存储当前核状态的公共缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "blockIdx",
          "类型": "输入",
          "说明": "表示等待核的idx号，取值范围：[0, 核数-1]。"
        },
        {
          "参数名": "eventID",
          "类型": "输入",
          "说明": "用来控制当前核的set、wait事件。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84",
      "约束限制": "",
      "相关接口": [
        "GlobalTensor",
        "LocalTensor",
        "核间同步"
      ],
      "版本信息": ""
    },
    {
      "API名称": "简介-TBufPool-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0121.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "BlockReduceMax-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0082.html",
      "功能说明": "对每个datablock内所有元素求最大值。归约指令的总体介绍请参考如何使用归约指令。 对每个datablock内所有元素求最大值。归约指令的总体介绍请参考如何使用归约指令。 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证16字节对齐（针对half数据类型），32字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 repeat 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 每个repeat(8个datablock)归约后，得到8个元素，所以输入类型为half类型时，RepStride单位为16Byte；输入类型为float类型时，RepStride单位为32Byte。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考dataBlockStride。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考repeatStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void BlockReduceMax(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal,const int32_t repeat, const uint64_t mask[], const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证16字节对齐（针对half数据类型），32字节对齐（针对float数据类型）。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "repeat",
          "类型": "输入",
          "说明": "迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "dstRepStride",
          "类型": "输入",
          "说明": "目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 每个repeat(8个datablock)归约后，得到8个元素，所以输入类型为half类型时，RepStride单位为16Byte；输入类型为float类型时，RepStride单位为32Byte。 注意，此参数值 Atlas 训练系列产品 不支持配置0。"
        },
        {
          "参数名": "srcBlkStride",
          "类型": "输入",
          "说明": "单次迭代内datablock的地址步长。详细说明请参考dataBlockStride。"
        },
        {
          "参数名": "srcRepStride",
          "类型": "输入",
          "说明": "源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考repeatStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6\n1 2 3 4 5 6",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "通用约束",
        "归约指令"
      ],
      "版本信息": "8.781"
    },
    {
      "API名称": "GetBlockIdx-系统变量访问-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0185.html",
      "功能说明": "获取当前核的index，用于代码内部的多核逻辑控制及多核偏移量计算等。 获取当前核的index，用于代码内部的多核逻辑控制及多核偏移量计算等。 GetBlockIdx为一个系统内置函数，返回当前核的index。",
      "函数原型": "__aicore__ inline void Init(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)",
      "参数说明": [],
      "返回值": "当前核的index，index的范围为[0, 用户配置的BlockDim数量 - 1]",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18",
      "约束限制": "GetBlockIdx为一个系统内置函数，返回当前核的index。",
      "相关接口": [
        "系统变量访问"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "ToFloat-标量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0022.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetArchVersion-系统变量访问-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0187.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetMMLayoutTransform-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0260.html",
      "功能说明": "设置Mmad计算时优先通过M/N中的哪个方向。 设置Mmad计算时优先通过M/N中的哪个方向。 表1 参数说明参数名 输入/输出 描述 mmLayoutMode 输入 控制Mmad 优先通过M/N的哪个方向，bool型，支持如下两种取值：true：代表CUBE将首先通过N方向，然后通过M方向产生结果。false：代表CUBE将首先通过M方向，然后通过N方向生成结果。",
      "函数原型": "__aicore__ inline void SetMMLayoutTransform(bool mmLayoutMode)",
      "参数说明": [
        {
          "参数名": "mmLayoutMode",
          "类型": "输入",
          "说明": "控制Mmad 优先通过M/N的哪个方向，bool型，支持如下两种取值：true：代表CUBE将首先通过N方向，然后通过M方向产生结果。false：代表CUBE将首先通过M方向，然后通过N方向生成结果。"
        }
      ],
      "返回值": "无",
      "调用示例": "__aicore__ inline void SetMMLayoutTransform(bool mmLayoutMode)\nbool mmLayoutMode = true; AscendC::SetMMLayoutTransform(mmLayoutMode);",
      "约束限制": "",
      "相关接口": [
        "矩阵计算(ISASI)"
      ],
      "版本信息": ""
    },
    {
      "API名称": "SetDeqScale-量化设置-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0099.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Axpy-Axpy-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0585.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ASCENDC_TPL_SEL_PARAM-Tiling数据结构注册-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00057.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "assert-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0194.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ReduceMax-ReduceMax-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10055.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Gatherb(ISASI)-数据分散/数据收集-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0234.html",
      "功能说明": "给定一个输入的张量和一个地址偏移张量，本接口根据偏移地址按照DataBlock的粒度将输入张量收集到结果张量中。 给定一个输入的张量和一个地址偏移张量，本接口根据偏移地址按照DataBlock的粒度将输入张量收集到结果张量中。 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/uint32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/uint32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/float/int32_t/uint32_t/bfloat16_t/int64_t 表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 offsetLocal 输入 每个datablock在源操作数中对应的地址偏移。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 该偏移量是相对于srcLocal的基地址而言的。每个元素值要大于等于0，单位为字节；且需要保证偏移后的地址满足32字节对齐。 repeatTimes 输入 重复迭代次数，每次迭代完成8个datablock的数据收集，数据范围：repeatTimes∈（0,255]。 repeatParams 输入 用于控制指令迭代的相关参数。 类型为GatherRepeatParams，具体定义可参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_gather.h。${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 其中dstBlkStride、dstRepStride支持用户配置，参数说明参考表3。 表3 GatherRepeatParams结构体参数说明 参数名称 含义 dstBlkStride 单次迭代内，矢量目的操作数不同datablock间的地址步长。 dstRepStride 相邻迭代间，矢量目的操作数相同datablock间的地址步长。 blockNumber 预留参数。为后续的功能做保留，开发者暂时无需关注，使用默认值即可。 src0BlkStride src1BlkStride src0RepStride src1RepStride repeatStrideMode strideSizeMode",
      "函数原型": "template <typename T> __aicore__ inline void Gatherb(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<uint32_t>& offsetLocal, const uint8_t repeatTimes, const GatherRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/uint32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/uint32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/float/int32_t/uint32_t/bfloat16_t/int64_t"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "offsetLocal",
          "类型": "输入",
          "说明": "每个datablock在源操作数中对应的地址偏移。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 该偏移量是相对于srcLocal的基地址而言的。每个元素值要大于等于0，单位为字节；且需要保证偏移后的地址满足32字节对齐。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数，每次迭代完成8个datablock的数据收集，数据范围：repeatTimes∈（0,255]。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "用于控制指令迭代的相关参数。 类型为GatherRepeatParams，具体定义可参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_gather.h。${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 其中dstBlkStride、dstRepStride支持用户配置，参数说明参考表3。"
        },
        {
          "参数名": "dstBlkStride",
          "类型": "",
          "说明": "单次迭代内，矢量目的操作数不同datablock间的地址步长。"
        },
        {
          "参数名": "dstRepStride",
          "类型": "",
          "说明": "相邻迭代间，矢量目的操作数相同datablock间的地址步长。"
        },
        {
          "参数名": "blockNumber",
          "类型": "",
          "说明": "预留参数。为后续的功能做保留，开发者暂时无需关注，使用默认值即可。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "数据分散/数据收集"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "SetFixPipeConfig(ISASI)-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0252.html",
      "功能说明": "DataCopy（CO1->GM、CO1->A1）过程中进行随路量化时，通过调用该接口设置量化流程中tensor量化参数。 DataCopy（CO1->GM、CO1->A1）过程中进行随路量化时，通过调用该接口设置量化流程中tensor量化参数。 表1 模板参数说明参数名 描述 T 操作数的数据类型。 setRelu 针对设置一个tensor的情况，当setRelu为true时，设置reluPreTensor；反之设置quantPreTensor。当前仅支持设置为false。 表2 参数说明参数名称 输入/输出 含义 reluPre 输入 源操作数，relu tensor，类型为LocalTensor，支持的TPosition为C2PIPE2GM。 预留参数，暂未启用，为后续的功能扩展做保留，传入一个空LocalTensor即可。 quantPre 输入 源操作数，quant tensor，量化操作时参与计算的tensor，类型为LocalTensor，支持的TPosition为C2PIPE2GM。 isUnitFlag 输入 UnitFlag配置项，类型为bool。预留参数，暂未启用，为后续的功能扩展做保留，保持默认值false即可。 preTensor 输入 支持设置一个Tensor，通过开关控制是relu Tensor还是quantTensor，支持的TPosition为C2PIPE2GM。当前仅支持传入quantTensor。",
      "函数原型": "template <typename T> __aicore__ inline void SetFixPipeConfig(const LocalTensor<T> &reluPre, const LocalTensor<T> &quantPre, bool isUnitFlag = false)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。"
        },
        {
          "参数名": "setRelu",
          "类型": "",
          "说明": "针对设置一个tensor的情况，当setRelu为true时，设置reluPreTensor；反之设置quantPreTensor。当前仅支持设置为false。"
        },
        {
          "参数名": "reluPre",
          "类型": "输入",
          "说明": "源操作数，relu tensor，类型为LocalTensor，支持的TPosition为C2PIPE2GM。 预留参数，暂未启用，为后续的功能扩展做保留，传入一个空LocalTensor即可。"
        },
        {
          "参数名": "quantPre",
          "类型": "输入",
          "说明": "源操作数，quant tensor，量化操作时参与计算的tensor，类型为LocalTensor，支持的TPosition为C2PIPE2GM。"
        },
        {
          "参数名": "isUnitFlag",
          "类型": "输入",
          "说明": "UnitFlag配置项，类型为bool。预留参数，暂未启用，为后续的功能扩展做保留，保持默认值false即可。"
        },
        {
          "参数名": "preTensor",
          "类型": "输入",
          "说明": "支持设置一个Tensor，通过开关控制是relu Tensor还是quantTensor，支持的TPosition为C2PIPE2GM。当前仅支持传入quantTensor。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8\n1 2 3 4 5 6 7 8",
      "约束限制": "",
      "相关接口": [
        "DataCopy",
        "数据搬运"
      ],
      "版本信息": ""
    },
    {
      "API名称": "CheckLocalMemoryIA-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0261.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "DEVICE_IMPL_OP_OPTILING-Tiling数据结构注册-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00060.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Round-Round-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0581.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Muls-标量双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0055.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SimpleSoftMax-SoftMax-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0755.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Lgamma-Lgamma-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0593.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ReduceAny-ReduceAny-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10142.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Cosh-Cosh-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0528.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetDataBlockSizeInBytes-系统变量访问-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0186.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetUserWorkspace-workspace-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0172.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Frac-Frac-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0540.html",
      "功能说明": "按元素做取小数计算。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： Frac(-258.41888) = -0.41888428 Frac(5592.625) = 0.625 按元素做取小数计算。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： Frac(-258.41888) = -0.41888428 Frac(5592.625) = 0.625 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Frac内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetFracMaxMinTmpSize。 calCount 输入 参与计算的元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void Frac(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Frac内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetFracMaxMinTmpSize。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66",
      "约束限制": "",
      "相关接口": [
        "GetFracMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "Frac"
      ],
      "版本信息": "258.41888"
    },
    {
      "API名称": "Transpose-数据转换-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0199.html",
      "功能说明": "用于实现16*16的二维矩阵数据块转置或者[N,C,H,W]与[N,H,W,C]数据格式互相转换。 用于实现16*16的二维矩阵数据块转置或者[N,C,H,W]与[N,H,W,C]数据格式互相转换。 表1 模板参数说明参数名 描述 T 操作数的数据类型。 普通转置:Atlas 训练系列产品，支持的数据类型为：uint16_t/int16_t/half Atlas 推理系列产品AI Core，支持的数据类型为：uint16_t/int16_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：uint16_t/int16_t/half Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：uint16_t/int16_t/half Atlas 200I/500 A2 推理产品，支持的数据类型为：uint16_t/int16_t/half 增强转置:transposeType为TRANSPOSE_ND2ND_B16：Atlas 推理系列产品AI Core，支持的数据类型为：uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：uint16_t Atlas 200I/500 A2 推理产品，支持的数据类型为：uint16_t transposeType为TRANSPOSE_NCHW2NHWC或TRANSPOSE_NHWC2NCHW：Atlas 推理系列产品AI Core，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float 表2 接口参数说明参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与dstLocal保持一致。 sharedTmpBuffer 输入 共享的临时Buffer，sharedTmpBuffer的大小参考表4。 transposeParams 输入 控制Transpose的数据结构。结构体内包含：输入的shape信息和transposeType参数。该数据结构的定义请参考表3。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16struct TransposeParamsExt { __aicore__ TransposeParamsExt() {} __aicore__ TransposeParamsExt(const uint16_t nSizeIn, const uint16_t cSizeIn, const uint16_t hSizeIn, const uint16_t wSizeIn, const TransposeType transposeTypeIn) : nSize(nSizeIn), cSize(cSizeIn), hSize(hSizeIn), wSize(wSizeIn), transposeType(transposeTypeIn) {} uint16_t nSize = 0; uint16_t cSize = 0; uint16_t hSize = 0; uint16_t wSize = 0; TransposeType transposeType = TransposeType::TRANSPOSE_ND2ND_B16; }; 表3 TransposeParamsExt结构体内参数说明参数名称 含义 nSize n轴长度。默认值为0。 二维矩阵数据块转置，无需传入，传入数值无效。[N,C,H,W]与[N,H,W,C]数据格式互相转换，取值范围：nSize∈[0, 65535]。 cSize c轴长度。默认值为0。 二维矩阵数据块转置，无需传入，传入数值无效。 [N,C,H,W]与[N,H,W,C]数据格式互相转换，取值范围：cSize∈[0, 4095] hSize h轴长度。默认值为0。 二维矩阵数据块转置，固定传入16。 [N,C,H,W]与[N,H,W,C]数据格式互相转换，取值范围：hSize * wSize ∈[0, 4095]，hSize * wSize * sizeof(T)需要保证32B对齐。 wSize w轴长度。默认值为0。 二维矩阵数据块转置，固定传入16。 [N,C,H,W]与[N,H,W,C]数据格式互相转换，取值范围：hSize * wSize ∈[0, 4095]，hSize * wSize * sizeof(T)需要保证32B对齐。 transposeType 数据排布及reshape的类型，类型为TransposeType枚举类。默认值为TRANSPOSE_ND2ND_B16。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15enum class TransposeType : uint8_t { TRANSPOSE_TYPE_NONE, // API不做任何处理 TRANSPOSE_NZ2ND_0213, // 当前不支持 TRANSPOSE_NZ2NZ_0213, // 当前不支持 TRANSPOSE_NZ2NZ_012_WITH_N, // 当前不支持 TRANSPOSE_NZ2ND_012_WITH_N, // 当前不支持 TRANSPOSE_NZ2ND_012_WITHOUT_N, // 当前不支持 TRANSPOSE_NZ2NZ_012_WITHOUT_N, // 当前不支持 TRANSPOSE_ND2ND_ONLY, // 当前不支持 TRANSPOSE_ND_UB_GM, // 当前不支持 TRANSPOSE_GRAD_ND_UB_GM, // 当前不支持 TRANSPOSE_ND2ND_B16, // [16,16]二维矩阵转置 TRANSPOSE_NCHW2NHWC, // [N,C,H,W]->[N,H,W,C]， TRANSPOSE_NHWC2NCHW // [N,H,W,C]->[N,C,H,W] }; 表4 增强转置接口sharedTmpBuffer所需的大小transposeType sharedTmpBuffer所需的大小 TRANSPOSE_ND2ND_B16 不需要临时Buffer。 TRANSPOSE_NCHW2NHWC 针对以下型号： Atlas 推理系列产品AI Core 不需要临时Buffer。 针对以下型号： Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件Atlas A3 训练系列产品/Atlas A3 推理系列产品 临时Buffer的大小按照下述计算规则（伪代码）进行计算。 1 2 3auto h0 = 16; // 当数据类型的位宽为8时，h0 = 32；其他情况下，h0 = 16 auto w0 = 32 / sizeof(type); // type代表数据类型 auto tmpBufferSize = (cSize + 2) * h0 * w0 * sizeof(type); TRANSPOSE_NHWC2NCHW 针对以下型号： Atlas 推理系列产品AI Core 不需要临时Buffer。 针对以下型号： Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件Atlas A3 训练系列产品/Atlas A3 推理系列产品 临时Buffer的大小按照下述计算规则（伪代码）进行计算。 1 2 3auto h0 = 16; // 当数据类型的位宽为8时，h0 = 32；其他情况下，h0 = 16 auto w0 = 32 / sizeof(type); // type代表数据类型 auto tmpBufferSize = (cSize * 2 + 1) * h0 * w0 * sizeof(type);",
      "函数原型": "template <typename T> __aicore__ inline void Transpose(const LocalTensor<T>& dstLocal, const LocalTensor<T> &srcLocal, const LocalTensor<uint8_t> &sharedTmpBuffer, const TransposeParamsExt &transposeParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 普通转置:Atlas 训练系列产品，支持的数据类型为：uint16_t/int16_t/half Atlas 推理系列产品AI Core，支持的数据类型为：uint16_t/int16_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：uint16_t/int16_t/half Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：uint16_t/int16_t/half Atlas 200I/500 A2 推理产品，支持的数据类型为：uint16_t/int16_t/half 增强转置:transposeType为TRANSPOSE_ND2ND_B16：Atlas 推理系列产品AI Core，支持的数据类型为：uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：uint16_t Atlas 200I/500 A2 推理产品，支持的数据类型为：uint16_t transposeType为TRANSPOSE_NCHW2NHWC或TRANSPOSE_NHWC2NCHW：Atlas 推理系列产品AI Core，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与dstLocal保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "共享的临时Buffer，sharedTmpBuffer的大小参考表4。"
        },
        {
          "参数名": "transposeParams",
          "类型": "输入",
          "说明": "控制Transpose的数据结构。结构体内包含：输入的shape信息和transposeType参数。该数据结构的定义请参考表3。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16struct TransposeParamsExt { __aicore__ TransposeParamsExt() {} __aicore__ TransposeParamsExt(const uint16_t nSizeIn, const uint16_t cSizeIn, const uint16_t hSizeIn, const uint16_t wSizeIn, const TransposeType transposeTypeIn) : nSize(nSizeIn), cSize(cSizeIn), hSize(hSizeIn), wSize(wSizeIn), transposeType(transposeTypeIn) {} uint16_t nSize = 0; uint16_t cSize = 0; uint16_t hSize = 0; uint16_t wSize = 0; TransposeType transposeType = TransposeType::TRANSPOSE_ND2ND_B16; };"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16",
          "类型": "",
          "说明": "struct TransposeParamsExt { __aicore__ TransposeParamsExt() {} __aicore__ TransposeParamsExt(const uint16_t nSizeIn, const uint16_t cSizeIn, const uint16_t hSizeIn, const uint16_t wSizeIn, const TransposeType transposeTypeIn) : nSize(nSizeIn), cSize(cSizeIn), hSize(hSizeIn), wSize(wSizeIn), transposeType(transposeTypeIn) {} uint16_t nSize = 0; uint16_t cSize = 0; uint16_t hSize = 0; uint16_t wSize = 0; TransposeType transposeType = TransposeType::TRANSPOSE_ND2ND_B16; };"
        },
        {
          "参数名": "nSize",
          "类型": "",
          "说明": "n轴长度。默认值为0。 二维矩阵数据块转置，无需传入，传入数值无效。[N,C,H,W]与[N,H,W,C]数据格式互相转换，取值范围：nSize∈[0, 65535]。"
        },
        {
          "参数名": "cSize",
          "类型": "",
          "说明": "c轴长度。默认值为0。 二维矩阵数据块转置，无需传入，传入数值无效。 [N,C,H,W]与[N,H,W,C]数据格式互相转换，取值范围：cSize∈[0, 4095]"
        },
        {
          "参数名": "hSize",
          "类型": "",
          "说明": "h轴长度。默认值为0。 二维矩阵数据块转置，固定传入16。 [N,C,H,W]与[N,H,W,C]数据格式互相转换，取值范围：hSize * wSize ∈[0, 4095]，hSize * wSize * sizeof(T)需要保证32B对齐。"
        },
        {
          "参数名": "wSize",
          "类型": "",
          "说明": "w轴长度。默认值为0。 二维矩阵数据块转置，固定传入16。 [N,C,H,W]与[N,H,W,C]数据格式互相转换，取值范围：hSize * wSize ∈[0, 4095]，hSize * wSize * sizeof(T)需要保证32B对齐。"
        },
        {
          "参数名": "transposeType",
          "类型": "数据排布及reshape的类型，类型为TransposeType枚举类。默认值为TRANSPOSE_ND2ND_B16。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15enum class TransposeType : uint8_t { TRANSPOSE_TYPE_NONE, // API不做任何处理 TRANSPOSE_NZ2ND_0213, // 当前不支持 TRANSPOSE_NZ2NZ_0213, // 当前不支持 TRANSPOSE_NZ2NZ_012_WITH_N, // 当前不支持 TRANSPOSE_NZ2ND_012_WITH_N, // 当前不支持 TRANSPOSE_NZ2ND_012_WITHOUT_N, // 当前不支持 TRANSPOSE_NZ2NZ_012_WITHOUT_N, // 当前不支持 TRANSPOSE_ND2ND_ONLY, // 当前不支持 TRANSPOSE_ND_UB_GM, // 当前不支持 TRANSPOSE_GRAD_ND_UB_GM, // 当前不支持 TRANSPOSE_ND2ND_B16, // [16,16]二维矩阵转置 TRANSPOSE_NCHW2NHWC, // [N,C,H,W]->[N,H,W,C]， TRANSPOSE_NHWC2NCHW // [N,H,W,C]->[N,C,H,W] };",
          "说明": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15",
          "类型": "",
          "说明": "enum class TransposeType : uint8_t { TRANSPOSE_TYPE_NONE, // API不做任何处理 TRANSPOSE_NZ2ND_0213, // 当前不支持 TRANSPOSE_NZ2NZ_0213, // 当前不支持 TRANSPOSE_NZ2NZ_012_WITH_N, // 当前不支持 TRANSPOSE_NZ2ND_012_WITH_N, // 当前不支持 TRANSPOSE_NZ2ND_012_WITHOUT_N, // 当前不支持 TRANSPOSE_NZ2NZ_012_WITHOUT_N, // 当前不支持 TRANSPOSE_ND2ND_ONLY, // 当前不支持 TRANSPOSE_ND_UB_GM, // 当前不支持 TRANSPOSE_GRAD_ND_UB_GM, // 当前不支持 TRANSPOSE_ND2ND_B16, // [16,16]二维矩阵转置 TRANSPOSE_NCHW2NHWC, // [N,C,H,W]->[N,H,W,C]， TRANSPOSE_NHWC2NCHW // [N,H,W,C]->[N,C,H,W] };"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "通用约束",
        "数据转换"
      ],
      "版本信息": ""
    },
    {
      "API名称": "SetFixPipeAddr(ISASI)-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0256.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetSysWorkSpacePtr-workspace-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0170.html",
      "功能说明": "获取系统workspace指针。部分高阶API如Matmul需要使用系统workspace，相关接口需要传入系统workspace指针，此时可以通过该接口获取。使用系统workspace时，host侧开发者需要自行申请系统workspace的空间，其预留空间大小可以通过GetLibApiWorkSpaceSize接口获取。具体内容请参考如何使用workspace。 获取系统workspace指针。部分高阶API如Matmul需要使用系统workspace，相关接口需要传入系统workspace指针，此时可以通过该接口获取。使用系统workspace时，host侧开发者需要自行申请系统workspace的空间，其预留空间大小可以通过GetLibApiWorkSpaceSize接口获取。具体内容请参考如何使用workspace。",
      "函数原型": "__aicore__ inline __gm__ uint8_t* __gm__ GetSysWorkSpacePtr()",
      "参数说明": [],
      "返回值": "系统workspace指针。",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13\n1 2 3 4 5 6 7 8 9 10 11 12 13",
      "约束限制": "",
      "相关接口": [
        "GetLibApiWorkSpaceSize",
        "workspace"
      ],
      "版本信息": ""
    },
    {
      "API名称": "GET_TILING_DATA_MEMBER-Kernel Tiling-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0216.html",
      "功能说明": "用于获取tiling结构体的成员变量。 用于获取tiling结构体的成员变量。 参数 输入/输出 说明 struct_name 输入 指定的结构体名称。 mem_name 输入 指定的成员变量名称。 tiling_data 输出 返回指定Tiling结构体的成员变量。 tiling_arg 输入 此参数为算子入口函数处传入的tiling参数。",
      "函数原型": "void add_custom(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *z, __gm__ uint8_t *tiling) {",
      "参数说明": [
        {
          "参数名": "struct_name",
          "类型": "输入",
          "说明": "指定的结构体名称。"
        },
        {
          "参数名": "mem_name",
          "类型": "输入",
          "说明": "指定的成员变量名称。"
        },
        {
          "参数名": "tiling_data",
          "类型": "输出",
          "说明": "返回指定Tiling结构体的成员变量。"
        },
        {
          "参数名": "tiling_arg",
          "类型": "输入",
          "说明": "此参数为算子入口函数处传入的tiling参数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13\n1 2 3 4 5 6 7 8 9 10 11 12 13",
      "约束限制": "",
      "相关接口": [
        "Kernel Tiling"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Brcb-数据填充-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0089.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetSubBlockNum(ISASI)-系统变量访问-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0280.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "WriteSpmBuffer-SPM Buffer-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0167.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Concat-Sort-排序-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0839.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "FasterGelu-Gelu-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0772.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GatherMask-选择指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0071.html",
      "功能说明": "以内置固定模式对应的二进制或者用户自定义输入的Tensor数值对应的二进制为gather mask（数据收集的掩码），从源操作数中选取元素写入目的操作数中。 以内置固定模式对应的二进制或者用户自定义输入的Tensor数值对应的二进制为gather mask（数据收集的掩码），从源操作数中选取元素写入目的操作数中。 表1 模板参数说明参数名称 含义 T 源操作数src0Local和目的操作数dstLocal的数据类型。 Atlas 推理系列产品AI Core，支持的数据类型为：half/uint16_t/int16_t/float/uint32_t/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t/uint16_t/int16_t/float/uint32_t/int32_t Atlas 200I/500 A2 推理产品，支持的数据类型为：half/uint16_t/int16_t/float/uint32_t/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t/uint16_t/int16_t/float/uint32_t/int32_t U 用户自定义模式下src1Pattern的数据类型。支持的数据类型为uint16_t/uint32_t。 当目的操作数数据类型为half/uint16_t/int16_t时，src1Pattern应为uint16_t数据类型。当目的操作数数据类型为float/uint32_t/int32_t时，src1Pattern应为uint32_t数据类型。 mode 预留参数，为后续功能做预留，当前提供默认值，用户无需设置该参数。 表2 参数说明参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 src1Pattern 输入 gather mask（数据收集的掩码），分为内置固定模式和用户自定义模式两种，根据内置固定模式对应的二进制或者用户自定义输入的Tensor数值对应的二进制从源操作数中选取元素写入目的操作数中。1为选取，0为不选取。 内置固定模式：src1Pattern数据类型为uint8_t，取值范围为[1,7]，所有repeat迭代使用相同的gather mask。不支持配置src1RepeatStride。1：01010101…0101 # 每个repeat取偶数索引元素2：10101010…1010 # 每个repeat取奇数索引元素3：00010001…0001 # 每个repeat内每四个元素取第一个元素4：00100010…0010 # 每个repeat内每四个元素取第二个元素，5：01000100…0100 # 每个repeat内每四个元素取第三个元素6：10001000…1000 # 每个repeat内每四个元素取第四个元素7：11111111...1111 # 每个repeat内取全部元素 Atlas 推理系列产品AI Core支持模式1-6 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件支持模式1-7 Atlas A3 训练系列产品/Atlas A3 推理系列产品支持模式1-7 Atlas 200I/500 A2 推理产品支持模式1-7 用户自定义模式：src1Pattern数据类型为LocalTensor，迭代间间隔由src1RepeatStride决定， 迭代内src1Pattern连续消耗。 reduceMode 输入 用于选择mask参数模式，数据类型为bool，支持如下取值。 false：Normal模式。该模式下，每次repeat操作256Bytes数据，总的数据计算量为repeatTimes * 256Bytes。mask参数无效，建议设置为0。按需配置repeatTimes、src0BlockStride、src0RepeatStride参数。支持src1Pattern配置为内置固定模式或用户自定义模式。用户自定义模式下可根据实际情况配置src1RepeatStride。 true：Counter模式。根据mask等参数含义的不同，该模式有以下两种配置方式：配置方式一：每次repeat操作mask个元素，总的数据计算量为repeatTimes * mask个元素。mask值配置为每一次repeat计算的元素个数。按需配置repeatTimes、src0BlockStride、src0RepeatStride参数。支持src1Pattern配置为内置固定模式或用户自定义模式。用户自定义模式下可根据实际情况配置src1RepeatStride。 配置方式二：总的数据计算量为mask个元素。mask配置为总的数据计算量。repeatTimes值不生效，指令的迭代次数由源操作数和mask共同决定。按需配置src0BlockStride、src0RepeatStride参数。支持src1Pattern配置为内置固定模式或用户自定义模式。用户自定义模式下可根据实际情况配置src1RepeatStride。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持配置方式一 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持配置方式一 Atlas 200I/500 A2 推理产品，支持配置方式一 Atlas 推理系列产品AI Core，支持配置方式二 mask 输入 用于控制每次迭代内参与计算的元素。根据reduceMode，分为两种模式： Normal模式：mask无效，建议设置为0。Counter模式：取值范围[1, 232 – 1]。不同的版本型号Counter模式下，mask参数表示含义不同。具体配置规则参考上文reduceMode参数描述。 gatherMaskParams 输入 控制操作数地址步长的数据结构，GatherMaskParams类型。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_gather.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 具体参数说明表3。 rsvdCnt 输出 该条指令筛选后保留下来的元素计数，对应dstLocal中有效元素个数，数据类型为uint64_t。 表3 GatherMaskParams结构体参数说明参数名称 含义 repeatTimes 迭代次数。 src0BlockStride 用于设置src0同一迭代不同DataBlock间的地址步长。 src0RepeatStride 用于设置src0相邻迭代间的地址步长。 src1RepeatStride 用于设置src1相邻迭代间的地址步长。",
      "函数原型": "template <typename T, typename U, GatherMaskMode mode = defaultGatherMaskMode> __aicore__ inline void GatherMask(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<U>& src1Pattern, const bool reduceMode, const uint32_t mask, const GatherMaskParams& gatherMaskParams, uint64_t& rsvdCnt)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "源操作数src0Local和目的操作数dstLocal的数据类型。 Atlas 推理系列产品AI Core，支持的数据类型为：half/uint16_t/int16_t/float/uint32_t/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t/uint16_t/int16_t/float/uint32_t/int32_t Atlas 200I/500 A2 推理产品，支持的数据类型为：half/uint16_t/int16_t/float/uint32_t/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t/uint16_t/int16_t/float/uint32_t/int32_t"
        },
        {
          "参数名": "U",
          "类型": "",
          "说明": "用户自定义模式下src1Pattern的数据类型。支持的数据类型为uint16_t/uint32_t。 当目的操作数数据类型为half/uint16_t/int16_t时，src1Pattern应为uint16_t数据类型。当目的操作数数据类型为float/uint32_t/int32_t时，src1Pattern应为uint32_t数据类型。"
        },
        {
          "参数名": "mode",
          "类型": "",
          "说明": "预留参数，为后续功能做预留，当前提供默认值，用户无需设置该参数。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "src1Pattern",
          "类型": "输入",
          "说明": "gather mask（数据收集的掩码），分为内置固定模式和用户自定义模式两种，根据内置固定模式对应的二进制或者用户自定义输入的Tensor数值对应的二进制从源操作数中选取元素写入目的操作数中。1为选取，0为不选取。 内置固定模式：src1Pattern数据类型为uint8_t，取值范围为[1,7]，所有repeat迭代使用相同的gather mask。不支持配置src1RepeatStride。1：01010101…0101 # 每个repeat取偶数索引元素2：10101010…1010 # 每个repeat取奇数索引元素3：00010001…0001 # 每个repeat内每四个元素取第一个元素4：00100010…0010 # 每个repeat内每四个元素取第二个元素，5：01000100…0100 # 每个repeat内每四个元素取第三个元素6：10001000…1000 # 每个repeat内每四个元素取第四个元素7：11111111...1111 # 每个repeat内取全部元素 Atlas 推理系列产品AI Core支持模式1-6 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件支持模式1-7 Atlas A3 训练系列产品/Atlas A3 推理系列产品支持模式1-7 Atlas 200I/500 A2 推理产品支持模式1-7 用户自定义模式：src1Pattern数据类型为LocalTensor，迭代间间隔由src1RepeatStride决定， 迭代内src1Pattern连续消耗。"
        },
        {
          "参数名": "reduceMode",
          "类型": "输入",
          "说明": "用于选择mask参数模式，数据类型为bool，支持如下取值。 false：Normal模式。该模式下，每次repeat操作256Bytes数据，总的数据计算量为repeatTimes * 256Bytes。mask参数无效，建议设置为0。按需配置repeatTimes、src0BlockStride、src0RepeatStride参数。支持src1Pattern配置为内置固定模式或用户自定义模式。用户自定义模式下可根据实际情况配置src1RepeatStride。 true：Counter模式。根据mask等参数含义的不同，该模式有以下两种配置方式：配置方式一：每次repeat操作mask个元素，总的数据计算量为repeatTimes * mask个元素。mask值配置为每一次repeat计算的元素个数。按需配置repeatTimes、src0BlockStride、src0RepeatStride参数。支持src1Pattern配置为内置固定模式或用户自定义模式。用户自定义模式下可根据实际情况配置src1RepeatStride。 配置方式二：总的数据计算量为mask个元素。mask配置为总的数据计算量。repeatTimes值不生效，指令的迭代次数由源操作数和mask共同决定。按需配置src0BlockStride、src0RepeatStride参数。支持src1Pattern配置为内置固定模式或用户自定义模式。用户自定义模式下可根据实际情况配置src1RepeatStride。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持配置方式一 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持配置方式一 Atlas 200I/500 A2 推理产品，支持配置方式一 Atlas 推理系列产品AI Core，支持配置方式二"
        },
        {
          "参数名": "mask",
          "类型": "输入",
          "说明": "用于控制每次迭代内参与计算的元素。根据reduceMode，分为两种模式： Normal模式：mask无效，建议设置为0。Counter模式：取值范围[1, 232 – 1]。不同的版本型号Counter模式下，mask参数表示含义不同。具体配置规则参考上文reduceMode参数描述。"
        },
        {
          "参数名": "gatherMaskParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的数据结构，GatherMaskParams类型。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_gather.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 具体参数说明表3。"
        },
        {
          "参数名": "rsvdCnt",
          "类型": "输出",
          "说明": "该条指令筛选后保留下来的元素计数，对应dstLocal中有效元素个数，数据类型为uint64_t。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "",
          "说明": "迭代次数。"
        },
        {
          "参数名": "src0BlockStride",
          "类型": "",
          "说明": "用于设置src0同一迭代不同DataBlock间的地址步长。"
        },
        {
          "参数名": "src0RepeatStride",
          "类型": "",
          "说明": "用于设置src0相邻迭代间的地址步长。"
        },
        {
          "参数名": "src1RepeatStride",
          "类型": "",
          "说明": "用于设置src1相邻迭代间的地址步长。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "通用约束",
        "选择指令"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "index_sequence-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10106.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Duplicate-数据填充-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0088.html",
      "功能说明": "将一个变量或立即数复制多次并填充到向量中。 将一个变量或立即数复制多次并填充到向量中。 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float/bfloat16_t Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float Atlas 训练系列产品 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 scalarValue 输入 被复制的源操作数，支持输入变量和立即数，数据类型需与dstLocal中元素的数据类型保持一致。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 矢量计算单元，每次读取连续的8个datablock（每个block32Bytes，共256Bytes）数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 dstBlockStride 输入 单次迭代内，矢量目的操作数不同datablock间地址步长。 dstRepeatStride 输入 相邻迭代间，矢量目的操作数相同datablock地址步长。",
      "函数原型": "void Duplicate(const LocalTensor<T>& dstLocal, const T& scalarValue, uint64_t mask[], const uint8_t repeatTimes, const uint16_t dstBlockStride, const uint8_t dstRepeatStride)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float/bfloat16_t Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float Atlas 训练系列产品 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "scalarValue",
          "类型": "输入",
          "说明": "被复制的源操作数，支持输入变量和立即数，数据类型需与dstLocal中元素的数据类型保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "矢量计算单元，每次读取连续的8个datablock（每个block32Bytes，共256Bytes）数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。"
        },
        {
          "参数名": "dstBlockStride",
          "类型": "输入",
          "说明": "单次迭代内，矢量目的操作数不同datablock间地址步长。"
        },
        {
          "参数名": "dstRepeatStride",
          "类型": "输入",
          "说明": "相邻迭代间，矢量目的操作数相同datablock地址步长。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6\n1 2 3 4 5 6",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "通用约束",
        "数据填充"
      ],
      "版本信息": "18.0"
    },
    {
      "API名称": "REGISTER_TILING_DEFAULT-Kernel Tiling-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00003.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Cos-Cos-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0508.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetBlockNum-系统变量访问-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0184.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "CrossCoreWaitFlag(ISASI)-核间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0274.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Swish-Swish-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0783.html",
      "功能说明": "在神经网络中，Swish是一个重要的激活函数。计算公式如下，其中β为常数： 在神经网络中，Swish是一个重要的激活函数。计算公式如下，其中β为常数： 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcLocal 输入 源操作数。 源操作数的数据类型需要与目的操作数保持一致。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 dataSize 输入 实际计算数据元素个数。 scalarValue 输入 激活函数中的β参数。支持的数据类型为：half/float β参数的数据类型需要与源操作数和目的操作数保持一致。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void Swish(const LocalTensor<T> &dstLocal, const LocalTensor<T> &srcLocal, uint32_t dataSize, const T &scalarValue)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 源操作数的数据类型需要与目的操作数保持一致。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "dataSize",
          "类型": "输入",
          "说明": "实际计算数据元素个数。"
        },
        {
          "参数名": "scalarValue",
          "类型": "输入",
          "说明": "激活函数中的β参数。支持的数据类型为：half/float β参数的数据类型需要与源操作数和目的操作数保持一致。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "通用约束",
        "Swish"
      ],
      "版本信息": "1.702"
    },
    {
      "API名称": "BlockReduceMin-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0083.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetMrgSortResult-排序组合(ISASI)-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0233.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "AscendQuant-量化反量化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0818.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetSubBlockIdx(ISASI)-系统变量访问-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0281.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetTaskRation-系统变量访问-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0188.html",
      "功能说明": "适用于Cube/Vector分离架构，用来获取Cube/Vector的配比。 适用于Cube/Vector分离架构，用来获取Cube/Vector的配比。",
      "函数原型": "__aicore__ inline int64_t GetTaskRation()",
      "参数说明": [],
      "返回值": "Cube/Vector的配比：",
      "调用示例": "__aicore__ inline int64_t GetTaskRation()\nuint64_t ratio = AscendC::GetTaskRation(); // 在分离架构融合算子场景，可以查看Cube/Vector的配比 AscendC::PRINTF(\"task ratio is %u\", ratio);",
      "约束限制": "",
      "相关接口": [
        "系统变量访问"
      ],
      "版本信息": ""
    },
    {
      "API名称": "GetStoreAtomicConfig(ISASI)-原子操作-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0287.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Atan-Atan-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0516.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Sort32-排序组合(ISASI)-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0231.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Ceil-Ceil-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0572.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SoftmaxFlashV2-SoftMax-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0758.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "使用说明-GroupBarrier-资源管理(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0301.html",
      "功能说明": "当同一个CubeResGroupHandle中的两个AIV任务之间存在依赖关系时，可以使用GroupBarrier控制同步。假设一组AIV A做完任务x以后，另外一组AIV B才可以开始后续业务，称AIV A组为Arrive组，AIV B组为Wait组。 基于GroupBarrier的组同步使用步骤如下： 创建GroupBarrier。被等待的AIV调用Arrive，需要等待的AIV调用Wait。 下文仅提供示例代码片段，更多完整样例请参考GroupBarrier样例。 创建GroupBarrier。1 2 3constexpr int32_t ARRIVE_NUM = 2; // Arrive组的AIV个数 constexpr int32_t WAIT_NUM = 6; // Wait组的AIV个数 AscendC::GroupBarrier<AscendC::PipeMode::MTE3_MODE> barA(workspace, ARRIVE_NUM, WAIT_NUM); // 创建GroupBarrier，用户自行管理并对这部分workspace清零 被等待的AIV调用调用Arrive，需要等待的AIV调用Wait。1 2 3 4 5 6 7 8auto id = AscendC::GetBlockIdx(); if (id > 0 && id < ARRIVE_NUM) { //各种Vector计算逻辑，用户自行实现 barA.Arrive(id); } else(id >= ARRIVE_NUM && id < ARRIVE_NUM + WAIT_NUM){ barA.Wait(id - ARRIVE_NUM); // 各种Vector计算逻辑，用户自行实现 } 父主题： GroupBarrier",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "constexpr int32_t ARRIVE_NUM = 2; // Arrive组的AIV个数 constexpr int32_t WAIT_NUM = 6; // Wait组的AIV个数 AscendC::GroupBarrier<AscendC::PipeMode::MTE3_MODE> barA(workspace, ARRIVE_NUM, WAIT_NUM); // 创建GroupBarrier，用户自行管理并对这部分workspace清零\nauto id = AscendC::GetBlockIdx(); if (id > 0 && id < ARRIVE_NUM) { //各种Vector计算逻辑，用户自行实现 barA.Arrive(id); } else(id >= ARRIVE_NUM && id < ARRIVE_NUM + WAIT_NUM){ barA.Wait(id - ARRIVE_NUM); // 各种Vector计算逻辑，用户自行实现 }",
      "约束限制": "",
      "相关接口": [
        "CubeResGroupHandle",
        "GroupBarrier"
      ],
      "版本信息": ""
    },
    {
      "API名称": "SetLoadDataRepeat-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0247.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "And-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0041.html",
      "功能说明": "每对elements按位与运算，公式表达如下： 每对elements按位与运算，公式表达如下： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int16_t/uint16_t isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void And(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int16_t/uint16_t"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void And(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void And(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void And(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask, const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\nuint64_t mask = 128; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::And(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::And(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nAscendC::And(dstLocal, src0Local, src1Local, 512);\n输入数据(src0Local): [1 2 3 ... 512] 输入数据(src1Local): [513 512 511 ... 2] 输出数据(dstLocal): [1 0 3 ... 0]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "BinaryRepeatParams",
        "通用约束",
        "更多样例",
        "双目指令"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "Xor-Xor-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0601.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "TransDataTo5HD-数据转换-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0200.html",
      "功能说明": "数据格式转换，一般用于将NCHW格式转换成NC1HWC0格式。特别的，也可以用于二维矩阵数据块的转置。完成转置功能时，相比于Transpose接口，Transpose仅支持16*16大小的矩阵转置；本接口单次repeat内可处理512Byte的数据（16个datablock），根据数据类型不同，支持不同shape的矩阵转置（比如数据类型为half时，单次repeat可完成16*16大小的矩阵转置），同还可以支持多次repeat操作。 单次repeat内转换规则如下： 基于以上的转换规则，使用该接口进行NC1HWC0格式转换或者矩阵转置。NC1HWC0格式转换相对复杂，这里给出其具体的转换方法： NCHW格式转换成NC1HWC0格式时，如果是数据类型的位宽为32位或者16位，则C0=16；如果数据类型的位宽为8位，则C0=32。下图以C0=16为例进行介绍： 数据格式转换，一般用于将NCHW格式转换成NC1HWC0格式。特别的，也可以用于二维矩阵数据块的转置。完成转置功能时，相比于Transpose接口，Transpose仅支持16*16大小的矩阵转置；本接口单次repeat内可处理512Byte的数据（16个datablock），根据数据类型不同，支持不同shape的矩阵转置（比如数据类型为half时，单次repeat可完成16*16大小的矩阵转置），同还可以支持多次repeat操作。 单次repeat内转换规则如下： 基于以上的转换规则，使用该接口进行NC1HWC0格式转换或者矩阵转置。NC1HWC0格式转换相对复杂，这里给出其具体的转换方法： NCHW格式转换成NC1HWC0格式时，如果是数据类型的位宽为32位或者16位，则C0=16；如果数据类型的位宽为8位，则C0=32。下图以C0=16为例进行介绍： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half Atlas 推理系列产品 AI Core，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float 表2 参数列表 参数名称 输入/输出 含义 dstLocalList/dstList 输出 目的操作数地址序列。 类型为LocalTensor或者LocalTensor的地址值，LocalTensor支持的TPosition为VECIN/VECCALC/VECOUT。LocalTensor的起始地址需要32B对齐。支持的数据类型参考模板参数T说明。 srcLocalList/srcList 输入 源操作数地址序列。 类型为LocalTensor或者LocalTensor的地址值，LocalTensor支持的TPosition为VECIN/VECCALC/VECOUT。LocalTensor的起始地址需要32B对齐。支持的数据类型参考模板参数T说明。 数据类型需要与dstLocalList/dstList保持一致。 dstLocal 输出 目的操作数。 类型为LocalTensor，连续存储对应LocalTensor的地址值。LocalTensor支持的TPosition为VECIN/VECCALC/VECOUT。LocalTensor的起始地址需要32B对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，连续存储对应LocalTensor的地址值。LocalTensor支持的TPosition为VECIN/VECCALC/VECOUT。LocalTensor的起始地址需要32B对齐。 nchwconvParams 输入 控制TransdataTo5HD的数据结构。结构体内包含：读取和写入位置的控制参数，迭代次数，相邻迭代间的地址步长等参数。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_transpose.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 参数说明请参考表3。 表3 TransDataTo5HDParams结构体内参数说明 参数名称 类型 说明 dstHighHalf 输入 指定每个dstLocalList地址中的数据存储到datablock的高半部还是低半部，该配置只支持int8_t/uint8_t的数据类型。 支持的数据类型为bool，有以下两种取值： True：表示存储于datablock的高半部 False：表示存储于datablock的低半部 srcHighHalf 输入 指定每个srcLocalList地址中的数据从datablock的高半部还是低半部读取，该配置只支持int8_t/uint8_t的数据类型。 支持的数据类型为bool，有以下两种取值： True：表示从datablock的高半部读取 False：表示从datablock的低半部读取 repeatTimes 输入 重复迭代次数，repeatTimes∈[0,255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 注意事项： 当repeatTimes为1时，目的操作数/源操作数的有效起始位置为dstLocalList/srcLocalList序列输入的起始位置加上dstRepStride/srcRepStride；repeatTimes为1，如果要让目的操作数/源操作数的有效起始位置为dstLocalList/srcLocalList序列输入的起始位置，需要将dstRepStride/srcRepStride置为0。 当repeatTimes大于1时，第一次repeat中目的操作数/源操作数的有效起始位置为dstLocalList/srcLocalList序列输入的起始位置，第二次需要加上dstRepStride/srcRepStride。以此类推。 dstRepStride 输入 相邻迭代间，目的操作数相同datablock地址stride，单位：datablock。 相邻迭代间相同datablock的地址步长参数的详细说明请参考repeatStride。 srcRepStride 输入 相邻迭代间，源操作数相同datablock地址stride，单位：datablock。 相邻迭代间相同datablock的地址步长参数的详细说明请参考repeatStride。",
      "函数原型": "template<typename T> __aicore__ inline void TransDataTo5HD(uint64_t dstList[NCHW_CONV_ADDR_LIST_SIZE], uint64_t srcList[NCHW_CONV_ADDR_LIST_SIZE], const TransDataTo5HDParams& nchwconvParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half Atlas 推理系列产品 AI Core，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float"
        },
        {
          "参数名": "dstLocalList/dstList",
          "类型": "输出",
          "说明": "目的操作数地址序列。 类型为LocalTensor或者LocalTensor的地址值，LocalTensor支持的TPosition为VECIN/VECCALC/VECOUT。LocalTensor的起始地址需要32B对齐。支持的数据类型参考模板参数T说明。"
        },
        {
          "参数名": "srcLocalList/srcList",
          "类型": "输入",
          "说明": "源操作数地址序列。 类型为LocalTensor或者LocalTensor的地址值，LocalTensor支持的TPosition为VECIN/VECCALC/VECOUT。LocalTensor的起始地址需要32B对齐。支持的数据类型参考模板参数T说明。 数据类型需要与dstLocalList/dstList保持一致。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，连续存储对应LocalTensor的地址值。LocalTensor支持的TPosition为VECIN/VECCALC/VECOUT。LocalTensor的起始地址需要32B对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，连续存储对应LocalTensor的地址值。LocalTensor支持的TPosition为VECIN/VECCALC/VECOUT。LocalTensor的起始地址需要32B对齐。"
        },
        {
          "参数名": "nchwconvParams",
          "类型": "输入",
          "说明": "控制TransdataTo5HD的数据结构。结构体内包含：读取和写入位置的控制参数，迭代次数，相邻迭代间的地址步长等参数。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_transpose.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 参数说明请参考表3。"
        },
        {
          "参数名": "dstHighHalf",
          "类型": "输入",
          "说明": "指定每个dstLocalList地址中的数据存储到datablock的高半部还是低半部，该配置只支持int8_t/uint8_t的数据类型。 支持的数据类型为bool，有以下两种取值： True：表示存储于datablock的高半部 False：表示存储于datablock的低半部"
        },
        {
          "参数名": "srcHighHalf",
          "类型": "输入",
          "说明": "指定每个srcLocalList地址中的数据从datablock的高半部还是低半部读取，该配置只支持int8_t/uint8_t的数据类型。 支持的数据类型为bool，有以下两种取值： True：表示从datablock的高半部读取 False：表示从datablock的低半部读取"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数，repeatTimes∈[0,255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 注意事项： 当repeatTimes为1时，目的操作数/源操作数的有效起始位置为dstLocalList/srcLocalList序列输入的起始位置加上dstRepStride/srcRepStride；repeatTimes为1，如果要让目的操作数/源操作数的有效起始位置为dstLocalList/srcLocalList序列输入的起始位置，需要将dstRepStride/srcRepStride置为0。 当repeatTimes大于1时，第一次repeat中目的操作数/源操作数的有效起始位置为dstLocalList/srcLocalList序列输入的起始位置，第二次需要加上dstRepStride/srcRepStride。以此类推。"
        },
        {
          "参数名": "dstRepStride",
          "类型": "输入",
          "说明": "相邻迭代间，目的操作数相同datablock地址stride，单位：datablock。 相邻迭代间相同datablock的地址步长参数的详细说明请参考repeatStride。"
        },
        {
          "参数名": "srcRepStride",
          "类型": "输入",
          "说明": "相邻迭代间，源操作数相同datablock地址stride，单位：datablock。 相邻迭代间相同datablock的地址步长参数的详细说明请参考repeatStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100",
      "约束限制": "",
      "相关接口": [
        "Transpose",
        "LocalTensor",
        "通用约束",
        "数据转换"
      ],
      "版本信息": "rc1"
    },
    {
      "API名称": "InitSpmBuffer-SPM Buffer-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0166.html",
      "功能说明": "初始化SPM Buffer。 SPM Buffer的具体介绍和完整使用样例请参考如何使用SPM Buffer。 初始化SPM Buffer。 SPM Buffer的具体介绍和完整使用样例请参考如何使用SPM Buffer。 参数名称 输入/输出 含义 wokspace 输入 workspace地址。 bufferSize 输入 SPM Buffer的大小，单位是字节。",
      "函数原型": "template <typename T> __aicore__ inline void InitSpmBuffer(const GlobalTensor<T>& workspace, const int32_t bufferSize)",
      "参数说明": [
        {
          "参数名": "wokspace",
          "类型": "输入",
          "说明": "workspace地址。"
        },
        {
          "参数名": "bufferSize",
          "类型": "输入",
          "说明": "SPM Buffer的大小，单位是字节。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void InitSpmBuffer(const GlobalTensor<T>& workspace, const int32_t bufferSize)\n__aicore__ inline void InitSpmBuffer(const int32_t bufferSize)\nAscendC::TPipe pipe; int len = 1024; // 设置spm buffer为1024个类型为T的数据 workspace_gm.SetGlobalBuffer((__gm__ T *)usrWorkspace, len); // 此处的usrWorkspace为用户自定义的workspace auto gm = workspace_gm[AscendC::GetBlockIdx() * len]; pipe.InitSpmBuffer(gm, len * sizeof(T));\nAscendC::TPipe pipe; int len = 1024; // 设置spm buffer为1024个类型为T的数据 pipe.InitSpmBuffer(len * sizeof(T));",
      "约束限制": "",
      "相关接口": [
        "SPM Buffer"
      ],
      "版本信息": ""
    },
    {
      "API名称": "SoftmaxFlash-SoftMax-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0756.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "InitConstValue-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0237.html",
      "功能说明": "将特定TPosition的LocalTensor初始化为某一具体数值。 将特定TPosition的LocalTensor初始化为某一具体数值。 表1 模板参数说明参数名 描述 T dstLocal的数据类型。 Atlas 训练系列产品，支持的数据类型为：half Atlas 推理系列产品AI Core，支持的数据类型为：half/int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/int16_t/uint16_t/bfloat16_t/float/int32_t/uint32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/int16_t/uint16_t/bfloat16_t/float/int32_t/uint32_t Atlas 200I/500 A2 推理产品，支持的数据类型为：half/int16_t/uint16_t/bfloat16_t/float/int32_t/uint32_t U 初始化值的数据类型。 当dstLocal使用基础数据类型时， U和dstLocal的数据类型T需保持一致，否则编译失败。当dstLocal使用TensorTrait类型时，U和dstLocal的数据类型T的LiteType需保持一致，否则编译失败。 最后一个模板参数仅用于上述数据类型检查，用户无需关注。 表2 参数说明参数名称 输入/输出 含义 dstLocal 输出 目的操作数，结果矩阵，类型为LocalTensor。 Atlas 训练系列产品，支持的TPosition为A1/A2/B1/B2。 Atlas 推理系列产品AI Core，支持的TPosition为A1/A2/B1/B2。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的TPosition为A1/A2/B1/B2。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的TPosition为A1/A2/B1/B2。 Atlas 200I/500 A2 推理产品，支持的TPosition为A1/A2/B1/B2。 如果TPosition为A1/B1，起始地址需要满足32B对齐；如果TPosition为A2/B2，起始地址需要满足512B对齐。 InitConstValueParams 输入 初始化相关参数，类型为InitConstValueParams。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_mm.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 参数说明请参考表3。 Atlas 训练系列产品，仅支持配置迭代次数（repeatTimes）和初始化值（initValue）。 Atlas 推理系列产品AI Core，仅支持配置迭代次数（repeatTimes）和初始化值（initValue）。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持配置所有参数。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持配置所有参数。 Atlas 200I/500 A2 推理产品，支持配置所有参数。 仅支持配置迭代次数（repeatTimes）和初始化值（initValue）场景下，其他参数配置无效。每次迭代处理固定数据量（512字节），迭代间无间隔。支持配置所有参数场景下，支持配置迭代次数（repeatTimes）、初始化值（initValue）、每个迭代处理的数据块个数（blockNum）和迭代间间隔（dstGap）。 表3 InitConstValueParams结构体参数说明参数名称 含义 repeatTimes 迭代次数。默认值为0。 仅支持配置迭代次数（repeatTimes）和初始化值（initValue）场景下，repeatTimes∈[0, 255]。支持配置所有参数场景下，repeatTimes∈[0, 32767] 。 blockNum 每次迭代初始化的数据块个数，取值范围：blockNum∈[0, 32767] 。默认值为0。 dstLocal的位置为A1/B1时，每一个block（数据块）大小是32B；dstLocal的位置为A2/B2时，每一个block（数据块）大小是512B。 dstGap 目的操作数前一个迭代结束地址到后一个迭代起始地址之间的距离。 dstLocal的位置为A1/B1时，单位是32B；dstLocal的位置为A2/B2时，单位是512B。 取值范围：dstGap∈[0, 32767] 。默认值为0。 initValue 初始化的value值，支持的数据类型与dstLocal保持一致。",
      "函数原型": "template <typename T, typename U = PrimT<T>, typename Std::enable_if<Std::is_same<PrimT<T>, U>::value, bool>::type = true> __aicore__ inline void InitConstValue(const LocalTensor<T> &dstLocal, const InitConstValueParams<U> &initConstValueParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "dstLocal的数据类型。 Atlas 训练系列产品，支持的数据类型为：half Atlas 推理系列产品AI Core，支持的数据类型为：half/int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/int16_t/uint16_t/bfloat16_t/float/int32_t/uint32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/int16_t/uint16_t/bfloat16_t/float/int32_t/uint32_t Atlas 200I/500 A2 推理产品，支持的数据类型为：half/int16_t/uint16_t/bfloat16_t/float/int32_t/uint32_t"
        },
        {
          "参数名": "U",
          "类型": "",
          "说明": "初始化值的数据类型。 当dstLocal使用基础数据类型时， U和dstLocal的数据类型T需保持一致，否则编译失败。当dstLocal使用TensorTrait类型时，U和dstLocal的数据类型T的LiteType需保持一致，否则编译失败。 最后一个模板参数仅用于上述数据类型检查，用户无需关注。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数，结果矩阵，类型为LocalTensor。 Atlas 训练系列产品，支持的TPosition为A1/A2/B1/B2。 Atlas 推理系列产品AI Core，支持的TPosition为A1/A2/B1/B2。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的TPosition为A1/A2/B1/B2。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的TPosition为A1/A2/B1/B2。 Atlas 200I/500 A2 推理产品，支持的TPosition为A1/A2/B1/B2。 如果TPosition为A1/B1，起始地址需要满足32B对齐；如果TPosition为A2/B2，起始地址需要满足512B对齐。"
        },
        {
          "参数名": "InitConstValueParams",
          "类型": "输入",
          "说明": "初始化相关参数，类型为InitConstValueParams。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_mm.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 参数说明请参考表3。 Atlas 训练系列产品，仅支持配置迭代次数（repeatTimes）和初始化值（initValue）。 Atlas 推理系列产品AI Core，仅支持配置迭代次数（repeatTimes）和初始化值（initValue）。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持配置所有参数。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持配置所有参数。 Atlas 200I/500 A2 推理产品，支持配置所有参数。 仅支持配置迭代次数（repeatTimes）和初始化值（initValue）场景下，其他参数配置无效。每次迭代处理固定数据量（512字节），迭代间无间隔。支持配置所有参数场景下，支持配置迭代次数（repeatTimes）、初始化值（initValue）、每个迭代处理的数据块个数（blockNum）和迭代间间隔（dstGap）。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "",
          "说明": "迭代次数。默认值为0。 仅支持配置迭代次数（repeatTimes）和初始化值（initValue）场景下，repeatTimes∈[0, 255]。支持配置所有参数场景下，repeatTimes∈[0, 32767] 。"
        },
        {
          "参数名": "blockNum",
          "类型": "",
          "说明": "每次迭代初始化的数据块个数，取值范围：blockNum∈[0, 32767] 。默认值为0。 dstLocal的位置为A1/B1时，每一个block（数据块）大小是32B；dstLocal的位置为A2/B2时，每一个block（数据块）大小是512B。"
        },
        {
          "参数名": "dstGap",
          "类型": "",
          "说明": "目的操作数前一个迭代结束地址到后一个迭代起始地址之间的距离。 dstLocal的位置为A1/B1时，单位是32B；dstLocal的位置为A2/B2时，单位是512B。 取值范围：dstGap∈[0, 32767] 。默认值为0。"
        },
        {
          "参数名": "initValue",
          "类型": "",
          "说明": "初始化的value值，支持的数据类型与dstLocal保持一致。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142",
      "约束限制": "",
      "相关接口": [
        "TensorTrait",
        "通用约束",
        "矩阵计算(ISASI)"
      ],
      "版本信息": ""
    },
    {
      "API名称": "DeepNorm-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0808.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetProgramCounter(ISASI)-系统变量访问-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0279.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "BatchNorm-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0806.html",
      "功能说明": "BatchNorm是对于每一层的输入做规范化处理，使得每一层的分布尽可能的相同，从而加速训练过程和提高模型的泛化能力（有效减少梯度消失和梯度爆炸问题）。基本思想是对于每个batch中的样本，对其输入的每个特征在batch的维度上进行归一化。具体来说，对于输入特征x，BatchNorm的计算过程可以表示为： BatchNorm是对于每一层的输入做规范化处理，使得每一层的分布尽可能的相同，从而加速训练过程和提高模型的泛化能力（有效减少梯度消失和梯度爆炸问题）。基本思想是对于每个batch中的样本，对其输入的每个特征在batch的维度上进行归一化。具体来说，对于输入特征x，BatchNorm的计算过程可以表示为： 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 isBasicBlock inputX、output的shape信息和Tiling切分策略满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。基本块要求如下： originB是8的倍数；S*H是64的倍数，但小于2048。 表2 接口参数说明参数名 输入/输出 描述 output 输出 目的操作数，shape为[B，S，H]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 outputMean 输出 均值，目的操作数，shape为[S，H]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 outputVariance 输出 方差，目的操作数，shape为[S，H]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 inputX 输入 源操作数，shape为[B，S，H]。inputX的数据类型需要与目的操作数保持一致，S*H需要32B对齐。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 gamm 输入 源操作数，shape为[B]。gamm的数据类型需要与目的操作数保持一致，长度需要32B对齐。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 beta 输入 源操作数，shape为[B]。beta的数据类型需要与目的操作数保持一致，长度需要32B对齐。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 sharedTmpBuffer 输入 接口内部复杂计算时用于存储中间变量，由开发者提供。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考BatchNorm Tiling。 epsilon 输入 防除0的权重系数。数据类型需要与inputX/output保持一致。 tiling 输入 输入数据的切分信息，Tiling信息的获取请参考BatchNorm Tiling。",
      "函数原型": "template <typename T, bool isReuseSource = false, bool isBasicBlock = false> __aicore__ inline void BatchNorm(const LocalTensor<T>& output, const LocalTensor<T>& outputMean, const LocalTensor<T>& outputVariance, const LocalTensor<T>& inputX, const LocalTensor<T>& gamm, const LocalTensor<T>& beta, const LocalTensor<uint8_t>& sharedTmpBuffer, const T epsilon, BatchNormTiling& tiling)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "isBasicBlock",
          "类型": "",
          "说明": "inputX、output的shape信息和Tiling切分策略满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。基本块要求如下： originB是8的倍数；S*H是64的倍数，但小于2048。"
        },
        {
          "参数名": "output",
          "类型": "输出",
          "说明": "目的操作数，shape为[B，S，H]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "outputMean",
          "类型": "输出",
          "说明": "均值，目的操作数，shape为[S，H]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "outputVariance",
          "类型": "输出",
          "说明": "方差，目的操作数，shape为[S，H]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "inputX",
          "类型": "输入",
          "说明": "源操作数，shape为[B，S，H]。inputX的数据类型需要与目的操作数保持一致，S*H需要32B对齐。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "gamm",
          "类型": "输入",
          "说明": "源操作数，shape为[B]。gamm的数据类型需要与目的操作数保持一致，长度需要32B对齐。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "beta",
          "类型": "输入",
          "说明": "源操作数，shape为[B]。beta的数据类型需要与目的操作数保持一致，长度需要32B对齐。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "接口内部复杂计算时用于存储中间变量，由开发者提供。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考BatchNorm Tiling。"
        },
        {
          "参数名": "epsilon",
          "类型": "输入",
          "说明": "防除0的权重系数。数据类型需要与inputX/output保持一致。"
        },
        {
          "参数名": "tiling",
          "类型": "输入",
          "说明": "输入数据的切分信息，Tiling信息的获取请参考BatchNorm Tiling。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "BatchNorm Tiling",
        "通用约束",
        "数据归一化"
      ],
      "版本信息": "0.001"
    },
    {
      "API名称": "SetKernelMode-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1211.html",
      "功能说明": "针对分离架构，CPU调测时，设置内核模式为单AIV模式，单AIC模式或者MIX模式，以分别支持单AIV矢量算子，单AIC矩阵算子，MIX混合算子的CPU调试。不调用该接口的情况下，默认为MIX模式。为保证算子代码在多个硬件平台兼容，耦合架构下也可以调用，该场景下接口不会生效，不影响正常调试。 针对分离架构，CPU调测时，设置内核模式为单AIV模式，单AIC模式或者MIX模式，以分别支持单AIV矢量算子，单AIC矩阵算子，MIX混合算子的CPU调试。不调用该接口的情况下，默认为MIX模式。为保证算子代码在多个硬件平台兼容，耦合架构下也可以调用，该场景下接口不会生效，不影响正常调试。 参数名 输入/输出 描述 mode 输入 内核模式，针对AIC，AIV，MIX算子的CPU调试，参数取值分别为AIC_MODE，AIV_MODE，MIX_MODE。 1 2 3 4 5enum class KernelMode { MIX_MODE = 0, AIC_MODE, AIV_MODE };",
      "函数原型": "int32_t main(int32_t argc, char* argv[]) {",
      "参数说明": [
        {
          "参数名": "mode",
          "类型": "输入",
          "说明": "内核模式，针对AIC，AIV，MIX算子的CPU调试，参数取值分别为AIC_MODE，AIV_MODE，MIX_MODE。 1 2 3 4 5enum class KernelMode { MIX_MODE = 0, AIC_MODE, AIV_MODE };"
        },
        {
          "参数名": "1 2 3 4 5",
          "类型": "",
          "说明": "enum class KernelMode { MIX_MODE = 0, AIC_MODE, AIV_MODE };"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16",
      "约束限制": "",
      "相关接口": [
        "算子调测API"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Asinh-Asinh-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0560.html",
      "功能说明": "按元素做反双曲正弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 按元素做反双曲正弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Asinh内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetAsinhMaxMinTmpSize。 calCount 输入 参与计算的元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void Asinh(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Asinh内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetAsinhMaxMinTmpSize。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6\n1 2 3 4 5 6",
      "约束限制": "",
      "相关接口": [
        "GetAsinhMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "更多样例",
        "Asinh"
      ],
      "版本信息": "0.80541134"
    },
    {
      "API名称": "SetLoadDataBoundary-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0246.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Sqrt-单目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0029.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ReduceSum-ReduceSum-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10018.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "WelfordFinalize-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0814.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Erf-Erf-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0544.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "conditional-type_traits-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10118.html",
      "功能说明": "conditional是定义在<type_traits>头文件里的一个类型特征工具，它在程序编译时根据一个布尔条件从两个类型中选择一个类型。本接口可应用在模板元编程中，用于根据不同的条件来灵活选择合适的类型，增强代码的通用性和灵活性。 conditional有一个嵌套的type成员，它的值取决于Bp的值：如果Bp为true，则conditional<Bp, If, Then>::type为If。如果Bp为false，则conditional<Bp, If, Then>::type为Then。 conditional是定义在<type_traits>头文件里的一个类型特征工具，它在程序编译时根据一个布尔条件从两个类型中选择一个类型。本接口可应用在模板元编程中，用于根据不同的条件来灵活选择合适的类型，增强代码的通用性和灵活性。 conditional有一个嵌套的type成员，它的值取决于Bp的值：如果Bp为true，则conditional<Bp, If, Then>::type为If。如果Bp为false，则conditional<Bp, If, Then>::type为Then。 表1 模板参数说明参数名 含义 Bp 一个布尔常量表达式，作为选择类型的条件。 If 当Bp为true时选择的类型。 Then 当Bp为false时选择的类型。 conditional的静态常量成员type用于获取返回值，conditional<Bp, If, Then>::type取值如下：",
      "函数原型": "template <bool Condition> __aicore__ inline void selectOtherType()",
      "参数说明": [
        {
          "参数名": "Bp",
          "类型": "",
          "说明": "一个布尔常量表达式，作为选择类型的条件。"
        },
        {
          "参数名": "If",
          "类型": "",
          "说明": "当Bp为true时选择的类型。"
        },
        {
          "参数名": "Then",
          "类型": "",
          "说明": "当Bp为false时选择的类型。"
        }
      ],
      "返回值": "conditional的静态常量成员type用于获取返回值，conditional<Bp, If, Then>::type取值如下：",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40",
      "约束限制": "",
      "相关接口": [
        "type_traits"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Mins-标量双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0057.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "MmadWithSparse-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0250.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "使用说明-Conv3DBackpropFilter-Conv3DBackpropFilter-卷积反向-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0893.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Fmod-Fmod-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0608.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Digamma-Digamma-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0597.html",
      "功能说明": "按元素计算x的gamma函数的对数导数，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数，为伽玛函数。 计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 按元素计算x的gamma函数的对数导数，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数，为伽玛函数。 计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。该参数仅在输入的数据类型为float时生效。 true：开发者允许源操作数被改写，可以使能该参数，使能后本接口内部计算时复用srcTensor的内存空间，节省部分内存空间； false：本接口内部计算时不复用srcTensor的内存空间。 isReuseSource的使用样例请参考更多样例。 表2 接口参数说明 参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Digamma内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetDigammaMaxMinTmpSize。 calCount 输入 参与计算的元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void Digamma(LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数，默认值为false。该参数仅在输入的数据类型为float时生效。 true：开发者允许源操作数被改写，可以使能该参数，使能后本接口内部计算时复用srcTensor的内存空间，节省部分内存空间； false：本接口内部计算时不复用srcTensor的内存空间。 isReuseSource的使用样例请参考更多样例。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Digamma内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetDigammaMaxMinTmpSize。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6\n1 2 3 4 5 6",
      "约束限制": "",
      "相关接口": [
        "GetDigammaMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "更多样例",
        "Digamma"
      ],
      "版本信息": "5.3675685"
    },
    {
      "API名称": "ReGlu-ReGlu-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0790.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetAtomicMin(ISASI)-原子操作-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0285.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ProposalExtract-排序组合(ISASI)-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0228.html",
      "功能说明": "与ProposalConcat功能相反，从Region Proposals内将相应位置的单个元素抽取后重排，每次迭代处理16个Region Proposals，抽取16个元素后连续排列。 与ProposalConcat功能相反，从Region Proposals内将相应位置的单个元素抽取后重排，每次迭代处理16个Region Proposals，抽取16个元素后连续排列。 表1 模板参数说明参数名 描述 T 操作数数据类型。 Atlas 训练系列产品，支持的数据类型为：half Atlas 推理系列产品AI Core，支持的数据类型为：half/float 表2 参数说明参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 repeatTimes 输入 重复迭代次数，int32_t类型，每次迭代完成16个Region Proposals的元素抽取并排布到16个元素里，下次迭代跳至相邻的下一组16个Region Proposals和下一组16个元素。取值范围：repeatTimes∈[0,255]。 modeNumber 输入 抽取位置参数，取值范围：modeNumber∈[0, 5]，int32_t类型，仅限于以下配置：0 – 从x1抽取1 – 从y1抽取2 – 从x2抽取3 – 从y2抽取4 – 从score抽取5 – 从label抽取",
      "函数原型": "template <typename T> __aicore__ inline void ProposalExtract(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t repeatTimes, const int32_t modeNumber)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品，支持的数据类型为：half Atlas 推理系列产品AI Core，支持的数据类型为：half/float"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数，int32_t类型，每次迭代完成16个Region Proposals的元素抽取并排布到16个元素里，下次迭代跳至相邻的下一组16个Region Proposals和下一组16个元素。取值范围：repeatTimes∈[0,255]。"
        },
        {
          "参数名": "modeNumber",
          "类型": "输入",
          "说明": "抽取位置参数，取值范围：modeNumber∈[0, 5]，int32_t类型，仅限于以下配置：0 – 从x1抽取1 – 从y1抽取2 – 从x2抽取3 – 从y2抽取4 – 从score抽取5 – 从label抽取"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void ProposalExtract(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t repeatTimes, const int32_t modeNumber)\n// repeatTimes = 2, modeNumber = 4, 把32个Region Proposal中的score域元素抽取出来排列成32个连续元素 AscendC::ProposalExtract(dstLocal, srcLocal, 2, 4);\n#include \"kernel_operator.h\" class KernelVecProposal { public: __aicore__ inline KernelVecProposal() {} __aicore__ inline void Init(__gm__ uint8_t* src, __gm__ uint8_t* dstGm) { srcGlobal.SetGlobalBuffer((__gm__ half*)src); dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm); pipe.InitBuffer(inQueueSrc, 1, srcDataSize * sizeof(half)); pipe.InitBuffer(outQueueDst, 1, dstDataSize * sizeof(half)); } __aicore__ inline void Process() { CopyIn(); Compute(); CopyOut(); } private: __aicore__ inline void CopyIn() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>(); AscendC::DataCopy(srcLocal, srcGlobal, srcDataSize); inQueueSrc.EnQue(srcLocal); } __aicore__ inline void Compute() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>(); AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>(); AscendC::ProposalExtract(dstLocal, srcLocal, repeat, mode); outQueueDst.EnQue<half>(dstLocal); inQueueSrc.FreeTensor(srcLocal); } __aicore__ inline void CopyOut() { AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>(); AscendC::DataCopy(dstGlobal, dstLocal, dstDataSize); outQueueDst.FreeTensor(dstLocal); } private: AscendC::TPipe pipe; AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc; AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst; AscendC::GlobalTensor<half> srcGlobal, dstGlobal; int srcDataSize = 256; int dstDataSize = 32; int repeat = srcDataSize / 16; int mode = 4; }; extern \"C\" __global__ __aicore__ void vec_proposal_kernel(__gm__ uint8_t* src, __gm__ uint8_t* dstGm) { KernelVecProposal op; op.Init(src, dstGm); op.Process(); }\n示例结果 输入数据(src_gm): [ 0. 0. 0. 0. 33.3 0. 0. 0. 0. 0. 0. 0. 67.56 0. 0. 0. 0. 0. 0. 0. 68.5 0. 0. 0. 0. 0. 0. 0. -11.914 0. 0. 0. 0. 0. 0. 0. 25.19 0. 0. 0. 0. 0. 0. 0. -72.8 0. 0. 0. 0. 0. 0. 0. 11.79 0. 0. 0. 0. 0. 0. 0. -49.47 0. 0. 0. 0. 0. 0. 0. 49.44 0. 0. 0. 0. 0. 0. 0. 84.4 0. 0. 0. 0. 0. 0. 0. -14.36 0. 0. 0. 0. 0. 0. 0. 45.97 0. 0. 0. 0. 0. 0. 0. 52.47 0. 0. 0. 0. 0. 0. 0. -5.387 0. 0. 0. 0. 0. 0. 0. -13.12 0. 0. 0. 0. 0. 0. 0. -88.9 0. 0. 0. 0. 0. 0. 0. 54. 0. 0. 0. 0. 0. 0. 0. -51.62 0. 0. 0. 0. 0. 0. 0. -20.67 0. 0. 0. 0. 0. 0. 0. 59.56 0. 0. 0. 0. 0. 0. 0. 35.72 0. 0. 0. 0. 0. 0. 0. -6.12 0. 0. 0. 0. 0. 0. 0. -39.4 0. 0. 0. 0. 0. 0. 0. -11.46 0. 0. 0. 0. 0. 0. 0. -7.066 0. 0. 0. 0. 0. 0. 0. 30.23 0. 0. 0. 0. 0. 0. 0. -11.18 0. 0. 0. 0. 0. 0. 0. -35.84 0. 0. 0. 0. 0. 0. 0. -40.88 0. 0. 0. 0. 0. 0. 0. 60.9 0. 0. 0. 0. 0. 0. 0. -73.3 0. 0. 0. 0. 0. 0. 0. 38.47 0. 0. 0. ] 输出数据(dst_gm): [ 33.3 67.56 68.5 -11.914 25.19 -72.8 11.79 -49.47 49.44 84.4 -14.36 45.97 52.47 -5.387 -13.12 -88.9 54. -51.62 -20.67 59.56 35.72 -6.12 -39.4 -11.46 -7.066 30.23 -11.18 -35.84 -40.88 60.9 -73.3 38.47 ]",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "通用约束",
        "排序组合(ISASI)"
      ],
      "版本信息": "33.3"
    },
    {
      "API名称": "WholeReduceMax-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0079.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "WelfordUpdate-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0812.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Relu-单目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0032.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Power-Power-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0520.html",
      "功能说明": "实现按元素做幂运算功能，提供3类接口，处理逻辑如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 实现按元素做幂运算功能，提供3类接口，处理逻辑如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float/int32_t Atlas 推理系列产品AI Core，支持的数据类型为：half/float/int32_t isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 src0Tensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 src1Tensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 src0Scalar/src1Scalar 输入 源操作数，类型为Scalar。源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时内存空间。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 针对3个power接口，不同输入数据类型情况下，临时空间大小BufferSize的获取方式请参考GetPowerMaxMinTmpSize。 calCount 输入 参与计算的元素个数。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const LocalTensor<T>& src1Tensor, const LocalTensor<uint8_t>& sharedTmpBuffer, uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float/int32_t Atlas 推理系列产品AI Core，支持的数据类型为：half/float/int32_t"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "src0Tensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "src1Tensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "src0Scalar/src1Scalar",
          "类型": "输入",
          "说明": "源操作数，类型为Scalar。源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时内存空间。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 针对3个power接口，不同输入数据类型情况下，临时空间大小BufferSize的获取方式请参考GetPowerMaxMinTmpSize。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const LocalTensor<T>& src1Tensor, const LocalTensor<uint8_t>& sharedTmpBuffer, uint32_t calCount)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const LocalTensor<T>& src1Tensor, const LocalTensor<uint8_t>& sharedTmpBuffer)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const LocalTensor<T>& src1Tensor, uint32_t calCount)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const LocalTensor<T>& src1Tensor)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const T& src1Scalar, const LocalTensor<uint8_t>& sharedTmpBuffer, uint32_t calCount)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const T& src1Scalar, const LocalTensor<uint8_t>& sharedTmpBuffer)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const T& src1Scalar, uint32_t calCount)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const T& src1Scalar)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const T& src0Scalar, const LocalTensor<T>& src1Tensor, const LocalTensor<uint8_t>& sharedTmpBuffer, uint32_t calCount)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const T& src0Scalar, const LocalTensor<T>& src1Tensor, const LocalTensor<uint8_t>& sharedTmpBuffer)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const T& src0Scalar, const LocalTensor<T>& src1Tensor, uint32_t calCount)\ntemplate <typename T, bool isReuseSource = false> __aicore__ inline void Power(const LocalTensor<T>& dstTensor, const T& src0Scalar, const LocalTensor<T>& src1Tensor)\nPower(dstLocal, srcLocal1, srcLocal2)\n输入数据(srcLocal1): [1.4608411 4.344736 ... 0.46437776] 输入数据(srcLocal2): [-5.4534287 4.5122147 ... -0.9344089] 输出数据(dstLocal): [0.12657544 756.1846 ... 2.0477564]\nPower(dstLocal, srcLocal1, scalarValue)\n输入数据(srcLocal1): [2.263972 2.902264 ... 0.40299487] 输入数据(scalarValue): 1.2260373 输出数据(dstLocal): [2.7232351 3.6926038 ... 0.32815763]\nPower(dstLocal, scalarValue, srcLocal2)\n输入数据(scalarValue): 4.382112 输入数据(srcLocal2): [5.504859 2.0677629 ... 1.053188] 输出数据(dstLocal): [3407.0386 21.225077 ... 4.7403817]\n#include \"kernel_operator.h\" template <typename srcType> class KernelPower { public: __aicore__ inline KernelPower() {} __aicore__ inline void Init(GM_ADDR src1Gm, GM_ADDR src2Gm, GM_ADDR dstGm, uint32_t srcSize) { src1Global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src1Gm), srcSize); src2Global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src2Gm), srcSize); dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), srcSize); pipe.InitBuffer(inQueueX1, 1, srcSize * sizeof(srcType)); pipe.InitBuffer(inQueueX2, 1, srcSize * sizeof(srcType)); pipe.InitBuffer(outQueue, 1, srcSize * sizeof(srcType)); bufferSize = srcSize; } __aicore__ inline void Process() { CopyIn(); Compute(); CopyOut(); } private: __aicore__ inline void CopyIn() { AscendC::LocalTensor<srcType> srcLocal1 = inQueueX1.AllocTensor<srcType>(); AscendC::DataCopy(srcLocal1, src1Global, bufferSize); inQueueX1.EnQue(srcLocal1); AscendC::LocalTensor<srcType> srcLocal2 = inQueueX2.AllocTensor<srcType>(); AscendC::DataCopy(srcLocal2, src2Global, bufferSize); inQueueX2.EnQue(srcLocal2); } __aicore__ inline void Compute() { AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>(); AscendC::LocalTensor<srcType> srcLocal1 = inQueueX1.DeQue<srcType>(); AscendC::LocalTensor<srcType> srcLocal2 = inQueueX2.DeQue<srcType>(); AscendC::LocalTensor<srcType> tmpLocal; srcType scalarValue1 = srcLocal1.GetValue(0); srcType scalarValue2 = srcLocal2.GetValue(0); AscendC::Power<srcType, false>(dstLocal, scalarValue1, srcLocal2); outQueue.EnQue<srcType>(dstLocal); inQueueX1.FreeTensor(srcLocal1); inQueueX2.FreeTensor(srcLocal2); } __aicore__ inline void CopyOut() { AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>(); AscendC::DataCopy(dstGlobal, dstLocal, bufferSize); outQueue.FreeTensor(dstLocal); } private: AscendC::GlobalTensor<srcType> src1Global; AscendC::GlobalTensor<srcType> src2Global; AscendC::GlobalTensor<srcType> dstGlobal; AscendC::TPipe pipe; AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX1; AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX2; AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue; uint32_t bufferSize = 0; }; template <typename dataType> __aicore__ void kernel_power_operator(GM_ADDR src1Gm, GM_ADDR src2Gm, GM_ADDR dstGm, uint32_t srcSize) { KernelPower<dataType> op; op.Init(src1Gm, src2Gm, dstGm, srcSize); op.Process(); } extern \"C\" __global__ __aicore__ void power_operator_custom(GM_ADDR src1Gm, GM_ADDR src2Gm, GM_ADDR dstGm, uint32_t srcSize) { kernel_power_operator<half>(src1Gm, src2Gm, dstGm, srcSize); }",
      "约束限制": "",
      "相关接口": [
        "GetPowerMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "Power"
      ],
      "版本信息": "1.4608411"
    },
    {
      "API名称": "TBuf简介-TBuf-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0160.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "FusedMulAdd-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0050.html",
      "功能说明": "按元素将src0Local和dstLocal相乘并加上src1Local，最终结果存放入dstLocal。计算公式如下： 按元素将src0Local和dstLocal相乘并加上src1Local，最终结果存放入dstLocal。计算公式如下： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输入/输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void FusedMulAdd(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输入/输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void FusedMulAdd(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void FusedMulAdd(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void FusedMulAdd(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask, const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\nuint64_t mask = 128; // repeatTimes = 2, 一次迭代计算128个数, 共计算256个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::FusedMulAdd(dstLocal, src0Local, src1Local, mask, 2, { 1, 1, 1, 8, 8, 8 });\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 2, 一次迭代计算128个数, 共计算256个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::FusedMulAdd(dstLocal, src0Local, src1Local, mask, 2, { 1, 1, 1, 8, 8, 8 });\nAscendC::FusedMulAdd(dstLocal, src0Local, src1Local, 256);\n输入数据(src0Local): [ 51.4 25.92 28.3 26.62 -4.523 -93.6 8.71 21.02 -49.8 -80.4 95.94 4.74 70.25 -60.38 79.5 -18.19 79.1 -66.7 62.5 83.6 -73.1 72.56 -63.03 81.3 -62.28 -49.94 -78.7 56.2 -52.97 66.2 43.94 13.43 43.06 51.16 34.16 -64.56 -73.1 -94.7 -68.94 73.06 -93.4 -46.62 -83.75 15.46 32.88 -76.4 53.84 70.6 -3.455 -88.4 -65.75 -16.1 88.9 -70.56 -69.44 -11.91 -77.06 76.06 22.73 91.25 -96.06 64.4 13.1 30.56 -99.2 -98.56 58.1 31.92 -56.47 -72.7 -42.94 49.1 98.44 83.75 -4.336 30.03 33.2 -54.78 -21.19 -57.22 -61.34 -39.8 -29.44 -16.12 38.4 -71.6 -28.52 63.62 36. 61.38 26.69 -16.34 92.2 -67.7 -92.75 -41.16 -85.44 -91.2 -22.31 -47.38 -27.28 -77.44 64. -78.56 52.22 -61.8 -84.94 -64.7 91.3 64.56 67.25 65.44 58.7 64.7 -75.06 -44.7 -22.05 71.7 78.9 34.7 -26.88 39.7 -83.3 0.6274 -34.56 -94.7 -7.027 86.1 -15.18 63.47 39. -53.1 54.53 75.44 32.53 -78.3 -22.34 74.7 -4.312 -33.2 2.19 98.25 -14.66 34.88 6.746 88.5 -55.03 88.25 -79.56 -61.62 82.3 47.47 -17.19 45.72 -71.4 -93.5 -32.84 -40. 49.88 27.98 -70.56 -47.6 76.25 54.62 -62.06 -13.484 86.94 21.81 -54.53 2.236 -25.16 86.75 -45.97 -44.5 -54. -53.6 -23.33 58.62 -48.16 -17.52 87.75 -60.7 -80.6 74.5 66.4 70.7 -34.28 -3.43 -88.5 -43.56 -22.9 -93.5 -95.75 -90.6 57.97 -60.06 75.94 -92.3 -15.87 38.5 37.34 -80.56 71.25 69. 36.25 55.53 74.75 31.1 -8.445 2.152 95.75 -4.777 9.41 97.8 -64.75 90.94 38.84 16.8 -17.44 87. -11.336 98.1 -94.6 -76.2 -20.14 18.1 -90.4 51.84 -22.88 20.33 45.38 96.06 -68.56 -57.66 61.78 -78.3 76. -26.23 27.36 -52.5 -90.4 23.78 -47.7 -36. 68.4 -59.2 -59.28 32.12 -44.84 -2.428 -9.266 57.44 66.25 -62.8 92.8 50.75 ] 输入数据(src1Local): [-43.1 -90. -0.7295 49.28 -52.12 -55.53 99.6 94.4 62.56 20.67 -25.4 -70.6 43.44 57.97 5.355 38.66 -67.3 -26.72 43.7 -81.06 54.47 -71.3 84.8 92.9 49.88 -49.94 79.75 -71.8 6.5 42.3 22.44 6.64 -83.6 -24.3 -97.06 43.47 -31.06 -9.55 -7.734 -30.27 70.3 10.91 55.72 60.03 85.8 -21.86 -34.28 -1.962 -11.18 -20.4 53.34 -44.72 9.28 -40.44 19.42 62.66 -84.75 39.1 45.9 -89.56 70.94 99.5 16.62 -36.7 -26.2 87.06 -87.94 19. -30.12 16.94 -85.44 -17.06 33.28 -49.84 -24.78 -58.25 27.81 -23.48 81.06 82.94 -35.88 -4.47 -74.7 85. -18.22 -67.5 76.5 96.1 -32.4 -45.56 21.53 -28.5 88. -0.1978 -20.34 -44.53 -13.27 -7.93 33.3 89.8 49.12 -19.84 48.38 83.9 53. -65.6 62.97 76.75 -74.4 -23.19 73.1 -9.38 -31.86 69.44 -52.47 -75.94 54.78 78.94 -74.9 -0.01271 21.88 -82.9 -34.44 20.56 64.25 7.57 -63.6 -78.44 19.06 67.25 34.62 82.4 15.6 84.06 75.06 -97.94 -41.12 -77.75 35.3 88. -2.758 -4.36 34.8 73.94 -33.28 -24.5 53.38 -54.3 19.14 57.1 43.4 -39.4 16.36 24.94 -42.94 -26.25 27.92 -35.44 79.94 42.12 -62.72 90. 98.75 -8.22 79. -96.94 -91.1 -32.94 64.4 -78.56 -49.56 10.23 82.9 -27. 7.023 -42.7 -25.67 -42.34 22.72 98.56 69.2 -72.9 60.28 -43.94 73.06 -28.31 37.5 84.8 -1.514 81.7 -68.3 46.3 66. 86.44 -26.78 -52.72 -3.766 -17.95 87.6 -93.5 9.13 58.25 44.62 2.64 90.25 -42.16 -50.62 18.48 -3.156 36.16 82.4 26.44 69.8 -47.56 -54.72 58.88 -16.77 58.44 -5.62 -38.88 40.44 -87.94 33.25 68.94 -73.2 3.64 45.3 -59.1 -69.9 -94.5 16.02 12.11 91.56 -30.4 -47.56 56.84 -17.06 60. -31.33 50. -40.44 9.17 31.9 -51.2 -34.72 -11.43 19.58 -89.6 -61.53 -98.25 94.94 43.8 -6.848 -99. 99.9 -28.66 ] 输入数据（dstLocal）： [-18.36 44.94 32.34 -50. -99.5 89.4 1.568 61.4 -36. -46.28 54.88 14.92 61.2 -16.14 42.72 87.25 -2.787 -66.8 58.3 23.94 89. -78.56 -38.94 -78.25 52.6 77.94 84.4 -63.94 90.7 51.97 84.1 99.3 -70.1 -3.691 4.16 24.98 -91.94 91.2 65.3 -47.28 68.1 -60.2 -90.4 0.1636 9.32 51.4 10.45 46.9 42.78 -38.2 -39.25 -79.1 52.2 56.03 -20.72 -25.81 27.5 -42.94 -71.6 -73.2 -16.45 99. -16. -75.94 -18.44 6.92 -54.66 12.016 35.53 65.6 84.4 55.28 34.16 -69.5 -0.4287 -83.1 -30.69 86.06 -67.56 -97.56 -23.44 73.56 -29.84 -0.49 -78.44 -17.45 -19.47 57.12 28.31 -86.8 95.44 82.4 40.53 92.7 20.36 -77.75 -44.62 -21. -63.44 71. -32.2 66.7 46.94 -95.3 -71.8 -1.351 20.95 -84.44 33.28 -55.2 10.17 22.27 -26.42 -76.06 90. 44.2 -80.4 -94.25 -9.055 15.44 75.94 -40.47 -43.78 18.31 -5.586 -55.1 -95.9 82.5 75.6 -76.25 -83.6 -70. -54.16 56.62 64.56 -97.06 93.5 -58.8 7.746 -12.164 53.06 -56.72 97.7 -11.07 68.2 -77.3 77.8 -41.44 -14.21 -48.56 -40.5 88.44 85.5 -92.25 -8.39 -41.78 27.44 85.44 40.8 -80.2 38.94 -7.598 3.83 74. -97.06 -84.3 74.9 -88.6 -92.3 -34.97 65.8 -60.8 39.06 -19.64 65.4 5.336 -0.07324 -52.16 70.44 11.75 4.72 77.8 -62.9 80.3 -24.66 62.84 -98.75 -58.88 -90.4 31.53 70.44 -97.7 64.8 -7.203 -28.3 30.5 -48.75 -89.06 25.94 -81.06 -62.72 -65.4 79.4 -90.7 65.6 79.56 -21.22 -0.1489 83.44 -29.86 -75.9 29.75 53.34 47.66 18.02 92.7 90.56 8.2 -98.6 -40.53 15.484 28.47 -49.28 24.05 -23. -0.0836 50.5 -70.1 -96.9 -10.23 -19.34 -86.6 63.38 -88.4 92.5 -16.52 -94.7 -92.1 82.2 -35.94 -67.5 -46.03 -70.44 -54.44 -85.5 48.72 -61.25 41. -51.25 -50.4 -50.66 51.84 -52.9 11.086 -74.1 50.66 ] 输出数据(dstLocal): [ -987. 1075. 914.5 -1282. 398. -8424. 113.3 1384. 1856. 3740. 5240. 0.0625 4344. 1032. 3402. -1548. -287.8 4428. 3688. 1921. -6452. -5772. 2538. -6272. -3226. -3942. -6560. -3664. -4796. 3482. 3718. 1341. -3104. -213.1 45.06 -1570. 6692. -8640. -4512. -3484. -6288. 2816. 7624. 62.56 392.2 -3948. 528.5 3310. -159. 3354. 2634. 1228. 4648. -3994. 1458. 370. -2204. -3226. -1582. -6768. 1652. 6472. -193. -2356. 1803. -595. -3264. 402.5 -2036. -4756. -3708. 2696. 3396. -5868. -22.92 -2554. -990.5 -4740. 1512. 5668. 1402. -2932. 804. 92.9 -3030. 1182. 631.5 3730. 986.5 -5372. 2568. -1374. 3824. -6272. -1908. 3156. 3798. 1907. 1448. -3274. 927. -5184. 3052. 7572. -3696. 17.88 -1717. 5540. 2964. -3588. 757. 1448. -1583. -4852. -6808. -2050. 1827. -6676. -789. 535.5 -2019. -1689. 3614. 32.06 257.5 5224. 610. 7024. -1129. -4772. -3228. 3798. -2938. 4356. 2176. 7504. -2132. -4468. 1.906 491.8 113.44 -5576. -1397. -312. 426.8 -6868. -4232. -3710. 1150. 3050. -3290. 4160. -1454. -4192. 556. 3880. -873. -3454. 2116. -2202. -2810. 451.5 390.8 4034. 6104. 1040. 6416. -1966. 5096. -156.8 -1706. -5264. -1713. 847. -3522. -328.8 -23.97 -3100. -3370. -107.2 483.2 -4796. 5132. 5940. -1564. 4416. 3424. 286.8 8000. -1292. -1681. 9184. -6136. 739.5 -1667. -1885. -3706. 8208. -324. -3214. -2332. 5328. 5700. -6252. 2468. 4376. -1637. 13.86 -707.5 -28.1 -7180. -115.7 571.5 4612. -1222. 8488. 3502. 196.2 1714. -3564. -135. 2706. 4696. -1763. 390. 2.129 -4520. -3696. 2146. -302.5 -861.5 -8304. -4252. 5064. 5668. 1350. -7212. 2476. 2216. 1937. 6060. -1086. 3390. 1909. -5884. -2896. 3650. 1227. 2236. 24.12 564. 3022. -3512. -795.5 -6780. 2542. ]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "BinaryRepeatParams",
        "通用约束",
        "更多样例",
        "双目指令"
      ],
      "版本信息": "51.4"
    },
    {
      "API名称": "Rsqrt-单目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0030.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetStoreAtomicConfig(ISASI)-原子操作-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0286.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "is_base_of-type_traits-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10115.html",
      "功能说明": "is_base_of是定义于<type_traits>头文件的一个类型特征工具，它能够在程序编译时检查一个类型是否为另一个类型的基类。本接口可应用在模板元编程、类型检查和条件编译等场景，用于在编译阶段捕获潜在的类型错误，提高代码的鲁棒性。 is_base_of是定义于<type_traits>头文件的一个类型特征工具，它能够在程序编译时检查一个类型是否为另一个类型的基类。本接口可应用在模板元编程、类型检查和条件编译等场景，用于在编译阶段捕获潜在的类型错误，提高代码的鲁棒性。 表1 模板参数说明参数名 含义 Base 待检查的基类类型，即Base类型是否为Derived类型的基类。 Derived 待检查的派生类类型，即Base类型是否为Derived类型的基类。 is_base_of的静态常量成员value用于获取返回的布尔值，is_base_of<Base, Derived>::value取值如下：",
      "函数原型": "of Derived (virtual inheritance)",
      "参数说明": [
        {
          "参数名": "Base",
          "类型": "",
          "说明": "待检查的基类类型，即Base类型是否为Derived类型的基类。"
        },
        {
          "参数名": "Derived",
          "类型": "",
          "说明": "待检查的派生类类型，即Base类型是否为Derived类型的基类。"
        }
      ],
      "返回值": "is_base_of的静态常量成员value用于获取返回的布尔值，is_base_of<Base, Derived>::value取值如下：",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41",
      "约束限制": "",
      "相关接口": [
        "type_traits"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Sigmoid-Sigmoid-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0793.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetHF32TransMode-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0259.html",
      "功能说明": "设置HF32模式取整的具体方式，需要先使用SetHF32Mode开启HF32取整模式。 设置HF32模式取整的具体方式，需要先使用SetHF32Mode开启HF32取整模式。 表1 参数说明参数名 输入/输出 描述 hf32TransMode 输入 Mmad HF32取整模式控制入参，bool类型。支持如下两种取值： true：则FP32将以向零靠近的方式四舍五入为HF32。false：则FP32将以最接近偶数的方式四舍五入为HF32。",
      "函数原型": "__aicore__ inline void SetHF32TransMode(bool hf32TransMode)",
      "参数说明": [
        {
          "参数名": "hf32TransMode",
          "类型": "输入",
          "说明": "Mmad HF32取整模式控制入参，bool类型。支持如下两种取值： true：则FP32将以向零靠近的方式四舍五入为HF32。false：则FP32将以最接近偶数的方式四舍五入为HF32。"
        }
      ],
      "返回值": "无",
      "调用示例": "__aicore__ inline void SetHF32TransMode(bool hf32TransMode)\nbool hf32TransMode = true; AscendC::SetHF32TransMode(hf32TransMode);",
      "约束限制": "",
      "相关接口": [
        "SetHF32Mode",
        "矩阵计算(ISASI)"
      ],
      "版本信息": ""
    },
    {
      "API名称": "SetCmpMask(ISASI)-比较指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0224.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "简介-ContextBuilder-Tiling数据结构注册-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1007.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "TilingData结构定义-Tiling数据结构注册-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1005.html",
      "功能说明": "定义一个TilingData的类，添加所需的成员变量（TilingData字段），用于保存所需TilingData参数。完成该TilingData类的定义后，该类通过继承TilingDef类（用来存放、处理用户自定义Tiling结构体成员变量的基类）提供以下接口： 定义一个TilingData的类，添加所需的成员变量（TilingData字段），用于保存所需TilingData参数。完成该TilingData类的定义后，该类通过继承TilingDef类（用来存放、处理用户自定义Tiling结构体成员变量的基类）提供以下接口： 表1 BEGIN_TILING_DATA_DEF参数说明参数 输入/输出 说明 class_name 输入 用户定义tiling结构体名，与c++变量命名要求一致 表2 TILING_DATA_FIELD_DEF参数说明参数 输入/输出 说明 data_type 输入 字段的数据类型 field_name 输入 字段名，与c++变量命名要求一致 表3 TILING_DATA_FIELD_DEF_ARR参数说明参数 输入/输出 说明 arr_type 输入 数组元素数据类型 arr_size 输入 数组元素个数 field_name 输入 字段名，与c++变量命名要求一致 表4 TILING_DATA_FIELD_DEF_STRUCT参数说明参数 输入/输出 说明 struct_type 输入 结构体类型 field_name 输入 字段名，与c++变量命名要求一致",
      "函数原型": "注册算子tilingdata类到对应的AddCustom算子 REGISTER_TILING_DATA_CLASS(AddCustom, AddCustomTilingData)",
      "参数说明": [
        {
          "参数名": "class_name",
          "类型": "输入",
          "说明": "用户定义tiling结构体名，与c++变量命名要求一致"
        },
        {
          "参数名": "data_type",
          "类型": "输入",
          "说明": "字段的数据类型"
        },
        {
          "参数名": "field_name",
          "类型": "输入",
          "说明": "字段名，与c++变量命名要求一致"
        },
        {
          "参数名": "arr_type",
          "类型": "输入",
          "说明": "数组元素数据类型"
        },
        {
          "参数名": "arr_size",
          "类型": "输入",
          "说明": "数组元素个数"
        },
        {
          "参数名": "field_name",
          "类型": "输入",
          "说明": "字段名，与c++变量命名要求一致"
        },
        {
          "参数名": "struct_type",
          "类型": "输入",
          "说明": "结构体类型"
        },
        {
          "参数名": "field_name",
          "类型": "输入",
          "说明": "字段名，与c++变量命名要求一致"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38",
      "约束限制": "",
      "相关接口": [
        "Tiling数据结构注册"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Broadcast-数据填充-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0853.html",
      "功能说明": "将输入按照输出shape进行广播。 比如A的shape为(2,1)，广播的目标shape为(2,16)，则会将原来的一列扩展为相同的16列。 1 2 3 4 5 6输入数据： [[ 1] [ 2]] 输出数据： [[ 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [ 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]] 将输入按照输出shape进行广播。 比如A的shape为(2,1)，广播的目标shape为(2,16)，则会将原来的一列扩展为相同的16列。 1 2 3 4 5 6输入数据： [[ 1] [ 2]] 输出数据： [[ 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [ 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]] 表1 模板参数说明参数名称 功能 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：uint8_t/int8_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：uint8_t/int8_t/half/float Atlas 推理系列产品AI Core，支持的数据类型为：uint8_t/int8_t/half/float dim 输入/输出tensor的维度，目前仅支持1维和2维。 axis 要广播的维度，目前仅支持0和1。 isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 表2 接口参数说明参数名称 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcLocal 输入 源操作数。 源操作数的数据类型需要与目的操作数保持一致。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 dstShape 输入 输出tensor的shape：uint32_t类型的数组，长度为1或者2， 输入/输出的shape维度数目必须一致。 srcShape 输入 输入tensor的shape：uint32_t类型的数组，长度为1或者2， 输入/输出的shape维度数目必须一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Broadcast内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetBroadCastMaxMinTmpSize。",
      "函数原型": "template <typename T, int32_t dim, int32_t axis, bool isReuseSource = false> __aicore__ inline void Broadcast(const LocalTensor<T> &dstLocal, const LocalTensor<T> &srcLocal, const uint32_t dstShape[dim], const uint32_t srcShape[dim], LocalTensor<uint8_t> &sharedTmpBuffer)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：uint8_t/int8_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：uint8_t/int8_t/half/float Atlas 推理系列产品AI Core，支持的数据类型为：uint8_t/int8_t/half/float"
        },
        {
          "参数名": "dim",
          "类型": "",
          "说明": "输入/输出tensor的维度，目前仅支持1维和2维。"
        },
        {
          "参数名": "axis",
          "类型": "",
          "说明": "要广播的维度，目前仅支持0和1。"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数。该参数预留，传入默认值false即可。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 源操作数的数据类型需要与目的操作数保持一致。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "dstShape",
          "类型": "输入",
          "说明": "输出tensor的shape：uint32_t类型的数组，长度为1或者2， 输入/输出的shape维度数目必须一致。"
        },
        {
          "参数名": "srcShape",
          "类型": "输入",
          "说明": "输入tensor的shape：uint32_t类型的数组，长度为1或者2， 输入/输出的shape维度数目必须一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Broadcast内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetBroadCastMaxMinTmpSize。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73",
      "约束限制": "",
      "相关接口": [
        "GetBroadCastMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "数据填充"
      ],
      "版本信息": ""
    },
    {
      "API名称": "ShiftLeft-标量双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0058.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetFlag/WaitFlag(ISASI)-核内同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0270.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ToBfloat16-标量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0021.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "RepeatReduceSum-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0086.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SyncAll-核间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0204.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LayerNorm-LayerNorm-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0796.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "DataCachePreload-缓存处理-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0176.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetSystemCycle(ISASI)-系统变量访问-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0282.html",
      "功能说明": "获取当前系统cycle数，若换算成时间需要按照50MHz的频率，时间单位为us，换算公式为：time = (cycle数/50) us 。 获取当前系统cycle数，若换算成时间需要按照50MHz的频率，时间单位为us，换算公式为：time = (cycle数/50) us 。 该接口是PIPE_S流水，若需要测试其他流水的指令时间，需要在调用该接口前通过PipeBarrier插入对应流水的同步，具体请参考调用示例。",
      "函数原型": "__aicore__ inline void InitTilingParam(int32_t& totalSize, int32_t& loopSize)",
      "参数说明": [],
      "返回值": "返回int64_t类型的系统cycle数。",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11\n1 2 3 4 5 6 7 8 9 10 11",
      "约束限制": "该接口是PIPE_S流水，若需要测试其他流水的指令时间，需要在调用该接口前通过PipeBarrier插入对应流水的同步，具体请参考调用示例。",
      "相关接口": [
        "PipeBarrier",
        "系统变量访问"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "Atanh-Atanh-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0556.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetSysWorkSpace-workspace-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0171.html",
      "功能说明": "框架需要使用的workspace称之为系统workspace。Matmul等高阶API需要系统workspace，所以在使用该类API时，需要调用该接口，设置系统workspace的指针。采用工程化算子开发方式或者kernel直调方式（开启-DHAVE_WORKSPACE编译选项）时，不需要开发者手动设置，框架会自动设置。其他场景下，需要开发者调用SetSysWorkSpace进行设置。 在kernel侧调用该接口前，需要在host侧调用GetLibApiWorkSpaceSize获取系统workspace的大小，并在host侧设置workspacesize大小。样例如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 // 用户自定义的tiling函数 static ge::graphStatus TilingFunc(gert::TilingContext* context) { AddApiTiling tiling; ... size_t usrSize = 256; // 设置用户需要使用的workspace大小。 // 如需要使用系统workspace需要调用GetLibApiWorkSpaceSize获取系统workspace的大小。 auto ascendcPlatform = platform_ascendc:: PlatformAscendC(context->GetPlatformInfo()); uint32_t sysWorkspaceSize = ascendcPlatform.GetLibApiWorkSpaceSize(); size_t *currentWorkspace = context->GetWorkspaceSizes(1); // 通过框架获取workspace的指针，GetWorkspaceSizes入参为所需workspace的块数。当前限制使用一块。 currentWorkspace[0] = usrSize + sysWorkspaceSize; // 设置总的workspace的数值大小，总的workspace空间由框架来申请并管理。 ... } 框架需要使用的workspace称之为系统workspace。Matmul等高阶API需要系统workspace，所以在使用该类API时，需要调用该接口，设置系统workspace的指针。采用工程化算子开发方式或者kernel直调方式（开启-DHAVE_WORKSPACE编译选项）时，不需要开发者手动设置，框架会自动设置。其他场景下，需要开发者调用SetSysWorkSpace进行设置。 在kernel侧调用该接口前，需要在host侧调用GetLibApiWorkSpaceSize获取系统workspace的大小，并在host侧设置workspacesize大小。样例如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 // 用户自定义的tiling函数 static ge::graphStatus TilingFunc(gert::TilingContext* context) { AddApiTiling tiling; ... size_t usrSize = 256; // 设置用户需要使用的workspace大小。 // 如需要使用系统workspace需要调用GetLibApiWorkSpaceSize获取系统workspace的大小。 auto ascendcPlatform = platform_ascendc:: PlatformAscendC(context->GetPlatformInfo()); uint32_t sysWorkspaceSize = ascendcPlatform.GetLibApiWorkSpaceSize(); size_t *currentWorkspace = context->GetWorkspaceSizes(1); // 通过框架获取workspace的指针，GetWorkspaceSizes入参为所需workspace的块数。当前限制使用一块。 currentWorkspace[0] = usrSize + sysWorkspaceSize; // 设置总的workspace的数值大小，总的workspace空间由框架来申请并管理。 ... } 表1 接口参数说明 参数名称 输入/输出 描述 workspace 输入 核函数传入的workspace的指针，包括系统workspace和用户使用的workspace。",
      "函数原型": "template<typename aType, typename bType, typename cType, typename biasType> __aicore__ inline void MatmulLeakyKernel<aType, bType, cType, biasType>::Init( GM_ADDR a, GM_ADDR b, GM_ADDR bias, GM_ADDR c, GM_ADDR workspace, const TCubeTiling& tiling, float alpha)",
      "参数说明": [
        {
          "参数名": "workspace",
          "类型": "输入",
          "说明": "核函数传入的workspace的指针，包括系统workspace和用户使用的workspace。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11\n1 2 3 4 5 6 7 8 9 10 11",
      "约束限制": "",
      "相关接口": [
        "Matmul",
        "workspace"
      ],
      "版本信息": ""
    },
    {
      "API名称": "DumpTensor-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0192.html",
      "功能说明": "基于算子工程开发的算子，可以使用该接口Dump指定Tensor的内容。同时支持打印自定义的附加信息（仅支持uint32_t数据类型的信息），比如打印当前行号等。 在算子kernel侧实现代码中需要打印Tensor数据的地方调用DumpTensor接口打印相关内容。样例如下： 1 AscendC::DumpTensor(srcLocal,5, dataLen); DumpTensor接口打印功能会对算子实际运行的性能带来一定影响，通常在调测阶段使用。开发者可以按需通过如下方式关闭打印功能。 自定义算子工程 修改算子工程op_kernel目录下的CMakeLists.txt文件，首行增加编译选项-DASCENDC_DUMP=0，关闭ASCENDC_DUMP开关，示例如下： 1 2 // 关闭所有算子的printf打印功能 add_ops_compile_options(ALL OPTIONS -DASCENDC_DUMP=0) Kernel直调工程 修改cmake目录下的npu_lib.cmake文件，在ascendc_compile_definitions命令中增加-DASCENDC_DUMP=0宏定义来关闭ASCENDC_DUMP开关。示例如下： 1 2 3 4 // 关闭所有算子的printf打印功能 ascendc_compile_definitions(ascendc_kernels_${RUN_MODE} PRIVATE -DASCENDC_DUMP=0 ) Dump时，每个block核的dump信息前会增加对应信息头DumpHead（32字节大小），用于记录核号和资源使用信息；每次Dump的Tensor数据前也会添加信息头DumpTensorHead（32字节大小），用于记录Tensor的相关信息。如下图所示，展示了多核打印场景下的打印信息结构。 DumpHead的具体信息如下： DumpHead打印时，除了上述打印还会自动打印当前所运行核的类型及对应的该类型下的核索引，如：AIV-0。 基于算子工程开发的算子，可以使用该接口Dump指定Tensor的内容。同时支持打印自定义的附加信息（仅支持uint32_t数据类型的信息），比如打印当前行号等。 在算子kernel侧实现代码中需要打印Tensor数据的地方调用DumpTensor接口打印相关内容。样例如下： 1 AscendC::DumpTensor(srcLocal,5, dataLen); DumpTensor接口打印功能会对算子实际运行的性能带来一定影响，通常在调测阶段使用。开发者可以按需通过如下方式关闭打印功能。 自定义算子工程 修改算子工程op_kernel目录下的CMakeLists.txt文件，首行增加编译选项-DASCENDC_DUMP=0，关闭ASCENDC_DUMP开关，示例如下： 1 2 // 关闭所有算子的printf打印功能 add_ops_compile_options(ALL OPTIONS -DASCENDC_DUMP=0) Kernel直调工程 修改cmake目录下的npu_lib.cmake文件，在ascendc_compile_definitions命令中增加-DASCENDC_DUMP=0宏定义来关闭ASCENDC_DUMP开关。示例如下： 1 2 3 4 // 关闭所有算子的printf打印功能 ascendc_compile_definitions(ascendc_kernels_${RUN_MODE} PRIVATE -DASCENDC_DUMP=0 ) Dump时，每个block核的dump信息前会增加对应信息头DumpHead（32字节大小），用于记录核号和资源使用信息；每次Dump的Tensor数据前也会添加信息头DumpTensorHead（32字节大小），用于记录Tensor的相关信息。如下图所示，展示了多核打印场景下的打印信息结构。 DumpHead的具体信息如下： DumpHead打印时，除了上述打印还会自动打印当前所运行核的类型及对应的该类型下的核索引，如：AIV-0。 表1 模板参数说明 参数名 描述 T 需要dump的Tensor的数据类型。支持的数据类型为uint8_t/int8_t/int16_t/uint16_t/int32_t/uint32_t/int64_t/uint64_t/float/half/bfloat16_t。 表2 参数说明 参数名 输入/输出 描述 tensor 输入 需要dump的Tensor。 待dump的tensor位于Unified Buffer/L1 Buffer/L0C Buffer时使用LocalTensor类型的tensor参数输入。 待dump的tensor位于Global Memory时使用GlobalTensor类型的tensor参数输入。 desc 输入 用户自定义附加信息（行号或其他自定义数字）。 在使用DumpTensor功能时，用户可通过desc参数附加自定义信息，以便在不同调用场景下区分Dump内容的来源。此功能有助于精准定位具体DumpTensor的输出，提升调试与分析效率。 dumpSize 输入 需要dump的元素个数。dump的元素总长度需要32字节对齐。 shapeInfo 输入 传入Tensor的shape信息，可按照shape信息进行打印。",
      "函数原型": "template <typename T> __aicore__ inline void DumpTensor(const GlobalTensor<T>& tensor, uint32_t desc, uint32_t dumpSize, const ShapeInfo& shapeInfo)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "需要dump的Tensor的数据类型。支持的数据类型为uint8_t/int8_t/int16_t/uint16_t/int32_t/uint32_t/int64_t/uint64_t/float/half/bfloat16_t。"
        },
        {
          "参数名": "tensor",
          "类型": "输入",
          "说明": "需要dump的Tensor。 待dump的tensor位于Unified Buffer/L1 Buffer/L0C Buffer时使用LocalTensor类型的tensor参数输入。 待dump的tensor位于Global Memory时使用GlobalTensor类型的tensor参数输入。"
        },
        {
          "参数名": "desc",
          "类型": "输入",
          "说明": "用户自定义附加信息（行号或其他自定义数字）。 在使用DumpTensor功能时，用户可通过desc参数附加自定义信息，以便在不同调用场景下区分Dump内容的来源。此功能有助于精准定位具体DumpTensor的输出，提升调试与分析效率。"
        },
        {
          "参数名": "dumpSize",
          "类型": "输入",
          "说明": "需要dump的元素个数。dump的元素总长度需要32字节对齐。"
        },
        {
          "参数名": "shapeInfo",
          "类型": "输入",
          "说明": "传入Tensor的shape信息，可按照shape信息进行打印。"
        }
      ],
      "返回值": "无",
      "调用示例": "AscendC::DumpTensor(srcLocal,5, dataLen);\n// 关闭所有算子的printf打印功能 add_ops_compile_options(ALL OPTIONS -DASCENDC_DUMP=0)\n// 关闭所有算子的printf打印功能 ascendc_compile_definitions(ascendc_kernels_${RUN_MODE} PRIVATE -DASCENDC_DUMP=0 )\ntemplate <typename T> __aicore__ inline void DumpTensor(const LocalTensor<T> &tensor, uint32_t desc, uint32_t dumpSize) template <typename T> __aicore__ inline void DumpTensor(const GlobalTensor<T>& tensor, uint32_t desc, uint32_t dumpSize)\ntemplate <typename T> __aicore__ inline void DumpTensor(const LocalTensor<T>& tensor, uint32_t desc, uint32_t dumpSize, const ShapeInfo& shapeInfo) template <typename T> __aicore__ inline void DumpTensor(const GlobalTensor<T>& tensor, uint32_t desc, uint32_t dumpSize, const ShapeInfo& shapeInfo)\nAscendC::DumpTensor(srcLocal,5, dataLen);\nuint32_t array[] = {static_cast<uint32_t>(8),static_cast<uint32_t>(8)}; AscendC::ShapeInfo shapeInfo(2, array); // dim为2， shape为(8,8) AscendC::DumpTensor(x, 2, 64, shapeInfo); // dump x的64个元素，且解析按照shapeInfo的(8,8)排列",
      "约束限制": "",
      "相关接口": [
        "通用约束",
        "算子调测API"
      ],
      "版本信息": "XX.XX,"
    },
    {
      "API名称": "使用说明-Conv3DBackpropInput-Conv3DBackpropInput-卷积反向-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0918.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Maxs-标量双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0056.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetFixpipePreQuantFlag(ISASI)-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0254.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "TPipe构造函数-TPipe-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0108.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "FasterGeluV2-Gelu-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0773.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "昇腾算子开发场景-昇腾社区",
      "API文档URL": "https://www.hiascend.com/developer/operator",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [
        "Ascend C HelloWorld样例",
        "算子开发指南",
        "算子开发工具文档",
        "算子开发代码样例",
        "矩阵/融合算子编程文档",
        "矩阵/融合算子编程样例"
      ],
      "版本信息": ""
    },
    {
      "API名称": "tuple-容器函数-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10108.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LogSoftMax-LogSoftMax-激活函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0768.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Mean-Mean-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0829.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "同步&异步API说明-AscendCL API（C&C++）-AscendCL应用开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/appdevgapi/aclcppdevg_03_0020.html",
      "功能说明": "CANN支持以下几类显式同步，调用此类接口后，主机线程会阻塞直到相关的任务执行完成。 设备同步：例如aclrtSynchronizeDevice阻塞当前主机线程直到Device上所有显式或隐式创建的Stream都完成所有先前下发的任务。应该尽量少使用该函数，以免拖延主机运行。 流同步：例如aclrtSynchronizeStream阻塞当前主机线程直到指定的Stream中完成所有下发的任务。 事件同步：例如aclrtSynchronizeEvent阻塞当前主机线程直到指定的Event事件完成。属于更细粒度的同步。 对于异步接口，主机线程调用异步接口后仅代表下发任务，在任务未完成前，异步接口已向主机线程返回成功。用户需要调用上面的显式同步接口阻塞主机线程，等待任务完成，否则可能会导致训练或推理等业务异常、Device断链掉卡等未知情况。 父主题： AscendCL API（C&C++）",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [
        "AscendCL API（C&C++）"
      ],
      "版本信息": ""
    },
    {
      "API名称": "is_same-type_traits-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10116.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "简介-TilingContext-gert命名空间-基础数据结构和接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/basicdataapi/atlasopapi_07_00223.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Normalize-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0810.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LayerNorm-LayerNorm-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0797.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ReduceXorSum-ReduceXorSum-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0833.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "enable_if-type_traits-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10117.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "设置kernel类型-Kernel Tiling-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0218.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "同步控制简介-TQueSync-核内同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0178.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "AscendDequant-量化反量化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0820.html",
      "功能说明": "按元素做反量化计算，比如将int32_t数据类型反量化为half/float等数据类型。本接口最多支持输入为二维数据，不支持更高维度的输入。 下面通过两个具体的示例来解释参数的配置和计算逻辑（下文中DequantParams类型为存储shape信息的结构体{m, n, calCount}）： 当用户将模板参数中的mode配置为DEQUANT_WITH_SINGLE_ROW时： 针对DequantParams {m, n, calCount}， 若同时满足以下3个条件： 此时 {1, n, calCount}会被视作为 {n / calCount, calCount, calCount} 进行反量化的计算。 按元素做反量化计算，比如将int32_t数据类型反量化为half/float等数据类型。本接口最多支持输入为二维数据，不支持更高维度的输入。 下面通过两个具体的示例来解释参数的配置和计算逻辑（下文中DequantParams类型为存储shape信息的结构体{m, n, calCount}）： 当用户将模板参数中的mode配置为DEQUANT_WITH_SINGLE_ROW时： 针对DequantParams {m, n, calCount}， 若同时满足以下3个条件： 此时 {1, n, calCount}会被视作为 {n / calCount, calCount, calCount} 进行反量化的计算。 表1 模板参数说明 参数名 描述 dstT 目的操作数的数据类型。 scaleT deqScale的数据类型。 mode 决定当DequantParams为{1, n, calCount}时的计算逻辑，传入enum DeQuantMode，支持以下 2 种配置： DEQUANT_WITH_SINGLE_ROW：当DequantParams {m, n, calCount} 同时满足以下条件：1、m = 1；2、calCount为 32 / sizeof(dstT)的倍数；3、n % calCount = 0时，即 {1, n, calCount} 会当作 {n / calCount, calCount, calCount} 进行计算。 DEQUANT_WITH_MULTI_ROW：即使满足上述所有条件，{1, n, calCount} 依然只会当作 {1, n, calCount} 进行计算， 即总共n个数，前calCount个数进行反量化的计算。 表2 接口参数说明 参数名 输入/输出 描述 dstTensor 输出 目的操作数。类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float/bfloat16_t Atlas 推理系列产品 AI Core，支持的数据类型为：half/float dstTensor的行数和srcTensor的行数保持一致 n * sizeof(dstT)不满足32字节对齐时，需要向上补齐为32字节，n_dst为向上补齐后的列数。如srcTensor数据类型为int32_t，shape为 (4, 8)，dstTensor为bfloat16_t，则n_dst应从8补齐为16，dstTensor shape为(4, 16)。补齐的计算过程为：n_dst = (8 * sizeof(bfloat16_t) + 32 - 1) / 32 * 32 / sizeof(bfloat16_t)。 srcTensor 输入 源操作数。类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int32_t Atlas 推理系列产品 AI Core，支持的数据类型为：int32_t shape为 [m, n]，n个输入数据所占字节数要求32字节对齐。 deqScale 输入 源操作数。类型为标量或者LocalTensor。类型为LocalTensor时，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，当deqScale为矢量时，支持的数据类型为：uint64_t/float/bfloat16_t；当deqScale为标量时，支持的数据类型为bfloat16_t/float。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，当deqScale为矢量时，支持的数据类型为：uint64_t/float/bfloat16_t；当deqScale为标量时，支持的数据类型为bfloat16_t/float。 Atlas 推理系列产品 AI Core，当deqScale为矢量时，支持的数据类型为：uint64_t/float；当deqScale为标量时，支持的数据类型为float。 dstTensor、srcTensor、deqScale支持的数据类型组合请参考表3和表4。 sharedTmpBuffer 输入 临时缓存。类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考GetAscendDequantMaxMinTmpSize。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint8_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint8_t Atlas 推理系列产品 AI Core，支持的数据类型为：uint8_t params 输入 srcTensor的shape信息。DequantParams类型，具体定义如下： 1 2 3 4 5 6 struct DequantParams { uint32_t m; // srcTensor的行数 uint32_t n; // srcTensor的列数 uint32_t calCount; // 针对srcTensor每一行，前calCount个数为有效数据，与deqScale的前calCount个数或者deqScale标量进行乘法计算 }; DequantParams.n * sizeof(T)必须是32字节的整数倍，T为srcTensor中元素的数据类型。 因为是每n个数中的前calCount个数进行乘法运算，因此DequantParams.n和calCount需要满足以下关系 1 <= DequantParams.calCount <= DequantParams.n。 deqScale为矢量时，DequantParams.calCount <= deqScale的元素个数。 表3 支持的数据类型组合（deqScale为LocalTensor） dstTensor srcTensor deqScale half int32_t uint64_t 注意：当deqScale的数据类型是uint64_t时，数值低32位是参与计算的数据，数据类型是float，数值高32位是一些控制参数，本接口不使用。 float int32_t float float int32_t bfloat16_t bfloat16_t int32_t bfloat16_t bfloat16_t int32_t float 表4 支持的数据类型组合（deqScale为标量） dstTensor srcTensor deqScale bfloat16_t int32_t bfloat16_t bfloat16_t int32_t float float int32_t bfloat16_t float int32_t float",
      "函数原型": "template <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW> __aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const LocalTensor<scaleT>& deqScale, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
      "参数说明": [
        {
          "参数名": "dstT",
          "类型": "",
          "说明": "目的操作数的数据类型。"
        },
        {
          "参数名": "scaleT",
          "类型": "",
          "说明": "deqScale的数据类型。"
        },
        {
          "参数名": "mode",
          "类型": "",
          "说明": "决定当DequantParams为{1, n, calCount}时的计算逻辑，传入enum DeQuantMode，支持以下 2 种配置： DEQUANT_WITH_SINGLE_ROW：当DequantParams {m, n, calCount} 同时满足以下条件：1、m = 1；2、calCount为 32 / sizeof(dstT)的倍数；3、n % calCount = 0时，即 {1, n, calCount} 会当作 {n / calCount, calCount, calCount} 进行计算。 DEQUANT_WITH_MULTI_ROW：即使满足上述所有条件，{1, n, calCount} 依然只会当作 {1, n, calCount} 进行计算， 即总共n个数，前calCount个数进行反量化的计算。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float/bfloat16_t Atlas 推理系列产品 AI Core，支持的数据类型为：half/float dstTensor的行数和srcTensor的行数保持一致 n * sizeof(dstT)不满足32字节对齐时，需要向上补齐为32字节，n_dst为向上补齐后的列数。如srcTensor数据类型为int32_t，shape为 (4, 8)，dstTensor为bfloat16_t，则n_dst应从8补齐为16，dstTensor shape为(4, 16)。补齐的计算过程为：n_dst = (8 * sizeof(bfloat16_t) + 32 - 1) / 32 * 32 / sizeof(bfloat16_t)。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int32_t Atlas 推理系列产品 AI Core，支持的数据类型为：int32_t shape为 [m, n]，n个输入数据所占字节数要求32字节对齐。"
        },
        {
          "参数名": "deqScale",
          "类型": "输入",
          "说明": "源操作数。类型为标量或者LocalTensor。类型为LocalTensor时，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，当deqScale为矢量时，支持的数据类型为：uint64_t/float/bfloat16_t；当deqScale为标量时，支持的数据类型为bfloat16_t/float。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，当deqScale为矢量时，支持的数据类型为：uint64_t/float/bfloat16_t；当deqScale为标量时，支持的数据类型为bfloat16_t/float。 Atlas 推理系列产品 AI Core，当deqScale为矢量时，支持的数据类型为：uint64_t/float；当deqScale为标量时，支持的数据类型为float。 dstTensor、srcTensor、deqScale支持的数据类型组合请参考表3和表4。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考GetAscendDequantMaxMinTmpSize。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint8_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint8_t Atlas 推理系列产品 AI Core，支持的数据类型为：uint8_t"
        },
        {
          "参数名": "params",
          "类型": "输入",
          "说明": "srcTensor的shape信息。DequantParams类型，具体定义如下： 1 2 3 4 5 6 struct DequantParams { uint32_t m; // srcTensor的行数 uint32_t n; // srcTensor的列数 uint32_t calCount; // 针对srcTensor每一行，前calCount个数为有效数据，与deqScale的前calCount个数或者deqScale标量进行乘法计算 }; DequantParams.n * sizeof(T)必须是32字节的整数倍，T为srcTensor中元素的数据类型。 因为是每n个数中的前calCount个数进行乘法运算，因此DequantParams.n和calCount需要满足以下关系 1 <= DequantParams.calCount <= DequantParams.n。 deqScale为矢量时，DequantParams.calCount <= deqScale的元素个数。"
        },
        {
          "参数名": "1 2 3 4 5 6",
          "类型": "",
          "说明": "struct DequantParams { uint32_t m; // srcTensor的行数 uint32_t n; // srcTensor的列数 uint32_t calCount; // 针对srcTensor每一行，前calCount个数为有效数据，与deqScale的前calCount个数或者deqScale标量进行乘法计算 };"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW> __aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const LocalTensor<scaleT>& deqScale, const LocalTensor<uint8_t>& sharedTmpBuffer, DequantParams params)\ntemplate <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW> __aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const LocalTensor<scaleT>& deqScale, DequantParams params)\ntemplate <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW> __aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const scaleT deqScale, const LocalTensor<uint8_t>& sharedTmpBuffer, DequantParams params)\ntemplate <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW> __aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const scaleT deqScale, DequantParams params)\ntemplate <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW> __aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const LocalTensor<scaleT>& deqScale, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)\ntemplate <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW> __aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const LocalTensor<scaleT>& deqScale, const LocalTensor<uint8_t>& sharedTmpBuffer)\ntemplate <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW> __aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const LocalTensor<scaleT>& deqScale, const uint32_t calCount)\ntemplate <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW> __aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const LocalTensor<scaleT>& deqScale)\nrowLen = m; // m = 4 colLen = n; // n = 8 //输入srcLocal的shape为4*8，类型为int32_t，deqScaleLocal的shape为8，类型为float，预留临时空间 AscendC::AscendDequant(dstLocal, srcLocal, deqScaleLocal, {rowLen, colLen, deqScaleLocal.GetSize()});\n输入数据(srcLocal) int32_t数据类型: [ -8 5 -5 -7 -3 -8 3 6 9 2 -5 0 0 -5 -7 0 -6 0 -2 3 -2 8 5 2 2 2 -4 5 -4 4 -8 3 ] 反量化参数deqScale float数据类型: [ 10.433567 10.765296 -30.694275 -65.47741 8.386527 -89.646194 65.11153 42.213394] 输出数据(dstLocal) float数据类型: [-83.46854 53.82648 153.47137 458.34186 -25.15958 717.16956 195.33458 253.28036 93.9021 21.530592 153.47137 -0. 0. 448.23096 -455.7807 0. -62.601402 0. 61.38855 -196.43222 -16.773054 -717.16956 325.55762 84.42679 20.867134 21.530592 122.7771 -327.38705 -33.54611 -358.58478 -520.8922 126.64018 ]",
      "约束限制": "",
      "相关接口": [
        "GetAscendDequantMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "量化反量化"
      ],
      "版本信息": "10.433567"
    },
    {
      "API名称": "ICachePreLoad(ISASI)-缓存处理-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0276.html",
      "功能说明": "从指令所在DDR地址预加载指令到ICache中。 从指令所在DDR地址预加载指令到ICache中。 表1 参数说明参数名 输入/输出 描述 preFetchLen 输入 预取长度。 针对Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件：preFetchLen参数单位为2K Byte, 取值应小于ICache的大小/2K。AIC和AIV的ICache大小分别为32KB和16KB。 针对Atlas A3 训练系列产品/Atlas A3 推理系列产品：preFetchLen参数单位为2K Byte, 取值应小于ICache的大小/2K。AIC和AIV的ICache大小分别为32KB和16KB。 针对Atlas 推理系列产品AI Core：传入该参数无效，预取长度均为128Byte。",
      "函数原型": "__aicore__ inline void ICachePreLoad(const int64_t preFetchLen)",
      "参数说明": [
        {
          "参数名": "preFetchLen",
          "类型": "输入",
          "说明": "预取长度。 针对Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件：preFetchLen参数单位为2K Byte, 取值应小于ICache的大小/2K。AIC和AIV的ICache大小分别为32KB和16KB。 针对Atlas A3 训练系列产品/Atlas A3 推理系列产品：preFetchLen参数单位为2K Byte, 取值应小于ICache的大小/2K。AIC和AIV的ICache大小分别为32KB和16KB。 针对Atlas 推理系列产品AI Core：传入该参数无效，预取长度均为128Byte。"
        }
      ],
      "返回值": "无",
      "调用示例": "__aicore__ inline void ICachePreLoad(const int64_t preFetchLen)\nint64_t preFetchLen = 2; AscendC::ICachePreLoad(preFetchLen);",
      "约束限制": "",
      "相关接口": [
        "缓存处理"
      ],
      "版本信息": ""
    },
    {
      "API名称": "REGISTER_TILING_FOR_TILINGKEY-Kernel Tiling-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00004.html",
      "功能说明": "用于在kernel侧注册与TilingKey相匹配的TilingData自定义结构体；该接口需提供一个逻辑表达式，逻辑表达式以字符串“TILING_KEY_VAR”代指实际TilingKey，表达TilingKey所满足的范围。 用于在kernel侧注册与TilingKey相匹配的TilingData自定义结构体；该接口需提供一个逻辑表达式，逻辑表达式以字符串“TILING_KEY_VAR”代指实际TilingKey，表达TilingKey所满足的范围。 参数 输入/输出 说明 EXPRESSION 输入 EXPRESSION为逻辑运算，其中用TILING_KEY_VAR指代TilingKey。 TILING_STRUCT 输入 用户注册的与TilingKey相匹配的TilingData自定义结构体。",
      "函数原型": "注册用户默认自定义TilingData结构体 REGISTER_TILING_FOR_TILINGKEY(\"TILING_KEY_VAR == 1\", optiling::TilingDataA);",
      "参数说明": [
        {
          "参数名": "EXPRESSION",
          "类型": "输入",
          "说明": "EXPRESSION为逻辑运算，其中用TILING_KEY_VAR指代TilingKey。"
        },
        {
          "参数名": "TILING_STRUCT",
          "类型": "输入",
          "说明": "用户注册的与TilingKey相匹配的TilingData自定义结构体。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23",
      "约束限制": "",
      "相关接口": [
        "Kernel Tiling"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Scatter(ISASI)-数据分散/数据收集-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0235.html",
      "功能说明": "给定一个连续的输入张量和一个目的地址偏移张量，Scatter指令根据偏移地址生成新的结果张量后将输入张量分散到结果张量中。 将源操作数src中的元素按照指定的位置（由dst_offset和base_addr共同作用）分散到目的操作数dst中。 给定一个连续的输入张量和一个目的地址偏移张量，Scatter指令根据偏移地址生成新的结果张量后将输入张量分散到结果张量中。 将源操作数src中的元素按照指定的位置（由dst_offset和base_addr共同作用）分散到目的操作数dst中。 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core，支持的数据类型为：uint16_t/uint32_t/float/half Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/uint32_t/int32_t/float 表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，类型为LocalTensor。LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数，类型为LocalTensor。数据类型需与dstLocal保持一致。 dstOffsetLocal 输入 用于存储源操作数的每个元素在dstLocal中对应的地址偏移。偏移基于dstLocal的基地址dstBaseAddr计算，以字节为单位，取值应保证按dstLocal数据类型位宽对齐，否则会导致非预期行为。 针对以下型号，地址偏移的取值范围不超出uint32_t的范围即可。 Atlas 推理系列产品 AI Core 针对以下型号，地址偏移的取值范围如下：当操作数为8位时，取值范围为[0, 216-1]；当操作数为16位时，取值范围为[0, 217-1]，当操作数为32位或者64位时，不超过uint32_t的范围即可。超出取值范围可能导致非预期输出。 Atlas 200I/500 A2 推理产品 dstBaseAddr 输入 dstLocal的起始偏移地址，单位是字节。取值应保证按dstLocal数据类型位宽对齐，否则会导致非预期行为。 count 输入 执行处理的数据个数。 mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。参数类型为长度为2的uint64_t类型数组。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 参数取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，mask[1]为0，mask[0]∈(0, 264-1]；当操作数为64位时，mask[1]为0，mask[0]∈(0, 232-1]。 repeatTimes 输入 指令迭代次数，每次迭代完成8个datablock的数据收集，数据范围：repeatTimes∈[0,255]。 特别地，针对以下型号： Atlas 200I/500 A2 推理产品 操作数为8位时，每次迭代完成4个datablock（32Bytes）的数据收集。 srcRepStride 输入 相邻迭代间的地址步长，单位是datablock。",
      "函数原型": "template <typename T> __aicore__ inline void Scatter(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<uint32_t>& dstOffsetLocal, const uint32_t dstBaseAddr, const uint64_t mask[], const uint8_t repeatTimes, const uint8_t srcRepStride)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 推理系列产品 AI Core，支持的数据类型为：uint16_t/uint32_t/float/half Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/uint32_t/int32_t/float"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数，类型为LocalTensor。LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数，类型为LocalTensor。数据类型需与dstLocal保持一致。"
        },
        {
          "参数名": "dstOffsetLocal",
          "类型": "输入",
          "说明": "用于存储源操作数的每个元素在dstLocal中对应的地址偏移。偏移基于dstLocal的基地址dstBaseAddr计算，以字节为单位，取值应保证按dstLocal数据类型位宽对齐，否则会导致非预期行为。 针对以下型号，地址偏移的取值范围不超出uint32_t的范围即可。 Atlas 推理系列产品 AI Core 针对以下型号，地址偏移的取值范围如下：当操作数为8位时，取值范围为[0, 216-1]；当操作数为16位时，取值范围为[0, 217-1]，当操作数为32位或者64位时，不超过uint32_t的范围即可。超出取值范围可能导致非预期输出。 Atlas 200I/500 A2 推理产品"
        },
        {
          "参数名": "dstBaseAddr",
          "类型": "输入",
          "说明": "dstLocal的起始偏移地址，单位是字节。取值应保证按dstLocal数据类型位宽对齐，否则会导致非预期行为。"
        },
        {
          "参数名": "count",
          "类型": "输入",
          "说明": "执行处理的数据个数。"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。参数类型为长度为2的uint64_t类型数组。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 参数取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，mask[1]为0，mask[0]∈(0, 264-1]；当操作数为64位时，mask[1]为0，mask[0]∈(0, 232-1]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "指令迭代次数，每次迭代完成8个datablock的数据收集，数据范围：repeatTimes∈[0,255]。 特别地，针对以下型号： Atlas 200I/500 A2 推理产品 操作数为8位时，每次迭代完成4个datablock（32Bytes）的数据收集。"
        },
        {
          "参数名": "srcRepStride",
          "类型": "输入",
          "说明": "相邻迭代间的地址步长，单位是datablock。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72",
      "约束限制": "",
      "相关接口": [
        "通用约束",
        "数据分散/数据收集"
      ],
      "版本信息": ""
    },
    {
      "API名称": "TILING_KEY_IS-Kernel Tiling-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0217.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "WaitPreTaskEnd-任务间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00088.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Log-Log-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0512.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ScalarCountLeadingZero-标量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0017.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "MetricsProfStop-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1215.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "IBWait-核间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0203.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Floor-Floor-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0568.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "DumpAccChkPoint-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0195.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Cast-精度转换指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0073.html",
      "功能说明": "根据源操作数和目的操作数Tensor的数据类型进行精度转换。 在了解精度转换规则之前，需要先了解浮点数的表示方式和二进制的舍入规则： 精度转换规则如下表所示（为方便描述下文描述中的src代表源操作数，dst代表目的操作数）： 表1 精度转换规则 src类型 dst类型 精度转换规则介绍 float float 将src按照round_mode（精度转换处理模式，参见参数说明中的round_mode参数）取整，仍以float格式存入dst中。 示例：输入0.5， CAST_RINT模式输出0.0，CAST_FLOOR模式输出0.0，CAST_CEIL模式输出1.0，CAST_ROUND模式输出1.0，CAST_TRUNC模式输出0.0。 half 将src按照round_mode取到half所能表示的数，以half格式（溢出默认按照饱和处理）存入dst中。 示例：输入0.5 + 2-12，写成float的表示形式：2-1 * (1 + 2-11)，因此E = -1 + 127 = 126，M = 2-11。 half的指数位可以表示出2-1，E = -1 + 15 = 14，但half只有10 bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数0000000000，E = 14，M = 0，最终表示的结果为0.5； CAST_FLOOR模式舍入得尾数0000000000，E = 14，M = 0，最终表示的结果为0.5； CAST_CEIL模式舍入得尾数0000000001，E = 14，M = 2-10，最终表示的结果为0.5 + 2-11； CAST_ROUND模式舍入得尾数0000000001，E = 14，M = 2-10，最终表示的结果为0.5 + 2-11； CAST_TRUNC模式舍入得尾数0000000000，E = 14，M = 0，最终表示的结果为0.5； CAST_ODD模式舍入得尾数0000000001，E = 14，M = 2-10，最终表示的结果为0.5 + 2-11 。 int64_t 将src按照round_mode取整，以int64_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入222 + 0.5， CAST_RINT模式输出222，CAST_FLOOR模式输出222，CAST_CEIL模式输出222 + 1，CAST_ROUND模式输出222 + 1，CAST_TRUNC模式输出222。 int32_t 将src按照round_mode取整，以int32_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入222 + 0.5， CAST_RINT模式输出222，CAST_FLOOR模式输出222 ，CAST_CEIL模式输出222 + 1，CAST_ROUND模式输出222 + 1，CAST_TRUNC模式输出222。 int16_t 将src按照round_mode取整，以int16_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入222 + 0.5， CAST_RINT模式输出215 - 1（溢出处理），CAST_FLOOR模式输出215 - 1（溢出处理），CAST_CEIL模式输出215 - 1（溢出处理），CAST_ROUND模式输出215 - 1（溢出处理），CAST_TRUNC模式输出215 - 1（溢出处理）。 bfloat16_t 将src按照round_mode取到bfloat16_t所能表示的数，以bfloat16_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入0.5+ 2-9 + 2-11 ，写成float的表示形式：2-1 * (1 + 2-8 + 2-10)，因此E = -1 + 127 = 126，M = 2-8 + 2-10 。 bfloat16_t的指数位位数和float的相同，有E = 126，但bfloat16_t只有7bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数0000001，E = 126，M = 2-7，最终表示的结果为0.5 + 2-8； CAST_FLOOR模式舍入得尾数0000000，E = 126，M = 0，最终表示的结果为0.5； CAST_CEIL模式舍入得尾数0000001，E = 126，M = 2-7，最终表示的结果为0.5 + 2-8； CAST_ROUND模式舍入得尾数0000001，E = 126，M = 2-7，最终表示的结果为0.5 + 2-8； CAST_TRUNC模式舍入得尾数0000000，E = 126，M = 0，最终表示的结果为0.5。 half float 将src以float格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1.5 - 2-10，输出1.5 - 2-10。 int32_t 将src按照round_mode取整，以int32_t格式存入dst中。 示例：输入-1.5， CAST_RINT模式输出-2，CAST_FLOOR模式输出-2，CAST_CEIL模式输出-1，CAST_ROUND模式输出-2，CAST_TRUNC模式输出-1。 int16_t 将src按照round_mode取整，以int16_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入27 - 0.5， CAST_RINT模式输出27，CAST_FLOOR模式输出27 - 1，CAST_CEIL模式输出27，CAST_ROUND模式输出27，CAST_TRUNC模式输出27 - 1。 int8_t 将src按照round_mode取整，以int8_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入27 - 0.5， CAST_RINT模式输出27 - 1（溢出处理），CAST_FLOOR模式输出27 - 1，CAST_CEIL模式输出27 - 1（溢出处理），CAST_ROUND模式输出27 - 1（溢出处理），CAST_TRUNC模式输出27 - 1。 uint8_t 将src按照round_mode取整，以uint8_t格式（溢出默认按照饱和处理）存入dst中。 负数输入会被视为异常。 示例：输入1.75， CAST_RINT模式输出2，CAST_FLOOR模式输出1，CAST_CEIL模式输出2，CAST_ROUND模式输出2，CAST_TRUNC模式输出1。 int4b_t 将src按照round_mode取整，以int4b_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入1.5， CAST_RINT模式输出2，CAST_FLOOR模式输出1，CAST_CEIL模式输出2，CAST_ROUND模式输出2，CAST_TRUNC模式输出1。 bfloat16_t float 将src以float格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1.5 - 2-6，输出1.5 - 2-6。 int32_t 将src按照round_mode取整，以int32_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入26 + 0.5 CAST_RINT模式输出26，CAST_FLOOR模式输出26 ，CAST_CEIL模式输出26 + 1，CAST_ROUND模式输出26 + 1，CAST_TRUNC模式输出26。 int4b_t half 将src以half格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1，输出1.0。 uint8_t half 将src以half格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1，输出1.0。 int8_t half 将src以half格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入-1，输出-1.0。 int16_t half 将src按照round_mode取到half所能表示的数，以half格式存入dst中。 示例：输入212 + 2，写成half的表示形式：212 * (1 + 2-11)，要求E = 12 + 15 = 27，M = 2-11： 由于half只有10bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数0000000000，E = 27，M = 0，最终表示的结果为212； CAST_FLOOR模式舍入得尾数0000000000，E = 27，M = 0，最终表示的结果为212； CAST_CEIL模式舍入得尾数0000000001，E = 27，M = 2-10，最终表示的结果为212 + 4； CAST_ROUND模式舍入得尾数0000000001，E = 27，M = 2-10，最终表示的结果为212 + 4； CAST_TRUNC模式舍入得尾数0000000000，E = 27，M = 0，最终表示的结果为212。 float 将src以float格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入215 - 1，输出215 - 1。 int32_t float 将src按照round_mode取到float所能表示的数，以float格式存入dst中。 示例：输入225 + 3，写成float的表示形式：225 * (1 + 2-24 + 2-25)，要求E = 25 + 127 = 152， M = 2-24 + 2-25。 由于float只有23bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数00000000000000000000001，E = 152，M = 2-23，最终表示的结果为225 + 4； CAST_FLOOR模式舍入得尾数00000000000000000000000，E = 152，M = 0，最终表示的结果为225； CAST_CEIL模式舍入得尾数00000000000000000000001，E = 152，M = 2-23，最终表示的结果为225 + 4； CAST_ROUND模式舍入得尾数00000000000000000000001，E = 152，M = 2-23，最终表示的结果为225 + 4； CAST_TRUNC模式舍入得尾数00000000000000000000000，E = 152，M = 0，最终表示的结果为225 。 int64_t 将src以int64_t格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入231 - 1，输出231 - 1。 int16_t 将src以int16_t格式（溢出默认按照饱和处理）存入dst中，不存在精度转换问题，无舍入模式。 示例：输入231 - 1，输出215 - 1。 half 与SetDeqScale(half scale)接口配合使用，输出src / 217 * scale * 217。 int64_t int32_t 将src以int32_t格式（溢出默认按照饱和处理）存入dst中，不存在精度转换问题，无舍入模式。 示例：输入231，输出231 - 1。 float 将src按照round_mode取到float所能表示的数，以float格式存入dst中。 示例：输入235 + 212 + 211，写成float的表示形式：235 * (1 + 2-23 + 2-24)，要求E = 35 + 127 = 162，M = 2-23 + 2-24。 由于float只有23bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数00000000000000000000010，E = 162，M = 2-22，最终表示的结果为235 + 213； CAST_FLOOR模式舍入得尾数00000000000000000000001，E = 162，M = 2-23，最终表示的结果为225 + 212； CAST_CEIL模式舍入得尾数00000000000000000000010，E = 162，M = 2-22，最终表示的结果为225 + 213； CAST_ROUND模式舍入得尾数00000000000000000000010，E = 162，M = 2-22，最终表示的结果为225 + 213； CAST_TRUNC模式舍入得尾数00000000000000000000001，E = 162，M = 2-23，最终表示的结果为225 + 212。 根据源操作数和目的操作数Tensor的数据类型进行精度转换。 在了解精度转换规则之前，需要先了解浮点数的表示方式和二进制的舍入规则： 精度转换规则如下表所示（为方便描述下文描述中的src代表源操作数，dst代表目的操作数）： 表1 精度转换规则 src类型 dst类型 精度转换规则介绍 float float 将src按照round_mode（精度转换处理模式，参见参数说明中的round_mode参数）取整，仍以float格式存入dst中。 示例：输入0.5， CAST_RINT模式输出0.0，CAST_FLOOR模式输出0.0，CAST_CEIL模式输出1.0，CAST_ROUND模式输出1.0，CAST_TRUNC模式输出0.0。 half 将src按照round_mode取到half所能表示的数，以half格式（溢出默认按照饱和处理）存入dst中。 示例：输入0.5 + 2-12，写成float的表示形式：2-1 * (1 + 2-11)，因此E = -1 + 127 = 126，M = 2-11。 half的指数位可以表示出2-1，E = -1 + 15 = 14，但half只有10 bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数0000000000，E = 14，M = 0，最终表示的结果为0.5； CAST_FLOOR模式舍入得尾数0000000000，E = 14，M = 0，最终表示的结果为0.5； CAST_CEIL模式舍入得尾数0000000001，E = 14，M = 2-10，最终表示的结果为0.5 + 2-11； CAST_ROUND模式舍入得尾数0000000001，E = 14，M = 2-10，最终表示的结果为0.5 + 2-11； CAST_TRUNC模式舍入得尾数0000000000，E = 14，M = 0，最终表示的结果为0.5； CAST_ODD模式舍入得尾数0000000001，E = 14，M = 2-10，最终表示的结果为0.5 + 2-11 。 int64_t 将src按照round_mode取整，以int64_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入222 + 0.5， CAST_RINT模式输出222，CAST_FLOOR模式输出222，CAST_CEIL模式输出222 + 1，CAST_ROUND模式输出222 + 1，CAST_TRUNC模式输出222。 int32_t 将src按照round_mode取整，以int32_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入222 + 0.5， CAST_RINT模式输出222，CAST_FLOOR模式输出222 ，CAST_CEIL模式输出222 + 1，CAST_ROUND模式输出222 + 1，CAST_TRUNC模式输出222。 int16_t 将src按照round_mode取整，以int16_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入222 + 0.5， CAST_RINT模式输出215 - 1（溢出处理），CAST_FLOOR模式输出215 - 1（溢出处理），CAST_CEIL模式输出215 - 1（溢出处理），CAST_ROUND模式输出215 - 1（溢出处理），CAST_TRUNC模式输出215 - 1（溢出处理）。 bfloat16_t 将src按照round_mode取到bfloat16_t所能表示的数，以bfloat16_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入0.5+ 2-9 + 2-11 ，写成float的表示形式：2-1 * (1 + 2-8 + 2-10)，因此E = -1 + 127 = 126，M = 2-8 + 2-10 。 bfloat16_t的指数位位数和float的相同，有E = 126，但bfloat16_t只有7bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数0000001，E = 126，M = 2-7，最终表示的结果为0.5 + 2-8； CAST_FLOOR模式舍入得尾数0000000，E = 126，M = 0，最终表示的结果为0.5； CAST_CEIL模式舍入得尾数0000001，E = 126，M = 2-7，最终表示的结果为0.5 + 2-8； CAST_ROUND模式舍入得尾数0000001，E = 126，M = 2-7，最终表示的结果为0.5 + 2-8； CAST_TRUNC模式舍入得尾数0000000，E = 126，M = 0，最终表示的结果为0.5。 half float 将src以float格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1.5 - 2-10，输出1.5 - 2-10。 int32_t 将src按照round_mode取整，以int32_t格式存入dst中。 示例：输入-1.5， CAST_RINT模式输出-2，CAST_FLOOR模式输出-2，CAST_CEIL模式输出-1，CAST_ROUND模式输出-2，CAST_TRUNC模式输出-1。 int16_t 将src按照round_mode取整，以int16_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入27 - 0.5， CAST_RINT模式输出27，CAST_FLOOR模式输出27 - 1，CAST_CEIL模式输出27，CAST_ROUND模式输出27，CAST_TRUNC模式输出27 - 1。 int8_t 将src按照round_mode取整，以int8_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入27 - 0.5， CAST_RINT模式输出27 - 1（溢出处理），CAST_FLOOR模式输出27 - 1，CAST_CEIL模式输出27 - 1（溢出处理），CAST_ROUND模式输出27 - 1（溢出处理），CAST_TRUNC模式输出27 - 1。 uint8_t 将src按照round_mode取整，以uint8_t格式（溢出默认按照饱和处理）存入dst中。 负数输入会被视为异常。 示例：输入1.75， CAST_RINT模式输出2，CAST_FLOOR模式输出1，CAST_CEIL模式输出2，CAST_ROUND模式输出2，CAST_TRUNC模式输出1。 int4b_t 将src按照round_mode取整，以int4b_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入1.5， CAST_RINT模式输出2，CAST_FLOOR模式输出1，CAST_CEIL模式输出2，CAST_ROUND模式输出2，CAST_TRUNC模式输出1。 bfloat16_t float 将src以float格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1.5 - 2-6，输出1.5 - 2-6。 int32_t 将src按照round_mode取整，以int32_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入26 + 0.5 CAST_RINT模式输出26，CAST_FLOOR模式输出26 ，CAST_CEIL模式输出26 + 1，CAST_ROUND模式输出26 + 1，CAST_TRUNC模式输出26。 int4b_t half 将src以half格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1，输出1.0。 uint8_t half 将src以half格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1，输出1.0。 int8_t half 将src以half格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入-1，输出-1.0。 int16_t half 将src按照round_mode取到half所能表示的数，以half格式存入dst中。 示例：输入212 + 2，写成half的表示形式：212 * (1 + 2-11)，要求E = 12 + 15 = 27，M = 2-11： 由于half只有10bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数0000000000，E = 27，M = 0，最终表示的结果为212； CAST_FLOOR模式舍入得尾数0000000000，E = 27，M = 0，最终表示的结果为212； CAST_CEIL模式舍入得尾数0000000001，E = 27，M = 2-10，最终表示的结果为212 + 4； CAST_ROUND模式舍入得尾数0000000001，E = 27，M = 2-10，最终表示的结果为212 + 4； CAST_TRUNC模式舍入得尾数0000000000，E = 27，M = 0，最终表示的结果为212。 float 将src以float格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入215 - 1，输出215 - 1。 int32_t float 将src按照round_mode取到float所能表示的数，以float格式存入dst中。 示例：输入225 + 3，写成float的表示形式：225 * (1 + 2-24 + 2-25)，要求E = 25 + 127 = 152， M = 2-24 + 2-25。 由于float只有23bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数00000000000000000000001，E = 152，M = 2-23，最终表示的结果为225 + 4； CAST_FLOOR模式舍入得尾数00000000000000000000000，E = 152，M = 0，最终表示的结果为225； CAST_CEIL模式舍入得尾数00000000000000000000001，E = 152，M = 2-23，最终表示的结果为225 + 4； CAST_ROUND模式舍入得尾数00000000000000000000001，E = 152，M = 2-23，最终表示的结果为225 + 4； CAST_TRUNC模式舍入得尾数00000000000000000000000，E = 152，M = 0，最终表示的结果为225 。 int64_t 将src以int64_t格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入231 - 1，输出231 - 1。 int16_t 将src以int16_t格式（溢出默认按照饱和处理）存入dst中，不存在精度转换问题，无舍入模式。 示例：输入231 - 1，输出215 - 1。 half 与SetDeqScale(half scale)接口配合使用，输出src / 217 * scale * 217。 int64_t int32_t 将src以int32_t格式（溢出默认按照饱和处理）存入dst中，不存在精度转换问题，无舍入模式。 示例：输入231，输出231 - 1。 float 将src按照round_mode取到float所能表示的数，以float格式存入dst中。 示例：输入235 + 212 + 211，写成float的表示形式：235 * (1 + 2-23 + 2-24)，要求E = 35 + 127 = 162，M = 2-23 + 2-24。 由于float只有23bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数00000000000000000000010，E = 162，M = 2-22，最终表示的结果为235 + 213； CAST_FLOOR模式舍入得尾数00000000000000000000001，E = 162，M = 2-23，最终表示的结果为225 + 212； CAST_CEIL模式舍入得尾数00000000000000000000010，E = 162，M = 2-22，最终表示的结果为225 + 213； CAST_ROUND模式舍入得尾数00000000000000000000010，E = 162，M = 2-22，最终表示的结果为225 + 213； CAST_TRUNC模式舍入得尾数00000000000000000000001，E = 162，M = 2-23，最终表示的结果为225 + 212。 表2 模板参数说明 参数名 描述 T1 目的操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型见表4 Atlas 推理系列产品 AI Core，支持的数据类型见表5 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型见表6 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型见表7 Atlas 200I/500 A2 推理产品 ，支持的数据类型见表8 T2 源操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型见表4 Atlas 推理系列产品 AI Core，支持的数据类型见表5 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型见表6 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型见表7 Atlas 200I/500 A2 推理产品 ，支持的数据类型见表8 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表3 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 round_mode 输入 精度转换处理模式，类型是RoundMode。 RoundMode为枚举类型，用以控制精度转换处理模式，具体定义为： 1 2 3 4 5 6 7 8 9 10 enum class RoundMode { CAST_NONE = 0, // 在转换有精度损失时表示CAST_RINT模式，不涉及精度损失时表示不舍入 CAST_RINT, // rint，四舍六入五成双舍入 CAST_FLOOR, // floor，向负无穷舍入 CAST_CEIL, // ceil，向正无穷舍入 CAST_ROUND, // round，四舍五入舍入 CAST_TRUNC, // trunc，向零舍入 CAST_ODD, // Von Neumann rounding，最近邻奇数舍入 }; 对于 Atlas 训练系列产品 ，CAST_ROUND表示反向0取整，远离0，对正数x.y变成(x + 1)，对负数-x.y，变成-(x + 1)。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数，repeatTimes∈[0,255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数，UnaryRepeatParams类型。包含操作数相邻迭代间的地址步长，操作数同一迭代内datablock的地址步长等参数。其中dstRepStride/srcRepStride∈[0,255]。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。 表4 Atlas 训练系列产品 Cast指令参数说明 src数据类型 dst数据类型 支持的roundMode half float CAST_NONE int32_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC int8_t CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_NONE uint8_t CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_NONE float half CAST_NONE/CAST_ODD int32_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC uint8_t half CAST_NONE int8_t half CAST_NONE int32_t float CAST_NONE 表5 Atlas 推理系列产品 AI CoreCast指令参数说明 src数据类型 dst数据类型 支持的roundMode half int32_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC int16_t CAST_RINT float CAST_NONE int8_t CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_NONE uint8_t CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_NONE int4b_t CAST_NONE float int32_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC half CAST_NONE/CAST_ODD uint8_t half CAST_NONE int8_t half CAST_NONE int16_t half CAST_NONE int32_t float CAST_NONE int16_t CAST_NONE half roundMode不生效，与SetDeqScale(half scale)接口配合使用。 表6 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Cast指令参数说明 src数据类型 dst数据类型 支持的roundMode half int32_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC int16_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC float CAST_NONE int8_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_NONE uint8_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_NONE int4b_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_NONE float float CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC int32_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC half CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_ODD/CAST_NONE int64_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC int16_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC float bfloat16_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC bfloat16_t float CAST_NONE int32_t CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC int4b_t half CAST_NONE uint8_t half CAST_NONE int8_t half CAST_NONE int16_t half CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_NONE float CAST_NONE int32_t float CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC/CAST_NONE int16_t CAST_NONE half roundMode不生效，与SetDeqScale(half scale)接口配合使用。 int64_t CAST_NONE int64_t int32_t CAST_NONE float CAST_RINT/CAST_FLOOR/CAST_CEIL/CAST_ROUND/CAST_TRUNC",
      "函数原型": "template <typename T1, typename T2, bool isSetMask = true> __aicore__ inline void Cast(const LocalTensor<T1>& dstLocal, const LocalTensor<T2>& srcLocal, const RoundMode& round_mode, const uint64_t mask[], const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T1",
          "类型": "",
          "说明": "目的操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型见表4 Atlas 推理系列产品 AI Core，支持的数据类型见表5 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型见表6 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型见表7 Atlas 200I/500 A2 推理产品 ，支持的数据类型见表8"
        },
        {
          "参数名": "T2",
          "类型": "",
          "说明": "源操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型见表4 Atlas 推理系列产品 AI Core，支持的数据类型见表5 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型见表6 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型见表7 Atlas 200I/500 A2 推理产品 ，支持的数据类型见表8"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "round_mode",
          "类型": "输入",
          "说明": "精度转换处理模式，类型是RoundMode。 RoundMode为枚举类型，用以控制精度转换处理模式，具体定义为： 1 2 3 4 5 6 7 8 9 10 enum class RoundMode { CAST_NONE = 0, // 在转换有精度损失时表示CAST_RINT模式，不涉及精度损失时表示不舍入 CAST_RINT, // rint，四舍六入五成双舍入 CAST_FLOOR, // floor，向负无穷舍入 CAST_CEIL, // ceil，向正无穷舍入 CAST_ROUND, // round，四舍五入舍入 CAST_TRUNC, // trunc，向零舍入 CAST_ODD, // Von Neumann rounding，最近邻奇数舍入 }; 对于 Atlas 训练系列产品 ，CAST_ROUND表示反向0取整，远离0，对正数x.y变成(x + 1)，对负数-x.y，变成-(x + 1)。"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9 10",
          "类型": "",
          "说明": "enum class RoundMode { CAST_NONE = 0, // 在转换有精度损失时表示CAST_RINT模式，不涉及精度损失时表示不舍入 CAST_RINT, // rint，四舍六入五成双舍入 CAST_FLOOR, // floor，向负无穷舍入 CAST_CEIL, // ceil，向正无穷舍入 CAST_ROUND, // round，四舍五入舍入 CAST_TRUNC, // trunc，向零舍入 CAST_ODD, // Von Neumann rounding，最近邻奇数舍入 };"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数，repeatTimes∈[0,255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数，UnaryRepeatParams类型。包含操作数相邻迭代间的地址步长，操作数同一迭代内datablock的地址步长等参数。其中dstRepStride/srcRepStride∈[0,255]。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T1, typename T2> __aicore__ inline void Cast(const LocalTensor<T1>& dstLocal, const LocalTensor<T2>& srcLocal, const RoundMode& round_mode, const uint32_t calCount)\ntemplate <typename T1, typename T2, bool isSetMask = true> __aicore__ inline void Cast(const LocalTensor<T1>& dstLocal, const LocalTensor<T2>& srcLocal, const RoundMode& round_mode, const uint64_t mask[], const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)\ntemplate <typename T1, typename T2, bool isSetMask = true> __aicore__ inline void Cast(const LocalTensor<T1>& dstLocal, const LocalTensor<T2>& srcLocal, const RoundMode& round_mode, const uint64_t mask, const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)\nuint64_t mask = 256 / sizeof(int32_t); // repeatTimes = 8, 64 elements one repeat, 512 elements total // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat // dstRepStride = 8, srcRepStride = 4, no gap between repeats AscendC::Cast(dstLocal, srcLocal, AscendC::RoundMode::CAST_CEIL, mask, 8, { 1, 1, 8, 4 });\nuint64_t mask[2] = { 0, UINT64_MAX }; // repeatTimes = 8, 64 elements one repeat, 512 elements total // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat // dstRepStride = 8, srcRepStride = 4, no gap between repeats AscendC::Cast(dstLocal, srcLocal, AscendC::RoundMode::CAST_CEIL, mask, 8, { 1, 1, 8, 4 });\nAscendC::Cast(dstLocal, srcLocal, AscendC::RoundMode::CAST_CEIL, 512);\n输入数据(srcLocal): [29.5 83.6 16.75 45.1 40.62 69.06 47.6 96.5 72.7 57.56 61.25 69.7 29.27 91.2 70.1 14.484 9.625 21.58 9.336 3.125 63.72 9.9 17.28 73.2 75.7 29.81 98.8 99.06 72.94 3.785 24.94 25.56 39.1 58.94 39.6 78.4 5.43 25.48 9.58 60.8 77.56 29.7 70.3 6.312 4.047 87.1 81.6 76.56 59.28 55.66 81.75 73.56 76.9 54.38 7.254 37.84 11.08 77.6 83.6 89.2 93.06 2.96 76.56 62.16 76.25 95.44 86.6 86.75 29.83 82.2 55.03 64.9 56.44 12.89 87.06 39.34 72.25 43.06 63.4 51.72 63.9 0.703 47.84 27.73 99. 89. 97.3 1.277 58.44 14.05 78.9 98.5 28.55 44.8 41.03 40.75 74.2 74.06 10.51 69.2 25.83 35.8 85.5 25.12 82.25 95.3 36.75 55.88 90.9 57.47 7.13 18.1 40.97 31. 99.3 69.4 72.94 62.44 63.7 80. 37.94 11.11 37. 39.72 87.94 31.72 25.7 54.7 32.8 21.64 14.53 55.1 3.607 40.16 77.7 15.15 77.44 43.25 85.75 67.3 30.33 67.56 60.72 58.16 19.84 89.2 18.75 55.56 31.61 9.445 6.5 27.95 48.5 37.16 7.805 37.72 69.6 36.2 92.56 24.72 41.56 48.44 19.27 25.94 25. 8.836 55.75 77.8 25.84 46.16 71.7 63.62 33.28 3.719 55.22 45.97 35.8 27.86 42.22 3.078 92.06 0.805 51.97 76.4 32.03 74.56 28.1 91.2 35.38 0.2009 74.25 87.5 92.75 76.25 51.28 22.9 34.4 28.23 87.5 78.75 63.1 61.56 79.94 6.766 95.1 55. 56.75 39.66 94.75 24.19 29.83 72.6 99.9 12.43 46.56 51.9 92.3 42.66 91.8 95.8 35.2 13.08 60.7 22.22 6.055 2.23 13.875 71.3 99.56 91.94 92. 96.06 97.5 68.75 8.61 1.157 68.2 20.73 63.44 90. 38.78 64.4 88.9 20.75 14.03 97.06 66.8 57.9 86.94 28.5 0.2279 51.8 84.56 39.53 93. 15.66 15.23 71.75 11.44 45.28 57.38 82.5 88.7 9.74 90.4 61.56 68.56 11.22 69.3 40.28 24.78 84.44 23.92 8.4 20.88 48.2 17.42 59.84 93.2 2.191 95.94 93.06 54.53 76.5 37. 41.7 82.7 69.5 92.6 5.8 32.78 84.56 26.5 96.56 0.858 96.44 52.8 90.9 30.52 2.656 32.03 35.72 8.125 21.94 84.5 66.7 96.75 46.8 1.42 58.3 28.75 44.94 66.2 28.67 11.695 41.75 67.25 26.75 17.72 35.9 5.72 55.88 94.7 80.8 71. 86.06 36.78 81.06 56.8 61.34 11.42 74. 32.16 14.695 78.6 56.1 64.4 61.75 50.88 39.6 79.94 71.25 40.7 5.99 67.4 62.28 89.25 12.02 63.12 33.1 59.06 28.2 19.22 59.66 51.6 53.28 97.8 42.25 82. 39.7 50.6 95.06 20.64 26.62 54.9 55. 28.44 26.25 46.56 87.06 98.44 49.34 37.2 97.4 34.3 83.4 57.4 94. 29.31 79.44 19.72 54.9 50.25 58.75 92.5 17.3 17.88 44.7 6.047 50.78 75.3 21.66 71.5 97.75 35.8 93.6 4.367 31.02 66.5 48.25 34. 92.7 36.97 86.5 10.37 82. 29.39 10.63 40.72 72.5 31.56 96.5 70.44 6.074 37.34 7.58 21.72 44.97 77.6 14.22 18.62 47.97 54.6 99.56 81.7 35.75 44.22 28.64 91.56 1.005 44. 8.125 11.7 93.6 70.25 63.94 11.05 50.97 56.47 39.4 35.53 84. 10.21 42.66 62.12 87.7 71.25 87.75 56.03 60.88 31.81 68.1 91.1 67.3 53.6 96.06 43.75 27.86 46.6 87.7 29.47 2.174 88.4 49.53 63.53 84.9 91.75 48.53 91.94 88.44 58.3 88.44 23.11 91.56 71.4 59.66 93.44 28.56 93.3 59.94 90. 18.95 52.8 70.3 58. 21.47 93.7 45.03 84.25 34.06 23.86 38.4 5.566 41.5 35.1 34.8 32.8 81.44 74.75 95.9 23.56 3.562 48.72 92.7 43.88 83.75 69.06 85.8 22.84 63.78 90.94 52.78 ] 输出数据(dstLocal): [ 30 84 17 46 41 70 48 97 73 58 62 70 30 92 71 15 10 22 10 4 64 10 18 74 76 30 99 100 73 4 25 26 40 59 40 79 6 26 10 61 78 30 71 7 5 88 82 77 60 56 82 74 77 55 8 38 12 78 84 90 94 3 77 63 77 96 87 87 30 83 56 65 57 13 88 40 73 44 64 52 64 1 48 28 99 89 98 2 59 15 79 99 29 45 42 41 75 75 11 70 26 36 86 26 83 96 37 56 91 58 8 19 41 31 100 70 73 63 64 80 38 12 37 40 88 32 26 55 33 22 15 56 4 41 78 16 78 44 86 68 31 68 61 59 20 90 19 56 32 10 7 28 49 38 8 38 70 37 93 25 42 49 20 26 25 9 56 78 26 47 72 64 34 4 56 46 36 28 43 4 93 1 52 77 33 75 29 92 36 1 75 88 93 77 52 23 35 29 88 79 64 62 80 7 96 55 57 40 95 25 30 73 100 13 47 52 93 43 92 96 36 14 61 23 7 3 14 72 100 92 92 97 98 69 9 2 69 21 64 90 39 65 89 21 15 98 67 58 87 29 1 52 85 40 93 16 16 72 12 46 58 83 89 10 91 62 69 12 70 41 25 85 24 9 21 49 18 60 94 3 96 94 55 77 37 42 83 70 93 6 33 85 27 97 1 97 53 91 31 3 33 36 9 22 85 67 97 47 2 59 29 45 67 29 12 42 68 27 18 36 6 56 95 81 71 87 37 82 57 62 12 74 33 15 79 57 65 62 51 40 80 72 41 6 68 63 90 13 64 34 60 29 20 60 52 54 98 43 82 40 51 96 21 27 55 55 29 27 47 88 99 50 38 98 35 84 58 94 30 80 20 55 51 59 93 18 18 45 7 51 76 22 72 98 36 94 5 32 67 49 34 93 37 87 11 82 30 11 41 73 32 97 71 7 38 8 22 45 78 15 19 48 55 100 82 36 45 29 92 2 44 9 12 94 71 64 12 51 57 40 36 84 11 43 63 88 72 88 57 61 32 69 92 68 54 97 44 28 47 88 30 3 89 50 64 85 92 49 92 89 59 89 24 92 72 60 94 29 94 60 90 19 53 71 58 22 94 46 85 35 24 39 6 42 36 35 33 82 75 96 24 4 49 93 44 84 70 86 23 64 91 53]\ninBufferSize_ = srcSize; // src buffer size outBufferSize_ = srcSize / 2; //dst buffer size uint64_t mask = 128; AscendC::LocalTensor<half> srcLocal; srcLocal.SetSize(inBufferSize_); AscendC::LocalTensor<int8_t> dstLocal; dstLocal.SetSize(outBufferSize_); AscendC::LocalTensor<AscendC::int4b_t> dstLocalTmp = dstLocal.ReinterpretCast<AscendC::int4b_t>(); // repeatTimes = 1, 128 elements one repeat, 128 elements total // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat // dstRepStride = 4, srcRepStride = 8, no gap between repeats AscendC::Cast<AscendC::int4b_t, half>(dstLocalTmp, srcLocal, AscendC::RoundMode::CAST_CEIL, mask, 1, {1, 1, 4, 8});\n#include \"kernel_operator.h\" class KernelCast { public: __aicore__ inline KernelCast() {} __aicore__ inline void Init(__gm__ uint8_t* srcGm, __gm__ uint8_t* dstGm) { srcGlobal.SetGlobalBuffer((__gm__ half*)srcGm); dstGlobal.SetGlobalBuffer((__gm__ int32_t*)dstGm); pipe.InitBuffer(inQueueSrc, 1, 512 * sizeof(half)); pipe.InitBuffer(outQueueDst, 1, 512 * sizeof(int32_t)); } __aicore__ inline void Process() { CopyIn(); Compute(); CopyOut(); } private: __aicore__ inline void CopyIn() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>(); AscendC::DataCopy(srcLocal, srcGlobal, 512); inQueueSrc.EnQue(srcLocal); } __aicore__ inline void Compute() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>(); AscendC::LocalTensor<int32_t> dstLocal = outQueueDst.AllocTensor<int32_t>(); AscendC::Cast(dstLocal, srcLocal, AscendC::RoundMode::CAST_CEIL, 512); outQueueDst.EnQue<int32_t>(dstLocal); inQueueSrc.FreeTensor(srcLocal); } __aicore__ inline void CopyOut() { AscendC::LocalTensor<int32_t> dstLocal = outQueueDst.DeQue<int32_t>(); AscendC::DataCopy(dstGlobal, dstLocal, 512); outQueueDst.FreeTensor(dstLocal); } private: AscendC::TPipe pipe; AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc; AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst; AscendC::GlobalTensor<half> srcGlobal; AscendC::GlobalTensor<int32_t> dstGlobal; }; extern \"C\" __global__ __aicore__ void cast_simple_kernel(__gm__ uint8_t* srcGm, __gm__ uint8_t* dstGm) { KernelCast op; op.Init(srcGm, dstGm); op.Process(); }\nuint64_t mask = 32; // 每个迭代内只计算前32个数 AscendC::Cast(dstLocal, srcLocal, AscendC::RoundMode::CAST_CEIL, mask, 8, { 1, 1, 8, 4 });\n输入数据(srcLocal): [37.4 7.11 53.5 19.44 22.66 43. 43.16 5.316 74.2 15.7 87.75 86.94 92.56 25.45 36.06 94.6 73.6 30.48 48.16 12.55 27.81 14.67 6.58 48.38 67.5 57.5 63.3 85.2 3.654 68.7 52.53 16.38 13.945 63.84 87.2 82.5 85.7 27.78 15.41 41.66 31.38 14.65 88.25 0.0332 43.06 46.88 15.57 87.1 53.16 33.5 91.06 36.5 55.34 60.53 3.238 23.92 97.5 91.1 78.44 54.47 82. 53.8 72.1 25.06 32.12 15.88 33.38 36.7 33.3 84.4 19.25 1.743 46.16 22.06 4.582 71.1 15.94 22.23 53.47 17.05 48.56 94.44 77.4 90.2 46.56 92.4 9.45 68.44 35.7 31.62 68.1 63.7 77. 92.06 20.45 27.67 93.4 22.39 17.22 73.06 7.12 25.34 36.34 13.54 38.12 24.56 86.56 69.7 68.3 30.38 68.4 86.1 54.44 70. 55.3 48.6 59.03 64.44 15.45 66.5 92.7 60.7 52.22 47. 99.75 41.94 43.06 89.5 36.9 62.5 1.306 48.06 9.37 62.25 20.61 43.8 69.25 27.22 71.44 52.75 11.82 80.6 63.44 53.22 85.44 25.25 2.309 26.88 84.5 29.83 9.93 81.9 97.75 75.75 97.7 72. 19.86 26.62 88.7 74.06 9.24 42.5 14. 39.44 98.56 66.94 89. 57.12 39. 11.57 19.05 86.56 32.66 19.25 99.3 95.6 58.7 79.6 37.38 65. 75.7 8.586 77.7 2.68 75.7 77.56 39.1 39.72 64.06 98.44 30.27 31.9 94.4 85.94 4.965 2.758 92.4 49.53 50.75 5.7 19.69 87.6 20.08 88.8 87.4 63.6 68.3 78.9 45.66 10.01 35.25 71.9 37.38 39.7 43.47 11.67 64.3 35.62 74.3 59.3 28.69 29.56 23.14 36.22 4.88 70.5 25.05 72.6 71.6 32.28 34.66 80. 96.1 98.7 12.91 95.4 61.97 87.94 19.1 40.47 89.6 84. 29.72 17.8 81.44 23.25 33.03 18.67 78. 49.62 63.1 72.75 77.25 3.74 38.9 17.92 76. 25.62 34.53 84. 32.03 57.3 9.21 6.836 68.9 35.78 96.75 56.3 96.1 23.45 78.75 94.25 12.44 56.7 24.55 25.11 90.7 50.94 78.4 3.576 21.81 53.28 26.2 43.1 7.742 13.4 86.44 86.9 13.93 16.48 91.06 42.3 95.5 66.8 40.6 98.06 71.9 67.6 55.9 82.44 93.75 41.53 23.62 40.12 40.53 80.7 80.25 96.3 51.38 93.6 91.3 32.84 88. 69.7 63.16 41.75 43.22 43.22 31.73 84.9 91.6 80. 53.34 27.12 76.6 97.25 44.5 30.28 74.3 76.06 40. 41.28 37.72 99.56 18.73 16.45 92.75 79.1 40.3 68. 23.98 88.7 86.6 24.97 59.6 28.25 82.94 46.12 60.12 34.53 79.7 11.086 20.25 44.88 39.97 42.12 62.7 30.66 42.56 16.69 85.2 90.8 78.75 26.16 18.14 94.06 40.3 20.16 38. 12.99 95.44 76.25 26.03 76. 30.06 27.25 84.56 30.45 66.1 83.25 3.732 39.1 54.22 82.8 43.22 53.03 11.66 88.1 6.83 66.8 44.4 7.5 24.77 74.4 35.9 79.75 41.62 37.06 60.12 57.9 96.94 84.25 39.88 22.55 72.7 58.9 44.75 90.4 46.34 71.3 16.4 26.12 21.45 10.27 91. 41.53 39.03 80.25 2.11 7.88 72.2 27.83 88.1 67.56 10.72 52.84 91.2 97.6 51.44 74.7 3.527 79.25 11.3 19.16 39.53 3.469 98.7 45.72 40.16 47.1 71.8 11.81 52.97 71.44 37.7 26.81 46.22 26.94 4.805 12.18 70.4 51.4 24.2 83.9 9.62 12.445 57.6 85.8 55.12 88.25 32.38 62.88 1.903 47.72 35.9 48.94 86.06 32.44 1.219 35.56 49.78 49.97 24.45 94.5 99.94 44.72 3.404 83.6 23.14 76.7 91.7 24.33 20.62 24.72 4.55 88.94 87.44 95.75 41.56 13.77 34.6 95.94 77.1 24.28 70.06 10.06 11.38 88.8 57.22 94.56 35. 79.8 58.22 44.06 26.9 16.25 99.94 51.1 42.38 84.25 0.9604 48.1 ] 输出数据(dstLocal): [ 38 8 54 20 23 43 44 6 75 16 88 87 93 26 37 95 74 31 49 13 28 15 7 49 68 58 64 86 4 69 53 17 1879993057 1827499998 1823960025 1570990114 1828150463 1811639312 1794470101 1754296176 1888841335 1715628997 1839753994 1850888497 1889364175 1891068936 1823369913 1769105534 1815638091 1808559970 1601662785 1739089473 1863146361 1694785989 1597138938 1836478181 1888774249 1637707434 1877372650 1796304934 1887530885 1839295471 1707240971 1873242695 33 16 34 37 34 85 20 2 47 23 5 72 16 23 54 18 49 95 78 91 47 93 10 69 36 32 69 64 77 93 21 28 1753837732 1488743807 1711632378 1799581711 1818783215 1891790695 1837723802 1752132873 1727950918 1760390205 1866887130 1824876865 1807839436 1890544910 1889755550 1787129270 1502702106 1841065201 1820156583 1779396288 1760521448 1844604520 1831039103 1843491014 1891199259 1839493317 1801349958 1577807434 1811377215 1879404734 1826057367 1837853054 37 63 2 49 10 63 21 44 70 28 72 53 12 81 64 54 86 26 3 27 85 30 10 82 98 76 98 72 20 27 89 75 1890086927 1826517134 1814783944 1824156809 1875733079 1842114682 1845456975 1830120794 1787980861 1807380585 1535469972 1883860884 1889167601 1747872128 1888317235 1720937006 1836806331 1654152236 1695309475 1892773593 1840737395 1868392748 1833724316 1600153936 1869310159 1883467778 1892641857 1776248953 1833201514 1886743848 1745972258 1860657622 95 86 5 3 93 50 51 6 20 88 21 89 88 64 69 79 46 11 36 72 38 40 44 12 65 36 75 60 29 30 24 37 1733652589 1756325317 1685744372 1780772214 1660252348 1629973784 1847815925 1828941229 1683778661 1519480967 1762160488 1844801381 1832742021 1891724641 1761701480 1695312651 1429433841 1774275423 1828349211 1779786303 1835953259 1784896595 1858432988 1413442268 1893363867 1886679050 1872588913 1473866635 1793158916 1762946052 1719627087 1893231666 76 26 35 84 33 58 10 7 69 36 97 57 97 24 79 95 13 57 25 26 91 51 79 4 22 54 27 44 8 14 87 87 1208960410 1208567888 1215973275 1214859418 1210992732 1208305714 1165379704 1215252623 1197033625 1212172318 1217415148 1211058280 1206798479 1215645776 1209223143 1217611809 1212500082 1215383615 1208567769 1200179260 1216694386 1218070398 1195526187 1211516213 1213089850 1213941743 1216825148 1212565573 1216694248 1217546087 1200178778 1215973524 92 80 54 28 77 98 45 31 75 77 40 42 38 100 19 17 93 80 41 68 24 89 87 25 60 29 83 47 61 35 80 12 1189759014 1218070662 1211057953 1216825400 1215121414 1214596952 1216169420 1210075102 1209157633 1213941279 1195984973 1211648118 1201686666 1212041360 1216103688 1212500024 1173112887 1194608648 1216825427 1209747582 1207191587 1214859224 1203980407 1215711379 1213155353 1203259396 1214859350 1211779156 1217218713 1202473003 1216628529 1196771437 44 54 12 89 7 67 45 8 25 75 36 80 42 38 61 58 97 85 40 23 73 59 45 91 47 72 17 27 22 11 91 42 1211516990 1198213215 1203848735 1217349746 1212303398 1217808150 1215514752 1209878647 1214138433 1215711277 1212041273 1215383541 1214728294 1197754500 1169574019 1208371214 1214269569 1216301092 1216563283 1213548677 1217873970 1203128459 1209812695 1218136029 1194805359 1204439186 1218005120 1213941626 1217153046 1208109091 1215055928 1215318166 5 13 71 52 25 84 10 13 58 86 56 89 33 63 2 48 36 49 87 33 2 36 50 50 25 95 100 45 4 84 24 77 1202210969 1213679767 1209288847 1217480263 1184319410 1214072674 1188382819 1217283870 1200769107 1217939416 1199327294 1213351841 1206667407 1217153163 1215580283 1214138474 1206798167 1194477696 1193690499 1214072706 1216825421 1216693888 1217611496 1198540949 1199654414 1206405188 1214203847 1165183076 1213745302 1208830102 1209944118 1215121459]",
      "约束限制": "",
      "相关接口": [
        "SetDeqScale(half scale)",
        "SetVectorMask",
        "LocalTensor",
        "UnaryRepeatParams",
        "通用约束",
        "精度转换指令"
      ],
      "版本信息": "1.75"
    },
    {
      "API名称": "WholeReduceSum-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0081.html",
      "功能说明": "每个迭代内所有数据求和。归约指令的总体介绍请参考如何使用归约指令。 每个迭代内所有数据求和。归约指令的总体介绍请参考如何使用归约指令。 表1 模板参数说明 参数名 描述 T 操作数数据类型。 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证2字节对齐（针对half数据类型），4字节对齐（针对float数据类型）。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，支持的数据类型为：支持数据类型half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 单位为dstLocal数据类型所占字节长度。比如当dstLocal为half时，单位为2Bytes。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考dataBlockStride。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考repeatStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void WholeReduceSum(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint64_t mask[], const int32_t repeatTimes, const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证2字节对齐（针对half数据类型），4字节对齐（针对float数据类型）。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，支持的数据类型为：支持数据类型half/float Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "dstRepStride",
          "类型": "输入",
          "说明": "目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 单位为dstLocal数据类型所占字节长度。比如当dstLocal为half时，单位为2Bytes。 注意，此参数值 Atlas 训练系列产品 不支持配置0。"
        },
        {
          "参数名": "srcBlkStride",
          "类型": "输入",
          "说明": "单次迭代内datablock的地址步长。详细说明请参考dataBlockStride。"
        },
        {
          "参数名": "srcRepStride",
          "类型": "输入",
          "说明": "源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考repeatStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T, bool isSetMask = true> __aicore__ inline void WholeReduceSum(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint64_t mask[], const int32_t repeatTimes, const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void WholeReduceSum(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t mask, const int32_t repeatTimes, const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)\n#include \"kernel_operator.h\" class KernelReduce { public: __aicore__ inline KernelReduce() {} __aicore__ inline void Init(__gm__ uint8_t* src, __gm__ uint8_t* dstGm) { srcGlobal.SetGlobalBuffer((__gm__ half*)src); dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm); repeat = srcDataSize / mask; pipe.InitBuffer(inQueueSrc, 1, srcDataSize * sizeof(half)); pipe.InitBuffer(outQueueDst, 1, dstDataSize * sizeof(half)); } __aicore__ inline void Process() { CopyIn(); Compute(); CopyOut(); } private: __aicore__ inline void CopyIn() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>(); AscendC::DataCopy(srcLocal, srcGlobal, srcDataSize); inQueueSrc.EnQue(srcLocal); } __aicore__ inline void Compute() { AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>(); AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>(); AscendC::WholeReduceSum<half>(dstLocal, srcLocal, mask, repeat, 1, 1, 8); outQueueDst.EnQue<half>(dstLocal); inQueueSrc.FreeTensor(srcLocal); } __aicore__ inline void CopyOut() { AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>(); AscendC::DataCopy(dstGlobal, dstLocal, dstDataSize); outQueueDst.FreeTensor(dstLocal); } private: AscendC::TPipe pipe; AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc; AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst; AscendC::GlobalTensor<half> srcGlobal, dstGlobal; int srcDataSize = 2048; int dstDataSize = 16; int mask = 128; int repeat = 0; }; extern \"C\" __global__ __aicore__ void reduce_kernel(__gm__ uint8_t* src, __gm__ uint8_t* dstGm) { KernelReduce op; op.Init(src, dstGm); op.Process(); }\n输入数据(src_gm): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 输出数据(dst_gm): [128. 128. 128. 128. 128. 128. 128. 128. 128. 128. 128. 128. 128. 128. 128. 128.]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "通用约束",
        "归约指令"
      ],
      "版本信息": ""
    },
    {
      "API名称": "DataSyncBarrier(ISASI)-核内同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0272.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Trunc-Trunc-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0536.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "TransData-变形-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10181.html",
      "功能说明": "将输入数据的排布格式转换为目标排布格式。 本接口支持的数据格式转换场景包括以下四种，除维度顺序变换外，其中涉及到C轴和N轴的拆分，具体转换方式为，C轴拆分为C1轴、C0轴，N轴拆分为N1轴、N0轴。对于位宽为16的数据类型的数据，C0和N0固定为16，C1和N1的计算公式如下。 将输入数据的排布格式转换为目标排布格式。 本接口支持的数据格式转换场景包括以下四种，除维度顺序变换外，其中涉及到C轴和N轴的拆分，具体转换方式为，C轴拆分为C1轴、C0轴，N轴拆分为N1轴、N0轴。对于位宽为16的数据类型的数据，C0和N0固定为16，C1和N1的计算公式如下。 表1 模板参数说明参数名 描述 config 指定数据格式转换的场景。当前支持的转换场景有如下四种：NCDHW -> NDC1HWC0、NDC1HWC0 -> NCDHW、NCDHW -> FRACTAL_Z_3D、FRACTAL_Z_3D -> NCDHW。该参数为TransDataConfig类型，具体定义如下。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15struct TransDataConfig { DataFormat srcFormat; DataFormat dstFormat; }; enum class DataFormat : uint8_t { ND = 0, NZ, NCHW, NC1HWC0, NHWC, NCDHW, NDC1HWC0, FRACTAL_Z_3D, }; 配置示例如下。 1constexpr AscendC::TransDataConfig config1 = {AscendC::DataFormat::NCDHW, AscendC::DataFormat::FRACTAL_Z_3D}; T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：int16_t/uint16_t/half/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：int16_t/uint16_t/half/bfloat16_t U 源操作数的Shape信息，Layout类型。 1AscendC::Layout ncdhwLayout = AscendC::MakeLayout(AscendC::MakeShape(n, c, d, h, w), AscendC::MakeStride()); S 目的操作数的Shape信息，Layout类型。 1AscendC::Layout fractalzLayout = AscendC::MakeLayout(AscendC::MakeShape(d, c1, h, w, n1, n0, c0), AscendC::MakeStride()); 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于TransData内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetTransDataMaxMinTmpSize。 params 输入 源操作数和目的操作数的Shape信息。该参数为TransDataParams数据类型，具体定义如下，其中模板参数T、U必须为Layout类型。该参数指定的Shape维度必须与config中Format对应维度保持一致。 1 2 3 4 5template <typename T, typename U> struct TransDataParams { T srcLayout; U dstLayout; }; 配置示例如下。 1 2 3AscendC::Layout ncdhwLayout = AscendC::MakeLayout(AscendC::MakeShape(n, c, d, h, w), AscendC::MakeStride()); AscendC::Layout fractalzLayout = AscendC::MakeLayout(AscendC::MakeShape(d, c1, h, w, n1, n0, c0), AscendC::MakeStride()); AscendC::TransDataParams<decltype(ncdhwLayout), decltype(fractalzLayout)> params = {ncdhwLayout, fractalzLayout};",
      "函数原型": "template <const TransDataConfig& config, typename T, typename U, typename S> __aicore__ inline void TransData(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const TransDataParams<U, S>& params)",
      "参数说明": [
        {
          "参数名": "config",
          "类型": "指定数据格式转换的场景。当前支持的转换场景有如下四种：NCDHW -> NDC1HWC0、NDC1HWC0 -> NCDHW、NCDHW -> FRACTAL_Z_3D、FRACTAL_Z_3D -> NCDHW。该参数为TransDataConfig类型，具体定义如下。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15struct TransDataConfig { DataFormat srcFormat; DataFormat dstFormat; }; enum class DataFormat : uint8_t { ND = 0, NZ, NCHW, NC1HWC0, NHWC, NCDHW, NDC1HWC0, FRACTAL_Z_3D, }; 配置示例如下。 1constexpr AscendC::TransDataConfig config1 = {AscendC::DataFormat::NCDHW, AscendC::DataFormat::FRACTAL_Z_3D};",
          "说明": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15",
          "类型": "",
          "说明": "struct TransDataConfig { DataFormat srcFormat; DataFormat dstFormat; }; enum class DataFormat : uint8_t { ND = 0, NZ, NCHW, NC1HWC0, NHWC, NCDHW, NDC1HWC0, FRACTAL_Z_3D, };"
        },
        {
          "参数名": "1",
          "类型": "",
          "说明": "constexpr AscendC::TransDataConfig config1 = {AscendC::DataFormat::NCDHW, AscendC::DataFormat::FRACTAL_Z_3D};"
        },
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：int16_t/uint16_t/half/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：int16_t/uint16_t/half/bfloat16_t"
        },
        {
          "参数名": "U",
          "类型": "源操作数的Shape信息，Layout类型。 1AscendC::Layout ncdhwLayout = AscendC::MakeLayout(AscendC::MakeShape(n, c, d, h, w), AscendC::MakeStride());",
          "说明": "1"
        },
        {
          "参数名": "1",
          "类型": "",
          "说明": "AscendC::Layout ncdhwLayout = AscendC::MakeLayout(AscendC::MakeShape(n, c, d, h, w), AscendC::MakeStride());"
        },
        {
          "参数名": "S",
          "类型": "目的操作数的Shape信息，Layout类型。 1AscendC::Layout fractalzLayout = AscendC::MakeLayout(AscendC::MakeShape(d, c1, h, w, n1, n0, c0), AscendC::MakeStride());",
          "说明": "1"
        },
        {
          "参数名": "1",
          "类型": "",
          "说明": "AscendC::Layout fractalzLayout = AscendC::MakeLayout(AscendC::MakeShape(d, c1, h, w, n1, n0, c0), AscendC::MakeStride());"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于TransData内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetTransDataMaxMinTmpSize。"
        },
        {
          "参数名": "params",
          "类型": "输入",
          "说明": "源操作数和目的操作数的Shape信息。该参数为TransDataParams数据类型，具体定义如下，其中模板参数T、U必须为Layout类型。该参数指定的Shape维度必须与config中Format对应维度保持一致。 1 2 3 4 5template <typename T, typename U> struct TransDataParams { T srcLayout; U dstLayout; }; 配置示例如下。 1 2 3AscendC::Layout ncdhwLayout = AscendC::MakeLayout(AscendC::MakeShape(n, c, d, h, w), AscendC::MakeStride()); AscendC::Layout fractalzLayout = AscendC::MakeLayout(AscendC::MakeShape(d, c1, h, w, n1, n0, c0), AscendC::MakeStride()); AscendC::TransDataParams<decltype(ncdhwLayout), decltype(fractalzLayout)> params = {ncdhwLayout, fractalzLayout};"
        },
        {
          "参数名": "1 2 3 4 5",
          "类型": "",
          "说明": "template <typename T, typename U> struct TransDataParams { T srcLayout; U dstLayout; };"
        },
        {
          "参数名": "1 2 3",
          "类型": "",
          "说明": "AscendC::Layout ncdhwLayout = AscendC::MakeLayout(AscendC::MakeShape(n, c, d, h, w), AscendC::MakeStride()); AscendC::Layout fractalzLayout = AscendC::MakeLayout(AscendC::MakeShape(d, c1, h, w, n1, n0, c0), AscendC::MakeStride()); AscendC::TransDataParams<decltype(ncdhwLayout), decltype(fractalzLayout)> params = {ncdhwLayout, fractalzLayout};"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9\n1 2 3 4 5 6 7 8 9",
      "约束限制": "",
      "相关接口": [
        "GetTransDataMaxMinTmpSize",
        "Layout",
        "LocalTensor",
        "通用约束",
        "变形"
      ],
      "版本信息": ""
    },
    {
      "API名称": "SetAtomicMax(ISASI)-原子操作-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0284.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "AddReluCast-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0044.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetFixPipeClipRelu(ISASI)-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0255.html",
      "功能说明": "DataCopy（CO1->GM）过程中进行随路量化后，通过调用该接口设置ClipRelu操作的最大值。 ClipRelu计算公式为min(clipReluMaxVal，srcData)，clipReluMaxVal为通过该接口设置的最大值，srcData为源数据。 DataCopy（CO1->GM）过程中进行随路量化后，通过调用该接口设置ClipRelu操作的最大值。 ClipRelu计算公式为min(clipReluMaxVal，srcData)，clipReluMaxVal为通过该接口设置的最大值，srcData为源数据。 表1 参数说明参数名称 输入/输出 含义 config 输入 clipReluMaxVal，ClipRelu操作中的最大值。clipReluMaxVal只占用0-15bit，必须大于0，不能为INF/NAN。 使能Relu的情况下，先进行Relu操作，之后再进行ClipRelu。",
      "函数原型": "__aicore__ inline void SetFixPipeClipRelu(uint64_t config)",
      "参数说明": [
        {
          "参数名": "config",
          "类型": "输入",
          "说明": "clipReluMaxVal，ClipRelu操作中的最大值。clipReluMaxVal只占用0-15bit，必须大于0，不能为INF/NAN。"
        }
      ],
      "返回值": "无",
      "调用示例": "__aicore__ inline void SetFixPipeClipRelu(uint64_t config)\nuint64_t clipReluMaxVal = 0x3c00; // value 1, half类型转换成uint64_t类型 SetFixPipeClipRelu(clipReluMaxVal);",
      "约束限制": "使能Relu的情况下，先进行Relu操作，之后再进行ClipRelu。",
      "相关接口": [
        "DataCopy",
        "数据搬运"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Axpy-标量三目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0063.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "InitDetermineComputeWorkspace-核间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0206.html",
      "功能说明": "初始化GM共享内存的值，完成初始化后才可以调用WaitPreBlock和NotifyNextBlock。 初始化GM共享内存的值，完成初始化后才可以调用WaitPreBlock和NotifyNextBlock。 表1 接口参数说明参数名称 输入/输出 含义 gmWorkspace 输入 临时空间，初始化核间同步的共享内存，类型为GlobalTensor。 ubWorkspace 输入 临时空间，用于操作gmWorkspace，类型为LocalTensor。",
      "函数原型": "__aicore__ inline void Init(GM_ADDR dstGm, GM_ADDR srcGm, GM_ADDR gmWorkspace, const DetermineComputeSyncTilingData& tiling_data)",
      "参数说明": [
        {
          "参数名": "gmWorkspace",
          "类型": "输入",
          "说明": "临时空间，初始化核间同步的共享内存，类型为GlobalTensor。"
        },
        {
          "参数名": "ubWorkspace",
          "类型": "输入",
          "说明": "临时空间，用于操作gmWorkspace，类型为LocalTensor。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62",
      "约束限制": "",
      "相关接口": [
        "WaitPreBlock",
        "NotifyNextBlock",
        "GetBlockNum",
        "核间同步"
      ],
      "版本信息": ""
    },
    {
      "API名称": "ArithProgression-索引操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0856.html",
      "功能说明": "给定起始值，等差值和长度，返回一个等差数列。 给定起始值，等差值和长度，返回一个等差数列。 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float/int16_t/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float/int16_t/int32_t Atlas 推理系列产品AI Core，支持的数据类型为：half/float/int16_t/int32_t 表2 接口参数说明参数名 输入/输出 描述 dstLocal 输出 目的操作数。dstLocal的大小应大于等于count * sizeof(T)。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 firstValue 输入 等差数列的首个元素值。 diffValue 输入 等差数列元素之间的差值，应大于等于0。 count 输入 等差数列的长度。count>0。 当前仅支持ND格式的输入，不支持其他格式。",
      "函数原型": "template <typename T> __aicore__ inline void ArithProgression(const LocalTensor<T> &dstLocal, const T firstValue, const T diffValue, const int32_t count)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float/int16_t/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float/int16_t/int32_t Atlas 推理系列产品AI Core，支持的数据类型为：half/float/int16_t/int32_t"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。dstLocal的大小应大于等于count * sizeof(T)。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "firstValue",
          "类型": "输入",
          "说明": "等差数列的首个元素值。"
        },
        {
          "参数名": "diffValue",
          "类型": "输入",
          "说明": "等差数列元素之间的差值，应大于等于0。"
        },
        {
          "参数名": "count",
          "类型": "输入",
          "说明": "等差数列的长度。count>0。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void ArithProgression(const LocalTensor<T> &dstLocal, const T firstValue, const T diffValue, const int32_t count)",
      "约束限制": "当前仅支持ND格式的输入，不支持其他格式。",
      "相关接口": [
        "LocalTensor",
        "索引操作"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Abs-单目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0027.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetAtomicAdd-原子操作-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0210.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Cast-基础核函数接口-单算子API执行相关接口-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1193.html",
      "功能说明": "将输入tensor转换为指定的数据类型。 将输入tensor转换为指定的数据类型。 参数 输入/输出 说明 self 输入 待转换的输入tensor，数据类型支持FLOAT16、FLOAT、DOUBLE、BFLOAT16、INT8、UINT8、INT16、UINT16、INT32、UINT32、INT64、UINT64、BOOL、COMPLEX64、COMPLEX128。数据格式支持ND。 说明： BFLOAT16适用于如下产品型号： Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 dstDtype 输入 转换后的目标dtype，数据类型支持FLOAT16、FLOAT、DOUBLE、BFLOAT16、INT8、UINT8、INT16、UINT16、INT32、UINT32、INT64、UINT64、BOOL、COMPLEX64、COMPLEX128。 说明： BFLOAT16适用于如下产品型号： Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 executor 输入 op执行器，包含了算子计算流程。 返回类型为dstDtype的tensor。",
      "函数原型": "",
      "参数说明": [
        {
          "参数名": "self",
          "类型": "输入",
          "说明": "待转换的输入tensor，数据类型支持FLOAT16、FLOAT、DOUBLE、BFLOAT16、INT8、UINT8、INT16、UINT16、INT32、UINT32、INT64、UINT64、BOOL、COMPLEX64、COMPLEX128。数据格式支持ND。 说明： BFLOAT16适用于如下产品型号： Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品"
        },
        {
          "参数名": "dstDtype",
          "类型": "输入",
          "说明": "转换后的目标dtype，数据类型支持FLOAT16、FLOAT、DOUBLE、BFLOAT16、INT8、UINT8、INT16、UINT16、INT32、UINT32、INT64、UINT64、BOOL、COMPLEX64、COMPLEX128。 说明： BFLOAT16适用于如下产品型号： Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品"
        },
        {
          "参数名": "executor",
          "类型": "输入",
          "说明": "op执行器，包含了算子计算流程。"
        }
      ],
      "返回值": "返回类型为dstDtype的tensor。",
      "调用示例": "1 2 3 4 5 6 7 8 9\n1 2 3 4 5 6 7 8 9",
      "约束限制": "",
      "相关接口": [
        "基础核函数接口"
      ],
      "版本信息": ""
    },
    {
      "API名称": "RpSort16-排序组合(ISASI)-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0229.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "简介-AnchorInstanceInfo-gert命名空间-基础数据结构和接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/basicdataapi/atlasopapi_07_00002.html",
      "功能说明": "本类用于描述算子原型定义中输入输出信息与算子实例化后实际输入输出之间的映射关系。每个AnchorInstanceInfo对象对应一个输入或输出，并记录两个关键信息：",
      "函数原型": "void SetInstantiationNum(const uint32_t instantiation_num)",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "AnchorInstanceInfo() AnchorInstanceInfo(const uint32_t instance_start, const uint32_t instantiation_num) size_t GetInstanceNum() const size_t GetInstanceStart() const void SetInstanceStart(const uint32_t instance_start) void SetInstantiationNum(const uint32_t instantiation_num)",
      "约束限制": "",
      "相关接口": [
        "AnchorInstanceInfo",
        "GetInstanceNum",
        "GetInstanceStart",
        "SetInstanceStart",
        "SetInstantiationNum"
      ],
      "版本信息": ""
    },
    {
      "API名称": "NotifyNextBlock-核间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0208.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ReduceProd-ReduceProd-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10150.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "UnPad-数据填充-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0851.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Copy-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0106.html",
      "功能说明": "VECIN，VECCALC，VECOUT之间的搬运指令，支持mask操作和DataBlock间隔操作。 VECIN，VECCALC，VECOUT之间的搬运指令，支持mask操作和DataBlock间隔操作。 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。起始地址需要保证32字节对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。起始地址需要保证32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的数据结构。CopyRepeatParams类型。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_data_copy.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 参数说明请参考表3。 表3 CopyRepeatParams结构体参数说明 参数名称 含义 dstStride、srcStride 用于设置同一迭代内datablock的地址步长，取值范围为[0,65535]。 同一迭代内datablock的地址步长参数说明请参考dataBlockStride。 dstRepeatSize、srcRepeatSize 用于设置相邻迭代间的地址步长，取值范围为[0,4095]。 相邻迭代间的地址步长参数说明请参考repeatStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void Copy(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint64_t mask[], const uint8_t repeatTimes, const CopyRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。起始地址需要保证32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。起始地址需要保证32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的数据结构。CopyRepeatParams类型。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_data_copy.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 参数说明请参考表3。"
        },
        {
          "参数名": "dstStride、srcStride",
          "类型": "",
          "说明": "用于设置同一迭代内datablock的地址步长，取值范围为[0,65535]。 同一迭代内datablock的地址步长参数说明请参考dataBlockStride。"
        },
        {
          "参数名": "dstRepeatSize、srcRepeatSize",
          "类型": "",
          "说明": "用于设置相邻迭代间的地址步长，取值范围为[0,4095]。 相邻迭代间的地址步长参数说明请参考repeatStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T, bool isSetMask = true> __aicore__ inline void Copy(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint64_t mask[], const uint8_t repeatTimes, const CopyRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Copy(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint64_t mask, const uint8_t repeatTimes, const CopyRepeatParams& repeatParams)\nuint64_t mask = 128; // repeatTimes = 4, 128 elements one repeat, 512 elements total // dstStride, srcStride = 1, no gap between blocks in one repeat // dstRepStride, srcRepStride = 8, no gap between repeats AscendC::Copy(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });\n输入数据(srcLocal): [9 -2 8 ... 9] 输出数据(dstLocal): [9 -2 8 ... 9]\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 4, 128 elements one repeat, 512 elements total // dstStride, srcStride = 1, no gap between blocks in one repeat // dstRepStride, srcRepStride = 8, no gap between repeats AscendC::Copy(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });\n输入数据(srcLocal): [9 -2 8 ... 9] 输出数据(dstLocal): [9 -2 8 ... 9]\n#include \"kernel_operator.h\" class KernelCopy { public: __aicore__ inline KernelCopy() {} __aicore__ inline void Init(__gm__ uint8_t* srcGm, __gm__ uint8_t* dstGm) { srcGlobal.SetGlobalBuffer((__gm__ int32_t*)srcGm); dstGlobal.SetGlobalBuffer((__gm__ int32_t*)dstGm); pipe.InitBuffer(inQueueSrc, 1, 512 * sizeof(int32_t)); pipe.InitBuffer(outQueueDst, 1, 512 * sizeof(int32_t)); } __aicore__ inline void Process() { CopyIn(); Compute(); CopyOut(); } private: __aicore__ inline void CopyIn() { AscendC::LocalTensor<int32_t> srcLocal = inQueueSrc.AllocTensor<int32_t>(); AscendC::DataCopy(srcLocal, srcGlobal, 512); inQueueSrc.EnQue(srcLocal); } __aicore__ inline void Compute() { AscendC::LocalTensor<int32_t> srcLocal = inQueueSrc.DeQue<int32_t>(); AscendC::LocalTensor<int32_t> dstLocal = outQueueDst.AllocTensor<int32_t>(); uint64_t mask = 64; AscendC::Copy(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 }); outQueueDst.EnQue<int32_t>(dstLocal); inQueueSrc.FreeTensor(srcLocal); } __aicore__ inline void CopyOut() { AscendC::LocalTensor<int32_t> dstLocal = outQueueDst.DeQue<int32_t>(); AscendC::DataCopy(dstGlobal, dstLocal, 512); outQueueDst.FreeTensor(dstLocal); } private: AscendC::TPipe pipe; AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc; AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst; AscendC::GlobalTensor<int32_t> srcGlobal, dstGlobal; }; extern \"C\" __global__ __aicore__ void copy_simple_kernel(__gm__ uint8_t* srcGm, __gm__ uint8_t* dstGm) { KernelCopy op; op.Init(srcGm, dstGm); op.Process(); }",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "数据搬运"
      ],
      "版本信息": ""
    },
    {
      "API名称": "BilinearInterpolation(ISASI)-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0222.html",
      "功能说明": "功能分为水平迭代和垂直迭代。每个水平迭代顺序地从src0Offset读取8个偏移值，表示src0的偏移，每个偏移值指向src0的一个DataBlock的起始地址，如果repeatMode=false，从src1中取一个值，与src0中8个DataBlock中每个值进行乘操作；如果repeatMode=true，从src1中取8个值，按顺序与src0中8个DataBlock中的值进行乘操作，最后当前迭代的dst结果与前一个dst结果按DataBlock进行累加，存入目的地址，在同一个水平迭代内dst地址不变。然后进行垂直迭代，垂直迭代的dst起始地址为上一轮垂直迭代的dst起始地址加上vROffset，本轮垂直迭代占用dst空间为dst起始地址之后的8个DataBlock，每轮垂直迭代进行hRepeat次水平迭代。 功能分为水平迭代和垂直迭代。每个水平迭代顺序地从src0Offset读取8个偏移值，表示src0的偏移，每个偏移值指向src0的一个DataBlock的起始地址，如果repeatMode=false，从src1中取一个值，与src0中8个DataBlock中每个值进行乘操作；如果repeatMode=true，从src1中取8个值，按顺序与src0中8个DataBlock中的值进行乘操作，最后当前迭代的dst结果与前一个dst结果按DataBlock进行累加，存入目的地址，在同一个水平迭代内dst地址不变。然后进行垂直迭代，垂直迭代的dst起始地址为上一轮垂直迭代的dst起始地址加上vROffset，本轮垂直迭代占用dst空间为dst起始地址之后的8个DataBlock，每轮垂直迭代进行hRepeat次水平迭代。 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core，支持的数据类型为：half 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 src0OffsetLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 hRepeat 输入 水平方向迭代次数，取值范围为[1, 255]。 repeatMode 输入 迭代模式： false：每次迭代src0读取的8个datablock中每个值均与src1的单个数值相乘。 true：每次迭代src0的每个datablock分别与src1的1个数值相乘，共消耗8个block和8个elements。 dstBlkStride 输入 单次迭代内，目的操作数不同DataBlock间地址步长，以32B为单位。 vROffset 输入 垂直迭代间，目的操作数地址偏移量，以元素为单位，取值范围为[128, 65535]。 vRepeat 输入 垂直方向迭代次数，取值范围为[1, 255]。 sharedTmpBuffer 输入 临时空间。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，需要保证至少分配了src0Local.GetSize() * 32 + src1Local.GetSize() * 32字节的空间。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，需要保证至少分配了src0Local.GetSize() * 32 + src1Local.GetSize() * 32字节的空间。 Atlas 推理系列产品 AI Core，需要保证至少分配了src0OffsetLocal.GetSize() * sizeof(uint32_t)字节的空间。",
      "函数原型": "template <typename T> __aicore__ inline void BilinearInterpolation(const LocalTensor<T> &dstLocal, const LocalTensor<T> &src0Local, const LocalTensor<uint32_t> &src0OffsetLocal, const LocalTensor<T> &src1Local, uint64_t mask[], uint8_t hRepeat, bool repeatMode, uint16_t dstBlkStride, uint16_t vROffset, uint8_t vRepeat, const LocalTensor<uint8_t> &sharedTmpBuffer)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core，支持的数据类型为：half"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "src0OffsetLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "hRepeat",
          "类型": "输入",
          "说明": "水平方向迭代次数，取值范围为[1, 255]。"
        },
        {
          "参数名": "repeatMode",
          "类型": "输入",
          "说明": "迭代模式： false：每次迭代src0读取的8个datablock中每个值均与src1的单个数值相乘。 true：每次迭代src0的每个datablock分别与src1的1个数值相乘，共消耗8个block和8个elements。"
        },
        {
          "参数名": "dstBlkStride",
          "类型": "输入",
          "说明": "单次迭代内，目的操作数不同DataBlock间地址步长，以32B为单位。"
        },
        {
          "参数名": "vROffset",
          "类型": "输入",
          "说明": "垂直迭代间，目的操作数地址偏移量，以元素为单位，取值范围为[128, 65535]。"
        },
        {
          "参数名": "vRepeat",
          "类型": "输入",
          "说明": "垂直方向迭代次数，取值范围为[1, 255]。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时空间。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，需要保证至少分配了src0Local.GetSize() * 32 + src1Local.GetSize() * 32字节的空间。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，需要保证至少分配了src0Local.GetSize() * 32 + src1Local.GetSize() * 32字节的空间。 Atlas 推理系列产品 AI Core，需要保证至少分配了src0OffsetLocal.GetSize() * sizeof(uint32_t)字节的空间。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12\n1 2 3 4 5 6 7 8 9 10 11 12",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "通用约束",
        "双目指令"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "AddDeqRelu-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0045.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Select-选择指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0070.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "max-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10053.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Conv2D-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0262.html",
      "功能说明": "该接口废弃，并将在后续版本移除，请不要使用该接口。 计算给定输入张量和权重张量的2-D卷积，输出结果张量。Conv2d卷积层多用于图像识别，使用过滤器提取图像中的特征。 该接口废弃，并将在后续版本移除，请不要使用该接口。 计算给定输入张量和权重张量的2-D卷积，输出结果张量。Conv2d卷积层多用于图像识别，使用过滤器提取图像中的特征。 表1 接口参数说明参数名称 类型 说明 dstLocal 输出 目的操作数。 Atlas 训练系列产品，支持的TPosition为：CO1，CO2 Atlas 推理系列产品AI Core，支持的TPosition为：CO1，CO2 结果中有效张量格式为[Cout/16, Ho, Wo, 16]，大小为Cout * Ho * Wo，Ho与Wo可以根据其他数据计算得出。 Ho = floor((H + pad_top + pad_bottom - dilation_h * (Kh - 1) - 1) / stride_h + 1) Wo = floor((W + pad_left + pad_right - dilation_w * (Kw - 1) - 1) / stride_w + 1) 由于硬件要求Ho*Wo需为16倍数，在申请dst Tensor时，shape应向上16对齐，实际申请shape大小应为Cout * round_howo。 round_howo = ceil(Ho * Wo /16) * 16。 featureMap 输入 输入张量，Tensor的TPosition为A1。 输入张量“feature_map”的形状，格式是[C1, H, W, C0]。 C1*C0为输入的channel数，要求如下： 当feature_map的数据类型为half时，C0=16。当feature_map的数据类型为int8_t时，C0=32。C1取值范围：[1,4], 输入的channel的范围：[16，32，64，128]。 H为高，取值范围：[1,40]。 W为宽，取值范围：[1,40]。 weight 输入 卷积核（权重）张量，Tensor的TPosition为B1。 卷积核张量“weight”的形状，格式是[C1, Kh, Kw, Cout, C0]。 C1*C0为输入的channel数，对于C0要求如下： 当feature_map的数据类型为half时，C0=16。当feature_map的数据类型为int8_t时，C0=32。C1取值范围：[1,4]。kernel_shape输入的channel数需与fm_shape输入的channel数保持一致。 Cout为卷积核数目，取值范围：[16，32，64，128]， Cout必须为16的倍数。 Kh为卷积核高；值的范围：[1,5]。 Kw表示卷积核宽；值的范围：[1,5]。 conv2dParams 输入 输入矩阵形状等状态参数，类型为Conv2dParams。结构体具体定义为： 1 2 3 4 5 6 7 8 9 10 11struct Conv2dParams { uint32_t imgShape[kConv2dImgSize]; // [H, W] uint32_t kernelShape[kConv2dkernelSize]; // [Kh, Kw] uint32_t stride[kConv2dStride]; // [stride_h, stride_w] uint32_t cin; // cin = C0 * C1; uint32_t cout; uint32_t padList[kConv2dPad]; // [pad_left, pad_right, pad_top, pad_bottom] uint32_t dilation[kConv2dDilation]; // [dilation_h, dilation_w] uint32_t initY; uint32_t partialSum; }; tilling 输入 分形控制参数，类型为Conv2dTilling。结构体具体定义为： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53struct Conv2dTilling { const uint32_t blockSize = 16; // # M block size is always 16 LoopMode loopMode = LoopMode::MODE_NM; uint32_t c0Size = 32; uint32_t dTypeSize = 1; uint32_t strideH = 0; uint32_t strideW = 0; uint32_t dilationH = 0; uint32_t dilationW = 0; uint32_t hi = 0; uint32_t wi = 0; uint32_t ho = 0; uint32_t wo = 0; uint32_t height = 0; uint32_t width = 0; uint32_t howo = 0; uint32_t mNum = 0; uint32_t nNum = 0; uint32_t kNum = 0; uint32_t mBlockNum = 0; uint32_t kBlockNum = 0; uint32_t nBlockNum = 0; uint32_t roundM = 0; uint32_t roundN = 0; uint32_t roundK = 0; uint32_t mTileBlock = 0; uint32_t nTileBlock = 0; uint32_t kTileBlock = 0; uint32_t mIterNum = 0; uint32_t nIterNum = 0; uint32_t kIterNum = 0; uint32_t mTileNums = 0; bool mHasTail = false; bool nHasTail = false; bool kHasTail = false; uint32_t kTailBlock = 0; uint32_t mTailBlock = 0; uint32_t nTailBlock = 0; uint32_t mTailNums = 0; }; 表2 Conv2DParams结构体内参数说明：参数名称 类型 说明 imgShape vector<int> 输入张量“feature_map”的形状，格式是[ H, W]。H为高，取值范围：[1,40]。W为宽，取值范围：[1,40]。 kernelShape vector<int> 卷积核张量“weight”的形状，格式是[Kh, Kw]。 Kh为高，取值范围：[1,5]。Kw为宽，取值范围：[1,5]。 stride vector<int> 卷积步长，格式是[stride_h, stride_w]。stride_h表示步长高， 值的范围：[1,4]。stride_w表示步长宽， 值的范围：[1,4]。 cin int 分形排布参数，Cin = C1 * C0，Cin为输入的channel数，C1取值范围：[1,4]。 当feature_map的数据类型为float时，C0=8。输入的channel的范围：[8，16，24，32]。当feature_map的数据类型为half时，C0=16。输入的channel的范围：[16，32，48，64]。当feature_map的数据类型为int8_t时，C0=32。输入的channel的范围：[32，64，96，128]。 cout int Cout为卷积核数目，取值范围：[16，32，64，128]， Cout必须为16的倍数。 padList vector<int> padding行数/列数，格式是[pad_left, pad_right, pad_top, pad_bottom]。pad_left为feature_map左侧pad列数，范围[0,4]。pad_right为feature_map右侧pad列数，范围[0,4]。pad_top为feature_map顶部pad行数，范围[0,4]。pad_bottom为feature_map底部pad行数，范围[0,4]。 dilation vector<int> 空洞卷积参数，格式[dilation_h, dilation_w]。dilation_h为空洞高，范围：[1,4]。dilation_w为空洞宽，范围：[1,4]。 膨胀后卷积核宽为dilation_w * (Kw - 1) + 1，高为dilation_h * (Kh - 1) + 1。 initY uint32_t 表示dstLocal是否需要初始化。 取值0：不使用bias，L0C需要初始化，dstLocal初始矩阵保存有之前结果，新计算结果会累加前一次conv2d计算结果。取值1：不使用bias，L0C不需要初始化，dstLocal初始矩阵中数据无意义，计算结果直接覆盖dstLocal中的数据。 partialSum uint32_t 当dstLocal参数所在的TPosition为CO2时，通过该参数控制计算结果是否搬出。取值0：搬出计算结果取值1：不搬出计算结果，可以进行后续计算 表3 Conv2dTilling结构体内参数说明参数名称 类型 说明 blockSize uint32_t 固定值，恒为16，一个维度内存放的元素个数。 loopMode LoopMode 遍历模式，结构体具体定义为： 1 2 3 4 5 6enum class LoopMode { MODE_NM = 0, MODE_MN = 1, MODE_KM = 2, MODE_KN = 3 }; c0Size uint32_t 一个block的字节长度，范围[16或者32]。 dtypeSize uint32_t 传入的数据类型的字节长度，范围[1, 2]。 strideH uint32_t 卷积步长-高，范围:[1,4]。 strideW uint32_t 卷积步长-宽，范围:[1,4]。 dilationH uint32_t 空洞卷积参数-高，范围：[1,4]。 dilationW uint32_t 空洞卷积参数-宽，范围：[1,4]。 hi uint32_t feature_map形状-高，范围：[1,40]。 wi uint32_t feature_map形状-宽，范围：[1,40]。 ho uint32_t feature_map形状-高，范围：[1,40]。 wo uint32_t feature_map形状-宽，范围：[1,40]。 height uint32_t weight形状-高，[1,5]。 width uint32_t weight形状-宽，[1,5]。 howo uint32_t feature_map形状大小，为ho * wo。 mNum uint32_t M轴等效数据长度参数值，范围：[1,4096]。 nNum uint32_t N轴等效数据长度参数值，范围：[1,4096]。 kNum uint32_t K轴等效数据长度参数值，范围：[1,4096]。 roundM uint32_t M轴等效数据长度参数值且以blockSize为倍数向上取整，范围：[1,4096]。 roundN uint32_t N轴等效数据长度参数值且以blockSize为倍数向上取整，范围：[1,4096]。 roundK uint32_t K轴等效数据长度参数值且以c0Size为倍数向上取整，范围：[1,4096]。 mBlockNum uint32_t M轴Block个数，mBlockNum = mNum / blockSize，范围：[1,4096]。 nBlockNum uint32_t N轴Block个数，nBlockNum = nNum / blockSize，范围：[1,4096]。 kBlockNum uint32_t K轴Block个数，kBlockNum = kNum / blockSize，范围：[1,4096]。 mIterNum uint32_t 遍历M轴维度数量，范围：[1,4096]。 nIterNum uint32_t 遍历N轴维度数量，范围：[1,4096]。 kIterNum uint32_t 遍历K轴维度数量，范围：[1,4096]。 mTileBlock uint32_t M轴切分块个数，范围：[1,4096]。 nTileBlock uint32_t N轴切分块个数，范围：[1,4096]。 kTileBlock uint32_t K轴切分块个数，范围：[1,4096]。 kTailBlock uint32_t K轴尾块个数，范围：[1,4096]。 mTailBlock uint32_t M轴尾块个数，范围：[1,4096]。 nTailBlock uint32_t N轴尾块个数，范围：[1,4096]。 kHasTail bool K轴是否存在尾块。 mHasTail bool M轴是否存在尾块。 nHasTail bool N轴是否存在尾块。 mTileNums uint32_t M轴切分块个数的长度，范围：[1,4096]。 mTailNums uint32_t M轴尾块个数的长度，范围：[1,4096]。 表4 imgShape、kernelShape和dstLocal的数据类型组合feature_map.dtype weight.dtype dst.dtype int8_t int8_t int32_t half half float half half half",
      "函数原型": "template <typename dst_T, typename src_T> __aicore__ inline void Conv2D(const LocalTensor<dst_T>& dstLocal, const LocalTensor<src_T>& featureMap, const LocalTensor<src_T>& weight, Conv2dParams& conv2dParams, Conv2dTilling& tilling)",
      "参数说明": [
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 Atlas 训练系列产品，支持的TPosition为：CO1，CO2 Atlas 推理系列产品AI Core，支持的TPosition为：CO1，CO2 结果中有效张量格式为[Cout/16, Ho, Wo, 16]，大小为Cout * Ho * Wo，Ho与Wo可以根据其他数据计算得出。 Ho = floor((H + pad_top + pad_bottom - dilation_h * (Kh - 1) - 1) / stride_h + 1) Wo = floor((W + pad_left + pad_right - dilation_w * (Kw - 1) - 1) / stride_w + 1) 由于硬件要求Ho*Wo需为16倍数，在申请dst Tensor时，shape应向上16对齐，实际申请shape大小应为Cout * round_howo。 round_howo = ceil(Ho * Wo /16) * 16。"
        },
        {
          "参数名": "featureMap",
          "类型": "输入",
          "说明": "输入张量，Tensor的TPosition为A1。 输入张量“feature_map”的形状，格式是[C1, H, W, C0]。 C1*C0为输入的channel数，要求如下： 当feature_map的数据类型为half时，C0=16。当feature_map的数据类型为int8_t时，C0=32。C1取值范围：[1,4], 输入的channel的范围：[16，32，64，128]。 H为高，取值范围：[1,40]。 W为宽，取值范围：[1,40]。"
        },
        {
          "参数名": "weight",
          "类型": "输入",
          "说明": "卷积核（权重）张量，Tensor的TPosition为B1。 卷积核张量“weight”的形状，格式是[C1, Kh, Kw, Cout, C0]。 C1*C0为输入的channel数，对于C0要求如下： 当feature_map的数据类型为half时，C0=16。当feature_map的数据类型为int8_t时，C0=32。C1取值范围：[1,4]。kernel_shape输入的channel数需与fm_shape输入的channel数保持一致。 Cout为卷积核数目，取值范围：[16，32，64，128]， Cout必须为16的倍数。 Kh为卷积核高；值的范围：[1,5]。 Kw表示卷积核宽；值的范围：[1,5]。"
        },
        {
          "参数名": "conv2dParams",
          "类型": "输入",
          "说明": "输入矩阵形状等状态参数，类型为Conv2dParams。结构体具体定义为： 1 2 3 4 5 6 7 8 9 10 11struct Conv2dParams { uint32_t imgShape[kConv2dImgSize]; // [H, W] uint32_t kernelShape[kConv2dkernelSize]; // [Kh, Kw] uint32_t stride[kConv2dStride]; // [stride_h, stride_w] uint32_t cin; // cin = C0 * C1; uint32_t cout; uint32_t padList[kConv2dPad]; // [pad_left, pad_right, pad_top, pad_bottom] uint32_t dilation[kConv2dDilation]; // [dilation_h, dilation_w] uint32_t initY; uint32_t partialSum; };"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9 10 11",
          "类型": "",
          "说明": "struct Conv2dParams { uint32_t imgShape[kConv2dImgSize]; // [H, W] uint32_t kernelShape[kConv2dkernelSize]; // [Kh, Kw] uint32_t stride[kConv2dStride]; // [stride_h, stride_w] uint32_t cin; // cin = C0 * C1; uint32_t cout; uint32_t padList[kConv2dPad]; // [pad_left, pad_right, pad_top, pad_bottom] uint32_t dilation[kConv2dDilation]; // [dilation_h, dilation_w] uint32_t initY; uint32_t partialSum; };"
        },
        {
          "参数名": "tilling",
          "类型": "输入",
          "说明": "分形控制参数，类型为Conv2dTilling。结构体具体定义为： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53struct Conv2dTilling { const uint32_t blockSize = 16; // # M block size is always 16 LoopMode loopMode = LoopMode::MODE_NM; uint32_t c0Size = 32; uint32_t dTypeSize = 1; uint32_t strideH = 0; uint32_t strideW = 0; uint32_t dilationH = 0; uint32_t dilationW = 0; uint32_t hi = 0; uint32_t wi = 0; uint32_t ho = 0; uint32_t wo = 0; uint32_t height = 0; uint32_t width = 0; uint32_t howo = 0; uint32_t mNum = 0; uint32_t nNum = 0; uint32_t kNum = 0; uint32_t mBlockNum = 0; uint32_t kBlockNum = 0; uint32_t nBlockNum = 0; uint32_t roundM = 0; uint32_t roundN = 0; uint32_t roundK = 0; uint32_t mTileBlock = 0; uint32_t nTileBlock = 0; uint32_t kTileBlock = 0; uint32_t mIterNum = 0; uint32_t nIterNum = 0; uint32_t kIterNum = 0; uint32_t mTileNums = 0; bool mHasTail = false; bool nHasTail = false; bool kHasTail = false; uint32_t kTailBlock = 0; uint32_t mTailBlock = 0; uint32_t nTailBlock = 0; uint32_t mTailNums = 0; };"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53",
          "类型": "",
          "说明": "struct Conv2dTilling { const uint32_t blockSize = 16; // # M block size is always 16 LoopMode loopMode = LoopMode::MODE_NM; uint32_t c0Size = 32; uint32_t dTypeSize = 1; uint32_t strideH = 0; uint32_t strideW = 0; uint32_t dilationH = 0; uint32_t dilationW = 0; uint32_t hi = 0; uint32_t wi = 0; uint32_t ho = 0; uint32_t wo = 0; uint32_t height = 0; uint32_t width = 0; uint32_t howo = 0; uint32_t mNum = 0; uint32_t nNum = 0; uint32_t kNum = 0; uint32_t mBlockNum = 0; uint32_t kBlockNum = 0; uint32_t nBlockNum = 0; uint32_t roundM = 0; uint32_t roundN = 0; uint32_t roundK = 0; uint32_t mTileBlock = 0; uint32_t nTileBlock = 0; uint32_t kTileBlock = 0; uint32_t mIterNum = 0; uint32_t nIterNum = 0; uint32_t kIterNum = 0; uint32_t mTileNums = 0; bool mHasTail = false; bool nHasTail = false; bool kHasTail = false; uint32_t kTailBlock = 0; uint32_t mTailBlock = 0; uint32_t nTailBlock = 0; uint32_t mTailNums = 0; };"
        },
        {
          "参数名": "imgShape",
          "类型": "vector<int>",
          "说明": "输入张量“feature_map”的形状，格式是[ H, W]。H为高，取值范围：[1,40]。W为宽，取值范围：[1,40]。"
        },
        {
          "参数名": "kernelShape",
          "类型": "vector<int>",
          "说明": "卷积核张量“weight”的形状，格式是[Kh, Kw]。 Kh为高，取值范围：[1,5]。Kw为宽，取值范围：[1,5]。"
        },
        {
          "参数名": "stride",
          "类型": "vector<int>",
          "说明": "卷积步长，格式是[stride_h, stride_w]。stride_h表示步长高， 值的范围：[1,4]。stride_w表示步长宽， 值的范围：[1,4]。"
        },
        {
          "参数名": "cin",
          "类型": "int",
          "说明": "分形排布参数，Cin = C1 * C0，Cin为输入的channel数，C1取值范围：[1,4]。 当feature_map的数据类型为float时，C0=8。输入的channel的范围：[8，16，24，32]。当feature_map的数据类型为half时，C0=16。输入的channel的范围：[16，32，48，64]。当feature_map的数据类型为int8_t时，C0=32。输入的channel的范围：[32，64，96，128]。"
        },
        {
          "参数名": "cout",
          "类型": "int",
          "说明": "Cout为卷积核数目，取值范围：[16，32，64，128]， Cout必须为16的倍数。"
        },
        {
          "参数名": "padList",
          "类型": "vector<int>",
          "说明": "padding行数/列数，格式是[pad_left, pad_right, pad_top, pad_bottom]。pad_left为feature_map左侧pad列数，范围[0,4]。pad_right为feature_map右侧pad列数，范围[0,4]。pad_top为feature_map顶部pad行数，范围[0,4]。pad_bottom为feature_map底部pad行数，范围[0,4]。"
        },
        {
          "参数名": "dilation",
          "类型": "vector<int>",
          "说明": "空洞卷积参数，格式[dilation_h, dilation_w]。dilation_h为空洞高，范围：[1,4]。dilation_w为空洞宽，范围：[1,4]。 膨胀后卷积核宽为dilation_w * (Kw - 1) + 1，高为dilation_h * (Kh - 1) + 1。"
        },
        {
          "参数名": "initY",
          "类型": "uint32_t",
          "说明": "表示dstLocal是否需要初始化。 取值0：不使用bias，L0C需要初始化，dstLocal初始矩阵保存有之前结果，新计算结果会累加前一次conv2d计算结果。取值1：不使用bias，L0C不需要初始化，dstLocal初始矩阵中数据无意义，计算结果直接覆盖dstLocal中的数据。"
        },
        {
          "参数名": "partialSum",
          "类型": "uint32_t",
          "说明": "当dstLocal参数所在的TPosition为CO2时，通过该参数控制计算结果是否搬出。取值0：搬出计算结果取值1：不搬出计算结果，可以进行后续计算"
        },
        {
          "参数名": "blockSize",
          "类型": "uint32_t",
          "说明": "固定值，恒为16，一个维度内存放的元素个数。"
        },
        {
          "参数名": "loopMode",
          "类型": "LoopMode",
          "说明": "遍历模式，结构体具体定义为： 1 2 3 4 5 6enum class LoopMode { MODE_NM = 0, MODE_MN = 1, MODE_KM = 2, MODE_KN = 3 };"
        },
        {
          "参数名": "1 2 3 4 5 6",
          "类型": "",
          "说明": "enum class LoopMode { MODE_NM = 0, MODE_MN = 1, MODE_KM = 2, MODE_KN = 3 };"
        },
        {
          "参数名": "c0Size",
          "类型": "uint32_t",
          "说明": "一个block的字节长度，范围[16或者32]。"
        },
        {
          "参数名": "dtypeSize",
          "类型": "uint32_t",
          "说明": "传入的数据类型的字节长度，范围[1, 2]。"
        },
        {
          "参数名": "strideH",
          "类型": "uint32_t",
          "说明": "卷积步长-高，范围:[1,4]。"
        },
        {
          "参数名": "strideW",
          "类型": "uint32_t",
          "说明": "卷积步长-宽，范围:[1,4]。"
        },
        {
          "参数名": "dilationH",
          "类型": "uint32_t",
          "说明": "空洞卷积参数-高，范围：[1,4]。"
        },
        {
          "参数名": "dilationW",
          "类型": "uint32_t",
          "说明": "空洞卷积参数-宽，范围：[1,4]。"
        },
        {
          "参数名": "hi",
          "类型": "uint32_t",
          "说明": "feature_map形状-高，范围：[1,40]。"
        },
        {
          "参数名": "wi",
          "类型": "uint32_t",
          "说明": "feature_map形状-宽，范围：[1,40]。"
        },
        {
          "参数名": "ho",
          "类型": "uint32_t",
          "说明": "feature_map形状-高，范围：[1,40]。"
        },
        {
          "参数名": "wo",
          "类型": "uint32_t",
          "说明": "feature_map形状-宽，范围：[1,40]。"
        },
        {
          "参数名": "height",
          "类型": "uint32_t",
          "说明": "weight形状-高，[1,5]。"
        },
        {
          "参数名": "width",
          "类型": "uint32_t",
          "说明": "weight形状-宽，[1,5]。"
        },
        {
          "参数名": "howo",
          "类型": "uint32_t",
          "说明": "feature_map形状大小，为ho * wo。"
        },
        {
          "参数名": "mNum",
          "类型": "uint32_t",
          "说明": "M轴等效数据长度参数值，范围：[1,4096]。"
        },
        {
          "参数名": "nNum",
          "类型": "uint32_t",
          "说明": "N轴等效数据长度参数值，范围：[1,4096]。"
        },
        {
          "参数名": "kNum",
          "类型": "uint32_t",
          "说明": "K轴等效数据长度参数值，范围：[1,4096]。"
        },
        {
          "参数名": "roundM",
          "类型": "uint32_t",
          "说明": "M轴等效数据长度参数值且以blockSize为倍数向上取整，范围：[1,4096]。"
        },
        {
          "参数名": "roundN",
          "类型": "uint32_t",
          "说明": "N轴等效数据长度参数值且以blockSize为倍数向上取整，范围：[1,4096]。"
        },
        {
          "参数名": "roundK",
          "类型": "uint32_t",
          "说明": "K轴等效数据长度参数值且以c0Size为倍数向上取整，范围：[1,4096]。"
        },
        {
          "参数名": "mBlockNum",
          "类型": "uint32_t",
          "说明": "M轴Block个数，mBlockNum = mNum / blockSize，范围：[1,4096]。"
        },
        {
          "参数名": "nBlockNum",
          "类型": "uint32_t",
          "说明": "N轴Block个数，nBlockNum = nNum / blockSize，范围：[1,4096]。"
        },
        {
          "参数名": "kBlockNum",
          "类型": "uint32_t",
          "说明": "K轴Block个数，kBlockNum = kNum / blockSize，范围：[1,4096]。"
        },
        {
          "参数名": "mIterNum",
          "类型": "uint32_t",
          "说明": "遍历M轴维度数量，范围：[1,4096]。"
        },
        {
          "参数名": "nIterNum",
          "类型": "uint32_t",
          "说明": "遍历N轴维度数量，范围：[1,4096]。"
        },
        {
          "参数名": "kIterNum",
          "类型": "uint32_t",
          "说明": "遍历K轴维度数量，范围：[1,4096]。"
        },
        {
          "参数名": "mTileBlock",
          "类型": "uint32_t",
          "说明": "M轴切分块个数，范围：[1,4096]。"
        },
        {
          "参数名": "nTileBlock",
          "类型": "uint32_t",
          "说明": "N轴切分块个数，范围：[1,4096]。"
        },
        {
          "参数名": "kTileBlock",
          "类型": "uint32_t",
          "说明": "K轴切分块个数，范围：[1,4096]。"
        },
        {
          "参数名": "kTailBlock",
          "类型": "uint32_t",
          "说明": "K轴尾块个数，范围：[1,4096]。"
        },
        {
          "参数名": "mTailBlock",
          "类型": "uint32_t",
          "说明": "M轴尾块个数，范围：[1,4096]。"
        },
        {
          "参数名": "nTailBlock",
          "类型": "uint32_t",
          "说明": "N轴尾块个数，范围：[1,4096]。"
        },
        {
          "参数名": "kHasTail",
          "类型": "bool",
          "说明": "K轴是否存在尾块。"
        },
        {
          "参数名": "mHasTail",
          "类型": "bool",
          "说明": "M轴是否存在尾块。"
        },
        {
          "参数名": "nHasTail",
          "类型": "bool",
          "说明": "N轴是否存在尾块。"
        },
        {
          "参数名": "mTileNums",
          "类型": "uint32_t",
          "说明": "M轴切分块个数的长度，范围：[1,4096]。"
        },
        {
          "参数名": "mTailNums",
          "类型": "uint32_t",
          "说明": "M轴尾块个数的长度，范围：[1,4096]。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename dst_T, typename src_T> __aicore__ inline void Conv2D(const LocalTensor<dst_T>& dstLocal, const LocalTensor<src_T>& featureMap, const LocalTensor<src_T>& weight, Conv2dParams& conv2dParams, Conv2dTilling& tilling)\ntemplate <typename T> __aicore__ inline Conv2dTilling GetConv2dTiling(Conv2dParams& conv2dParams)",
      "约束限制": "",
      "相关接口": [
        "通用约束",
        "矩阵计算(ISASI)"
      ],
      "版本信息": ""
    },
    {
      "API名称": "CastDeq-精度转换指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0074.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LoadDataUnzip-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0243.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GroupNorm-数据归一化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0816.html",
      "功能说明": "对一个特征进行标准化的一般公式如下所示： 其中，i表示特征中的索引， 和 表示特征中每个值标准化前后的值，μ和σ表示特征的均值和标准差，计算公式如下所示： 其中，ε是一个很小的常数，S表示参与计算的数据的集合，m表示集合的大小。不同类型的特征标准化方法（BatchNorm、LayerNorm、InstanceNorm、GroupNorm等）的主要区别在于参与计算的数据集合的选取上。不同Norm类算子参与计算的数据集合的选取方式如下： 对于一个shape为[N, C, H, W]的输入，GroupNorm将每个[C, H, W]在C维度上分为groupNum组，然后对每一组进行标准化。最后对标准化后的特征进行缩放和平移。其中缩放参数γ和平移参数β是可训练的。 对一个特征进行标准化的一般公式如下所示： 其中，i表示特征中的索引， 和 表示特征中每个值标准化前后的值，μ和σ表示特征的均值和标准差，计算公式如下所示： 其中，ε是一个很小的常数，S表示参与计算的数据的集合，m表示集合的大小。不同类型的特征标准化方法（BatchNorm、LayerNorm、InstanceNorm、GroupNorm等）的主要区别在于参与计算的数据集合的选取上。不同Norm类算子参与计算的数据集合的选取方式如下： 对于一个shape为[N, C, H, W]的输入，GroupNorm将每个[C, H, W]在C维度上分为groupNum组，然后对每一组进行标准化。最后对标准化后的特征进行缩放和平移。其中缩放参数γ和平移参数β是可训练的。 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为true，则本接口内部计算时复用inputX的内存空间，节省内存空间；设置为false，则本接口内部计算时不复用inputX的内存空间。 对于float数据类型的输入支持开启该参数，half数据类型的输入不支持开启该参数。 isReuseSource的使用样例请参考更多样例。 表2 接口参数说明参数名 输入/输出 描述 output 输出 目的操作数，对标准化后的输入进行缩放和平移计算的结果。shape为[N, C, H, W]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 outputMean 输出 目的操作数，均值。shape为[N, groupNum]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 outputVariance 输出 目的操作数，方差。shape为[N, groupNum]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 inputX 输入 源操作数。shape为[N, C, H, W]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 gamma 输入 源操作数，缩放参数。该参数支持的取值范围为[-100, 100]。shape为[C]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 beta 输入 源操作数，平移参数。该参数支持的取值范围为[-100, 100]。shape为[C]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 sharedTmpBuffer 输入 接口内部复杂计算时用于存储中间变量，由开发者提供。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考GroupNorm Tiling。 epsilon 输入 防除0的权重系数。数据类型需要与inputX/output保持一致。 tiling 输入 输入数据的切分信息，Tiling信息的获取请参考GroupNorm Tiling。",
      "函数原型": "template <typename T, bool isReuseSource = false> __aicore__ inline void GroupNorm(const LocalTensor<T>& output, const LocalTensor<T>& outputMean, const LocalTensor<T>& outputVariance, const LocalTensor<T>& inputX, const LocalTensor<T>& gamma, const LocalTensor<T>& beta, const LocalTensor<uint8_t>& sharedTmpBuffer, const T epsilon, GroupNormTiling& tiling)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为true，则本接口内部计算时复用inputX的内存空间，节省内存空间；设置为false，则本接口内部计算时不复用inputX的内存空间。 对于float数据类型的输入支持开启该参数，half数据类型的输入不支持开启该参数。 isReuseSource的使用样例请参考更多样例。"
        },
        {
          "参数名": "output",
          "类型": "输出",
          "说明": "目的操作数，对标准化后的输入进行缩放和平移计算的结果。shape为[N, C, H, W]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "outputMean",
          "类型": "输出",
          "说明": "目的操作数，均值。shape为[N, groupNum]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "outputVariance",
          "类型": "输出",
          "说明": "目的操作数，方差。shape为[N, groupNum]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "inputX",
          "类型": "输入",
          "说明": "源操作数。shape为[N, C, H, W]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "gamma",
          "类型": "输入",
          "说明": "源操作数，缩放参数。该参数支持的取值范围为[-100, 100]。shape为[C]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "beta",
          "类型": "输入",
          "说明": "源操作数，平移参数。该参数支持的取值范围为[-100, 100]。shape为[C]。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "接口内部复杂计算时用于存储中间变量，由开发者提供。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考GroupNorm Tiling。"
        },
        {
          "参数名": "epsilon",
          "类型": "输入",
          "说明": "防除0的权重系数。数据类型需要与inputX/output保持一致。"
        },
        {
          "参数名": "tiling",
          "类型": "输入",
          "说明": "输入数据的切分信息，Tiling信息的获取请参考GroupNorm Tiling。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74",
      "约束限制": "",
      "相关接口": [
        "LocalTensor",
        "GroupNorm Tiling",
        "通用约束",
        "数据归一化"
      ],
      "版本信息": "0.001"
    },
    {
      "API名称": "Gemm-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0263.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ScalarGetCountOfValue-标量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0016.html",
      "功能说明": "获取一个uint64_t类型数字的二进制中0或者1的个数。 获取一个uint64_t类型数字的二进制中0或者1的个数。 表1 模板参数说明参数名 描述 countValue 指定统计0还是统计1的个数。 只能输入0或1。 表2 参数说明参数名 输入/输出 描述 valueIn 输入 被统计的二进制数字。",
      "函数原型": "template <int countValue> __aicore__ inline int64_t ScalarGetCountOfValue(uint64_t valueIn)",
      "参数说明": [
        {
          "参数名": "countValue",
          "类型": "",
          "说明": "指定统计0还是统计1的个数。 只能输入0或1。"
        },
        {
          "参数名": "valueIn",
          "类型": "输入",
          "说明": "被统计的二进制数字。"
        }
      ],
      "返回值": "valueIn中0或者1的个数。",
      "调用示例": "template <int countValue> __aicore__ inline int64_t ScalarGetCountOfValue(uint64_t valueIn)\nuint64_t valueIn = 0xffff; // 输出数据(oneCount): 16 int64_t oneCount = AscendC::ScalarGetCountOfValue<1>(valueIn);",
      "约束限制": "",
      "相关接口": [
        "标量计算"
      ],
      "版本信息": ""
    },
    {
      "API名称": "MetricsProfStart-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1214.html",
      "功能说明": "用于设置性能数据采集信号启动，和MetricsProfStop配合使用。使用msProf工具进行算子上板调优时，可在kernel侧代码段前后分别调用MetricsProfStart和MetricsProfStop来指定需要调优的代码段范围。 用于设置性能数据采集信号启动，和MetricsProfStop配合使用。使用msProf工具进行算子上板调优时，可在kernel侧代码段前后分别调用MetricsProfStart和MetricsProfStop来指定需要调优的代码段范围。",
      "函数原型": "__aicore__ inline void MetricsProfStart()",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "__aicore__ inline void MetricsProfStart()",
      "约束限制": "",
      "相关接口": [
        "算子调测API"
      ],
      "版本信息": ""
    },
    {
      "API名称": "TopK-排序-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0836.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetAippFunctions-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0240.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "AscendAntiQuant-量化反量化-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0822.html",
      "功能说明": "按元素做伪量化计算，比如将int8_t数据类型伪量化为half数据类型，计算公式如下： 按元素做伪量化计算，比如将int8_t数据类型伪量化为half数据类型，计算公式如下： 表1 模板参数说明参数名 描述 InputDataType 输入的数据类型。 OutputDataType 输出的数据类型。 isTranspose 是否使能输入数据转置。 表2 接口参数说明参数名 输入/输出 描述 dst 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t Atlas 推理系列产品AI Core，支持的数据类型为：half src 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：int8_t/int4b_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：int8_t/int4b_t Atlas 推理系列产品AI Core，支持的数据类型为：int8_t offset 输入 输入数据反量化时的偏移量。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t Atlas 推理系列产品AI Core，支持的数据类型为：half scale 输入 输入数据反量化时的缩放因子。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t Atlas 推理系列产品AI Core，支持的数据类型为：half sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考GetAscendAntiQuantMaxMinTmpSize。 K 输入 isTranspose为true时，src的shape为[N,K]；isTranspose为false时，src的shape为[K,N]。 参数K对应其中的K值。 shapeInfo 输入 设置参数offset和scale的shape信息，仅PER_CHANNEL场景（按通道量化）需要配置。 可选参数。在PER_CHANNEL场景，如果未传入该参数或者结构体中数据设置为0，将从offset和scale的ShapeInfo中获取offset和scale的shape信息。 AntiQuantShapeInfo类型，定义如下： 1 2 3 4 5 6struct AntiQuantShapeInfo { uint32_t offsetHeight{0}; // offset 的高 uint32_t offsetWidth{0}; // offset 的宽 uint32_t scaleHeight{0}; // scale 的高 uint32_t scaleWidth{0}; // scale 的宽 };",
      "函数原型": "template <typename InputDataType, typename OutputDataType, bool isTranspose> __aicore__ inline void AscendAntiQuant(const LocalTensor<OutputDataType> &dst, const LocalTensor<InputDataType> &src, const LocalTensor<OutputDataType> &offset, const LocalTensor<OutputDataType> &scale, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t K, const AntiQuantShapeInfo& shapeInfo = {})",
      "参数说明": [
        {
          "参数名": "InputDataType",
          "类型": "",
          "说明": "输入的数据类型。"
        },
        {
          "参数名": "OutputDataType",
          "类型": "",
          "说明": "输出的数据类型。"
        },
        {
          "参数名": "isTranspose",
          "类型": "",
          "说明": "是否使能输入数据转置。"
        },
        {
          "参数名": "dst",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t Atlas 推理系列产品AI Core，支持的数据类型为：half"
        },
        {
          "参数名": "src",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：int8_t/int4b_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：int8_t/int4b_t Atlas 推理系列产品AI Core，支持的数据类型为：int8_t"
        },
        {
          "参数名": "offset",
          "类型": "输入",
          "说明": "输入数据反量化时的偏移量。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t Atlas 推理系列产品AI Core，支持的数据类型为：half"
        },
        {
          "参数名": "scale",
          "类型": "输入",
          "说明": "输入数据反量化时的缩放因子。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t Atlas 推理系列产品AI Core，支持的数据类型为：half"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考GetAscendAntiQuantMaxMinTmpSize。"
        },
        {
          "参数名": "K",
          "类型": "输入",
          "说明": "isTranspose为true时，src的shape为[N,K]；isTranspose为false时，src的shape为[K,N]。 参数K对应其中的K值。"
        },
        {
          "参数名": "shapeInfo",
          "类型": "输入",
          "说明": "设置参数offset和scale的shape信息，仅PER_CHANNEL场景（按通道量化）需要配置。 可选参数。在PER_CHANNEL场景，如果未传入该参数或者结构体中数据设置为0，将从offset和scale的ShapeInfo中获取offset和scale的shape信息。 AntiQuantShapeInfo类型，定义如下： 1 2 3 4 5 6struct AntiQuantShapeInfo { uint32_t offsetHeight{0}; // offset 的高 uint32_t offsetWidth{0}; // offset 的宽 uint32_t scaleHeight{0}; // scale 的高 uint32_t scaleWidth{0}; // scale 的宽 };"
        },
        {
          "参数名": "1 2 3 4 5 6",
          "类型": "",
          "说明": "struct AntiQuantShapeInfo { uint32_t offsetHeight{0}; // offset 的高 uint32_t offsetWidth{0}; // offset 的宽 uint32_t scaleHeight{0}; // scale 的高 uint32_t scaleWidth{0}; // scale 的宽 };"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93",
      "约束限制": "",
      "相关接口": [
        "GetAscendAntiQuantMaxMinTmpSize",
        "LocalTensor",
        "ShapeInfo",
        "通用约束",
        "量化反量化"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Asin-Asin-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0496.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "简介-OpMC2Def-原型注册与管理-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0999.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Exp-Exp-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0589.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SubRelu-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0046.html",
      "功能说明": "按元素求差，再进行Relu计算（结果和0对比取较大值）。计算公式如下： 按元素求差，再进行Relu计算（结果和0对比取较大值）。计算公式如下： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 src0Local、src1Local 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void SubRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为half/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "src0Local、src1Local",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 两个源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。BinaryRepeatParams类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void SubRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void SubRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask[], const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void SubRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, uint64_t mask, const uint8_t repeatTimes, const BinaryRepeatParams& repeatParams)\nuint64_t mask = 128; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::SubRelu(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 4, 一次迭代计算128个数, 共计算512个数 // dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入 // dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入 AscendC::SubRelu(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\nAscendC::SubRelu(dstLocal, src0Local, src1Local, 512);\n输入数据(src0Local): [1 2 3 ... 512] 输入数据(src1Local): [0 1 4 ... 513] 输出数据(dstLocal): [1 1 0 ... 0]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "BinaryRepeatParams",
        "通用约束",
        "更多样例",
        "双目指令"
      ],
      "版本信息": "rc0"
    },
    {
      "API名称": "Pad-数据填充-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0849.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "GetCmpMask(ISASI)-比较指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0223.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "使用说明-CubeResGroupHandle-资源管理(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0289.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetHF32Mode-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0258.html",
      "功能说明": "用于设置Mmad计算是否开启HF32模式，开启该模式后L0A/L0B中的FP32数据将在参与Mmad计算之前被舍入为HF32。 用于设置Mmad计算是否开启HF32模式，开启该模式后L0A/L0B中的FP32数据将在参与Mmad计算之前被舍入为HF32。 表1 参数说明参数名 输入/输出 描述 hf32Mode 输入 Mmad HF32模式控制入参，bool类型。支持如下两种取值： true：L0A/L0B中的FP32数据将在矩阵乘法之前被舍入为HF32。false：将执行常规的FP32矩阵乘法。",
      "函数原型": "__aicore__ inline void SetHF32Mode(bool hf32Mode)",
      "参数说明": [
        {
          "参数名": "hf32Mode",
          "类型": "输入",
          "说明": "Mmad HF32模式控制入参，bool类型。支持如下两种取值： true：L0A/L0B中的FP32数据将在矩阵乘法之前被舍入为HF32。false：将执行常规的FP32矩阵乘法。"
        }
      ],
      "返回值": "无",
      "调用示例": "__aicore__ inline void SetHF32Mode(bool hf32Mode)\nbool hf32Mode = true; AscendC::SetHF32Mode(hf32Mode);",
      "约束限制": "",
      "相关接口": [
        "矩阵计算(ISASI)"
      ],
      "版本信息": ""
    },
    {
      "API名称": "SetNextTaskStart-任务间同步-内存管理与同步控制-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00087.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LoadData-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0238.html",
      "功能说明": "LoadData分为Load2D和Load3D，其功能分别如下： LoadData分为Load2D和Load3D，其功能分别如下： 表1 模板参数说明 参数名称 含义 T 源操作数和目的操作数的数据类型。 Load2D接口： Atlas 训练系列产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half Atlas 推理系列产品 AI Core，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Load3Dv1接口： Atlas 训练系列产品 ，支持的数据类型为：uint8_t/int8_t/half Atlas 推理系列产品 AI Core，支持的数据类型为：uint8_t/int8_t/half Load3Dv2接口： Atlas 推理系列产品 AI Core，支持的数据类型为：uint8_t/int8_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ， TPosition为A1/A2时，支持数据类型为：uint8_t/int8_t/half/bfloat16_t/uint32_t/int32_t/float/int4b_t TPosition为B1/B2时，支持数据类型为：half/bfloat16_t/uint32_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ， TPosition为A1/A2时，支持数据类型为：uint8_t/int8_t/half/bfloat16_t/uint32_t/int32_t/float/int4b_t TPosition为B1/B2时，支持数据类型为：half/bfloat16_t/uint32_t/int32_t/float Atlas 200I/500 A2 推理产品 ， TPosition为A1/A2时，支持数据类型为：uint8_t/int8_t/half/bfloat16/uint32_t/int32_t/float/int4b_t TPosition为B1/B2时，支持数据类型为：half/bfloat16_t/uint32_t/int32_t/float defaultConfig 控制是否在Load3Dv1/Load3Dv2接口内部设置相关属性。 IsResetLoad3dConfig类型。IsResetLoad3dConfig结构定义如下： 1 2 3 4 struct IsResetLoad3dConfig { bool isSetFMatrix = true; bool isSetPadding = true; }; isSetFMatrix配置为true，表示在接口内部设置FeatureMap的属性描述（包括l1H、l1W、padList，参数介绍参考表4 LoadData3DParamsV1结构体内参数说明、表5 LoadData3DParamsV2结构体内参数说明）；设置为false，表示该接口传入的FeatureMap的属性描述不生效，开发者需要通过SetFmatrix进行设置。 isSetPadding配置为true，表示在接口内部设置Pad属性描述（即padValue参数，参数介绍参考表4 LoadData3DParamsV1结构体内参数说明、表5 LoadData3DParamsV2结构体内参数说明）；设置为false，表示该接口传入的Pad属性不生效，开发者需要通过SetLoadDataPaddingValue进行设置。可参考样例调用示例。 该参数的默认值如下： 1 constexpr IsResetLoad3dConfig IS_RESER_LOAD3D_DEFAULT_CONFIG = {true, true}; U LoadData3DParamsV1/LoadData3DParamsV2中padValue的数据类型。 当dstLocal、srcLocal使用基础数据类型时， U和dstLocal、srcLocal的数据类型T需保持一致，否则编译失败。 当dstLocal 、srcLocal使用TensorTrait类型时，U和dstLocal、srcLocal的数据类型T的LiteType需保持一致，否则编译失败。 最后一个模板参数仅用于上述数据类型检查，用户无需关注。 表2 通用参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，类型为LocalTensor。目的操作数的起始地址对齐约束请参考表6。 数据连续排列顺序由目的操作数所在TPosition决定，具体约束如下： A2：小Z大Z格式； B2：小N大Z格式； A1/B1：无格式要求，一般情况下为小Z大N格式。 srcLocal 输入 源操作数，类型为LocalTensor或GlobalTensor。源操作数的起始地址对齐约束请参考表6。 数据类型需要与dstLocal保持一致。 loadDataParams 输入 LoadData参数结构体，类型为： LoadData2DParams，具体参考表3。 LoadData3DParamsV1，具体参考表4。 LoadData3DParamsV2，具体参考表5。 上述结构体参数定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_mm.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 表3 LoadData2DParams结构体内参数说明 参数名称 含义 startIndex 分形矩阵ID，说明搬运起始位置为源操作数中第几个分形（0为源操作数中第1个分形矩阵）。取值范围：startIndex∈[0, 65535] 。单位：512B。默认为0。 repeatTimes 迭代次数，每个迭代可以处理512B数据。取值范围：repeatTimes∈[1, 255]。 srcStride 相邻迭代间，源操作数前一个分形与后一个分形起始地址的间隔，单位：512B。取值范围：src_stride∈[0, 65535]。默认为0。 sid 预留参数，配置为0即可。 dstGap 相邻迭代间，目的操作数前一个分形结束地址与后一个分形起始地址的间隔，单位：512B。取值范围：dstGap∈[0, 65535]。默认为0。 注： Atlas 训练系列产品 此参数不使能。 ifTranspose 是否启用转置功能，对每个分形矩阵进行转置，默认为false: true：启用 false：不启用 注意：只有A1->A2和B1->B2通路才能使能转置，使能转置功能时，源操作数、目的操作数仅支持uint16_t/int16_t/half数据类型。 addrMode 预留参数，配置为0即可。 表4 LoadData3DParamsV1结构体内参数说明 参数名称 含义 padList padding列表 [padding_left, padding_right, padding_top, padding_bottom]，每个元素取值范围：[0,255]。默认为{0, 0, 0, 0}。 l1H 源操作数 height，取值范围：l1H∈[1, 32767]。 l1W 源操作数 width，取值范围：l1W∈[1, 32767] 。 c1Index 该指令在源tensor C1维度的起点，取值范围：c1Index∈[0, 4095] 。默认为0。 fetchFilterW 该指令在卷积核上w维度的起始位置，取值范围：fetchFilterW∈[0, 254] 。默认为0。 fetchFilterH 该指令在filter上h维度的起始位置，取值范围：fetchFilterH∈[0, 254] 。默认为0。 leftTopW 该指令在源操作数上w维度的起点，取值范围：leftTopW∈[-255, 32767] 。默认为0。如果padding_left = a，leftTopW配置为-a。 leftTopH 该指令在源操作数上h维度的起点，取值范围：leftTopH∈[-255, 32767] 。默认为0。如果padding_top = a，leftTopH配置为-a。 strideW 卷积核在源操作数w维度滑动的步长，取值范围：strideW∈[1, 63] 。 strideH 卷积核在源操作数h维度滑动的步长，取值范围：strideH∈[1, 63] 。 filterW 卷积核width，取值范围：filterW∈[1, 255] 。 filterH 卷积核height，取值范围：filterH∈[1, 255] 。 dilationFilterW 卷积核width膨胀系数，取值范围：dilationFilterW∈[1, 255] 。 dilationFilterH 卷积核height膨胀系数，取值范围：dilationFilterH∈[1, 255] 。 jumpStride 迭代之间，目的操作数首地址步长，取值范围：jumpStride∈[1, 127] 。 repeatMode 迭代模式。 模式0：每次迭代，增加卷积核窗口中的点，对应在目的矩阵上往w维度方向增长。 模式1：每次迭代，增加滑动窗口左上坐标，对应在目的矩阵上往h维度方向增长。 取值范围：repeatMode∈[0, 1] 。默认为0。 repeatTime 迭代次数，每一次源操作数和目的操作数的地址都会改变。取值范围：repeatTime∈[1，255] 。 cSize 配置是否开启cSize = 4(b16) / cSize = 8(b8)优化，取值范围：cSize∈[0, 1] 。默认为0。 padValue Pad填充值的数值，数据类型需要与srcLocal保持一致。默认为0。若不想使能padding，可将padList设为全0。 表5 LoadData3DParamsV2结构体内参数说明 参数名称 含义 padList padding 列表 [padding_left, padding_right, padding_top, padding_bottom]，每个元素取值范围：[0,255]。默认为{0, 0, 0, 0}。 l1H 源操作数height，取值范围：l1H∈[1, 32767]。 l1W 源操作数weight，取值范围：l1W∈[1, 32767] 。 channelSize 源操作数的通道数，取值范围：channelSize∈[1, 63] 。 针对以下型号，channelSize的取值要求为：对于half，channelSize可取值为4，8，16，N * 16 + 4，N * 16 + 8；对于int8_t/uint8_t，channelSize可取值为4，8，16，32，N * 32 + 4，N * 32 + 8，N * 32 + 16。N为正整数。 Atlas 推理系列产品 AI Core 针对以下型号，channelSize的取值要求为：对于uint32_t/int32_t/float，channelSize可取值为4，N * 8，N * 8 + 4；对于half/bfloat16，channelSize可取值为4，8，N * 16，N * 16 + 4，N * 16 + 8；对于int8_t/uint8_t，channelSize可取值为4，8，16， 32 * N，N * 32 + 4，N * 32 + 8，N * 32 + 16；对于int4b_t，ChannelSize可取值为8，16，32，N * 64，N * 64 + 8，N * 64 + 16，N * 64 + 32。N为正整数。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 Atlas 200I/500 A2 推理产品 kExtension 该指令在目的操作数width维度的传输长度，如果不覆盖最右侧的分形，对于half类型，应为16的倍数，对于int8_t/uint8_t应为32的倍数；覆盖的情况则无倍数要求。取值范围: kExtension∈[1, 65535] 。 mExtension 该指令在目的操作数height维度的传输长度，如果不覆盖最下侧的分形，对于half/int8_t/uint8_t，应为16的倍数；覆盖的情况则无倍数要求。取值范围：mExtension∈[1, 65535] 。 kStartPt 该指令在目的操作数width维度的起点，对于half类型，应为16的倍数，对于int8_t/uint8_t应为32的倍数。取值范围[0, 65535] 。默认为0。 mStartPt 该指令在目的操作数height维度的起点，如果不覆盖最下侧的分形，对于half/int8_t/uint8_t，应为16的倍数；覆盖的情况则无倍数要求。取值范围[0, 65535] 。默认为0。 strideW 卷积核在源操作数width维度滑动的步长，取值范围：strideW∈[1, 63] 。 strideH 卷积核在源操作数height 维度滑动的步长，取值范围：strideH∈[1, 63] 。 filterW 卷积核width，取值范围：filterW∈[1, 255] 。 filterH 卷积核height，取值范围：filterH∈[1, 255] 。 dilationFilterW 卷积核width膨胀系数，取值范围：dilationFilterW∈[1, 255] 。 dilationFilterH 卷积核height膨胀系数，取值范围：dilationFilterH∈[1, 255] 。 enTranspose 是否启用转置功能，对整个目标矩阵进行转置，支持数据类型为 bool，仅在目的TPosition为A2，且源操作数为half类型时有效。默认为false。 true：启用 false：不启用 enSmallK 是否使能small k特性，每个分形矩阵大小为16*4，支持数据类型为 bool，默认为false。当前产品形态，该特性已不再支持。 true：使能 false：不使能 padValue Pad填充值的数值，数据类型需要与srcLocal保持一致。默认为0。若不想使能padding，可将padList设为全0。 filterSizeW 是否在filterW的基础上将卷积核width增加256 个元素。true，增加；false，不增加。 filterSizeH 是否在filterH的基础上将卷积核height增加256个元素。true，增加；false，不增加。 fMatrixCtrl 表示LoadData3DV2指令从左矩阵还是右矩阵获取FeatureMap的属性描述，与SetFmatrix配合使用，当前只支持设置为false，默认值为false。 true：从右矩阵中获取FeatureMap的属性描述； false：从左矩阵中获取FeatureMap的属性描述。 要求输入的feature map和filter的格式是 NC1HWC0，其中 C0 是最低维度而且 C0 是固定值为 16（对于u8/s8类型为32），C1=C/C0。 为了简化场景，以下场景假设输入的 feature map 的 channel 为4，即 Ci=4。输入 feature maps 在 A1 中的形状为 (Hi,Wi,Ci)，经过 load3dv1 处理后在 A2 的数据形状为(Wo*Ho, Hk*Wk*Ci)。其中 Wo 和 Ho 是卷积后输出的shape，Hk 和 Wk 是 filter 的 shape。 直观的来看，img2col 的过程就是 filter 在 feature map 上扫过，将对应 feature map 的数据展开成输出数据的每一行的过程。filter 首先在W方向上滑动 Wo 步,然后在 H 方向上走一步然后重复以上过程，最终输出 Wo*Ho 行数据。下图中红色和黄色的数据分别代表第一行和第二行。数字表示原始输入数据，filter 和输出数据三者之间的关联关系。可以看到，load3dv1 首先在输入数据的 Ci 维度搬运对应于 00 的 4 个数，然后搬运对应于 01 的四个数，最终这一行的大小为 Hk*Wk*Ci 即 3*3*4=36 个数。 对应的feature map格式如下图： 对应的 filter 的格式如下图：",
      "函数原型": "template <typename T, const IsResetLoad3dConfig &defaultConfig = IS_RESER_LOAD3D_DEFAULT_CONFIG, typename U = PrimT<T>, typename Std::enable_if<Std::is_same<PrimT<T>, U>::value, bool>::type = true> __aicore__ inline void LoadData(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LoadData3DParamsV1<U>& loadDataParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "源操作数和目的操作数的数据类型。 Load2D接口： Atlas 训练系列产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half Atlas 推理系列产品 AI Core，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Load3Dv1接口： Atlas 训练系列产品 ，支持的数据类型为：uint8_t/int8_t/half Atlas 推理系列产品 AI Core，支持的数据类型为：uint8_t/int8_t/half Load3Dv2接口： Atlas 推理系列产品 AI Core，支持的数据类型为：uint8_t/int8_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ， TPosition为A1/A2时，支持数据类型为：uint8_t/int8_t/half/bfloat16_t/uint32_t/int32_t/float/int4b_t TPosition为B1/B2时，支持数据类型为：half/bfloat16_t/uint32_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ， TPosition为A1/A2时，支持数据类型为：uint8_t/int8_t/half/bfloat16_t/uint32_t/int32_t/float/int4b_t TPosition为B1/B2时，支持数据类型为：half/bfloat16_t/uint32_t/int32_t/float Atlas 200I/500 A2 推理产品 ， TPosition为A1/A2时，支持数据类型为：uint8_t/int8_t/half/bfloat16/uint32_t/int32_t/float/int4b_t TPosition为B1/B2时，支持数据类型为：half/bfloat16_t/uint32_t/int32_t/float"
        },
        {
          "参数名": "defaultConfig",
          "类型": "控制是否在Load3Dv1/Load3Dv2接口内部设置相关属性。 IsResetLoad3dConfig类型。IsResetLoad3dConfig结构定义如下： 1 2 3 4 struct IsResetLoad3dConfig { bool isSetFMatrix = true; bool isSetPadding = true; }; isSetFMatrix配置为true，表示在接口内部设置FeatureMap的属性描述（包括l1H、l1W、padList，参数介绍参考表4 LoadData3DParamsV1结构体内参数说明、表5 LoadData3DParamsV2结构体内参数说明）；设置为false，表示该接口传入的FeatureMap的属性描述不生效，开发者需要通过SetFmatrix进行设置。 isSetPadding配置为true，表示在接口内部设置Pad属性描述（即padValue参数，参数介绍参考表4 LoadData3DParamsV1结构体内参数说明、表5 LoadData3DParamsV2结构体内参数说明）；设置为false，表示该接口传入的Pad属性不生效，开发者需要通过SetLoadDataPaddingValue进行设置。可参考样例调用示例。 该参数的默认值如下： 1 constexpr IsResetLoad3dConfig IS_RESER_LOAD3D_DEFAULT_CONFIG = {true, true};",
          "说明": "1 2 3 4"
        },
        {
          "参数名": "1 2 3 4",
          "类型": "",
          "说明": "struct IsResetLoad3dConfig { bool isSetFMatrix = true; bool isSetPadding = true; };"
        },
        {
          "参数名": "1",
          "类型": "",
          "说明": "constexpr IsResetLoad3dConfig IS_RESER_LOAD3D_DEFAULT_CONFIG = {true, true};"
        },
        {
          "参数名": "U",
          "类型": "",
          "说明": "LoadData3DParamsV1/LoadData3DParamsV2中padValue的数据类型。 当dstLocal、srcLocal使用基础数据类型时， U和dstLocal、srcLocal的数据类型T需保持一致，否则编译失败。 当dstLocal 、srcLocal使用TensorTrait类型时，U和dstLocal、srcLocal的数据类型T的LiteType需保持一致，否则编译失败。 最后一个模板参数仅用于上述数据类型检查，用户无需关注。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数，类型为LocalTensor。目的操作数的起始地址对齐约束请参考表6。 数据连续排列顺序由目的操作数所在TPosition决定，具体约束如下： A2：小Z大Z格式； B2：小N大Z格式； A1/B1：无格式要求，一般情况下为小Z大N格式。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数，类型为LocalTensor或GlobalTensor。源操作数的起始地址对齐约束请参考表6。 数据类型需要与dstLocal保持一致。"
        },
        {
          "参数名": "loadDataParams",
          "类型": "输入",
          "说明": "LoadData参数结构体，类型为： LoadData2DParams，具体参考表3。 LoadData3DParamsV1，具体参考表4。 LoadData3DParamsV2，具体参考表5。 上述结构体参数定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_mm.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。"
        },
        {
          "参数名": "startIndex",
          "类型": "",
          "说明": "分形矩阵ID，说明搬运起始位置为源操作数中第几个分形（0为源操作数中第1个分形矩阵）。取值范围：startIndex∈[0, 65535] 。单位：512B。默认为0。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "",
          "说明": "迭代次数，每个迭代可以处理512B数据。取值范围：repeatTimes∈[1, 255]。"
        },
        {
          "参数名": "srcStride",
          "类型": "",
          "说明": "相邻迭代间，源操作数前一个分形与后一个分形起始地址的间隔，单位：512B。取值范围：src_stride∈[0, 65535]。默认为0。"
        },
        {
          "参数名": "sid",
          "类型": "",
          "说明": "预留参数，配置为0即可。"
        },
        {
          "参数名": "dstGap",
          "类型": "",
          "说明": "相邻迭代间，目的操作数前一个分形结束地址与后一个分形起始地址的间隔，单位：512B。取值范围：dstGap∈[0, 65535]。默认为0。 注： Atlas 训练系列产品 此参数不使能。"
        },
        {
          "参数名": "ifTranspose",
          "类型": "",
          "说明": "是否启用转置功能，对每个分形矩阵进行转置，默认为false: true：启用 false：不启用 注意：只有A1->A2和B1->B2通路才能使能转置，使能转置功能时，源操作数、目的操作数仅支持uint16_t/int16_t/half数据类型。"
        },
        {
          "参数名": "addrMode",
          "类型": "",
          "说明": "预留参数，配置为0即可。"
        },
        {
          "参数名": "padList",
          "类型": "",
          "说明": "padding列表 [padding_left, padding_right, padding_top, padding_bottom]，每个元素取值范围：[0,255]。默认为{0, 0, 0, 0}。"
        },
        {
          "参数名": "l1H",
          "类型": "",
          "说明": "源操作数 height，取值范围：l1H∈[1, 32767]。"
        },
        {
          "参数名": "l1W",
          "类型": "",
          "说明": "源操作数 width，取值范围：l1W∈[1, 32767] 。"
        },
        {
          "参数名": "c1Index",
          "类型": "",
          "说明": "该指令在源tensor C1维度的起点，取值范围：c1Index∈[0, 4095] 。默认为0。"
        },
        {
          "参数名": "fetchFilterW",
          "类型": "",
          "说明": "该指令在卷积核上w维度的起始位置，取值范围：fetchFilterW∈[0, 254] 。默认为0。"
        },
        {
          "参数名": "fetchFilterH",
          "类型": "",
          "说明": "该指令在filter上h维度的起始位置，取值范围：fetchFilterH∈[0, 254] 。默认为0。"
        },
        {
          "参数名": "leftTopW",
          "类型": "",
          "说明": "该指令在源操作数上w维度的起点，取值范围：leftTopW∈[-255, 32767] 。默认为0。如果padding_left = a，leftTopW配置为-a。"
        },
        {
          "参数名": "leftTopH",
          "类型": "",
          "说明": "该指令在源操作数上h维度的起点，取值范围：leftTopH∈[-255, 32767] 。默认为0。如果padding_top = a，leftTopH配置为-a。"
        },
        {
          "参数名": "strideW",
          "类型": "",
          "说明": "卷积核在源操作数w维度滑动的步长，取值范围：strideW∈[1, 63] 。"
        },
        {
          "参数名": "strideH",
          "类型": "",
          "说明": "卷积核在源操作数h维度滑动的步长，取值范围：strideH∈[1, 63] 。"
        },
        {
          "参数名": "filterW",
          "类型": "",
          "说明": "卷积核width，取值范围：filterW∈[1, 255] 。"
        },
        {
          "参数名": "filterH",
          "类型": "",
          "说明": "卷积核height，取值范围：filterH∈[1, 255] 。"
        },
        {
          "参数名": "dilationFilterW",
          "类型": "",
          "说明": "卷积核width膨胀系数，取值范围：dilationFilterW∈[1, 255] 。"
        },
        {
          "参数名": "dilationFilterH",
          "类型": "",
          "说明": "卷积核height膨胀系数，取值范围：dilationFilterH∈[1, 255] 。"
        },
        {
          "参数名": "jumpStride",
          "类型": "",
          "说明": "迭代之间，目的操作数首地址步长，取值范围：jumpStride∈[1, 127] 。"
        },
        {
          "参数名": "repeatMode",
          "类型": "",
          "说明": "迭代模式。 模式0：每次迭代，增加卷积核窗口中的点，对应在目的矩阵上往w维度方向增长。 模式1：每次迭代，增加滑动窗口左上坐标，对应在目的矩阵上往h维度方向增长。 取值范围：repeatMode∈[0, 1] 。默认为0。"
        },
        {
          "参数名": "repeatTime",
          "类型": "",
          "说明": "迭代次数，每一次源操作数和目的操作数的地址都会改变。取值范围：repeatTime∈[1，255] 。"
        },
        {
          "参数名": "cSize",
          "类型": "",
          "说明": "配置是否开启cSize = 4(b16) / cSize = 8(b8)优化，取值范围：cSize∈[0, 1] 。默认为0。"
        },
        {
          "参数名": "padValue",
          "类型": "",
          "说明": "Pad填充值的数值，数据类型需要与srcLocal保持一致。默认为0。若不想使能padding，可将padList设为全0。"
        },
        {
          "参数名": "padList",
          "类型": "",
          "说明": "padding 列表 [padding_left, padding_right, padding_top, padding_bottom]，每个元素取值范围：[0,255]。默认为{0, 0, 0, 0}。"
        },
        {
          "参数名": "l1H",
          "类型": "",
          "说明": "源操作数height，取值范围：l1H∈[1, 32767]。"
        },
        {
          "参数名": "l1W",
          "类型": "",
          "说明": "源操作数weight，取值范围：l1W∈[1, 32767] 。"
        },
        {
          "参数名": "channelSize",
          "类型": "",
          "说明": "源操作数的通道数，取值范围：channelSize∈[1, 63] 。 针对以下型号，channelSize的取值要求为：对于half，channelSize可取值为4，8，16，N * 16 + 4，N * 16 + 8；对于int8_t/uint8_t，channelSize可取值为4，8，16，32，N * 32 + 4，N * 32 + 8，N * 32 + 16。N为正整数。 Atlas 推理系列产品 AI Core 针对以下型号，channelSize的取值要求为：对于uint32_t/int32_t/float，channelSize可取值为4，N * 8，N * 8 + 4；对于half/bfloat16，channelSize可取值为4，8，N * 16，N * 16 + 4，N * 16 + 8；对于int8_t/uint8_t，channelSize可取值为4，8，16， 32 * N，N * 32 + 4，N * 32 + 8，N * 32 + 16；对于int4b_t，ChannelSize可取值为8，16，32，N * 64，N * 64 + 8，N * 64 + 16，N * 64 + 32。N为正整数。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 Atlas 200I/500 A2 推理产品"
        },
        {
          "参数名": "kExtension",
          "类型": "",
          "说明": "该指令在目的操作数width维度的传输长度，如果不覆盖最右侧的分形，对于half类型，应为16的倍数，对于int8_t/uint8_t应为32的倍数；覆盖的情况则无倍数要求。取值范围: kExtension∈[1, 65535] 。"
        },
        {
          "参数名": "mExtension",
          "类型": "",
          "说明": "该指令在目的操作数height维度的传输长度，如果不覆盖最下侧的分形，对于half/int8_t/uint8_t，应为16的倍数；覆盖的情况则无倍数要求。取值范围：mExtension∈[1, 65535] 。"
        },
        {
          "参数名": "kStartPt",
          "类型": "",
          "说明": "该指令在目的操作数width维度的起点，对于half类型，应为16的倍数，对于int8_t/uint8_t应为32的倍数。取值范围[0, 65535] 。默认为0。"
        },
        {
          "参数名": "mStartPt",
          "类型": "",
          "说明": "该指令在目的操作数height维度的起点，如果不覆盖最下侧的分形，对于half/int8_t/uint8_t，应为16的倍数；覆盖的情况则无倍数要求。取值范围[0, 65535] 。默认为0。"
        },
        {
          "参数名": "strideW",
          "类型": "",
          "说明": "卷积核在源操作数width维度滑动的步长，取值范围：strideW∈[1, 63] 。"
        },
        {
          "参数名": "strideH",
          "类型": "",
          "说明": "卷积核在源操作数height 维度滑动的步长，取值范围：strideH∈[1, 63] 。"
        },
        {
          "参数名": "filterW",
          "类型": "",
          "说明": "卷积核width，取值范围：filterW∈[1, 255] 。"
        },
        {
          "参数名": "filterH",
          "类型": "",
          "说明": "卷积核height，取值范围：filterH∈[1, 255] 。"
        },
        {
          "参数名": "dilationFilterW",
          "类型": "",
          "说明": "卷积核width膨胀系数，取值范围：dilationFilterW∈[1, 255] 。"
        },
        {
          "参数名": "dilationFilterH",
          "类型": "",
          "说明": "卷积核height膨胀系数，取值范围：dilationFilterH∈[1, 255] 。"
        },
        {
          "参数名": "enTranspose",
          "类型": "",
          "说明": "是否启用转置功能，对整个目标矩阵进行转置，支持数据类型为 bool，仅在目的TPosition为A2，且源操作数为half类型时有效。默认为false。 true：启用 false：不启用"
        },
        {
          "参数名": "enSmallK",
          "类型": "",
          "说明": "是否使能small k特性，每个分形矩阵大小为16*4，支持数据类型为 bool，默认为false。当前产品形态，该特性已不再支持。 true：使能 false：不使能"
        },
        {
          "参数名": "padValue",
          "类型": "",
          "说明": "Pad填充值的数值，数据类型需要与srcLocal保持一致。默认为0。若不想使能padding，可将padList设为全0。"
        },
        {
          "参数名": "filterSizeW",
          "类型": "",
          "说明": "是否在filterW的基础上将卷积核width增加256 个元素。true，增加；false，不增加。"
        },
        {
          "参数名": "filterSizeH",
          "类型": "",
          "说明": "是否在filterH的基础上将卷积核height增加256个元素。true，增加；false，不增加。"
        },
        {
          "参数名": "fMatrixCtrl",
          "类型": "",
          "说明": "表示LoadData3DV2指令从左矩阵还是右矩阵获取FeatureMap的属性描述，与SetFmatrix配合使用，当前只支持设置为false，默认值为false。 true：从右矩阵中获取FeatureMap的属性描述； false：从左矩阵中获取FeatureMap的属性描述。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133",
      "约束限制": "",
      "相关接口": [
        "SetFmatrix",
        "SetLoadDataPaddingValue",
        "TensorTrait",
        "矩阵计算(ISASI)"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Add-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0035.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "TRACE_STOP-算子调测API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1213.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Adds-标量双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0054.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "简介-PlatformAscendC-平台信息获取-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1026.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "BlockReduceSum-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0084.html",
      "功能说明": "对每个datablock内所有元素求和。源操作数相加采用二叉树方式，两两相加。归约指令的总体介绍请参考如何使用归约指令。 以128个half类型的数据求和为例，每个datablock可以计算16个half类型数据，分成8个datablock进行计算；每个datablock内，通过二叉树的方式，两两相加，BlockReduceSum求和示意图如下。 图1 BlockReduceSum求和示意图 需要注意的是两两相加的计算过程中，计算结果大于65504时结果保存为65504。例如，源操作数为[60000,60000,-30000,100]，首先60000+60000溢出，结果为65504，然后计算-30000+100=-29900，最后计算65504-29900=35604，计算示意图如下图所示。 图2 存在溢出场景时的计算示意图 对每个datablock内所有元素求和。源操作数相加采用二叉树方式，两两相加。归约指令的总体介绍请参考如何使用归约指令。 以128个half类型的数据求和为例，每个datablock可以计算16个half类型数据，分成8个datablock进行计算；每个datablock内，通过二叉树的方式，两两相加，BlockReduceSum求和示意图如下。 图1 BlockReduceSum求和示意图 需要注意的是两两相加的计算过程中，计算结果大于65504时结果保存为65504。例如，源操作数为[60000,60000,-30000,100]，首先60000+60000溢出，结果为65504，然后计算-30000+100=-29900，最后计算65504-29900=35604，计算示意图如下图所示。 图2 存在溢出场景时的计算示意图 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证16字节对齐（针对half数据类型），32字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 repeat 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 mask/mask[] 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 每个repeat(8个datablock)归约后，得到8个元素，所以输入类型为half类型时，RepStride单位为16Byte；输入类型为float类型时，RepStride单位为32Byte。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考dataBlockStride。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考repeatStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void BlockReduceSum (const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal,const int32_t repeat, const uint64_t mask[], const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证16字节对齐（针对half数据类型），32字节对齐（针对float数据类型）。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "repeat",
          "类型": "输入",
          "说明": "迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "mask/mask[]",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "dstRepStride",
          "类型": "输入",
          "说明": "目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 每个repeat(8个datablock)归约后，得到8个元素，所以输入类型为half类型时，RepStride单位为16Byte；输入类型为float类型时，RepStride单位为32Byte。 注意，此参数值 Atlas 训练系列产品 不支持配置0。"
        },
        {
          "参数名": "srcBlkStride",
          "类型": "输入",
          "说明": "单次迭代内datablock的地址步长。详细说明请参考dataBlockStride。"
        },
        {
          "参数名": "srcRepStride",
          "类型": "输入",
          "说明": "源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考repeatStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6\n1 2 3 4 5 6",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "通用约束",
        "归约指令"
      ],
      "版本信息": "7.289"
    },
    {
      "API名称": "MulCast-双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0049.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "VectorPadding(ISASI)-单目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0221.html",
      "功能说明": "根据padMode（pad模式）与padSide（pad方向）对源操作数按照datablock进行填充操作。 假设源操作数的一个datablock有16个数，datablock[0:15]=a~p： 根据padMode（pad模式）与padSide（pad方向）对源操作数按照datablock进行填充操作。 假设源操作数的一个datablock有16个数，datablock[0:15]=a~p： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 padMode 输入 padding模式，类型为uint8_t，取值范围：[0,2]。 0：用邻近数作为填充值。 1：用邻近datablock值对称填充。 2：用邻近datablock值填充，偏移一个数，做对称填充。 padSide 输入 padding的方向，类型为bool。 false：左边。 true：右边。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。UnaryRepeatParams类型，包含操作数相邻迭代间相同DataBlock的地址步长，操作数同一迭代内不同DataBlock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void VectorPadding(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint8_t padMode, const bool padSide, const uint64_t mask[], const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 推理系列产品 AI Core，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "padMode",
          "类型": "输入",
          "说明": "padding模式，类型为uint8_t，取值范围：[0,2]。 0：用邻近数作为填充值。 1：用邻近datablock值对称填充。 2：用邻近datablock值填充，偏移一个数，做对称填充。"
        },
        {
          "参数名": "padSide",
          "类型": "输入",
          "说明": "padding的方向，类型为bool。 false：左边。 true：右边。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。UnaryRepeatParams类型，包含操作数相邻迭代间相同DataBlock的地址步长，操作数同一迭代内不同DataBlock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7\n1 2 3 4 5 6 7",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "UnaryRepeatParams",
        "通用约束",
        "单目指令"
      ],
      "版本信息": "6.938"
    },
    {
      "API名称": "使用说明-Hccl-Hccl-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0868.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "随路格式转换-DataCopy-数据搬运-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0105.html",
      "功能说明": "随路格式转换数据搬运，适用于在搬运时进行格式转换。 随路格式转换数据搬运，适用于在搬运时进行格式转换。 表6 模板参数说明参数名 描述 T 源操作数或者目的操作数的数据类型。 U 源操作数的数据类型。 表7 接口参数说明参数名称 输入/输出 含义 dstLocal，dstGlobal 输出 目的操作数，类型为LocalTensor或GlobalTensor。 srcLocal，srcGlobal 输入 源操作数，类型为LocalTensor或GlobalTensor。 intriParams 输入 搬运参数，类型为Nd2NzParams/Nz2NdParamsFull/DataCopyCO12DstParams。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_data_copy.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。",
      "函数原型": "template <typename dst_T, typename fmap_T, typename weight_T, typename dstCO1_T> class KernelCubeDataCopy{ public: __aicore__ inline KernelCubeDataCopy(uint16_t CoutIn, uint8_t dilationHIn, uint8_t dilationWIn, QuantMode_t deqModeIn)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "源操作数或者目的操作数的数据类型。"
        },
        {
          "参数名": "U",
          "类型": "",
          "说明": "源操作数的数据类型。"
        },
        {
          "参数名": "dstLocal，dstGlobal",
          "类型": "输出",
          "说明": "目的操作数，类型为LocalTensor或GlobalTensor。"
        },
        {
          "参数名": "srcLocal，srcGlobal",
          "类型": "输入",
          "说明": "源操作数，类型为LocalTensor或GlobalTensor。"
        },
        {
          "参数名": "intriParams",
          "类型": "输入",
          "说明": "搬运参数，类型为Nd2NzParams/Nz2NdParamsFull/DataCopyCO12DstParams。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_data_copy.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。"
        },
        {
          "参数名": "ndNum",
          "类型": "",
          "说明": "传输nd矩阵的数目，取值范围：ndNum∈[0, 4095]。"
        },
        {
          "参数名": "nValue",
          "类型": "",
          "说明": "nd矩阵的行数，取值范围：nValue∈[0, 16384]。"
        },
        {
          "参数名": "dValue",
          "类型": "",
          "说明": "nd矩阵的列数，取值范围：dValue∈[0, 65535]。"
        },
        {
          "参数名": "srcNdMatrixStride",
          "类型": "",
          "说明": "源操作数相邻nd矩阵起始地址间的偏移，取值范围：srcNdMatrixStride∈[0, 65535]，单位为元素。"
        },
        {
          "参数名": "srcDValue",
          "类型": "",
          "说明": "源操作数同一nd矩阵的相邻行起始地址间的偏移，取值范围：srcDValue∈[1, 65535]，单位为元素。"
        },
        {
          "参数名": "dstNzC0Stride",
          "类型": "",
          "说明": "ND转换到NZ格式后，源操作数中的一行会转换为目的操作数的多行。dstNzC0Stride表示，目的nz矩阵中，来自源操作数同一行的多行数据相邻行起始地址间的偏移，取值范围：dstNzC0Stride∈[1, 16384]，单位：C0_SIZE（32B）。"
        },
        {
          "参数名": "dstNzNStride",
          "类型": "",
          "说明": "目的nz矩阵中，Z型矩阵相邻行起始地址之间的偏移。取值范围：dstNzNStride∈[1, 16384]，单位：C0_SIZE（32B）。"
        },
        {
          "参数名": "dstNzMatrixStride",
          "类型": "",
          "说明": "目的nz矩阵中，相邻nz矩阵起始地址间的偏移，取值范围：dstNzMatrixStride∈[1, 65535]，单位为元素。"
        },
        {
          "参数名": "ndNum",
          "类型": "",
          "说明": "传输nz矩阵的数目，取值范围：ndNum∈[0, 4095]。"
        },
        {
          "参数名": "nValue",
          "类型": "",
          "说明": "nz矩阵的行数，取值范围：nValue∈[1, 8192]。"
        },
        {
          "参数名": "dValue",
          "类型": "",
          "说明": "nz矩阵的列数，取值范围：dValue∈[1, 8192]。dValue必须为16的倍数。"
        },
        {
          "参数名": "srcNdMatrixStride",
          "类型": "",
          "说明": "源相邻nz矩阵的偏移（头与头），取值范围：srcNdMatrixStride∈[1, 512]，单位256 (16 * 16) 个元素。"
        },
        {
          "参数名": "srcNStride",
          "类型": "",
          "说明": "源同一nz矩阵的相邻z排布的偏移（头与头），取值范围：srcNStride∈[0, 4096]，单位16个元素。"
        },
        {
          "参数名": "dstDStride",
          "类型": "",
          "说明": "目的nd矩阵的相邻行的偏移（头与头），取值范围：dstDStride∈[1, 65535]，单位：element。"
        },
        {
          "参数名": "dstNdMatrixStride",
          "类型": "",
          "说明": "目的nd矩阵中，来自源相邻nz矩阵的偏移（头与头），取值范围：dstNdMatrixStride∈[1, 65535]，单位：element。"
        },
        {
          "参数名": "nSize",
          "类型": "",
          "说明": "srcLocal横向方向的size大小。 不使能NZ2ND功能，必须为C0的倍数，此时连续传输数据块的个数为nSize/C0。使能NZ2ND功能，不受限制。"
        },
        {
          "参数名": "mSize",
          "类型": "",
          "说明": "srcLocal纵向方向的size大小。 不使能NZ2ND功能，连续传输数据块的大小为mSize * C0个元素的长度。 使能NZ2ND功能，NZ/ND矩阵的大小为mSize*nSize。"
        },
        {
          "参数名": "dstStride",
          "类型": "",
          "说明": "不使能NZ2ND功能dstLocal相邻连续数据片段间隔（前面一个数据块的头与后面数据块的头的间隔），取值不为0。 针对Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，单位为datablock(32Bytes)。 针对Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，单位为datablock(32Bytes)。 使能NZ2ND功能dstLocal同一ND矩阵的相邻行的偏移(头与头)，取值不为0， 单位为元素。"
        },
        {
          "参数名": "srcStride",
          "类型": "",
          "说明": "不使能NZ2ND功能srcLocal相邻连续数据片段间隔（前面一个数据块的头与后面数据块的头的间隔），必须为16的倍数。取值范围：srcStride∈[0, 65535]， 单位：C0_Size(C0*sizeof(U)，U为srcLocal的数据类型)。 使能NZ2ND功能srcLocal同一NZ矩阵的相邻Z排布的偏移（头与头），必须为16的倍数，取值范围：srcStride∈[0, 65535]，单位C0_size。"
        },
        {
          "参数名": "quantPre",
          "类型": "用于控制量化模式，QuantMode_t类型，具体定义如下。默认值为QuantMode_t::NoQuant，即不使能量化功能。 配置为scalar量化时，需要调用SetFixpipePreQuantFlag接口来设置scalar量化参数；配置为tensor量化时，需要调用SetFixPipeConfig来设置tensor量化参数。 1 2 3 4 5 6 7 8 9 10 11 12enum QuantMode_t { NoQuant, // 不使能量化功能 F322F16, // float量化成half, scalar量化 F322BF16, // float量化成bfloat16_t, scalar量化 DEQF16, // int32_t量化成half, scalar量化 VDEQF16, // int32_t量化成half，tensor量化 QF322B8_PRE, // float量化成int8_t/uint8_t，scalar量化 VQF322B8_PRE, // float量化成int8_t/uint8_t，tensor量化 REQ8, // int32_t量化成int8_t/uint8_t，scalar量化 VREQ8, // int32_t量化成int8_t/uint8_t，tensor量化 };",
          "说明": "1 2 3 4 5 6 7 8 9 10 11 12"
        },
        {
          "参数名": "1 2 3 4 5 6 7 8 9 10 11 12",
          "类型": "",
          "说明": "enum QuantMode_t { NoQuant, // 不使能量化功能 F322F16, // float量化成half, scalar量化 F322BF16, // float量化成bfloat16_t, scalar量化 DEQF16, // int32_t量化成half, scalar量化 VDEQF16, // int32_t量化成half，tensor量化 QF322B8_PRE, // float量化成int8_t/uint8_t，scalar量化 VQF322B8_PRE, // float量化成int8_t/uint8_t，tensor量化 REQ8, // int32_t量化成int8_t/uint8_t，scalar量化 VREQ8, // int32_t量化成int8_t/uint8_t，tensor量化 };"
        },
        {
          "参数名": "reluPre",
          "类型": "",
          "说明": "用于配置relu操作的模式，类型为uint8_t，取值如下： 0：不使能relu1：Normal relu"
        },
        {
          "参数名": "channelSplit",
          "类型": "",
          "说明": "类型为bool，配置是否使能channel切分，对于float类型的dstLocal生效。 false：不使能true：使能"
        },
        {
          "参数名": "nz2ndEn",
          "类型": "",
          "说明": "类型为bool，配置是否使能NZ2ND的格式转换，仅在L0C->GM通路生效。 如果要使能NZ2ND的功能需要同步调用SetFixpipeNz2ndFlag来设置格式转换的相关配置信息。 false：不使能true：使能"
        },
        {
          "参数名": "clipReluPre",
          "类型": "",
          "说明": "用于配置是否使能ClipRelu操作，参数类型为uint8_t，取值如下：0，不使能ClipRelu；1，使能ClipRelu，此时需要调用SetFixPipeClipRelu来设置clipRelu的最大值。 该操作在随路量化后进行，quantPre配置后才能使用，当前支持的量化模式有F322F16/DEQF16/VDEQF16/QF322B8_PRE/VQF322B8_PRE/REQ8/VREQ8。该参数仅在Atlas 200I/500 A2 推理产品支持。"
        },
        {
          "参数名": "eltWiseOp",
          "类型": "",
          "说明": "用于配置是否使能element-wise操作及操作模式。element-wise操作是指进行随路量化后，可以逐个元素加/减一个LocalTensor，大小为mSize * nSize，具体LocalTensor地址相关参数需要调用SetFixPipeAddr来设置。 eltWiseOp参数类型为uint8_t，取值如下： 0：不使能element-wise1：element-wise Addition2：element-wise Subtraction 该参数仅在Atlas 200I/500 A2 推理产品支持。"
        },
        {
          "参数名": "sid",
          "类型": "",
          "说明": "预留参数，为后续的功能做保留，开发者暂时无需关注。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55",
      "约束限制": "",
      "相关接口": [
        "SetFixpipePreQuantFlag",
        "SetFixPipeConfig",
        "SetFixpipeNz2ndFlag",
        "SetFixPipeClipRelu",
        "SetFixPipeAddr",
        "DataCopy"
      ],
      "版本信息": "0.5"
    },
    {
      "API名称": "Sinh-Sinh-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0524.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ReduceMax-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0076.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "LoadDataWithTranspose-矩阵计算(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0239.html",
      "功能说明": "该接口实现带转置的2D格式数据从A1/B1到A2/B2的加载。 下面通过示例来讲解接口功能和关键参数：下文图中一个N形或者一个Z形代表一个分形。 该接口实现带转置的2D格式数据从A1/B1到A2/B2的加载。 下面通过示例来讲解接口功能和关键参数：下文图中一个N形或者一个Z形代表一个分形。 表1 模板参数说明参数名 描述 T Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t/float/int32_t/uint32_t/uint8_t/int8_t/int4b_t。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t/float/int32_t/uint32_t/uint8_t/int8_t/int4b_t。 Atlas 200I/500 A2 推理产品，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float/int4b_t。 其中int4b_t数据类型仅在LocalTensor的TPosition为B2时支持。 表2 参数说明参数名称 输入/输出 含义 dstLocal 输出 目的操作数，结果矩阵，类型为LocalTensor。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的TPosition为A2/B2。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的TPosition为A2/B2。 Atlas 200I/500 A2 推理产品，支持的TPosition为A2/B2。 LocalTensor的起始地址需要保证512字节对齐。 数据类型和srcLocal的数据类型保持一致。 srcLocal 输入 源操作数，类型为LocalTensor。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的TPosition为A1/B1。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的TPosition为A1/B1。 Atlas 200I/500 A2 推理产品，支持的TPosition为A1/B1。 LocalTensor的起始地址需要保证32字节对齐。 数据类型和dstLocal的数据类型保持一致。 loadDataParams 输入 LoadDataWithTranspose相关参数，类型为LoadData2dTransposeParams。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_mm.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 参数说明请参考表3。 表3 LoadData2dTransposeParams结构体内参数说明参数名称 输入/输出 含义 startIndex 输入 方块矩阵ID，搬运起始位置为源操作数中第几个方块矩阵（0 为源操作数中第1个方块矩阵）。取值范围：startIndex∈[0, 65535] 。默认为0。 例如，源操作数中有20个大小为16*8*4B的分形（数据类型为float），startIndex=1表示搬运起始位置为第2个方块矩阵，即将第3和第4个分形从源操作数中转置到目的操作数中（第1、2个分形组成第1个方块矩阵，第3、4个分形组成第2个方块矩阵）。 repeatTimes 输入 迭代次数。 对于uint8_t/int8_t数据类型，每次迭代处理32*32*1B数据； 对于half/bfloat16_t数据类型，每次迭代处理16*16*2B数据； 对于float/int32_t/uint32_t数据类型，每次迭代处理16*16*4B数据。 对于int4b_t数据类型，每次迭代处理16*64*0.5B数据。 取值范围：repeatTimes∈[0, 255]。默认为0。 srcStride 输入 相邻迭代间，源操作数前一个分形与后一个分形起始地址的间隔。这里的单位实际上是拼接后的方块矩阵的大小。 对于uint8_t/int8_t数据类型，单位是32*32*1B； 对于half/bfloat16_t数据类型，单位是16*16*2B； 对于float/int32_t/uint32_t数据类型，单位是16*16*4B。 对于int4b_t数据类型，每次迭代处理16*64*0.5B数据。 取值范围：srcStride∈[0, 65535]。默认为0。 dstGap 输入 相邻迭代间，目的操作数前一个迭代第一个分形的结束地址到下一个迭代第一个分形起始地址的间隔，单位：512B。取值范围：dstGap∈[0, 65535]。默认为0。 dstFracGap 输入 每个迭代内目的操作数转置前一个分形结束地址与后一个分形起始地址的间隔，单位为512B，仅在数据类型为float/int32_t/uint32_t/uint8_t/int8_t/int4b_t时有效。取值范围：dstFracGap∈[0, 65535]。默认为0。 addrMode 输入 预留参数。为后续的功能做保留，开发者暂时无需关注，使用默认值即可。",
      "函数原型": "template <typename T> __aicore__ inline void LoadDataWithTranspose(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LoadData2dTransposeParams& loadDataParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/bfloat16_t/float/int32_t/uint32_t/uint8_t/int8_t/int4b_t。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/bfloat16_t/float/int32_t/uint32_t/uint8_t/int8_t/int4b_t。 Atlas 200I/500 A2 推理产品，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float/int4b_t。 其中int4b_t数据类型仅在LocalTensor的TPosition为B2时支持。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数，结果矩阵，类型为LocalTensor。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的TPosition为A2/B2。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的TPosition为A2/B2。 Atlas 200I/500 A2 推理产品，支持的TPosition为A2/B2。 LocalTensor的起始地址需要保证512字节对齐。 数据类型和srcLocal的数据类型保持一致。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数，类型为LocalTensor。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的TPosition为A1/B1。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的TPosition为A1/B1。 Atlas 200I/500 A2 推理产品，支持的TPosition为A1/B1。 LocalTensor的起始地址需要保证32字节对齐。 数据类型和dstLocal的数据类型保持一致。"
        },
        {
          "参数名": "loadDataParams",
          "类型": "输入",
          "说明": "LoadDataWithTranspose相关参数，类型为LoadData2dTransposeParams。 具体定义请参考${INSTALL_DIR}/include/ascendc/basic_api/interface/kernel_struct_mm.h，${INSTALL_DIR}请替换为CANN软件安装后文件存储路径。 参数说明请参考表3。"
        },
        {
          "参数名": "startIndex",
          "类型": "输入",
          "说明": "方块矩阵ID，搬运起始位置为源操作数中第几个方块矩阵（0 为源操作数中第1个方块矩阵）。取值范围：startIndex∈[0, 65535] 。默认为0。 例如，源操作数中有20个大小为16*8*4B的分形（数据类型为float），startIndex=1表示搬运起始位置为第2个方块矩阵，即将第3和第4个分形从源操作数中转置到目的操作数中（第1、2个分形组成第1个方块矩阵，第3、4个分形组成第2个方块矩阵）。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "迭代次数。 对于uint8_t/int8_t数据类型，每次迭代处理32*32*1B数据； 对于half/bfloat16_t数据类型，每次迭代处理16*16*2B数据； 对于float/int32_t/uint32_t数据类型，每次迭代处理16*16*4B数据。 对于int4b_t数据类型，每次迭代处理16*64*0.5B数据。 取值范围：repeatTimes∈[0, 255]。默认为0。"
        },
        {
          "参数名": "srcStride",
          "类型": "输入",
          "说明": "相邻迭代间，源操作数前一个分形与后一个分形起始地址的间隔。这里的单位实际上是拼接后的方块矩阵的大小。 对于uint8_t/int8_t数据类型，单位是32*32*1B； 对于half/bfloat16_t数据类型，单位是16*16*2B； 对于float/int32_t/uint32_t数据类型，单位是16*16*4B。 对于int4b_t数据类型，每次迭代处理16*64*0.5B数据。 取值范围：srcStride∈[0, 65535]。默认为0。"
        },
        {
          "参数名": "dstGap",
          "类型": "输入",
          "说明": "相邻迭代间，目的操作数前一个迭代第一个分形的结束地址到下一个迭代第一个分形起始地址的间隔，单位：512B。取值范围：dstGap∈[0, 65535]。默认为0。"
        },
        {
          "参数名": "dstFracGap",
          "类型": "输入",
          "说明": "每个迭代内目的操作数转置前一个分形结束地址与后一个分形起始地址的间隔，单位为512B，仅在数据类型为float/int32_t/uint32_t/uint8_t/int8_t/int4b_t时有效。取值范围：dstFracGap∈[0, 65535]。默认为0。"
        },
        {
          "参数名": "addrMode",
          "类型": "输入",
          "说明": "预留参数。为后续的功能做保留，开发者暂时无需关注，使用默认值即可。"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152",
      "约束限制": "",
      "相关接口": [
        "通用约束",
        "矩阵计算(ISASI)"
      ],
      "版本信息": "0.5"
    },
    {
      "API名称": "ReduceSum-归约指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0078.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ReduceMin-ReduceMin-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10056.html",
      "功能说明": "对一个多维向量在指定的维度求最小值。 定义指定计算的维度（Reduce轴）为R轴，非指定维度（Normal轴）为A轴。如下图所示，对shape为(2, 3)的二维矩阵进行运算，指定在第一维求最小值，输出结果为[[1, 2, 3]]；指定在第二维求最小值，输出结果为[[1] [4]]。 图1 ReduceMin按第一个维度计算示例 图2 ReduceMin按最后一个维度计算示例 对一个多维向量在指定的维度求最小值。 定义指定计算的维度（Reduce轴）为R轴，非指定维度（Normal轴）为A轴。如下图所示，对shape为(2, 3)的二维矩阵进行运算，指定在第一维求最小值，输出结果为[[1, 2, 3]]；指定在第二维求最小值，输出结果为[[1] [4]]。 图1 ReduceMin按第一个维度计算示例 图2 ReduceMin按最后一个维度计算示例 表1 模板参数说明参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float pattern 用于指定ReduceMin计算轴，包括Reduce轴和Normal轴。pattern由与向量维度数量相同的A、R字母组合形成，字母A表示Normal轴，R表示Reduce轴。例如，AR表示对二维向量进行ReduceMin计算：第一维是Normal轴，第二维是Reduce轴，即对第二维数据求最小值。 pattern是定义在AscendC::Pattern::Reduce命名空间下的结构体，其成员变量用户无需关注。 pattern当前只支持取值为AR和RA。 isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为true，则本接口内部计算时复用src的内存空间，节省内存空间；设置为false，则本接口内部计算时不复用src的内存空间。 isReuseSource的使用样例请参考更多样例。 表2 接口参数说明参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于ReduceMin内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetReduceMinMaxMinTmpSize。 srcShape 输入 uint32_t类型的数组，表示源操作数的shape信息。该shape的维度必须和模板参数pattern的维度一致，例如，pattern为AR，该shape维度只能是二维。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，当前只支持二维shape Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，当前只支持二维shape srcInnerPad 输入 表示实际需要计算的最内层轴数据是否32Bytes对齐。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，当前只支持true Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，当前只支持true",
      "函数原型": "template <class T, class pattern, bool isReuseSource = false> __aicore__ inline void ReduceMin(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t srcShape[], bool srcInnerPad)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，支持的数据类型为：half/float"
        },
        {
          "参数名": "pattern",
          "类型": "",
          "说明": "用于指定ReduceMin计算轴，包括Reduce轴和Normal轴。pattern由与向量维度数量相同的A、R字母组合形成，字母A表示Normal轴，R表示Reduce轴。例如，AR表示对二维向量进行ReduceMin计算：第一维是Normal轴，第二维是Reduce轴，即对第二维数据求最小值。 pattern是定义在AscendC::Pattern::Reduce命名空间下的结构体，其成员变量用户无需关注。 pattern当前只支持取值为AR和RA。"
        },
        {
          "参数名": "isReuseSource",
          "类型": "",
          "说明": "是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为true，则本接口内部计算时复用src的内存空间，节省内存空间；设置为false，则本接口内部计算时不复用src的内存空间。 isReuseSource的使用样例请参考更多样例。"
        },
        {
          "参数名": "dstTensor",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。"
        },
        {
          "参数名": "srcTensor",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "sharedTmpBuffer",
          "类型": "输入",
          "说明": "临时缓存。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 用于ReduceMin内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考GetReduceMinMaxMinTmpSize。"
        },
        {
          "参数名": "srcShape",
          "类型": "输入",
          "说明": "uint32_t类型的数组，表示源操作数的shape信息。该shape的维度必须和模板参数pattern的维度一致，例如，pattern为AR，该shape维度只能是二维。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，当前只支持二维shape Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，当前只支持二维shape"
        },
        {
          "参数名": "srcInnerPad",
          "类型": "输入",
          "说明": "表示实际需要计算的最内层轴数据是否32Bytes对齐。 Atlas A3 训练系列产品/Atlas A3 推理系列产品，当前只支持true Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件，当前只支持true"
        }
      ],
      "返回值": "无",
      "调用示例": "1 2 3 4 5 6\n1 2 3 4 5 6",
      "约束限制": "",
      "相关接口": [
        "GetReduceMinMaxMinTmpSize",
        "LocalTensor",
        "通用约束",
        "ReduceMin"
      ],
      "版本信息": "0.0"
    },
    {
      "API名称": "LeakyRelu-标量双目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0060.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "is_convertible-type_traits-模板库函数-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10114.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "OpAttrDef-OpAttrDef-原型注册与管理-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0976.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Acosh-Acosh-数学库-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0564.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetAtomicType-原子操作-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0211.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "Exp-单目指令-矢量计算-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0025.html",
      "功能说明": "按元素取自然指数，计算公式如下： 按元素取自然指数，计算公式如下： 表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float。 Atlas 推理系列产品 AI Core，支持的数据类型为：half/float。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float。 Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float。 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。Vector计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。 repeatParams 输入 控制操作数地址步长的参数。UnaryRepeatParams类型，包含操作数相邻迭代间相同DataBlock的地址步长，操作数同一迭代内不同DataBlock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。",
      "函数原型": "template <typename T, bool isSetMask = true> __aicore__ inline void Exp(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint64_t mask[], const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)",
      "参数说明": [
        {
          "参数名": "T",
          "类型": "",
          "说明": "操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float。 Atlas 推理系列产品 AI Core，支持的数据类型为：half/float。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float。 Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float。"
        },
        {
          "参数名": "isSetMask",
          "类型": "",
          "说明": "是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用SetVectorMask接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。"
        },
        {
          "参数名": "dstLocal",
          "类型": "输出",
          "说明": "目的操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。"
        },
        {
          "参数名": "srcLocal",
          "类型": "输入",
          "说明": "源操作数。 类型为LocalTensor，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。"
        },
        {
          "参数名": "calCount",
          "类型": "输入",
          "说明": "参与计算的元素个数。"
        },
        {
          "参数名": "mask[]/mask",
          "类型": "输入",
          "说明": "mask用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 264-1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 264-1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 232-1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。"
        },
        {
          "参数名": "repeatTimes",
          "类型": "输入",
          "说明": "重复迭代次数。Vector计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考如何使用Tensor高维切分计算API。"
        },
        {
          "参数名": "repeatParams",
          "类型": "输入",
          "说明": "控制操作数地址步长的参数。UnaryRepeatParams类型，包含操作数相邻迭代间相同DataBlock的地址步长，操作数同一迭代内不同DataBlock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考repeatStride；同一迭代内DataBlock的地址步长参数说明请参考dataBlockStride。"
        }
      ],
      "返回值": "无",
      "调用示例": "template <typename T> __aicore__ inline void Exp(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Exp(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint64_t mask[], const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)\ntemplate <typename T, bool isSetMask = true> __aicore__ inline void Exp(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint64_t mask, const uint8_t repeatTimes, const UnaryRepeatParams& repeatParams)\nuint64_t mask = 256 / sizeof(half); // repeatTimes = 4, 128 elements one repeat, 512 elements total // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat // dstRepStride, srcRepStride = 8, no gap between repeats AscendC::Exp(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });\nuint64_t mask[2] = { UINT64_MAX, UINT64_MAX }; // repeatTimes = 4, 128 elements one repeat, 512 elements total // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat // dstRepStride, srcRepStride = 8, no gap between repeats AscendC::Exp(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });\nAscendC::Exp(dstLocal, srcLocal, 512);\n输入数据(srcLocal): [0.0 1.0 2.0 3.0 ...] 输出数据(dstLocal): [1.0 2.719 7.391 20.08 ...]",
      "约束限制": "",
      "相关接口": [
        "SetVectorMask",
        "LocalTensor",
        "UnaryRepeatParams",
        "通用约束",
        "单目指令"
      ],
      "版本信息": "0.0"
    },
    {
      "API名称": "ReduceMean-ReduceMean-归约操作-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10157.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "使用说明-Conv3D-Conv3D-卷积正向-高阶API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10005.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "SetTiling-OpAICoreDef-原型注册与管理-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0978.html",
      "功能说明": "注册Tiling函数。Tiling函数的原型是固定的，接受一个TilingContext作为输入，在此context上可以获取到输入、输出的Shape指针等内容。注册的Tiling函数由框架调用，调用时会传入TilingContext参数。 注册Tiling函数。Tiling函数的原型是固定的，接受一个TilingContext作为输入，在此context上可以获取到输入、输出的Shape指针等内容。注册的Tiling函数由框架调用，调用时会传入TilingContext参数。 参数 输入/输出 说明 func 输入 Tiling函数。TilingKernelFunc类型定义如下： 1 using TilingKernelFunc = UINT32 (*)(TilingContext *); OpAICoreDef算子定义，OpAICoreDef请参考OpAICoreDef。",
      "函数原型": "",
      "参数说明": [
        {
          "参数名": "func",
          "类型": "输入",
          "说明": "Tiling函数。TilingKernelFunc类型定义如下： 1 using TilingKernelFunc = UINT32 (*)(TilingContext *);"
        },
        {
          "参数名": "1",
          "类型": "",
          "说明": "using TilingKernelFunc = UINT32 (*)(TilingContext *);"
        }
      ],
      "返回值": "OpAICoreDef算子定义，OpAICoreDef请参考OpAICoreDef。",
      "调用示例": "OpAICoreDef &SetTiling(gert::OpImplRegisterV2::TilingKernelFunc func)\nusing TilingKernelFunc = UINT32 (*)(TilingContext *);",
      "约束限制": "",
      "相关接口": [
        "OpAICoreDef"
      ],
      "版本信息": ""
    },
    {
      "API名称": "Input-OpAICoreConfig-原型注册与管理-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0988.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "构造函数与析构函数-KfcWorkspace-资源管理(ISASI)-基础API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0307.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ParamType-OpParamDef-原型注册与管理-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0957.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    },
    {
      "API名称": "ADD_TO_LAUNCHER_LIST_AICORE-常用宏和类-框架能力接口-单算子API执行相关接口-Host API-Ascend C算子开发接口-CANN商用版8.2.RC1开发文档-昇腾社区",
      "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1043.html",
      "功能说明": "",
      "函数原型": "",
      "参数说明": [],
      "返回值": "无",
      "调用示例": "",
      "约束限制": "",
      "相关接口": [],
      "版本信息": ""
    }
  ],
  "错误信息": {
    "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0249.html": "解析失败: 'NoneType' object has no attribute 'find_next'",
    "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0841.html": "解析失败: 'NoneType' object has no attribute 'find_next'"
  }
}