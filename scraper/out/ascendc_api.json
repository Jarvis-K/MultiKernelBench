[
  {
    "API名称": "ScalarGetCountOfValue",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0016.html",
    "功能说明": "获取一个uint64_t类型数字的二进制中0或者1的个数。",
    "函数原型": "template <int countValue> \n__aicore__ inline int64_t ScalarGetCountOfValue(uint64_t valueIn)",
    "参数说明": "表1 模板参数说明 参数名 描述 countValue 指定统计0还是统计1的个数。 只能输入0或1。\n\n表2 参数说明 参数名 输入/输出 描述 valueIn 输入 被统计的二进制数字。",
    "返回值": "valueIn中0或者1的个数。",
    "调用示例": "uint64_t valueIn = 0xffff;\n// 输出数据(oneCount): 16\nint64_t oneCount = AscendC::ScalarGetCountOfValue<1>(valueIn);",
    "错误": null
  },
  {
    "API名称": "ScalarCountLeadingZero",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0017.html",
    "功能说明": "计算一个uint64_t类型数字前导0的个数（二进制从最高位到第一个1一共有多少个0）。",
    "函数原型": "__aicore__ inline int64_t ScalarCountLeadingZero(uint64_t valueIn)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 valueIn 输入 被统计的二进制数字。",
    "返回值": "返回valueIn的前导0的个数。",
    "调用示例": "uint64_t valueIn = 0x0fffffffffffffff;\n// 输出数据(ans): 4\nint64_t ans = AscendC::ScalarCountLeadingZero(valueIn);",
    "错误": null
  },
  {
    "API名称": "ScalarCast",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0018.html",
    "功能说明": "将一个scalar的类型转换为指定的类型。",
    "函数原型": "template <typename srcT, typename dstT, RoundMode roundMode>\n__aicore__ inline dstT ScalarCast(srcT valueIn)",
    "参数说明": "表1 模板参数说明 参数名 描述 srcT valueIn的数据类型，支持float。 dstT 转换后的数据类型，支持half、int32_t。 roundMode 精度转换处理模式，类型是RoundMode。 RoundMode为枚举类型，用以控制精度转换处理模式，具体定义为： enum class RoundMode { CAST_NONE = 0 , // 在转换有精度损失时表示CAST_RINT模式，不涉及精度损失时表示不取整 CAST_RINT , // rint，四舍六入五成双取整 CAST_FLOOR , // floor，向负无穷取整 CAST_CEIL , // ceil，向正无穷取整 CAST_ROUND , // round，四舍五入取整 CAST_TRUNC , // trunc，向零取整 CAST_ODD , // Von Neumann rounding，最近邻奇数舍入 };\n\n表2 参数说明 参数名 输入/输出 描述 valueIn 输入 被转换数据类型的Scalar。",
    "返回值": "dstT类型的valueIn。",
    "调用示例": "float valueIn = 2.5;\n// 输出数据(valueOut): 3\nint32_t valueOut = AscendC::ScalarCast<float, int32_t, AscendC::RoundMode::CAST_ROUND>(valueIn);",
    "错误": null
  },
  {
    "API名称": "CountBitsCntSameAsSignBit",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0019.html",
    "功能说明": "计算一个int64_t类型数字的二进制中，从最高数值位开始与符号位相同的连续比特位的个数。 当输入是-1（比特位全1）或者0（比特位全0）时，返回-1。",
    "函数原型": "__aicore__ inline int64_t CountBitsCntSameAsSignBit(int64_t valueIn)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 valueIn 输入 输入数据，数据类型int64_t。",
    "返回值": "返回从最高数值位开始和符号位相同的连续比特位的个数。",
    "调用示例": "int64_t valueIn = 0x0f00000000000000;\n// 输出数据(ans): 3\nint64_t ans = AscendC::CountBitsCntSameAsSignBit(valueIn);",
    "错误": null
  },
  {
    "API名称": "ScalarGetSFFValue",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0020.html",
    "功能说明": "获取一个uint64_t类型数字的二进制表示中从最低有效位开始的第一个0或1出现的位置，如果没找到则返回-1。",
    "函数原型": "template <int countValue> \n__aicore__ inline int64_t ScalarGetSFFValue(uint64_t valueIn)",
    "参数说明": "表1 模板参数说明 参数名 描述 countValue 指定要查找的值，0表示查找第一个0的位置，1表示查找第一个1的位置，数据类型是int，只能输入0或1。\n\n表2 参数说明 参数名 输入/输出 描述 valueIn 输入 输入数据，数据类型是uint64_t。",
    "返回值": "int64_t类型的数，valueIn中第一个0或1出现的位置。",
    "调用示例": "uint64_t valueIn = 28;\n// 输出数据(oneCount): 2\nint64_t oneCount = AscendC::ScalarGetSFFValue<1>(valueIn);",
    "错误": null
  },
  {
    "API名称": "ToBfloat16",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0021.html",
    "功能说明": "float类型标量数据转换成bfloat16_t类型标量数据。",
    "函数原型": "__aicore__ inline bfloat16_t ToBfloat16(const float& fVal)",
    "参数说明": "表1 接口参数说明 参数名称 输入/输出 含义 fVal 输入 float类型标量数据。",
    "返回值": "转换后的bfloat16_t类型标量数据。",
    "调用示例": "float m = 3.0f;\nbfloat16_t n = AscendC::ToBfloat16(m);",
    "错误": null
  },
  {
    "API名称": "ToFloat",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0022.html",
    "功能说明": "将输入数据转换为float类型。",
    "函数原型": "__aicore__ inline float ToFloat(const bfloat16_t& bVal)",
    "参数说明": "表1 接口参数说明 参数名称 输入/输出 含义 bVal 输入 待转换的标量数据。",
    "返回值": "转换后的float类型标量数据。",
    "调用示例": "void CalcFunc(bfloat16_t n)\n{\n\tint dataLen = 32;\n\tAscendC::TPipe pipe;\n\tAscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrcVecIn;\n\tAscendC::TQue<AscendC::TPosition::VECOUT, 1> inQueueDstVecIn;\n\tpipe.InitBuffer(inQueueDstVecIn, 1, dataLen * sizeof(bfloat16_t));\n\tpipe.InitBuffer(inQueueSrcVecIn, 1, dataLen * sizeof(float));\n\tAscendC::LocalTensor<bfloat16_t> dstLocal = inQueueDstVecIn.AllocTensor<bfloat16_t>();\n\tAscendC::LocalTensor<float> srcLocal = inQueueSrcVecIn.AllocTensor<float>();\n\tfloat t = AscendC::ToFloat(n);// 对标量进行加法，不支持bfloat16_t，需要先转换成float\n\tPipeBarrier<PIPE_ALL>();\n\tAscendC::Duplicate(srcLocal, float(4.0f), dataLen);\n\tPipeBarrier<PIPE_ALL>();\n\tAdds(srcLocal, srcLocal, t, dataLen);\n\tPipeBarrier<PIPE_ALL>();\n\t// 做加法运算后，输出bfloat16_t类型tensor\n\tCast(dstLocal, srcLocal, AscendC::RoundMode::CAST_ROUND, dataLen);\n\t// ……\n}",
    "错误": null
  },
  {
    "API名称": "Exp",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0025.html",
    "功能说明": "按元素取自然指数，计算公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void Exp(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float。 Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float。 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。Vector计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half);     \n// repeatTimes = 4, 128 elements one repeat, 512 elements total     \n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat     \n// dstRepStride, srcRepStride = 8, no gap between repeats     \nAscendC::Exp(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Ln",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0026.html",
    "功能说明": "按元素取自然对数，计算公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void Ln(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half);\n// repeatTimes = 4, 128 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::Ln(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Abs",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0027.html",
    "功能说明": "按元素取绝对值，计算公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void Abs(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int16_t/half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half);\n// repeatTimes = 4, 128 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::Abs(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Reciprocal",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0028.html",
    "功能说明": "按元素取倒数，计算公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void Reciprocal(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。Vector计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half);\n// repeatTimes = 4, 128 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::Reciprocal(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Sqrt",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0029.html",
    "功能说明": "按元素做开方，计算公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void Sqrt(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half);\n// repeatTimes = 4, 128 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::Sqrt(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Rsqrt",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0030.html",
    "功能说明": "按元素进行开方后取倒数的计算，公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void Rsqrt(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half);\n// repeatTimes = 4, 128 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::Rsqrt(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Not",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0031.html",
    "功能说明": "按元素做按位取反，计算公式如下 :",
    "函数原型": "template <typename T>\n__aicore__ inline void Not(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int16_t/uint16_t isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(int16_t);\n// repeatTimes = 4, 128 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::Not(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Relu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0032.html",
    "功能说明": "按元素做线性整流Relu，计算公式如下 ：",
    "函数原型": "template <typename T>\n__aicore__ inline void Relu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half);\n// repeatTimes = 4, 128 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::Relu(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Add",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0035.html",
    "功能说明": "按元素求和，计算公式如下：",
    "函数原型": "dstLocal = src0Local + src1Local;",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为： half/int32_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为： half/int16_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： half/int16_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： half/int16_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为： half/int16_t/int32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::Add(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Sub",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0036.html",
    "功能说明": "按元素求差，计算公式如下：",
    "函数原型": "dstLocal = src0Local - src1Local;",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为： half/int32_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为： half/int16_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： half/int16_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： half/int16_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为： half/int16_t/int32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::Sub(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Mul",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0037.html",
    "功能说明": "按元素求积，公式表达如下：",
    "函数原型": "dstLocal = src0Local * src1Local;",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为： half/int32_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为： half/int16_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： half/int16_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： half/int16_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为： half/int16_t/int32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::Mul(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Div",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0038.html",
    "功能说明": "按元素求商，公式表达如下：",
    "函数原型": "dstLocal = src0Local / src1Local;",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n \nclass KernelDiv {\npublic:\n    __aicore__ inline KernelDiv() {}\n    __aicore__ inline void Init(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n    {\n        src0Global.SetGlobalBuffer((__gm__ half*)src0Gm);\n        src1Global.SetGlobalBuffer((__gm__ half*)src1Gm);\n        dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm);\n        pipe.InitBuffer(inQueueSrc0, 1, 512 * sizeof(half));\n        pipe.InitBuffer(inQueueSrc1, 1, 512 * sizeof(half));\n        pipe.InitBuffer(outQueueDst, 1, 512 * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.AllocTensor<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.AllocTensor<half>();\n        AscendC::DataCopy(src0Local, src0Global, 512);\n        AscendC::DataCopy(src1Local, src1Global, 512);\n        inQueueSrc0.EnQue(src0Local);\n        inQueueSrc1.EnQue(src1Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.DeQue<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n        \n        uint64_t mask = 128;\n        AscendC::Div(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });\n\n \n        outQueueDst.EnQue<half>(dstLocal);\n        inQueueSrc0.FreeTensor(src0Local);\n        inQueueSrc1.FreeTensor(src1Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstLocal, 512);\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc0, inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<half> src0Global, src1Global, dstGlobal;\n};\n \nextern \"C\" __global__ __aicore__ void div_simple_kernel(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm,\n    __gm__ uint8_t* dstGm)\n{\n    KernelDiv op;\n    op.Init(src0Gm, src1Gm, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "Max",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0039.html",
    "功能说明": "按元素求最大值，公式表达如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void Max(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 Atlas 训练系列产品 ，支持的数据类型为： half/int32_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为： half/int16_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： half/int16_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： half/int16_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为： half/int16_t/int32_t/float src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，支持的数据类型为：half/float/int32_t Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::Max(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Min",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0040.html",
    "功能说明": "按元素求最小值，公式表达如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void Min(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为： half/int32_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为： half/int16_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： half/int16_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： half/int16_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为： half/int16_t/int32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::Min(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "And",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0041.html",
    "功能说明": "每对elements按位与运算，公式表达如下：",
    "函数原型": "dstLocal = src0Local & src1Local;",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为： int16_t/uint16_t Atlas 推理系列产品 AI Core ，支持的数据类型为： int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： int16_t/uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： int16_t/uint16_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为： int16_t/uint16_t isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::And(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Or",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0042.html",
    "功能说明": "每对elements按位或运算，计算公式如下：",
    "函数原型": "dstLocal = src0Local | src1Local;",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为： int16_t/uint16_t Atlas 推理系列产品 AI Core ，支持的数据类型为： int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： int16_t/uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： int16_t/uint16_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为： int16_t/uint16_t isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::Or(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "AddRelu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0043.html",
    "功能说明": "按元素求和，再进行Relu计算（结果和0对比取较大值）。计算公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void AddRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为： int16_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： int16_t/half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： int16_t/half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::AddRelu(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "AddReluCast",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0044.html",
    "功能说明": "按元素求和，结果和0对比取较大值，并根据源操作数和目的操作数Tensor的数据类型进行精度转换。计算公式如下，其中dstType表示目的操作数的数据类型：",
    "函数原型": "template <typename T1, typename T2>\n__aicore__ inline void AddReluCast(const LocalTensor<T1>& dstLocal, const LocalTensor<T2>& src0Local, const LocalTensor<T2>& src1Local, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T1 目的操作数数据类型。不同数据类型对应的精度转换规则见 表3 。 Atlas 推理系列产品 AI Core ，支持的数据类型为： int8_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： int8_t/half Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： int8_t/half Atlas 200I/500 A2 推理产品 ， 支持的数据类型为 int8_t/half T2 源操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为： int16_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： int16_t/half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： int16_t/half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 当源操作数和目的操作数位数不同时，以数据类型的字节较大的为准。例如，源操作数为half类型，目的操作数为int8_t类型，计算mask时以half为准。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half); // 128\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride = 4, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::AddReluCast(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 4, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "AddDeqRelu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0045.html",
    "功能说明": "依次计算按元素求和、结果进行deq量化后再进行relu计算（结果和0对比取较大值）。计算公式如下： Deq的计算公式如下： 如上公式先除以2^17再乘以2^17用于防止x乘以DeqScale出现溢出情况；公式中DeqScale需要通过SetDeqScale进行设置，具体可参考 SetDeqScale 。",
    "函数原型": "__aicore__ inline void AddDeqRelu(const LocalTensor<half>& dstLocal, const LocalTensor<int32_t>& src0Local, const LocalTensor<int32_t>& src1Local, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。 T 目的操作数的数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half U 源操作数的数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int32_t\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 当源操作数和目的操作数位数不同时，以数据类型的字节较大的为准。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(int32_t); // 64\n// repeatTimes = 4, 一次迭代计算64个数, 共计算256个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride = 4, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nhalf scale = 0.1;\nAscendC::SetDeqScale(scale);\nAscendC::AddDeqRelu(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 4, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "SubRelu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0046.html",
    "功能说明": "按元素求差，再进行Relu计算（结果和0对比取较大值）。计算公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void SubRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为： int16_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： int16_t/half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： int16_t/half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::SubRelu(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "SubReluCast",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0047.html",
    "功能说明": "按元素求差，再进行Relu计算（结果和0对比取较大值），并根据源操作数和目的操作数Tensor的数据类型进行精度转换。计算公式如下，其中dstType表示目的操作数的数据类型：",
    "函数原型": "template <typename T1, typename T2>\n__aicore__ inline void SubReluCast(const LocalTensor<T1>& dstLocal, const LocalTensor<T2>& src0Local, const LocalTensor<T2>& src1Local, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T1 目的操作数数据类型。不同数据类型对应的精度转换规则见 表3 。 Atlas 推理系列产品 AI Core ，支持的数据类型为： int8_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： int8_t/half Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： int8_t/half Atlas 200I/500 A2 推理产品 ，支持的数据类型为 int8_t/half T2 源操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为： int16_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为： int16_t/half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为： int16_t/half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 当源操作数和目的操作数位数不同时，以数据类型的字节较大的为准。例如，源操作数为half类型，目的操作数为int8_t类型，计算mask时以half为准。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half); // 128\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride = 4, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::SubReluCast(dstLocal, src0Local, src1Local, mask, 4, { 1, 1, 1, 4, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "MulAddDst",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0048.html",
    "功能说明": "按元素将src0Local和src1Local相乘并和dstLocal相加，将最终结果存放进dstLocal中。计算公式如下：",
    "函数原型": "template <typename T, typename U>\n__aicore__ inline void MulAddDst(const LocalTensor<T>& dstLocal, const LocalTensor<U>& src0Local, const LocalTensor<U>& src1Local, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 目的操作数数据类型。目的操作数和源操作数的数据类型约束请参考 表3 。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为： int16_t/uint16_t/half/int32_t/uint32_t/float U 源操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ， 支持的数据类型为： int16_t/uint16_t/half/int32_t/uint32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。源操作数数据类型和目的操作数数据类型可以不一致。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 64;\n// repeatTimes = 4, 一次迭代计算64个数, 共计算256个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride = 8, src0RepStride, src1RepStride = 4, 相邻迭代间数据连续读取和写入\nAscendC::MulAddDst(dstLocal, src0Local, src1Local, 64, 4, { 1, 1, 1, 8, 4, 4 });",
    "错误": null
  },
  {
    "API名称": "MulCast",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0049.html",
    "功能说明": "按元素求积，并根据源操作数和目的操作数Tensor的数据类型进行精度转换。计算公式如下 :",
    "函数原型": "template <typename T, typename U>\n__aicore__ inline void MulCast(const LocalTensor<T> &dstLocal, const LocalTensor<U> &src0Local,\nconst LocalTensor<U> &src1Local, uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 目的操作数数据类型。不同数据类型对应的精度转换规则见 表3 。 Atlas 推理系列产品 AI Core ，支持的数据类型为：int8_t/uint8_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int8_t/uint8_t Atlas 200I/500 A2 推理产品 ， 支持的数据类型为：int8_t/uint8_t U 源操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 一次迭代计算128个数, 共计算512个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride = 4, 相邻迭代间数据连续写入\n// src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取\nAscendC::MulCast(dstLocal, src0Local, src1Local, mask, repeatTimes, repeatParams);",
    "错误": null
  },
  {
    "API名称": "FusedMulAdd",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0050.html",
    "功能说明": "按元素将src0Local和dstLocal相乘并加上src1Local，最终结果存放入dstLocal。计算公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void FusedMulAdd(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输入/输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 2, 一次迭代计算128个数, 共计算256个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::FusedMulAdd(dstLocal, src0Local, src1Local, mask, 2, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "FusedMulAddRelu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0051.html",
    "功能说明": "按元素将src0Local和dstLocal相乘并加上src1Local，再进行Relu计算（结果和0对比取较大值），最终结果存放进dstLocal中。计算公式如下：",
    "函数原型": "template <typename T>\n__aicore__ inline void FusedMulAddRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 BinaryRepeatParams 类型，包含操作数相邻迭代间相同datablock的地址步长，操作数同一迭代内不同datablock的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 2, 一次迭代计算128个数, 共计算256个数\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::FusedMulAddRelu(dstLocal, src0Local, src1Local, mask, 2, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Adds",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0054.html",
    "功能说明": "矢量内每个元素与标量求和，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void Adds(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const T& scalarValue, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t U scalarValue数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t isSetMask 是否在接口内部设置mask模式和mask值。 true，表示在接口内部设置。 tensor高维切分计算API/tensor前n个数据计算API内部使用了mask的 Normal模式/Counter模式 ，一般情况下保持isSetMask默认值即可，表示在API内部进行根据开发者传入的mask/calCount参数进行mask模式和mask值的设置。 false，表示在接口外部设置。 针对tensor高维切分计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskNorm / SetMaskCount 设置mask模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的mask值必须设置为MASK_PLACEHOLDER。 针对tensor前n个数据计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskCount 设置mask模式为Counter模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的calCount不生效，建议设置成1。 针对以下型号，tensor前n个数据计算API中的isSetMask参数不生效，保持默认值即可。 Atlas 200I/500 A2 推理产品\n\n表2 参数说明 参数名称 类型 说明 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 scalarValue 输入 源操作数，数据类型需要与目的操作数中的元素类型保持一致。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。 矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 元素操作控制结构信息，具体请参考 UnaryRepeatParams 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\nint16_t scalar = 2;\n// repeatTimes = 4, 单次迭代处理128个数，计算512个数需要迭代4次\n// dstBlkStride, srcBlkStride = 1, 每个迭代内src0参与计算的数据地址间隔为1个datablock，表示单次迭代内数据连续读取和写入\n// dstRepStride, srcRepStride = 8, 相邻迭代间的地址间隔为8个datablock，表示相邻迭代间数据连续读取和写入\nAscendC::Adds(dstLocal, srcLocal, scalar, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Muls",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0055.html",
    "功能说明": "矢量内每个元素与标量求积，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void Muls(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const T& scalarValue, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 U scalarValue数据类型。 isSetMask 是否在接口内部设置mask模式和mask值。 true，表示在接口内部设置。 tensor高维切分计算API/tensor前n个数据计算API内部使用了mask的 Normal模式/Counter模式 ，一般情况下保持isSetMask默认值即可，表示在API内部进行根据开发者传入的mask/calCount参数进行mask模式和mask值的设置。 false，表示在接口外部设置。 针对tensor高维切分计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskNorm / SetMaskCount 设置mask模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的mask值必须设置为MASK_PLACEHOLDER。 针对tensor前n个数据计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskCount 设置mask模式为Counter模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的calCount不生效，建议设置成1。 针对以下型号，tensor前n个数据计算API中的isSetMask参数不生效，保持默认值即可。 Atlas 200I/500 A2 推理产品\n\n表2 参数说明 参数名称 输入/输出 说明 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t scalarValue 输入 源操作数，数据类型需要与目的操作数Tensor中的元素类型保持一致 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。 矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 元素操作控制结构信息，具体请参考 UnaryRepeatParams 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\nint16_t scalar = 2;\n// repeatTimes = 4, 单次迭代处理128个数，计算512个数需要迭代4次\n// dstBlkStride, srcBlkStride = 1, 每个迭代内src0参与计算的数据地址间隔为1个datablock，表示单次迭代内数据连续读取和写入\n// dstRepStride, srcRepStride = 8, 相邻迭代间的地址间隔为8个datablock，表示相邻迭代间数据连续读取和写入\nAscendC::Muls(dstLocal, srcLocal, scalar, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Maxs",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0056.html",
    "功能说明": "源操作数矢量内每个元素与标量相比，如果比标量大，则取源操作数值，比标量的值小，则取标量值。 计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void Maxs(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const T& scalarValue, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t U scalarValue数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t isSetMask 是否在接口内部设置mask模式和mask值。 true，表示在接口内部设置。 tensor高维切分计算API/tensor前n个数据计算API内部使用了mask的 Normal模式/Counter模式 ，一般情况下保持isSetMask默认值即可，表示在API内部进行根据开发者传入的mask/calCount参数进行mask模式和mask值的设置。 false，表示在接口外部设置。 针对tensor高维切分计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskNorm / SetMaskCount 设置mask模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的mask值必须设置为MASK_PLACEHOLDER。 针对tensor前n个数据计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskCount 设置mask模式为Counter模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的calCount不生效，建议设置成1。 针对以下型号，tensor前n个数据计算API中的isSetMask参数不生效，保持默认值即可。 Atlas 200I/500 A2 推理产品\n\n表2 参数说明 参数名称 类型 说明 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 scalarValue 输入 源操作数，数据类型需要与目的操作数Tensor中元素的数据类型保持一致。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。 矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 元素操作控制结构信息，具体请参考 UnaryRepeatParams 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\nint16_t scalar = 2;\n// repeatTimes = 4, 单次迭代处理128个数，计算512个数需要迭代4次\n// dstBlkStride, srcBlkStride = 1, 每个迭代内src0参与计算的数据地址间隔为1个datablock，表示单次迭代内数据连续读取和写入\n// dstRepStride, srcRepStride = 8, 相邻迭代间的地址间隔为8个datablock，表示相邻迭代间数据连续读取和写入\nAscendC::Maxs(dstLocal, srcLocal, scalar, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "Mins",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0057.html",
    "功能说明": "源操作数矢量内每个元素与标量相比，如果比标量大，则取标量值，比标量的值小，则取源操作数。 计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void Mins(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const T& scalarValue, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t U scalarValue数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/float/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/float/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/float/int32_t isSetMask 是否在接口内部设置mask模式和mask值。 true，表示在接口内部设置。 tensor高维切分计算API/tensor前n个数据计算API内部使用了mask的 Normal模式/Counter模式 ，一般情况下保持isSetMask默认值即可，表示在API内部进行根据开发者传入的mask/calCount参数进行mask模式和mask值的设置。 false，表示在接口外部设置。 针对tensor高维切分计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskNorm / SetMaskCount 设置mask模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的mask值必须设置为MASK_PLACEHOLDER。 针对tensor前n个数据计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskCount 设置mask模式为Counter模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的calCount不生效，建议设置成1。 针对以下型号，tensor前n个数据计算API中的isSetMask参数不生效，保持默认值即可。 Atlas 200I/500 A2 推理产品\n\n表2 参数说明 参数名 输入/输出 说明 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 scalarValue 输入 源操作数，数据类型需要与目的操作数Tensor中元素的数据类型保持一致。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。 矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 元素操作控制结构信息，具体请参考 UnaryRepeatParams 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\nint16_t scalar = 2;\n// repeatTimes = 4, 单次迭代处理128个数，计算512个数需要迭代4次\n// dstBlkStride, srcBlkStride = 1, 每个迭代内src0参与计算的数据地址间隔为1个datablock，表示单次迭代内数据连续读取和写入\n// dstRepStride, srcRepStride = 8, 相邻迭代间的地址间隔为8个datablock，表示相邻迭代间数据连续读取和写入\nAscendC::Mins(dstLocal, srcLocal, scalar, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "ShiftLeft",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0058.html",
    "功能说明": "对源操作数中的每个元素进行左移操作，左移的位数由输入参数scalarValue决定。根据源操作数的数据类型，左移操作分为以下两种情况： 数据类型为无符号类型：执行逻辑左移。逻辑左移会将二进制数整体向左移动指定的位数，最高位被丢弃，最低位用0填充。例如，二进制数1010101010101010（uint16_t 类型）逻辑左移1位后，结果为0101010101010100。 数据类型为有符号类型：执行算术左移。算术左移会将二进制数整体向左移动指定的位数，次高位被丢弃，最低位用0填充。例如，二进制数1010101010101010（int16_t 类型）算术左移1位后，结果为1101010101010100；算术左移3位后，结果为1101010101010000。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void ShiftLeft(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const T& scalarValue, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t U scalarValue数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t isSetMask 是否在接口内部设置mask模式和mask值。 true，表示在接口内部设置。 tensor高维切分计算API/tensor前n个数据计算API内部使用了mask的 Normal模式/Counter模式 ，一般情况下保持isSetMask默认值即可，表示在API内部进行根据开发者传入的mask/calCount参数进行mask模式和mask值的设置。 false，表示在接口外部设置。 针对tensor高维切分计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskNorm / SetMaskCount 设置mask模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的mask值必须设置为MASK_PLACEHOLDER。 针对tensor前n个数据计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskCount 设置mask模式为Counter模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的calCount不生效，建议设置成1。 针对以下型号，tensor前n个数据计算API中的isSetMask参数不生效，保持默认值即可。 Atlas 200I/500 A2 推理产品\n\n表2 参数说明 参数名称 输入/输出 说明 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 scalarValue 输入 左移的位数，数据类型需要与目的操作数Tensor中的元素数据类型保持一致。 针对 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，当srcLocal为uint16_t或int16_t类型时，scalarValue的取值范围为[0, 16]；当srcLocal为uint32_t或int32_t类型时，scalarValue的取值范围为[0, 32]。 针对 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，当srcLocal为uint16_t或int16_t类型时，scalarValue的取值范围为[0, 16]；当srcLocal为uint32_t或int32_t类型时，scalarValue的取值范围为[0, 32]。 针对 Atlas 200I/500 A2 推理产品 ，当srcLocal为uint16_t或int16_t类型时，scalarValue的取值范围为[0, 16]；当srcLocal为uint32_t或int32_t类型时，scalarValue的取值范围为[0, 32]。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。 矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 元素操作控制结构信息，具体请参考 UnaryRepeatParams 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\nint16_t scalar = 2;\n// repeatTimes = 4, 单次迭代处理128个数，计算512个数需要迭代4次\n// dstBlkStride, srcBlkStride = 1, 每个迭代内src0参与计算的数据地址间隔为1个datablock，表示单次迭代内数据连续读取和写入\n// dstRepStride, srcRepStride = 8, 相邻迭代间的地址间隔为8个datablock，表示相邻迭代间数据连续读取和写入\nAscendC::ShiftLeft(dstLocal, srcLocal, scalar, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "ShiftRight",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0059.html",
    "功能说明": "对源操作数中的每个元素进行右移操作，右移的位数由输入参数scalarValue决定。根据源操作数的数据类型，右移操作分为以下两种情况： 数据类型为无符号类型：执行逻辑右移。逻辑右移会将二进制数整体向右移动指定的位数，最低位被丢弃，最高位用0填充。例如，二进制数1010101010101010（uint16_t类型）逻辑右移1位后，结果为0101010101010101。 数据类型为有符号类型：执行算术右移。算术右移会将二进制数整体向右移动指定的位数，最低位被丢弃，最高位复制符号位。例如，二进制数1010101010101010（int16_t 类型）算术右移1位后，结果为1101010101010101；算术右移3位后，结果为1111010101010101。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void ShiftRight(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const T& scalarValue, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t U scalarValue数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint16_t/int16_t/uint32_t/int32_t isSetMask 是否在接口内部设置mask模式和mask值。 true，表示在接口内部设置。 tensor高维切分计算API/tensor前n个数据计算API内部使用了mask的 Normal模式/Counter模式 ，一般情况下保持isSetMask默认值即可，表示在API内部进行根据开发者传入的mask/calCount参数进行mask模式和mask值的设置。 false，表示在接口外部设置。 针对tensor高维切分计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskNorm / SetMaskCount 设置mask模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的mask值必须设置为MASK_PLACEHOLDER。 针对tensor前n个数据计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskCount 设置mask模式为Counter模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的calCount不生效，建议设置成1。 针对以下型号，tensor前n个数据计算API中的isSetMask参数不生效，保持默认值即可。 Atlas 200I/500 A2 推理产品\n\n表2 参数说明 参数名称 输入/输出 说明 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 scalarValue 输入 右移的位数，数据类型需要与目的操作数Tensor中的元素数据类型保持一致。 针对 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，当srcLocal为uint16_t或int16_t类型时，scalarValue的取值范围为[0, 16]；当srcLocal为uint32_t或int32_t类型时，scalarValue的取值范围为[0, 32]。 针对 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，当srcLocal为uint16_t或int16_t类型时，scalarValue的取值范围为[0, 16]；当srcLocal为uint32_t或int32_t类型时，scalarValue的取值范围为[0, 32]。 针对 Atlas 200I/500 A2 推理产品 ，当srcLocal为uint16_t或int16_t类型时，scalarValue的取值范围为[0, 16]；当srcLocal为uint32_t或int32_t类型时，scalarValue的取值范围为[0, 32]。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。 矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 元素操作控制结构信息，具体请参考 UnaryRepeatParams 。 roundEn 输入 舍入功能使能开关，支持数据类型：bool，true为使能，false为不使能。仅当src为int16_t/int32_t类型时使能有效。 例：使能舍入功能，src数据类型为int16_t，将src算数右移5位，如果src_ele二进制数中的第5位为1，则dst_ele值为对src_ele算术右移5后加1。 src_ele = 17 = 0b0000000000010001 第五位为1 dst_ele = arithmetic_righ_shift(src_ele, 5) + 1 = 0b0000000000000000 + 1 = 0b0000000000000001 Atlas 200I/500 A2 推理产品 ，不支持使能舍入功能，仅支持传入false。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\nint16_t scalar = 2;\n// repeatTimes = 4, 单次迭代处理128个数，计算512个数需要迭代4次\n// dstBlkStride, srcBlkStride = 1, 每个迭代内src0参与计算的数据地址间隔为1个datablock，表示单次迭代内数据连续读取和写入\n// dstRepStride, srcRepStride = 8, 相邻迭代间的地址间隔为8个datablock，表示相邻迭代间数据连续读取和写入\nAscendC::ShiftRight(dstLocal, srcLocal, scalar, mask, 4, { 1, 1, 8, 8 }, false);",
    "错误": null
  },
  {
    "API名称": "LeakyRelu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0060.html",
    "功能说明": "按元素执行Leaky ReLU（Leaky Rectified Linear Unit）操作，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： Leaky ReLU带泄露线性整流函数是一种人工神经网络中常用的激活函数，其数学表达式为： 和ReLU的区别是：ReLU是将所有的负值都设为零，而Leaky ReLU是给所有负值赋予一个斜率。下图表示了Relu和Leaky ReLU的区别：",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void LeakyRelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const T& scalarValue, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 U scalarValue数据类型。 isSetMask 是否在接口内部设置mask模式和mask值。 true，表示在接口内部设置。 tensor高维切分计算API/tensor前n个数据计算API内部使用了mask的 Normal模式/Counter模式 ，一般情况下保持isSetMask默认值即可，表示在API内部进行根据开发者传入的mask/calCount参数进行mask模式和mask值的设置。 false，表示在接口外部设置。 针对tensor高维切分计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskNorm / SetMaskCount 设置mask模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的mask值必须设置为MASK_PLACEHOLDER。 针对tensor前n个数据计算接口，对性能要求较高的部分场景下，开发者需要使用 SetMaskCount 设置mask模式为Counter模式，并通过 SetVectorMask 接口设置mask值。本接口入参中的calCount不生效，建议设置成1。 针对以下型号，tensor前n个数据计算API中的isSetMask参数不生效，保持默认值即可。 Atlas 200I/500 A2 推理产品\n\n表2 参数说明 参数名称 类型 说明 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 Atlas 推理系列产品 AI Core ，支持的数据类型为：Tensor（half/float） Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：Tensor（half/float） Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：Tensor（half/float） Atlas 200I/500 A2 推理产品 ，支持的数据类型为：Tensor（half/float） srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 Atlas 推理系列产品 AI Core ，支持的数据类型为：Tensor（half/float） Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：Tensor（half/float） Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：Tensor（half/float） Atlas 200I/500 A2 推理产品 ，支持的数据类型为：Tensor（half/float） scalarValue 输入 源操作数，数据类型需要与目的操作数Tensor中的元素保持一致。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。 矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 元素操作控制结构信息，具体请参考 UnaryRepeatParams 。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\nclass KernelBinaryScalar {\npublic:\n    __aicore__ inline KernelBinaryScalar() {}\n    __aicore__ inline void Init(__gm__ uint8_t* src, __gm__ uint8_t* dstGm)\n    {\n        srcGlobal.SetGlobalBuffer((__gm__ half*)src);\n        dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm);\n        pipe.InitBuffer(inQueueSrc, 1, 512 * sizeof(half));\n        pipe.InitBuffer(outQueueDst, 1, 512 * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>();\n        AscendC::DataCopy(srcLocal, srcGlobal, 512);\n        inQueueSrc.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n \n        uint64_t mask = 128;\n        half scalar = 2;\n        // repeatTimes = 4, 128 elements one repeat, 512 elements total\n        // dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n        // dstRepStride, srcRepStride =8, no gap between repeats\n        AscendC::LeakyRelu(dstLocal, srcLocal, scalar, mask, 4, {1, 1, 8, 8});\n        \n        outQueueDst.EnQue<half>(dstLocal);\n        inQueueSrc.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstLocal, 512);\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<half> srcGlobal, dstGlobal;\n};\nextern \"C\" __global__ __aicore__ void binary_scalar_simple_kernel(__gm__ uint8_t* src, __gm__ uint8_t* dstGm)\n{\n    KernelBinaryScalar op;\n    op.Init(src, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "Axpy",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0063.html",
    "功能说明": "源操作数(srcLocal)中每个元素与标量求积后和目的操作数(dstLocal)中的对应元素相加，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, typename U>\n__aicore__ inline void Axpy(const LocalTensor<T>& dstLocal, const LocalTensor<U>& srcLocal, const U& scalarValue, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 目的操作数数据类型。目的操作数和源操作数的数据类型约束请参考 表3 。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float U 源操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 说明 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 scalarValue 输入 源操作数，scalar标量。scalarValue的数据类型需要和srcLocal保持一致。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。 矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "// repeatTimes = 4, mask = 128, 128 elements one repeat, 512 elements total\n// srcLocal数据类型为half，scalar数据类型为half，dstLocal数据类型为half\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats \nAscendC::Axpy(dstLocal, srcLocal, (half)2.0, 128, 4,{ 1, 1, 8, 8 });\n\n// srcLocal数据类型为half，scalar数据类型为half，dstLocal数据类型为float\n// repeatTimes = 8, mask = 64, 64 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride = 8, srcRepStride = 4, no gap between repeats \nAscendC::Axpy(dstLocal, srcLocal, (half)2.0, 64, 8,{ 1, 1, 8, 4 }); // 每次迭代选取源操作数前4个datablock参与计算",
    "错误": null
  },
  {
    "API名称": "Compare",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0066.html",
    "功能说明": "逐元素比较两个tensor大小，如果比较后的结果为真，则输出结果的对应比特位为1，否则为0。 支持多种比较模式： LT：小于（less than） GT：大于（greater than） GE：大于或等于（greater than or equal to） EQ：等于（equal to） NE：不等于（not equal to） LE：小于或等于（less than or equal to）",
    "函数原型": "dstLocal = src0Local < src1Local;\ndstLocal = src0Local > src1Local;\ndstLocal = src0Local <= src1Local;\ndstLocal = src0Local >= src1Local;\ndstLocal = src0Local == src1Local;\ndstLocal = src0Local != src1Local;",
    "参数说明": "表1 模板参数说明 参数名 描述 T 源操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float（所有CMPMODE都支持）， int32_t（只支持CMPMODE::EQ） Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float（所有CMPMODE都支持）， int32_t（只支持CMPMODE::EQ） Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float U 目的操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：int8_t/uint8_t Atlas 推理系列产品 AI Core ，支持的数据类型为：int8_t/uint8_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int8_t/uint8_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int8_t/uint8_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int8_t/uint8_t isSetMask 保留参数， 保持默认值即可。",
    "返回值": "无",
    "调用示例": "dstLocal = src0Local < src1Local;",
    "错误": null
  },
  {
    "API名称": "Compare（结果存入寄存器）",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0067.html",
    "功能说明": "逐元素比较两个tensor大小，如果比较后的结果为真，则输出结果的对应比特位为1，否则为0。Compare接口需要mask参数时，可以使用此接口。计算结果存放入寄存器中。 支持多种比较模式： LT：小于（less than） GT：大于（greater than） GE：大于或等于（greater than or equal to） EQ：等于（equal to） NE：不等于（not equal to） LE：小于或等于（less than or equal to）",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void Compare(const LocalTensor<T>& src0Local, const LocalTensor<T>& src1Local, CMPMODE cmpMode, const uint64_t mask[], const BinaryRepeatParams& repeatParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 源操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(float); // 256为每个迭代处理的字节数\nAscendC::BinaryRepeatParams repeatParams = { 1, 1, 1, 8, 8, 8 };\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, src0RepStride, src1RepStride = 8, no gap between repeats\nAscendC::Compare(src0Local, src1Local, AscendC::CMPMODE::LT, mask, repeatParams);",
    "错误": null
  },
  {
    "API名称": "CompareScalar",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0068.html",
    "功能说明": "逐元素比较一个tensor中的元素和另一个Scalar的大小，如果比较后的结果为真，则输出结果的对应比特位为1，否则为0。 支持多种比较模式： LT：小于（less than） GT：大于（greater than） GE：大于或等于（greater than or equal to） EQ：等于（equal to） NE：不等于（not equal to） LE：小于或等于（less than or equal to）",
    "函数原型": "template <typename T, typename U>\n__aicore__ inline void CompareScalar(const LocalTensor<U>& dstLocal, const LocalTensor<T>& src0Local, const T src1Scalar, CMPMODE cmpMode, uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 源操作数数据类型。 U 目的操作数数据类型。 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。",
    "返回值": "无",
    "调用示例": "AscendC::CompareScalar(dstLocal, src0Local, src1Scalar, AscendC::CMPMODE::LT, srcDataSize);",
    "错误": null
  },
  {
    "API名称": "Select",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0070.html",
    "功能说明": "给定两个源操作数src0和src1，根据selMask（用于选择的Mask掩码）的比特位值选取元素，得到目的操作数dst。选择的规则为：当selMask的比特位是1时，从src0中选取，比特位是0时从src1选取。 对于tensor高维切分计算接口，支持根据mask参数对上述选取结果，再次进行过滤，有效位填入最终的dst，无效位则保持dst原始值。例如：src0为[1,2,3,4,5,6,7,8]，src1为[9,10,11,12,13,14,15,16]，selMask为[0,0,0,0,1,1,1,1]，mask为[1,1,1,1,0,0,0,0]，dst原始值为[-1,-2,-3,-4,-5,-6,-7,-8]，则根据selMask的比特位选取后的结果dst_temp为：[9,10,11,12,5,6,7,8]，然后再根据mask进行过滤，dst的最终输出结果为[9,10,11,12,-5,-6,-7,-8]。 本选择功能支持三种模式： 模式0：根据selMask在两个tensor中选取元素。selMask中有效数据的个数存在限制，具体取决于源操作数的数据类型。在每一轮迭代中，根据selMask的有效位数据进行选择操作，每一轮迭代采用的selMask，均为相同数值，即selMask的有效数值。 模式1：根据selMask在1个tensor和1个scalar标量中选取元素，selMask无有效数据限制。多轮迭代时，每轮迭代连续使用selMask的不同部分。 模式2：根据selMask在两个tensor中选取元素，selMask无有效数据限制。多轮迭代时，每轮迭代连续使用selMask的不同部分。 Atlas 训练系列产品 ，仅支持模式0。 Atlas 推理系列产品 AI Core ，支持模式0、1、2。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持模式0、1、2。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持模式0、1、2。 Atlas 200I/500 A2 推理产品 ，支持模式0、1、2。",
    "函数原型": "template <typename T, typename U>\n__aicore__ inline void Select(const LocalTensor<T>& dstLocal, const LocalTensor<U>& selMask, const LocalTensor<T>& src0Local, T src1Local, SELMODE selMode, uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名称 含义 T 源操作数和目的操作数的数据类型。 U selMask的数据类型。 isSetMask 保留参数， 保持默认值即可。如需使用在接口外部设置mask的功能，可以调用不传入mask参数的接口来实现。 selMode 同 表2 参数说明 中的selMode参数说明。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float selMask 输入 选取mask。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 支持的数据类型为：uint8_t/uint16_t/uint32_t/uint64_t。 每个bit表示1个元素的选取，当selMask的比特位是1时从src0中选取，比特位是0时从src1选取。 selMode为模式0时，在每一轮迭代中，根据selMask的有效位数据进行选择操作，每一轮迭代采用的selMask，均为相同数值，即selMask的有效数值。selMode为模式1/2时，多次迭代对selMask连续消耗。 模式0：根据selMask在两个tensor中选取元素，selMask有位数限制，不管迭代多少次，每次迭代都只根据截取后的固定位数的selMask进行选择。当源操作数的数据类型为8位时，selMask前256比特位有效；当源操作数的数据类型为16位时，selMask前128比特位有效；源操作数的数据类型为32位时，selMask前64比特位有效。 模式1：根据selMask在1个tensor和1个scalar标量中选取元素。支持多次迭代，选取方式为，根据selMask的设置值，如果selMask比特值为1，则选择src0Local内的同位置数值，如果selMask比特值为0，则选择标量值。selMask连续存放，当源操作数的数据类型为8位时，一次比较获取selMask256bit长度的数据；当源操作数的数据类型为16位时，一次比较获取selMask128bit长度的数据；源操作数的数据类型为32位时，一次比较获取selMask64bit长度的数据。 模式2：根据selMask在两个tensor中选取元素。支持多次迭代，选取方式为，根据selMask的设置值，如果selMask比特值为1，则选择src0Local内的同位置数值，如果selMask比特值为0，则选择src1Local内的同位置数值。selMask连续存放，当源操作数的数据类型为8位时，一次比较获取selMask256bit长度的数据；当源操作数的数据类型为16位时，一次比较获取selMask128bit长度的数据；源操作数的数据类型为32位时，一次比较获取selMask64bit长度的数据。 src0Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float src1Local 输入 源操作数。 当selMode为模式0或模式2时： 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 当selMode为模式1时，类型为T，标量数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float selMode 输入 指令模式，SELMODE类型，取值如下： enum class SELMODE : uint8_t { VSEL_CMPMASK_SPR = 0 , VSEL_TENSOR_SCALAR_MODE , VSEL_TENSOR_TENSOR_MODE , };",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256/sizeof(float);\nint repeat = 4;\nAscendC::BinaryRepeatParams repeatParams = { 1, 1, 1, 8, 8, 8 };\n// repeat = 4, 64 elements one repeat, 256 elements total\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, src0RepStride, src1RepStride = 8, no gap between repeats\nAscendC::Select(dstLocal, maskLocal, src0Local, src1Local, AscendC::SELMODE::VSEL_TENSOR_TENSOR_MODE, mask, repeat, repeatParams);",
    "错误": null
  },
  {
    "API名称": "GatherMask",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0071.html",
    "功能说明": "以 内置固定模式 对应的二进制或者 用户自定义输入的Tensor 数值对应的二进制为gather mask（数据收集的掩码），从源操作数中选取元素写入目的操作数中。",
    "函数原型": "template <typename T, typename U, GatherMaskMode mode = defaultGatherMaskMode>\n__aicore__ inline void GatherMask(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<U>& src1Pattern, const bool reduceMode, const uint32_t mask, const GatherMaskParams& gatherMaskParams, uint64_t& rsvdCnt)",
    "参数说明": "表1 模板参数说明 参数名称 含义 T 源操作数src0Local和目的操作数dstLocal的数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half/uint16_t/int16_t/float/uint32_t/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/bfloat16_t/uint16_t/int16_t/float/uint32_t/int32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/uint16_t/int16_t/float/uint32_t/int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/bfloat16_t/uint16_t/int16_t/float/uint32_t/int32_t U 用户自定义模式下src1Pattern的数据类型。支持的数据类型为uint16_t/uint32_t。 当目的操作数数据类型为half/uint16_t/int16_t时，src1Pattern应为uint16_t数据类型。 当目的操作数数据类型为float/uint32_t/int32_t时，src1Pattern应为uint32_t数据类型。 mode 预留参数，为后续功能做预留，当前提供默认值，用户无需设置该参数。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 src1Pattern 输入 gather mask（数据收集的掩码），分为内置固定模式和用户自定义模式两种，根据内置固定模式对应的二进制或者用户自定义输入的Tensor数值对应的二进制从源操作数中选取元素写入目的操作数中。1为选取，0为不选取。 内置固定模式：src1Pattern数据类型为uint8_t，取值范围为[1,7]，所有repeat迭代使用相同的gather mask。不支持配置src1RepeatStride。 1：01010101…0101 # 每个repeat取偶数索引元素 2：10101010…1010 # 每个repeat取奇数索引元素 3：00010001…0001 # 每个repeat内每四个元素取第一个元素 4：00100010…0010 # 每个repeat内每四个元素取第二个元素， 5：01000100…0100 # 每个repeat内每四个元素取第三个元素 6：10001000…1000 # 每个repeat内每四个元素取第四个元素 7：11111111...1111 # 每个repeat内取全部元素 Atlas 推理系列产品 AI Core 支持模式1-6 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 支持模式1-7 Atlas A3 训练系列产品/Atlas A3 推理系列产品 支持模式1-7 Atlas 200I/500 A2 推理产品 支持模式1-7 用户自定义模式：src1Pattern数据类型为LocalTensor，迭代间间隔由src1RepeatStride决定， 迭代内src1Pattern连续消耗。 reduceMode 输入 用于选择mask参数模式，数据类型为bool，支持如下取值。 false：Normal模式。该模式下，每次repeat操作256Bytes数据，总的数据计算量为repeatTimes * 256Bytes。 mask参数无效，建议设置为0。 按需配置repeatTimes、src0BlockStride、src0RepeatStride参数。 支持src1Pattern配置为内置固定模式或用户自定义模式。用户自定义模式下可根据实际情况配置src1RepeatStride。 true：Counter模式。根据mask等参数含义的不同，该模式有以下两种配置方式： 配置方式一 ：每次repeat操作mask个元素，总的数据计算量为repeatTimes * mask个元素。 mask值配置为每一次repeat计算的元素个数。 按需配置repeatTimes、src0BlockStride、src0RepeatStride参数。 支持src1Pattern配置为内置固定模式或用户自定义模式。用户自定义模式下可根据实际情况配置src1RepeatStride。 配置方式二 ：总的数据计算量为mask个元素。 mask配置为总的数据计算量。 repeatTimes值不生效，指令的迭代次数由源操作数和mask共同决定。 按需配置src0BlockStride、src0RepeatStride参数。 支持src1Pattern配置为内置固定模式或用户自定义模式。用户自定义模式下可根据实际情况配置src1RepeatStride。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持配置方式一 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持配置方式一 Atlas 200I/500 A2 推理产品 ，支持配置方式一 Atlas 推理系列产品 AI Core ，支持配置方式二 mask 输入 用于控制每次迭代内参与计算的元素。根据reduceMode，分为两种模式： Normal模式：mask无效，建议设置为0。 Counter模式：取值范围[1, 2 32 – 1]。不同的版本型号Counter模式下，mask参数表示含义不同。具体配置规则参考上文reduceMode参数描述。 gatherMaskParams 输入 控制操作数地址步长的数据结构，GatherMaskParams类型。 具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_gather.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 具体参数说明 表3 。 rsvdCnt 输出 该条指令筛选后保留下来的元素计数，对应dstLocal中有效元素个数，数据类型为uint64_t。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\nclass KernelGatherMask {\npublic:\n    __aicore__ inline KernelGatherMask () {}\n    __aicore__ inline void Init(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n    {\n        src0Global.SetGlobalBuffer((__gm__ uint32_t*)src0Gm);\n        src1Global.SetGlobalBuffer((__gm__ uint32_t*)src1Gm);\n        dstGlobal.SetGlobalBuffer((__gm__ uint32_t*)dstGm);\n        pipe.InitBuffer(inQueueSrc0, 1, 256 * sizeof(uint32_t));\n        pipe.InitBuffer(inQueueSrc1, 1, 32 * sizeof(uint32_t));\n        pipe.InitBuffer(outQueueDst, 1, 256 * sizeof(uint32_t));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<uint32_t> src0Local = inQueueSrc0.AllocTensor<uint32_t>();\n        AscendC::LocalTensor<uint32_t> src1Local = inQueueSrc1.AllocTensor<uint32_t>();\n        AscendC::DataCopy(src0Local, src0Global, 256);\n        AscendC::DataCopy(src1Local, src1Global, 32);\n        inQueueSrc0.EnQue(src0Local);\n        inQueueSrc1.EnQue(src1Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<uint32_t> src0Local = inQueueSrc0.DeQue<uint32_t>();\n        AscendC::LocalTensor<uint32_t> src1Local = inQueueSrc1.DeQue<uint32_t>();\n        AscendC::LocalTensor<uint32_t> dstLocal = outQueueDst.AllocTensor<uint32_t>();\n        uint32_t mask = 70;\n       uint64_t rsvdCnt = 0;\n        // reduceMode = true;    使用Counter模式\n        // src0BlockStride = 1;  单次迭代内数据间隔1个datablock，即数据连续读取和写入\n        // repeatTimes = 2;      Counter模式时，仅在部分产品型号下会生效\n        // src0RepeatStride = 4; 源操作数迭代间数据间隔4个datablock\n        // src1RepeatStride = 0; src1迭代间数据间隔0个datablock，即原位置读取\n        AscendC::GatherMask (dstLocal, src0Local, src1Local, true, mask, { 1, 2, 4, 0 }, rsvdCnt);\n        outQueueDst.EnQue<uint32_t>(dstLocal);\n        inQueueSrc0.FreeTensor(src0Local);\n        inQueueSrc1.FreeTensor(src1Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<uint32_t> dstLocal = outQueueDst.DeQue<uint32_t>();\n        AscendC::DataCopy(dstGlobal, dstLocal, 256);\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc0, inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<uint32_t> src0Global, src1Global, dstGlobal;\n};\nextern \"C\" __global__ __aicore__ void gather_mask_simple_kernel(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n{\n    KernelGatherMask op;\n    op.Init(src0Gm, src1Gm, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "Cast",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0073.html",
    "功能说明": "根据源操作数和目的操作数Tensor的数据类型进行精度转换。 在了解精度转换规则之前，需要先了解浮点数的表示方式和二进制的舍入规则： 浮点数的表示方式 half共16bit，包括1bit符号位（S），5bit指数位（E）和10bit尾数位（M）。 当E不全为0或不全为1时，表示的结果为： (-1) S * 2 E - 15 * (1 + M) 当E全为0时，表示的结果为： (-1) S * 2 -14 * M 当E全为1时，若M全为0，表示的结果为±inf（取决于符号位）；若M不全为0，表示的结果为nan。 上图中S=0，E=15，M = 2 -1 + 2 -2 ，表示的结果为1.75。 float共32bit，包括1bit符号位（S），8bit指数位（E）和23bit尾数位（M）。 当E不全为0或不全为1时，表示的结果为： (-1) S * 2 E - 127 * (1 + M) 当E全为0时，表示的结果为： (-1) S * 2 -126 * M 当E全为1时，若M全为0，表示的结果为±inf（取决于符号位）；若M不全为0，表示的结果为nan。 上图中S = 0，E = 127，M = 2 -1 + 2 -2 ，最终表示的结果为1.75 。 bfloat16_t共16bit，包括1bit符号位（S），8bit指数位（E）和7bit尾数位（M）。 当E不全为0或不全为1时，表示的结果为： (-1) S * 2 E - 127 * (1 + M) 当E全为0时，表示的结果为： (-1) S * 2 -126 * M 当E全为1时，若M全为0，表示的结果为±inf（取决于符号位）；若M不全为0，表示的结果为nan。 上图中S = 0，E = 127，M = 2 -1 + 2 -2 ，最终表示的结果为1.75。 二进制的舍入规则和十进制类似，具体如下： CAST_RINT模式下，若待舍入部分的第一位为0，则不进位；若第一位为1且后续位不全为0，则进位；若第一位为1且后续位全为0，当M的最后一位为0则不进位，当M的最后一位为1则进位。 CAST_FLOOR模式下，若S为0，则不进位；若S为1，当待舍入部分全为0则不进位，否则，进位。 CAST_CEIL模式下，若S为1，则不进位；若S为0，当待舍入部分全为0则不进位；否则，进位。 CAST_ROUND模式下，若待舍入部分的第一位为0，则不进位；否则，进位。 CAST_TRUNC模式下，总是不进位。 CAST_ODD模式下，若待舍入部分全为0，则不进位；若待舍入部分不全为0，当M的最后一位为1则不进位，当M的最后一位为0则进位。 精度转换规则如下表所示（为方便描述下文描述中的src代表源操作数，dst代表目的操作数）： 表1 精度转换规则 src类型 dst类型 精度转换规则介绍 float float 将src按照round_mode（精度转换处理模式，参见 参数说明 中的round_mode参数）取整，仍以float格式存入dst中。 示例：输入0.5， CAST_RINT模式输出0.0，CAST_FLOOR模式输出0.0，CAST_CEIL模式输出1.0，CAST_ROUND模式输出1.0，CAST_TRUNC模式输出0.0。 half 将src按照round_mode取到half所能表示的数，以half格式（溢出默认按照饱和处理）存入dst中。 示例：输入0.5 + 2 -12 ，写成float的表示形式：2 -1 * (1 + 2 -11 )，因此E = -1 + 127 = 126，M = 2 -11。 half的指数位可以表示出2 -1 ，E = -1 + 15 = 14，但half只有10 bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数0000000000，E = 14，M = 0，最终表示的结果为0.5； CAST_FLOOR模式舍入得尾数0000000000，E = 14，M = 0，最终表示的结果为0.5； CAST_CEIL模式舍入得尾数0000000001，E = 14，M = 2 -10 ，最终表示的结果为0.5 + 2 -11 ； CAST_ROUND模式舍入得尾数0000000001，E = 14，M = 2 -10 ，最终表示的结果为0.5 + 2 -11 ； CAST_TRUNC模式舍入得尾数0000000000，E = 14，M = 0，最终表示的结果为0.5； CAST_ODD模式舍入得尾数0000000001，E = 14，M = 2 -10 ，最终表示的结果为0.5 + 2 -11 。 int64_t 将src按照round_mode取整，以int64_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入2 22 + 0.5， CAST_RINT模式输出2 22 ，CAST_FLOOR模式输出2 22 ，CAST_CEIL模式输出2 22 + 1，CAST_ROUND模式输出2 22 + 1，CAST_TRUNC模式输出2 22 。 int32_t 将src按照round_mode取整，以int32_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入2 22 + 0.5， CAST_RINT模式输出2 22 ，CAST_FLOOR模式输出2 22 ，CAST_CEIL模式输出2 22 + 1，CAST_ROUND模式输出2 22 + 1，CAST_TRUNC模式输出2 22 。 int16_t 将src按照round_mode取整，以int16_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入2 22 + 0.5， CAST_RINT模式输出2 15 - 1（溢出处理），CAST_FLOOR模式输出2 15 - 1（溢出处理），CAST_CEIL模式输出2 15 - 1（溢出处理），CAST_ROUND模式输出2 15 - 1（溢出处理），CAST_TRUNC模式输出2 15 - 1（溢出处理）。 bfloat16_t 将src按照round_mode取到bfloat16_t所能表示的数，以bfloat16_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入0.5+ 2 -9 + 2 -11 ，写成float的表示形式：2 -1 * (1 + 2 -8 + 2 -10 )，因此E = -1 + 127 = 126，M = 2 -8 + 2 -10 。 bfloat16_t的指数位位数和float的相同，有E = 126，但bfloat16_t只有7bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数0000001，E = 126，M = 2 -7 ，最终表示的结果为0.5 + 2 -8 ； CAST_FLOOR模式舍入得尾数0000000，E = 126，M = 0，最终表示的结果为0.5； CAST_CEIL模式舍入得尾数0000001，E = 126，M = 2 -7 ，最终表示的结果为0.5 + 2 -8 ； CAST_ROUND模式舍入得尾数0000001，E = 126，M = 2 -7 ，最终表示的结果为0.5 + 2 -8 ； CAST_TRUNC模式舍入得尾数0000000，E = 126，M = 0，最终表示的结果为0.5。 half float 将src以float格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1.5 - 2 -10 ，输出1.5 - 2 -10 。 int32_t 将src按照round_mode取整，以int32_t格式存入dst中。 示例：输入-1.5， CAST_RINT模式输出-2，CAST_FLOOR模式输出-2，CAST_CEIL模式输出-1，CAST_ROUND模式输出-2，CAST_TRUNC模式输出-1。 int16_t 将src按照round_mode取整，以int16_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入2 7 - 0.5， CAST_RINT模式输出2 7 ，CAST_FLOOR模式输出2 7 - 1，CAST_CEIL模式输出2 7 ，CAST_ROUND模式输出2 7 ，CAST_TRUNC模式输出2 7 - 1。 int8_t 将src按照round_mode取整，以int8_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入2 7 - 0.5， CAST_RINT模式输出2 7 - 1（溢出处理），CAST_FLOOR模式输出2 7 - 1，CAST_CEIL模式输出2 7 - 1（溢出处理），CAST_ROUND模式输出2 7 - 1（溢出处理），CAST_TRUNC模式输出2 7 - 1。 uint8_t 将src按照round_mode取整，以uint8_t格式（溢出默认按照饱和处理）存入dst中。 负数输入会被视为异常。 示例：输入1.75， CAST_RINT模式输出2，CAST_FLOOR模式输出1，CAST_CEIL模式输出2，CAST_ROUND模式输出2，CAST_TRUNC模式输出1。 int4b_t 将src按照round_mode取整，以int4b_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入1.5， CAST_RINT模式输出2，CAST_FLOOR模式输出1，CAST_CEIL模式输出2，CAST_ROUND模式输出2，CAST_TRUNC模式输出1。 bfloat16_t float 将src以float格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1.5 - 2 -6 ，输出1.5 - 2 -6 。 int32_t 将src按照round_mode取整，以int32_t格式（溢出默认按照饱和处理）存入dst中。 示例：输入2 6 + 0.5 CAST_RINT模式输出2 6 ，CAST_FLOOR模式输出2 6 ，CAST_CEIL模式输出2 6 + 1，CAST_ROUND模式输出2 6 + 1，CAST_TRUNC模式输出2 6 。 int4b_t half 将src以half格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1，输出1.0。 uint8_t half 将src以half格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入1，输出1.0。 int8_t half 将src以half格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入-1，输出-1.0。 int16_t half 将src按照round_mode取到half所能表示的数，以half格式存入dst中。 示例：输入2 12 + 2，写成half的表示形式：2 12 * (1 + 2 -11 )，要求E = 12 + 15 = 27，M = 2 -11 ： 由于half只有10bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数0000000000，E = 27，M = 0，最终表示的结果为2 12 ； CAST_FLOOR模式舍入得尾数0000000000，E = 27，M = 0，最终表示的结果为2 12 ； CAST_CEIL模式舍入得尾数0000000001，E = 27，M = 2 -10 ，最终表示的结果为2 12 + 4； CAST_ROUND模式舍入得尾数0000000001，E = 27，M = 2 -10 ，最终表示的结果为2 12 + 4； CAST_TRUNC模式舍入得尾数0000000000，E = 27，M = 0，最终表示的结果为2 12 。 float 将src以float格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入2 15 - 1，输出2 15 - 1。 int32_t float 将src按照round_mode取到float所能表示的数，以float格式存入dst中。 示例：输入2 25 + 3，写成float的表示形式：2 25 * (1 + 2 -24 + 2 -25 )，要求E = 25 + 127 = 152， M = 2 -24 + 2 -25。 由于float只有23bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数00000000000000000000001，E = 152，M = 2 -23 ，最终表示的结果为2 25 + 4； CAST_FLOOR模式舍入得尾数00000000000000000000000，E = 152，M = 0，最终表示的结果为2 25 ； CAST_CEIL模式舍入得尾数00000000000000000000001，E = 152，M = 2 -23 ，最终表示的结果为2 25 + 4； CAST_ROUND模式舍入得尾数00000000000000000000001，E = 152，M = 2 -23 ，最终表示的结果为2 25 + 4； CAST_TRUNC模式舍入得尾数00000000000000000000000，E = 152，M = 0，最终表示的结果为2 25 。 int64_t 将src以int64_t格式存入dst中，不存在精度转换问题，无舍入模式。 示例：输入2 31 - 1，输出2 31 - 1。 int16_t 将src以int16_t格式（溢出默认按照饱和处理）存入dst中，不存在精度转换问题，无舍入模式。 示例：输入2 31 - 1，输出2 15 - 1。 half 与 SetDeqScale(half scale) 接口配合使用，输出src / 2 17 * scale * 2 17 。 int64_t int32_t 将src以int32_t格式（溢出默认按照饱和处理）存入dst中，不存在精度转换问题，无舍入模式。 示例：输入2 31 ，输出2 31 - 1。 float 将src按照round_mode取到float所能表示的数，以float格式存入dst中。 示例：输入2 35 + 2 12 + 2 11 ，写成float的表示形式：2 35 * (1 + 2 -23 + 2 -24 )，要求E = 35 + 127 = 162，M = 2 -23 + 2 -24 。 由于float只有23bit尾数位，因此灰色部分要进行舍入。 CAST_RINT模式舍入得尾数00000000000000000000010，E = 162，M = 2 -22 ，最终表示的结果为2 35 + 2 13 ； CAST_FLOOR模式舍入得尾数00000000000000000000001，E = 162，M = 2 -23 ，最终表示的结果为2 25 + 2 12 ； CAST_CEIL模式舍入得尾数00000000000000000000010，E = 162，M = 2 -22 ，最终表示的结果为2 25 + 2 13 ； CAST_ROUND模式舍入得尾数00000000000000000000010，E = 162，M = 2 -22 ，最终表示的结果为2 25 + 2 13 ； CAST_TRUNC模式舍入得尾数00000000000000000000001，E = 162，M = 2 -23 ，最终表示的结果为2 25 + 2 12 。",
    "函数原型": "template <typename T1, typename T2>\n__aicore__ inline void Cast(const LocalTensor<T1>& dstLocal, const LocalTensor<T2>& srcLocal, const RoundMode& round_mode, const uint32_t calCount)",
    "参数说明": "表2 模板参数说明 参数名 描述 T1 目的操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型见 表4 Atlas 推理系列产品 AI Core ，支持的数据类型见 表5 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型见 表6 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型见 表7 Atlas 200I/500 A2 推理产品 ，支持的数据类型见 表8 T2 源操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型见 表4 Atlas 推理系列产品 AI Core ，支持的数据类型见 表5 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型见 表6 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型见 表7 Atlas 200I/500 A2 推理产品 ，支持的数据类型见 表8 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表3 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 round_mode 输入 精度转换处理模式，类型是RoundMode。 RoundMode为枚举类型，用以控制精度转换处理模式，具体定义为： enum class RoundMode { CAST_NONE = 0 , // 在转换有精度损失时表示CAST_RINT模式，不涉及精度损失时表示不舍入 CAST_RINT , // rint，四舍六入五成双舍入 CAST_FLOOR , // floor，向负无穷舍入 CAST_CEIL , // ceil，向正无穷舍入 CAST_ROUND , // round，四舍五入舍入 CAST_TRUNC , // trunc，向零舍入 CAST_ODD , // Von Neumann rounding，最近邻奇数舍入 };",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(int32_t);\n// repeatTimes = 8, 64 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride = 8, srcRepStride = 4, no gap between repeats\nAscendC::Cast(dstLocal, srcLocal, AscendC::RoundMode::CAST_CEIL, mask, 8, { 1, 1, 8, 4 });",
    "错误": null
  },
  {
    "API名称": "CastDeq",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0074.html",
    "功能说明": "对输入做量化并进行精度转换。不同的数据类型，转换公式不同。 在输入类型为int16_t的情况下， 对int16_t类型的输入做量化并进行精度转换，得到int8_t/uint8_t类型的数据。使用该接口前需要调用 SetDeqScale 设置scale、offset、signMode等量化参数。 通过模板参数isVecDeq控制是否选择向量量化模式。 当isVecDeq=false时，根据SetDeqScale设置的scale、offset、signMode，对输入做量化并进行精度转换。计算公式如下： 当isVecDeq=true时，根据SetDeqScale设置的一段128B的UB上的16组量化参数scale 0 -scale 15 、offset 0 -offset 15 、signMode 0 -signMode 15 ，以循环的方式对输入做量化并进行精度转换。计算公式如下： 在输入类型为int32_t的情况下，对int32_t类型的输入做量化并进行精度转换，得到half类型的数据。使用该接口前需要调用 SetDeqScale 设置scale参数。 .",
    "函数原型": "template <typename T1, typename T2, bool isVecDeq = true, bool halfBlock = true>\n__aicore__ inline void CastDeq(const LocalTensor<T1>& dstLocal, const LocalTensor<T2>& srcLocal, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 halfBlock 对int16_t类型的输入做量化并进行精度转换得到int8_t/uint8_t类型的数据时，halfBlock参数用于指示输出元素存放在上半还是下半Block。halfBlock=true时，结果存放在下半Block；halfBlock=false时，结果存放在上半Block，如图 图1 。 T1 输出Tensor的数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int8_t/uint8_t /half Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int8_t/uint8_t /half Atlas 推理系列产品 AI Core ，支持的数据类型为：int8_t/uint8_t 和SetDeqScale接口的signMode入参配合使用，当signMode=true时输出数据类型int8_t；signMode=false时输出数据类型uint8_t。 T2 输入Tensor的数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t /int32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t /int32_t Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t isVecDeq 和SetDeqScale(const LocalTensor<T>& src)接口配合使用，当SetDeqScale接口传入Tensor时，isVecDeq必须为true。 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。",
    "返回值": "无",
    "调用示例": "int32_t mask = 256 / sizeof(int16_t);\n// repeatTimes = 2, 128 elements one repeat, 256 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::CastDeq<uint8_t, int16_t, true, true, true>(dstLocal, srcLocal, mask, 2, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "ReduceMax",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0076.html",
    "功能说明": "在所有的输入数据中找出最大值及最大值对应的索引位置。归约指令的总体介绍请参考 如何使用归约指令 。",
    "函数原型": "template <typename T>\n__aicore__ inline void ReduceMax(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<T>& workLocal, const int32_t count, bool calIndex = 0)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证4字节对齐（针对half数据类型），8字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 workLocal 输入 API执行期间， 部分硬件型号 需要一块空间用于存储中间结果，空间大小需要满足最小所需空间的要求，具体计算方法可参考下文 ReduceMax计算示意图 中的介绍。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，需要使用workLocal。 Atlas 推理系列产品 AI Core ，需要使用workLocal Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，需要使用workLocal。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，需要使用workLocal。 Atlas 200I/500 A2 推理产品 ，需要使用workLocal。 count 输入 参与计算的元素个数。 参数取值范围和操作数的数据类型有关，数据类型不同，能够处理的元素个数最大值不同，最大处理的数据量不能超过UB大小限制。 calIndex 输入 指定是否获取最大值的索引，bool类型，默认值为false，取值： true：同时获取最大值和最大值索引。 false：不获取索引，只获取最大值。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 迭代次数。与 通用参数说明 中不同的是，支持更大的取值范围，保证不超过int32_t最大值的范围即可。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "// dstLocal,srcLocal和workLocal均为half类型,srcLocal的计算数据量为8320,并且连续排布，需要索引值，使用tensor高维切分计算接口，设定repeatTimes为65，mask为全部元素参与计算\nint32_t mask = 128;\nAscendC::ReduceMax<half>(dstLocal, srcLocal, workLocal, mask, 65, 8, true);",
    "错误": null
  },
  {
    "API名称": "ReduceMin",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0077.html",
    "功能说明": "在所有的输入数据中找出最小值及最小值对应的索引位置。归约指令的总体介绍请参考 如何使用归约指令 。ReduceMin计算原理参考 ReduceMax 。",
    "函数原型": "template <typename T>\n__aicore__ inline void ReduceMin(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<T>& workLocal, const int32_t count, bool calIndex = 0)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证4字节对齐（针对half数据类型），8字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 workLocal 输入 API执行期间， 部分硬件型号 需要一块空间用于存储中间结果，空间大小需要满足最小所需空间的要求，具体计算方法可参考 ReduceMax计算示意图 中的介绍。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，需要使用workLocal。 Atlas 推理系列产品 AI Core ，需要使用workLocal Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，需要使用workLocal。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，需要使用workLocal。 Atlas 200I/500 A2 推理产品 ，需要使用workLocal。 count 输入 参与计算的元素个数。 参数取值范围和操作数的数据类型有关，数据类型不同，能够处理的元素个数最大值不同，最大处理的数据量不能超过UB大小限制。 calIndex 输入 指定是否获取最小值的索引，bool类型，默认值为false，取值： true：同时获取最小值和最小值索引。 false：不获取索引，只获取最小值。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 迭代次数。与 通用参数说明 中不同的是，支持更大的取值范围，保证不超过int32_t最大值的范围即可。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "// dstLocal,srcLocal和workLocal均为half类型,srcLocal的计算数据量为8320,并且连续排布，需要索引值，使用tensor高维切分计算接口，设定repeatTimes为65，mask为全部元素参与计算\nint32_t mask = 128;\nAscendC::ReduceMin<half>(dstLocal, srcLocal, workLocal, mask, 65, 8, true);",
    "错误": null
  },
  {
    "API名称": "ReduceSum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0078.html",
    "功能说明": "对所有的输入数据求和。归约指令的总体介绍请参考 如何使用归约指令 。 ReduceSum的相加方式分为两种： 方式一：同一repeat内先按照二叉树累加、不同repeat的结果也按照二叉树累加。 假设源操作数为128个half类型的数据[data0,data1,data2...data127]，一个repeat可以计算完，计算过程如下。 data0和data1相加得到data00，data2和data3相加得到data01，...，data124和data125相加得到data62，data126和data127相加得到data63； data00和data01相加得到data000，data02和data03相加得到data001，...，data62和data63相加得到data031； 以此类推，得到目的操作数为1个half类型的数据[data]。 需要注意的是两两相加的计算过程中，计算结果大于65504时结果保存为65504。例如源操作数为[60000,60000,-30000,100]，首先60000+60000溢出，结果为65504，第二步计算-30000+100=-29900，第四步计算65504-29900=35604。 方式二：同一repeat内采用二叉树累加，不同repeat的结果按顺序累加。 不同硬件形态对应的ReduceSum相加方式如下： Atlas 训练系列产品 采用方式一 Atlas 推理系列产品 AI Core 采用方式一 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 tensor前n个数据计算接口采用方式二，tensor高维切分计算接口采用方式一 Atlas A3 训练系列产品/Atlas A3 推理系列产品 tensor前n个数据计算接口采用方式二，tensor高维切分计算接口采用方式一 Atlas 200I/500 A2 推理产品 采用方式一 workLocal支持两种处理方式： 方式一：按照如下计算公式计算最小所需空间： // 先定义一个向上取整函数 int RoundUp ( int a , int b ) { return ( a + b - 1 ) / b ; } // 然后定义参与计算的数据类型 int typeSize = 2 ; // half类型为2Bytes，float类型为4Bytes，按需填入 // 再根据数据类型定义两个单位 int elementsPerBlock = 32 / typeSize ; // 1个datablock存放的元素个数 int elementsPerRepeat = 256 / typeSize ; // 1次repeat可以处理的元素个数 // 最后确定首次最大repeat值 int firstMaxRepeat = repeatTimes ; // 此处需要注意：对于tensor高维切分计算接口，firstMaxRepeat就是repeatTimes；对于tensor前n个数据计算接口，firstMaxRepeat为count/elementsPerRepeat，比如在half类型下firstMaxRepeat就是count/128，在float类型下为count/64，按需填入，对于count<elementsPerRepeat的场景，firstMaxRepeat就是1 int iter1OutputCount = firstMaxRepeat ; // 第一轮操作产生的元素个数 int iter1AlignEnd = RoundUp ( iter1OutputCount , elementsPerBlock ) * elementsPerBlock ; // 第一轮产生的元素个数做向上取整 int finalWorkLocalNeedSize = iter1AlignEnd ; // 最终workLocal所需的elements空间大小就是第一轮操作产生元素做向上取整后的结果 方式二：传入任意大小的workLocal，workLocal的值不会被改变。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void ReduceSum(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<T>& workLocal, const int32_t count)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 预留参数，为后续的功能做保留。保持默认值即可。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证2字节对齐（针对half数据类型），4字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 workLocal 输入 指令执行期间用于存储中间结果，用于内部计算所需操作空间，需特别注意空间大小，参见 约束说明 。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型需要与目的操作数保持一致。 count 输入 参与计算的元素个数。 参数取值范围和操作数的数据类型有关，数据类型不同，能够处理的元素个数最大值不同，最大处理的数据量不能超过UB大小限制。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 迭代次数。与 通用参数说明 中不同的是，支持更大的取值范围，保证不超过int32_t最大值的范围即可。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "// dstLocal,srcLocal和workLocal均为half类型,srcLocal的计算数据量为8320,并且连续排布，使用tensor高维切分计算接口，设定repeatTimes为65，mask为全部元素参与计算\nint32_t mask = 128;\nAscendC::ReduceSum<half>(dstLocal, srcLocal, workLocal, mask, 65, 8);",
    "错误": null
  },
  {
    "API名称": "WholeReduceMax",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0079.html",
    "功能说明": "每个repeat内所有数据求最大值以及其索引index，返回的索引值为每个repeat内部索引。归约指令的总体介绍请参考 如何使用归约指令 。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void WholeReduceMax(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint64_t mask[], const int32_t repeatTimes, const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride, ReduceOrder order = ReduceOrder::ORDER_VALUE_INDEX)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证4字节对齐（针对half数据类型），8字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 返回索引和最值时，单位为dstLocal数据类型所占字节长度的两倍。比如当dstLocal为half时，单位为4Bytes； 仅返回最值时，单位为dstLocal数据类型所占字节长度； 仅返回索引时，单位为uint32_t类型所占字节长度。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考 dataBlockStride 。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。 order 输入 使用order参数指定dstLocal中index与value的相对位置以及返回结果行为，ReduceOrder类型，默认值为ORDER_VALUE_INDEX。取值范围如下： ORDER_VALUE_INDEX：表示value位于低半部，返回结果存储顺序为[value, index]。 ORDER_INDEX_VALUE：表示index位于低半部，返回结果存储顺序为[index, value]。 ORDER_ONLY_VALUE：表示只返回最值，返回结果存储顺序为[value]。 ORDER_ONLY_INDEX：表示只返回最值索引，返回结果存储顺序为[index]。 Atlas 训练系列产品 ，支持ORDER_VALUE_INDEX。 Atlas 推理系列产品 AI Core ，支持ORDER_VALUE_INDEX、ORDER_INDEX_VALUE。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持ORDER_VALUE_INDEX、ORDER_INDEX_VALUE、ORDER_ONLY_VALUE、ORDER_ONLY_INDEX。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持ORDER_VALUE_INDEX、ORDER_INDEX_VALUE、ORDER_ONLY_VALUE、ORDER_ONLY_INDEX。 Atlas 200I/500 A2 推理产品 ，支持ORDER_VALUE_INDEX、ORDER_ONLY_VALUE。",
    "返回值": "无",
    "调用示例": "// dstLocal,srcLocal均为half类型,srcLocal的计算数据量为512，连续排布，计算结果也需要连续排布，使用tensor高维切分计算接口，设定mask为最多的128个全部元素参与计算\n// 根据以上信息，推断出repeatTimes为4，dstRepStride为1，srcBlkStride为1，srcRepStride为8\n// 若求最大值及索引，并且需要存储顺序为[value, index]的结果，可以使用默认order，接口示例为：\nAscendC::WholeReduceMax<half>(dstLocal, srcLocal, 128, 4, 1, 1, 8);\n// 若求最大值及索引，并且需要存储顺序为[index, value]的结果，接口示例为：\nAscendC::WholeReduceMax<half>(dstLocal, srcLocal, 128, 4, 1, 1, 8, AscendC::ReduceOrder::ORDER_INDEX_VALUE);",
    "错误": null
  },
  {
    "API名称": "WholeReduceMin",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0080.html",
    "功能说明": "每个repeat内所有数据求最小值以及其索引index，返回的索引值为每个repeat内部索引。归约指令的总体介绍请参考 如何使用归约指令 。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void WholeReduceMin(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint64_t mask[], const int32_t repeatTimes, const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride, ReduceOrder order = ReduceOrder::ORDER_VALUE_INDEX)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证4字节对齐（针对half数据类型），8字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 返回索引和最值时，单位为dstLocal数据类型所占字节长度的两倍。比如当dstLocal为half时，单位为4Bytes； 仅返回最值时，单位为dstLocal数据类型所占字节长度； 仅返回索引时，单位为uint32_t类型所占字节长度。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考 dataBlockStride 。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。 order 输入 使用order参数指定dstLocal中index与value的相对位置以及返回结果行为，ReduceOrder类型，默认值为ORDER_VALUE_INDEX。取值范围如下： ORDER_VALUE_INDEX：表示value位于低半部，返回结果存储顺序为[value, index]。 ORDER_INDEX_VALUE：表示index位于低半部，返回结果存储顺序为[index, value]。 ORDER_ONLY_VALUE：表示只返回最值，返回结果存储顺序为[value]。 ORDER_ONLY_INDEX：表示只返回最值索引，返回结果存储顺序为[index]。 Atlas 训练系列产品 ，支持ORDER_VALUE_INDEX。 Atlas 推理系列产品 AI Core ，支持ORDER_VALUE_INDEX、ORDER_INDEX_VALUE。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持ORDER_VALUE_INDEX、ORDER_INDEX_VALUE、ORDER_ONLY_VALUE、ORDER_ONLY_INDEX。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持ORDER_VALUE_INDEX、ORDER_INDEX_VALUE、ORDER_ONLY_VALUE、ORDER_ONLY_INDEX。 Atlas 200I/500 A2 推理产品 ，支持ORDER_VALUE_INDEX、ORDER_ONLY_VALUE。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\nclass KernelReduce {\npublic:\n    __aicore__ inline KernelReduce() {}\n    __aicore__ inline void Init(__gm__ uint8_t* src, __gm__ uint8_t* dstGm)\n    {\n        srcGlobal.SetGlobalBuffer((__gm__ half*)src);\n        dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm);\n        repeat = srcDataSize / mask;\n        pipe.InitBuffer(inQueueSrc, 1, srcDataSize * sizeof(half));\n        pipe.InitBuffer(outQueueDst, 1, dstDataSize * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>();\n        AscendC::DataCopy(srcLocal, srcGlobal, srcDataSize);\n        inQueueSrc.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n        AscendC::WholeReduceMin<half>(dstLocal, srcLocal, mask, repeat, 1, 1, 8); // 使用默认order, ReduceOrder::ORDER_VALUE_INDEX\n        outQueueDst.EnQue<half>(dstLocal);\n        inQueueSrc.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstLocal, dstDataSize);\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<half> srcGlobal, dstGlobal;\n    int srcDataSize = 1024;\n    int dstDataSize = 16;\n    int mask = 128;\n    int repeat = 0;\n};\nextern \"C\" __global__ __aicore__ void reduce_kernel(__gm__ uint8_t* src, __gm__ uint8_t* dstGm)\n{\n    KernelReduce op;\n    op.Init(src, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "WholeReduceSum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0081.html",
    "功能说明": "每个迭代内所有数据求和。归约指令的总体介绍请参考 如何使用归约指令 。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void WholeReduceSum(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint64_t mask[], const int32_t repeatTimes, const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证2字节对齐（针对half数据类型），4字节对齐（针对float数据类型）。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，支持的数据类型为：支持数据类型half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 单位为dstLocal数据类型所占字节长度。比如当dstLocal为half时，单位为2Bytes。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考 dataBlockStride 。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "// dstLocal,srcLocal均为half类型,srcLocal的计算数据量为512，连续排布，计算结果也需要连续排布，使用tensor高维切分计算接口，设定mask为最多的128个全部元素参与计算\n// 根据以上信息，推断出repeatTimes为4，dstRepStride为1，srcBlkStride为1，srcRepStride为8\nAscendC::WholeReduceSum<half>(dstLocal, srcLocal, 128, 4, 1, 1, 8);",
    "错误": null
  },
  {
    "API名称": "BlockReduceMax",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0082.html",
    "功能说明": "对每个datablock内所有元素求最大值。归约指令的总体介绍请参考 如何使用归约指令 。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void BlockReduceMax(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal,const int32_t repeat, const uint64_t mask[], const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证16字节对齐（针对half数据类型），32字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 repeat 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 每个repeat(8个datablock)归约后，得到8个元素，所以输入类型为half类型时，RepStride单位为16Byte；输入类型为float类型时，RepStride单位为32Byte。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考 dataBlockStride 。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "int32_t mask = 256/sizeof(half);\nint repeat = 1;\n// repeat = 1, 128 elements one repeat, 128 elements total\n// srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride = 1, srcRepStride = 8, no gap between repeats\nAscendC::BlockReduceMax<half>(dstLocal, srcLocal, repeat, mask, 1, 1, 8);",
    "错误": null
  },
  {
    "API名称": "BlockReduceMin",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0083.html",
    "功能说明": "对每个datablock内所有元素求最小值。归约指令的总体介绍请参考 如何使用归约指令 。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void BlockReduceMin (const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal,const int32_t repeat, const uint64_t mask[], const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证16字节对齐（针对half数据类型），32字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 repeat 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 每个repeat(8个datablock)归约后，得到8个元素，所以源操作数类型为half类型时，RepStride单位为16Byte；源操作数类型为float类型时，RepStride单位为32Byte。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考 dataBlockStride 。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "int32_t mask = 256/sizeof(half);\nint repeat = 1;\n// repeatTimes = 1, 128 elements one repeat, 128 elements total\n// srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride = 1, srcRepStride = 8, no gap between repeats\nAscendC::BlockReduceMin<half>(dstLocal, srcLocal, repeat, mask, 1, 1, 8);",
    "错误": null
  },
  {
    "API名称": "BlockReduceSum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0084.html",
    "功能说明": "对每个datablock内所有元素求和。源操作数相加采用二叉树方式，两两相加。归约指令的总体介绍请参考 如何使用归约指令 。 以128个half类型的数据求和为例，每个datablock可以计算16个half类型数据，分成8个datablock进行计算；每个datablock内，通过二叉树的方式，两两相加，BlockReduceSum求和示意图如下。 图1 BlockReduceSum求和示意图 需要注意的是两两相加的计算过程中，计算结果大于65504时结果保存为65504。例如，源操作数为[60000,60000,-30000,100]，首先60000+60000溢出，结果为65504，然后计算-30000+100=-29900，最后计算65504-29900=35604，计算示意图如下图所示。 图2 存在溢出场景时的计算示意图",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void BlockReduceSum (const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal,const int32_t repeat, const uint64_t mask[], const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证16字节对齐（针对half数据类型），32字节对齐（针对float数据类型）。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 repeat 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 每个repeat(8个datablock)归约后，得到8个元素，所以输入类型为half类型时，RepStride单位为16Byte；输入类型为float类型时，RepStride单位为32Byte。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考 dataBlockStride 。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "int32_t mask = 256/sizeof(half);\nint repeat = 1;\n// repeat = 1, 128 elements one repeat, 128 elements total\n// srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride = 1, srcRepStride = 8, no gap between repeats\nAscendC::BlockReduceSum<half>(dstLocal, srcLocal, repeat, mask, 1, 1, 8);",
    "错误": null
  },
  {
    "API名称": "PairReduceSum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0085.html",
    "功能说明": "PairReduceSum：相邻两个（奇偶）元素求和，例如（a1, a2, a3, a4, a5, a6...），相邻两个数据求和为（a1+a2, a3+a4, a5+a6, ......）。归约指令的总体介绍请参考 如何使用归约指令 。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void PairReduceSum(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t repeat, const uint64_t mask[], const int32_t dstRepStride, const int32_t srcBlkStride, const int32_t srcRepStride)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 repeat 输入 迭代次数。取值范围为[0, 255]。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。PairReduce完成后，一个repeat的长度减半。即单位为128Byte。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考 dataBlockStride 。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "int32_t mask = 256/sizeof(half);\nint repeat = 1;\n// repeat = 1, 128 elements one repeat, 128 elements total\n// srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride = 1, srcRepStride = 8, no gap between repeats\nAscendC::PairReduceSum<half>(dstLocal, srcLocal, repeat, mask, 1, 1, 8);",
    "错误": null
  },
  {
    "API名称": "RepeatReduceSum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0086.html",
    "功能说明": "每个repeat内所有数据求和。和 WholeReduceSum 接口相比，不支持mask逐bit模式。建议使用功能更全面的 WholeReduceSum 接口。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void RepeatReduceSum(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t repeat, const int32_t mask, const int32_t dstBlkStride, const int32_t srcBlkStride, const int32_t dstRepStride, const int32_t srcRepStride);",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要保证2字节对齐（针对half数据类型），4字节对齐（针对float数据类型）。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 Atlas 训练系列产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float repeat 输入 重复迭代次数。取值范围为[0, 255]。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代才能完成所有数据的读取与计算。repeat表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 mask 输入 用于控制每次迭代内连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]。 dstBlkStride 输入 此参数无效，可以配置任意值。 srcBlkStride 输入 单次迭代内datablock的地址步长。详细说明请参考 dataBlockStride 。 dstRepStride 输入 目的操作数相邻迭代间的地址步长。以一个repeat归约后的长度为单位。 单位为dstLocal数据类型所占字节长度。比如当dstLocal为half时，单位为2Bytes。 注意，此参数值 Atlas 训练系列产品 不支持配置0。 srcRepStride 输入 源操作数相邻迭代间的地址步长，即源操作数每次迭代跳过的datablock数目。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "// dstLocal，srcLocal均为half类型，srcLocal的计算数据量为512，连续排布，计算结果也需要连续排布，使用tensor高维切分计算接口，设定mask为最多的128个全部元素参与计算\n// 根据以上信息，推断出repeat为4，dstRepStride为1，srcBlkStride为1，srcRepStride为8，dstBlkStride无效，此处配置0，因此接口示例为：\nAscendC::RepeatReduceSum<half>(dstLocal, srcLocal, 4, 128, 0, 1, 1, 8);",
    "错误": null
  },
  {
    "API名称": "Transpose",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0199.html",
    "功能说明": "用于实现16*16的二维矩阵数据块转置或者[N,C,H,W]与[N,H,W,C]数据格式互相转换。",
    "函数原型": "template <typename T>\n__aicore__ inline void Transpose(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 普通转置 : Atlas 训练系列产品 ，支持的数据类型为：uint16_t/int16_t/half Atlas 推理系列产品 AI Core ，支持的数据类型为：uint16_t/int16_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/int16_t/half Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/int16_t/half Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint16_t/int16_t/half 增强转置 : transposeType为TRANSPOSE_ND2ND_B16： Atlas 推理系列产品 AI Core ，支持的数据类型为：uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint16_t transposeType为TRANSPOSE_NCHW2NHWC或TRANSPOSE_NHWC2NCHW： Atlas 推理系列产品 AI Core ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass KernelTranspose {\npublic:\n    __aicore__ inline KernelTranspose() {}\n    __aicore__ inline void Init(__gm__ uint8_t* src, __gm__ uint8_t* dstGm)\n    {\n        srcGlobal.SetGlobalBuffer((__gm__ half*)src);\n        dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm);\n\n        pipe.InitBuffer(inQueueSrc, 1, srcDataSize * sizeof(half));\n        pipe.InitBuffer(outQueueDst, 1, dstDataSize * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>();\n        AscendC::DataCopy(srcLocal, srcGlobal, srcDataSize);\n        inQueueSrc.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n\n        AscendC::Transpose<half>(dstLocal, srcLocal);\n\n        outQueueDst.EnQue<half>(dstLocal);\n        inQueueSrc.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstLocal, dstDataSize);\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n\n    AscendC::GlobalTensor<half> srcGlobal, dstGlobal;\n    int srcDataSize = 256;\n    int dstDataSize = 256;\n};\n\nextern \"C\" __global__ __aicore__ void transpose_kernel(__gm__ uint8_t* src, __gm__ uint8_t* dstGm)\n{\n    KernelTranspose op;\n    op.Init(src, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "TransDataTo5HD",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0200.html",
    "功能说明": "数据格式转换，一般用于将NCHW格式转换成NC1HWC0格式。特别的，也可以用于二维矩阵数据块的转置。完成转置功能时，相比于 Transpose 接口，Transpose仅支持16*16大小的矩阵转置；本接口单次repeat内可处理512Byte的数据（16个datablock），根据数据类型不同，支持不同shape的矩阵转置（比如数据类型为half时，单次repeat可完成16*16大小的矩阵转置），同还可以支持多次repeat操作。 单次repeat内转换规则如下： 当输入数据类型位宽为16位时，每个datablock中包含16个数，指令内部会循环16次，每次循环都会分别从指定的16个datablock中的对应位置取值，组成一个新的datablock单元放入目的地址中。如下图所示，图中的srcLocalList[0]-srcLocalList[15]代表源操作数的16个datablock。 图1 输入数据类型位宽为16位时的转换规则 当数据类型位宽为32位时，每个datablock包含8个数，指令内部会循环8次，每次循环都会分别从指定的16个datablock中的对应位置取值，组成2个新的datablock放入目的地址中。如下图所示： 图2 输入数据类型位宽为32位时的转换规则 当数据类型位宽为8位时，每个datablock包含32个数，指令内部会循环16次，每次循环都会分别从指定的16个datablock中的对应位置取值，组成半个datablock放入目的地址中，读取和存放是在datablock的高半部还是低半部由参数srcHighHalf和dstHighHalf决定。如下图所示： 图3 输入数据类型位宽为8位时的转换规则 基于以上的转换规则，使用该接口进行NC1HWC0格式转换或者矩阵转置。NC1HWC0格式转换相对复杂，这里给出其具体的转换方法： NCHW格式转换成NC1HWC0格式时，如果是数据类型的位宽为32位或者16位，则C0=16；如果数据类型的位宽为8位，则C0=32。下图以C0=16为例进行介绍：",
    "函数原型": "// NCHW_CONV_ADDR_LIST_SIZE值为16\ntemplate <typename T>\n__aicore__ inline void TransDataTo5HD(const LocalTensor<T> (&dstLocalList)[NCHW_CONV_ADDR_LIST_SIZE], const LocalTensor<T> (&srcLocalList)[NCHW_CONV_ADDR_LIST_SIZE], const TransDataTo5HDParams& nchwconvParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half Atlas 推理系列产品 AI Core ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为： int8_t/uint8_t/int16_t/uint16_t/half/int32_t/uint32_t/float",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass KernelTransDataTo5HD {\npublic:\n    __aicore__ inline KernelTransDataTo5HD() {}\n    __aicore__ inline void Init(__gm__ uint8_t *src, __gm__ uint8_t *dstGm)\n    {\n        srcGlobal.SetGlobalBuffer((__gm__ half *)src);\n        dstGlobal.SetGlobalBuffer((__gm__ half *)dstGm);\n        pipe.InitBuffer(inQueueSrc, 1, srcDataSize * sizeof(half));\n        pipe.InitBuffer(workQueueSrc1, 1, 16 * sizeof(uint64_t));\n        pipe.InitBuffer(workQueueSrc2, 1, 16 * sizeof(uint64_t));\n        pipe.InitBuffer(outQueueDst, 1, dstDataSize * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>();\n        AscendC::DataCopy(srcLocal, srcGlobal, srcDataSize);\n        inQueueSrc.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n        AscendC::TransDataTo5HDParams transDataParams;\n        transDataParams.dstHighHalf = false;\n        transDataParams.srcHighHalf = false;\n        transDataParams.repeatTimes = 16;\n        transDataParams.dstRepStride = 16;\n        transDataParams.srcRepStride = 1;\n        for(int j = 0; j < 4; j++) {\n            // // 入参类型是LocalTensor的调用方式\n            // AscendC::LocalTensor<half> dstLocalList[16];\n            // for (int i = 0; i < 16; i++) {\n            //     dstLocalList[i] = dstLocal[j * c0size * height * width + width * i];\n            // }\n            // AscendC::LocalTensor<half> srcLocalList[16];\n            // for (int i = 0; i < 16; i++) {\n            //     srcLocalList[i] = srcLocal[j * c0size * height * width + height * width * i];\n            // }\n            // AscendC::TransDataTo5HD<half>(dstLocalList, srcLocalList, transDataParams);\n            // 入参类型是LocalTensor地址值的调用方式，推荐使用\n            uint64_t dstLocalList[16];\n            for (int i = 0; i < 16; i++) {\n               dstLocalList[i] = (uint64_t)(dstLocal[j * c0size * height * width + width * i].GetPhyAddr());\n            }\n            uint64_t srcLocalList[16];\n            for (int i = 0; i < 16; i++) {\n               srcLocalList[i] = (uint64_t)(srcLocal[j * c0size * height * width + height * width * i].GetPhyAddr());\n            }\n            AscendC::TransDataTo5HD<half>(dstLocalList, srcLocalList, transDataParams);\n            // // 入参类型是地址LocalTensor的调用方式\n            // AscendC::LocalTensor<uint64_t> dst = workQueueSrc1.AllocTensor<uint64_t>();\n            // for (int i = 0; i < 16; i++) {\n            //     dst.SetValue(i, (uint64_t)(dstLocal[j * c0size * height * width + width * i].GetPhyAddr()));\n            // }\n            // AscendC::LocalTensor<uint64_t> src = workQueueSrc2.AllocTensor<uint64_t>();\n            // for (int i = 0; i < 16; i++) {\n            //     src.SetValue(i, (uint64_t)(srcLocal[j * c0size * height * width + height * width * i].GetPhyAddr()));\n            // }\n            // AscendC::TransDataTo5HD<half>(dst, src, transDataParams);\n            // workQueueSrc1.FreeTensor(dst);\n            // workQueueSrc2.FreeTensor(src);\n        }\n        outQueueDst.EnQue<half>(dstLocal);\n        inQueueSrc.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstLocal, dstDataSize);\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> workQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> workQueueSrc2;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<half> srcGlobal, dstGlobal;\n    int srcDataSize = 16384;\n    int dstDataSize = 16384;\n    int width = 16; // H\n    int height = 16; // W\n    int c0size = 16; // C0\n};\n\nextern \"C\" __global__ __aicore__ void vec_transdata5hd_b16_nchw2nc1hwc0(__gm__ uint8_t *src, __gm__ uint8_t *dstGm)\n{\n    KernelTransDataTo5HD op;\n    op.Init(src, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "Duplicate",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0088.html",
    "功能说明": "将一个变量或立即数复制多次并填充到向量中。",
    "函数原型": "template <typename T>\nvoid Duplicate(const LocalTensor<T>& dstLocal, const T& scalarValue, const int32_t& calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float/bfloat16_t Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float Atlas 训练系列产品 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 scalarValue 输入 被复制的源操作数，支持输入变量和立即数，数据类型需与dstLocal中元素的数据类型保持一致。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 矢量计算单元，每次读取连续的8个datablock（每个block32Bytes，共256Bytes）数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 dstBlockStride 输入 单次迭代内，矢量目的操作数不同datablock间地址步长。 dstRepeatStride 输入 相邻迭代间，矢量目的操作数相同datablock地址步长。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\nhalf scalar = 18.0;\n// repeatTimes = 2, 128 elements one repeat, 256 elements total\n// dstBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride = 8, no gap between repeats\nAscendC::Duplicate(dstLocal, scalar, mask, 2, 1, 8 );",
    "错误": null
  },
  {
    "API名称": "Brcb",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0089.html",
    "功能说明": "给定一个输入张量，每一次取输入张量中的8个数填充到结果张量的8个datablock（32Bytes）中去，每个数对应一个datablock。",
    "函数原型": "template <typename T>\n__aicore__ inline void Brcb(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const uint8_t repeatTimes, const BrcbRepeatParams& repeatParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/half/bfloat16_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/half/bfloat16_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/half/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型和dstLocal保持一致。 每一次迭代读取src0Local中的8个元素，所以src0Local的元素个数不小于8 * repeatTimes。 repeatTimes 输入 指令迭代次数，每次迭代完成8个datablock的数据收集，数据范围：repeatTimes∈[0,255]。 repeatParams 输入 用于控制指令迭代的相关参数。 类型为BrcbRepeatParams，具体定义可参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_brcb.h。 ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 其中dstBlkStride、dstRepStride支持用户配置，参数说明参考 表3 。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\nclass VbrcbCase {\npublic:\n    __aicore__ inline VbrcbCase()\n    {}\n    __aicore__ inline void Init(__gm__ uint8_t *x, __gm__ uint8_t *y)\n    {\n        x_gm.SetGlobalBuffer(reinterpret_cast<__gm__ uint16_t *>(x));\n        y_gm.SetGlobalBuffer(reinterpret_cast<__gm__ uint16_t *>(y));\n        tpipe.InitBuffer(vecIn, 1, 16 * sizeof(uint16_t));\n        tpipe.InitBuffer(vecOut, 1, 256 * sizeof(uint16_t));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n    __aicore__ inline void CopyIn()\n    {\n        auto x_buf = vecIn.AllocTensor<uint16_t>();\n        AscendC::DataCopy(x_buf, x_gm, 16);\n        vecIn.EnQue(x_buf);\n    }\n    __aicore__ inline void Compute()\n    {\n        auto x_buf = vecIn.DeQue<uint16_t>();\n        auto y_buf = vecOut.AllocTensor<uint16_t>();\n        AscendC::Brcb(y_buf, x_buf, 2, {1,8});\n        vecOut.EnQue(y_buf);\n        vecIn.FreeTensor(x_buf);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        auto y_buf = vecOut.DeQue<uint16_t>();\n        AscendC::DataCopy(y_gm, y_buf, 256);\n        vecOut.FreeTensor(y_buf);\n    }\nprivate:\n    AscendC::GlobalTensor<uint16_t> x_gm;\n    AscendC::GlobalTensor<uint16_t> y_gm;\n    AscendC::TPipe tpipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> vecIn;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> vecOut;\n};\nextern \"C\" __global__ __aicore__ void vbrcb_uint16_t_16(__gm__ uint8_t *x, __gm__ uint8_t *y)\n{\n    VbrcbCase op;\n    op.Init(x, y);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "CreateVecIndex",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0090.html",
    "功能说明": "创建指定起始值的向量索引。",
    "函数原型": "template <typename T>\n__aicore__ inline void CreateVecIndex(LocalTensor<T> dstLocal, const T &firstValue, uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/half/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/half/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/half/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int16_t/half/int32_t/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 firstValue 输入 索引的第一个数值，数据类型需与dstLocal中元素的数据类型保持一致。 calCount 输入 参与计算的元素个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 通用参数说明 。 dstBlkStride 输入 单次迭代内，目的操作数不同datablock间地址步长。详细说明请参考 dataBlockStride 。 dstRepStride 输入 相邻迭代间，目的操作数相同datablock地址步长。详细说明请参考 repeatStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 1\n// dstBlkStride = 1, 单次迭代内数据连续写入\n// dstRepStride = 8, 相邻迭代内数据连续写入\nAscendC::CreateVecIndex(dstLocal, (T)0, mask, repeatTimes, dstBlkStride, dstRepStride);",
    "错误": null
  },
  {
    "API名称": "Gather",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0092.html",
    "功能说明": "给定输入的张量和一个地址偏移张量，本接口根据偏移地址将输入张量按元素收集到结果张量中。",
    "函数原型": "template <typename T>\n__aicore__ inline void Gather(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<uint32_t>& srcOffsetLocal, const uint32_t srcBaseAddr, const uint32_t count)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/float/half/bfloat16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/float/half/bfloat16_t Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/uint16_t/int32_t/uint32_t/float/half Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/uint32_t/int32_t/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 数据类型和dstLocal保持一致。 srcOffsetLocal 输入 每个元素在src中对应的地址偏移。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 该偏移量相对于src的起始基地址而言。单位为Bytes。地址偏移要大于等于0，取值应保证src元素类型位宽对齐，否则会导致非预期行为；同时需要保证偏移地址后不能超出UB大小数据的范围。 针对以下型号，地址偏移的取值范围不超出uint32_t的范围即可。 Atlas 推理系列产品 AI Core Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 针对以下型号，地址偏移的取值范围如下：当操作数为8位时，取值范围为[0, 2 16 -1]；当操作数为16位时，取值范围为[0, 2 17 -1]，当操作数为32位或者64位时，不超过uint32_t的范围即可，超出取值范围可能导致非预期输出。 Atlas 200I/500 A2 推理产品 srcBaseAddr 输入 srcLocal的起始基地址，单位为Bytes。取值应保证src元素类型位宽对齐，否则会导致非预期行为。 count 输入 执行处理的数据个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。参数类型为长度为2的uint64_t类型数组。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 参数取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，mask[1]为0，mask[0]∈(0, 2 64 -1]；当操作数为64位时，mask[1]为0，mask[0]∈(0, 2 32 -1]。 repeatTimes 输入 指令迭代次数，每次迭代完成8个datablock（32Bytes）的数据收集，数据范围：repeatTimes∈[0,255]。 特别地，针对以下型号： Atlas 200I/500 A2 推理产品 操作数为 8位 时，每次迭代完成 4个datablock （32Bytes）的数据收集。 dstRepStride 输入 相邻迭代间的地址步长，单位是datablock（32Bytes）。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\ntemplate <typename T>\nclass GatherTest {\npublic:\n    __aicore__ inline GatherTest() {}\n    __aicore__ inline void Init(__gm__ uint8_t* dstGm, __gm__ uint8_t* srcGm,\n        __gm__ uint8_t* srcOffsetGm, const uint32_t count)\n    {\n        m_elementCount = count;\n        m_dstGlobal.SetGlobalBuffer((__gm__ T*)dstGm);\n        m_srcGlobal.SetGlobalBuffer((__gm__ T*)srcGm);\n        m_srcOffsetGlobal.SetGlobalBuffer((__gm__ uint32_t*)srcOffsetGm);\n        m_pipe.InitBuffer(m_queIn, 2, m_elementCount * sizeof(uint32_t));\n        m_pipe.InitBuffer(m_queOut, 2, m_elementCount * sizeof(uint32_t));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = m_queIn.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, m_srcGlobal, m_elementCount);\n        m_queIn.EnQue(srcLocal);\n        AscendC::LocalTensor<uint32_t> srcOffsetLocal = m_queIn.AllocTensor<uint32_t>();\n        AscendC::DataCopy(srcOffsetLocal, m_srcOffsetGlobal, m_elementCount);\n        m_queIn.EnQue(srcOffsetLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal = m_queIn.DeQue<T>();\n        AscendC::LocalTensor<uint32_t> srcOffsetLocal = m_queIn.DeQue<uint32_t>();\n        AscendC::LocalTensor<T> dstLocal = m_queOut.AllocTensor<T>();\n        srcLocal.SetSize(m_elementCount);\n        AscendC::Gather(dstLocal, srcLocal, srcOffsetLocal, (uint32_t)0, m_elementCount);\n        m_queIn.FreeTensor(srcLocal);\n        m_queIn.FreeTensor(srcOffsetLocal);\n        m_queOut.EnQue(dstLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = m_queOut.DeQue<T>();\n        AscendC::DataCopy(m_dstGlobal, dstLocal, m_elementCount);\n        m_queOut.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe m_pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> m_queCalc;\n    AscendC::GlobalTensor<T> m_valueGlobal;\n    uint32_t m_concatRepeatTimes;\n    uint32_t m_sortRepeatTimes;\n    uint32_t m_extractRepeatTimes;\n    uint32_t m_elementCount;\n    AscendC::GlobalTensor<uint32_t> m_srcOffsetGlobal;\n    AscendC::GlobalTensor<T> m_srcGlobal;\n    AscendC::GlobalTensor<T> m_dstGlobal;\n    AscendC::TQue<AscendC::TPosition::VECIN, 2> m_queIn;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 2> m_queOut;\n}; // class GatherTest\n\nextern \"C\" __global__ __aicore__ void kernel_gather(GM_ADDR dstGm, GM_ADDR srcGm, GM_ADDR srcOffsetGm)\n{\n    GatherTest<half> op; \n    op.Init(dstGm, srcGm, srcOffsetGm, 128);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SetMaskCount",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0094.html",
    "功能说明": "设置mask模式为Counter模式。该模式下，不需要开发者去感知迭代次数、处理非对齐的尾块等操作，可直接传入计算数据量，实际迭代次数由Vector计算单元自动推断。mask模式分为Counter模式和Normal模式，两种模式的概念和使用场景请参考 如何使用掩码操作API 。",
    "函数原型": "__aicore__ inline void SetMaskCount()",
    "参数说明": "无",
    "返回值": "无",
    "调用示例": "请参考 Counter模式调用示例 。 父主题： 掩码操作 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": null
  },
  {
    "API名称": "SetMaskNorm",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0095.html",
    "功能说明": "设置mask模式为Normal模式。该模式为系统默认模式，支持开发者配置迭代次数。mask模式分为Counter模式和Normal模式，两种模式的概念和使用场景请参考 如何使用掩码操作API 。Normal模式的设置和使用流程请参考 如何使用掩码操作API 。",
    "函数原型": "__aicore__ inline void SetMaskNorm()",
    "参数说明": "无",
    "返回值": "无",
    "调用示例": "请参考 Normal模式调用示例 。 父主题： 掩码操作 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": null
  },
  {
    "API名称": "SetVectorMask",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0096.html",
    "功能说明": "用于在矢量计算时设置mask，使用前需要先调用 SetMaskCount / SetMaskNorm 设置mask模式。在不同的模式下，mask的含义不同： Normal模式下，mask参数用来控制单次迭代内参与计算的元素个数。此时又可以划分为如下两种模式： 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 逐 比特 模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。分为maskHigh（高位mask）和maskLow（低位mask）。参数取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，maskLow、maskHigh∈[0, 2 64 -1]，并且不同时为0；当操作数为32位时，maskHigh为0，maskLow∈(0, 2 64 -1]；当操作数为64位时，maskHigh为0，maskLow∈(0, 2 32 -1]。 Counter模式下，mask参数表示整个矢量计算参与计算的元素个数。",
    "函数原型": "template <typename T, MaskMode mode = MaskMode::NORMAL>\n__aicore__ static inline void SetVectorMask(const uint64_t maskHigh, const uint64_t maskLow)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 矢量计算操作数数据类型。 mode mask模式，MaskMode类型，定义如下： enum class MaskMode : uint8_t { NORMAL = 0 , // Normal模式 COUNTER // Counter模式 };\n\n表2 参数说明 参数名 输入/输出 描述 maskHigh 输入 Normal模式：对应Normal模式下的逐比特模式，可以按位控制哪些元素参与计算。传入高位mask值。 Counter模式：需要置0，本入参不生效。 maskLow 输入 Normal模式：对应Normal模式下的逐比特模式，可以按位控制哪些元素参与计算。传入低位mask值。 Counter模式：整个矢量计算过程中，参与计算的元素个数。 len 输入 Normal模式：对应Normal模式下的mask连续模式，表示单次迭代内表示前面连续的多少个元素参与计算。 Counter模式：整个矢量计算过程中，参与计算的元素个数。",
    "返回值": "无",
    "调用示例": "AscendC::LocalTensor<half> dstLocal;\nAscendC::LocalTensor<half> src0Local;\nAscendC::LocalTensor<half> src1Local;\n\n// Normal模式\nAscendC::SetMaskNorm();\nAscendC::SetVectorMask<half, AscendC::MaskMode::NORMAL>(0xffffffffffffffff, 0xffffffffffffffff);  // 逐bit模式\n\n// SetVectorMask<half, MaskMode::NORMAL>(128);  // 连续模式\n// 多次调用矢量计算API, 可以统一设置为Normal模式，并设置mask参数，无需在API内部反复设置，省去了在API反复设置的过程，会有一定的性能优势\n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::Add<half, false>(dstLocal, src0Local, src1Local, AscendC::MASK_PLACEHOLDER, 1, { 2, 2, 2, 8, 8, 8 });\nAscendC::Sub<half, false>(src0Local, dstLocal, src1Local, AscendC::MASK_PLACEHOLDER, 1, { 2, 2, 2, 8, 8, 8 });\nAscendC::Mul<half, false>(src1Local, dstLocal, src0Local, AscendC::MASK_PLACEHOLDER, 1, { 2, 2, 2, 8, 8, 8 });\nAscendC::ResetMask();",
    "错误": null
  },
  {
    "API名称": "ResetMask",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0097.html",
    "功能说明": "恢复mask的值为默认值（全1），表示矢量计算中每次迭代内的所有元素都将参与运算。",
    "函数原型": "__aicore__ inline void ResetMask()",
    "参数说明": "无",
    "返回值": "无",
    "调用示例": "AscendC::SetVectorMask<half, AscendC::MaskMode::NORMAL>(128);\nAscendC::ResetMask();",
    "错误": null
  },
  {
    "API名称": "SetDeqScale",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0099.html",
    "功能说明": "设置DEQSCALE寄存器的值。",
    "函数原型": "__aicore__ inline void SetDeqScale(half scale)",
    "参数说明": "表1 模板参数说明 参数名 描述 T vdeqTensor的数据类型。支持的数据类型为uint64_t。\n\n表2 参数说明 参数名 输入/输出 描述 scale（half） 输入 scale量化参数，half类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，用于 AddDeqRelu / Cast / CastDeq 的s322f16场景。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，用于 AddDeqRelu / Cast / CastDeq 的s322f16场景。 Atlas 推理系列产品 AI Core ：用于 AddDeqRelu 或者 Cast 的s322f16场景。 scale（float） 输入 scale量化参数，float类型。 用于 CastDeq （isVecDeq=false）场景设置DEQSCALE寄存器的值。 offset 输入 offset量化参数，int16_t类型，只有前9位有效。 用于 CastDeq （isVecDeq=false）的场景，设置offset。 signMode 输入 bool类型，表示量化结果是否带符号。 用于 CastDeq （isVecDeq=false）的场景，设置signMode。 vdeqTensor 输入 用于 CastDeq （isVecDeq=true）的场景，输入量化tensor，大小为128Byte。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 vdeqInfo 输入 存储量化tensor信息的数据结构，结构体内包含量化tensor中的16组量化参数 const uint8_t VDEQ_TENSOR_SIZE = 16 ; struct VdeqInfo { __aicore__ VdeqInfo () {} __aicore__ VdeqInfo ( const float vdeqScaleIn [ VDEQ_TENSOR_SIZE ], const int16_t vdeqOffsetIn [ VDEQ_TENSOR_SIZE ], const bool vdeqSignModeIn [ VDEQ_TENSOR_SIZE ]) { for ( int32_t i = 0 ; i < VDEQ_TENSOR_SIZE ; ++ i ) { vdeqScale [ i ] = vdeqScaleIn [ i ]; vdeqOffset [ i ] = vdeqOffsetIn [ i ]; vdeqSignMode [ i ] = vdeqSignModeIn [ i ]; } } float vdeqScale [ VDEQ_TENSOR_SIZE ] = { 0 }; int16_t vdeqOffset [ VDEQ_TENSOR_SIZE ] = { 0 }; bool vdeqSignMode [ VDEQ_TENSOR_SIZE ] = { 0 }; };",
    "返回值": "无",
    "调用示例": "AscendC::LocalTensor<int8_t> dstLocal;\nAscendC::LocalTensor<int16_t> srcLocal;\nAscendC::LocalTensor<uint64_t> tmpBuffer;\nuint32_t srcSize = 256;\n// Cast\nAscendC::LocalTensor<half> castDstLocal;\nAscendC::LocalTensor<int32_t> castSrcLocal;\nhalf scale = 1.0;\nAscendC::SetDeqScale(scale);\nAscendC::Cast(castDstLocal, castSrcLocal, AscendC::RoundMode::CAST_NONE, srcSize);\n// CastDeq\nfloat scale = 1.0;\nint16_t offset = 0;\nbool signMode = true;\nAscendC::SetDeqScale(scale, offset, signMode);\nAscendC::CastDeq<int8_t, int16_t, false, false>(dstLocal, srcLocal, srcSize);\n// CastVdeq\nfloat vdeqScale[16] = { 0 };\nint16_t vdeqOffset[16] = { 0 };\nbool vdeqSignMode[16] = { 0 };\nfor (int i = 0; i < 16; i++) {\n    vdeqScale[i] = 1.0;\n    vdeqOffset[i] = 0;\n    vdeqSignMode[i] = true;\n}\nAscendC::VdeqInfo vdeqInfo(vdeqScale, vdeqOffset, vdeqSignMode);\nAscendC::SetDeqScale<uint64_t>(tmpBuffer, vdeqInfo);\nAscendC::CastDeq<int8_t, int16_t, true, false>(dstLocal, srcLocal, srcSize);",
    "错误": null
  },
  {
    "API名称": "普通数据搬运",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0101.html",
    "功能说明": "普通数据搬运接口，适用于连续和不连续数据搬运。",
    "函数原型": "// 支持连续\ntemplate <typename T>\n__aicore__ inline void DataCopy(const LocalTensor<T>& dstLocal, const GlobalTensor<T>& srcGlobal, const uint32_t calCount)\n\n// 支持连续和不连续\ntemplate <typename T>\n__aicore__ inline void DataCopy(const LocalTensor<T>& dstLocal, const GlobalTensor<T>& srcGlobal, const DataCopyParams& repeatParams)",
    "参数说明": "表5 模板参数说明 参数名 描述 T 源操作数和目的操作数的数据类型。 dst_T 目的操作数的数据类型。 src_T 源操作数的数据类型。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\nclass KernelDataCopy {\npublic:\n    __aicore__ inline KernelDataCopy() {}\n    __aicore__ inline void Init(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n    {\n        src0Global.SetGlobalBuffer((__gm__ half*)src0Gm);\n        src1Global.SetGlobalBuffer((__gm__ half*)src1Gm);\n        dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm);\n        pipe.InitBuffer(inQueueSrc0, 1, 512 * sizeof(half));\n        pipe.InitBuffer(inQueueSrc1, 1, 512 * sizeof(half));\n        pipe.InitBuffer(outQueueDst, 1, 512 * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.AllocTensor<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.AllocTensor<half>();\n        AscendC::DataCopy(src0Local, src0Global, 512);\n        AscendC::DataCopy(src1Local, src1Global, 512);\n        inQueueSrc0.EnQue(src0Local);\n        inQueueSrc1.EnQue(src1Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.DeQue<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n        AscendC::Add(dstLocal, src0Local, src1Local, 512);\n        outQueueDst.EnQue<half>(dstLocal);\n        inQueueSrc0.FreeTensor(src0Local);\n        inQueueSrc1.FreeTensor(src1Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstLocal, 512);\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc0, inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<half> src0Global, src1Global, dstGlobal;\n};\nextern \"C\" __global__ __aicore__ void data_copy_kernel(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n{\n    KernelDataCopy op;\n    op.Init(src0Gm, src1Gm, dstGm);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Copy",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0106.html",
    "功能说明": "VECIN，VECCALC，VECOUT之间的搬运指令，支持mask操作和 DataBlock 间隔操作。",
    "函数原型": "template <typename T, bool isSetMask = true>\n__aicore__ inline void Copy(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint64_t mask[], const uint8_t repeatTimes, const CopyRepeatParams& repeatParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。起始地址需要保证32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。起始地址需要保证32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的数据结构。CopyRepeatParams类型。 具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_data_copy.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 参数说明请参考 表3 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 128;\n// repeatTimes = 4, 128 elements one repeat, 512 elements total\n// dstStride, srcStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::Copy(dstLocal, srcLocal, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "TPipe构造函数",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0108.html",
    "功能说明": "构造用来管理内存和同步的TPipe对象。",
    "函数原型": "__aicore__ inline TPipe()",
    "参数说明": "",
    "返回值": "无",
    "调用示例": "template <typename ComputeT> class KernelExample {\npublic:\n    __aicore__ inline KernelExample() {}\n    __aicore__ inline void Init(..., TPipe* pipeIn)\n    {\n        ...\n        pipe = pipeIn;\n        pipe->InitBuffer(xxxBuf, BUFFER_NUM, xxxSize);\n        ...\n    }\nprivate:\n    ...\n    TPipe* pipe;\n    ...\n};\nextern \"C\" __global__ __aicore__ void example_kernel(...) {\n    ...\n    TPipe pipe;\n    KernelExample<float> op;\n    op.Init(..., &pipe);\n    ...\n}",
    "错误": "缺失字段: 参数说明"
  },
  {
    "API名称": "GetTPipePtr",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0120.html",
    "功能说明": "创建 TPipe 对象时，对象初始化会设置全局唯一的TPipe指针。本接口用于获取该指针，获取该指针后，可进行 TPipe 相关的操作。",
    "函数原型": "__aicore__ inline AscendC::TPipe* GetTPipePtr()",
    "参数说明": "",
    "返回值": "",
    "调用示例": "class KernelAdd {\npublic:\n    __aicore__ inline KernelAdd() {}\n    __aicore__ inline void Init(GM_ADDR x, GM_ADDR y, GM_ADDR z)\n    {\n        xGm.SetGlobalBuffer((__gm__ half *)x + 2048 * AscendC::GetBlockIdx(), 2048);\n        yGm.SetGlobalBuffer((__gm__ half *)y + 2048 * AscendC::GetBlockIdx(), 2048);\n        zGm.SetGlobalBuffer((__gm__ half *)z + 2048 * AscendC::GetBlockIdx(), 2048);\n        GetTPipePtr()->InitBuffer(inQueueX, 2, 128 * sizeof(half));\n        GetTPipePtr()->InitBuffer(inQueueY, 2, 128 * sizeof(half));\n        GetTPipePtr()->InitBuffer(outQueueZ, 2, 128 * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        // 算子kernel逻辑\n        ...\n    }\nprivate:\n    AscendC::TQue<AscendC::TPosition::VECIN, 2> inQueueX, inQueueY;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 2> outQueueZ;\n    AscendC::GlobalTensor<half> xGm, yGm, zGm;\n};\nextern \"C\" __global__ __aicore__ void add_custom(GM_ADDR x, GM_ADDR y, GM_ADDR z)\n{\n    AscendC::TPipe pipe;\n    KernelAdd op;\n    op.Init(x, y, z);\n    op.Process();\n}",
    "错误": "缺失字段: 参数说明,返回值"
  },
  {
    "API名称": "简介",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0121.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "简介",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0136.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "// 用户自定义的构造TQueConfig的元函数\n__aicore__ constexpr AscendC::TQueConfig GetMyTQueConfig(bool nd2nzIn, bool nz2ndIn, bool scmBlockGroupIn,\n    uint32_t bufferLenIn, uint32_t bufferNumberIn, uint32_t consumerSizeIn, const AscendC::TPosition consumerIn[])\n{\n    return {\n        .nd2nz = nd2nzIn,\n        .nz2nd = nz2ndIn,\n        .scmBlockGroup = scmBlockGroupIn,\n        .bufferLen = bufferLenIn,\n        .bufferNumber = bufferNumberIn,\n        .consumerSize = consumerSizeIn,\n        .consumer = {consumerIn[0], consumerIn[1], consumerIn[2], consumerIn[3],\n            consumerIn[4], consumerIn[5], consumerIn[6], consumerIn[7]}\n    };\n}\nstatic constexpr AscendC::TPosition tp[8] = {AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX,\n            AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX, AscendC::TPosition::MAX};\nstatic constexpr AscendC::TQueConfig conf = GetMyTQueConfig(false, false, false, 0, 1, 0, tp);\ntemplate <typename srcType> class KernelAscendQuant {\npublic:\n    __aicore__ inline KernelAscendQuant() {}\n    __aicore__ inline void Init(GM_ADDR src_gm, GM_ADDR dst_gm, uint32_t inputSize)\n    {\n        dataSize = inputSize;\n        src_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType*>(src_gm), dataSize);\n        dst_global.SetGlobalBuffer(reinterpret_cast<__gm__ int8_t*>(dst_gm), dataSize);\n        pipe.InitBuffer(inQueueX, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, dataSize * sizeof(int8_t));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        ...\n    }\n    __aicore__ inline void Compute()\n    {\n        ...\n    }\n    __aicore__ inline void CopyOut()\n    {\n        ...\n    }\nprivate:\n    AscendC::GlobalTensor<srcType> src_global;\n    AscendC::GlobalTensor<int8_t> dst_global;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1, &conf> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1, &conf> outQueue;\n    uint32_t dataSize = 0;\n};\ntemplate <typename dataType> __aicore__ void kernel_ascend_quant_operator(GM_ADDR src_gm, GM_ADDR dst_gm, uint32_t dataSize)\n{\n    KernelAscendQuant<dataType> op;\n    op.Init(src_gm, dst_gm, dataSize);\n    op.Process();\n}",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "简介",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0146.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "表2 模板参数说明 参数名 描述 src 源逻辑位置，支持的TPosition可以为VECIN、VECOUT、A1、A2、B1、B2、CO1、CO2。关于TPosition的具体介绍请参考 TPosition 。支持的src和dst组合请参考 表1 。 dst 目的逻辑位置，TPosition可以为VECIN、VECOUT、A1、A2、B1、B2、CO1、CO2。 depth TQue的深度，一般不超过4。 mask 如果用户在某一个Que上，数据搬运的时候需要做转换，可以设置为0或1。一般不需要用户配置，默认为0。 设置为0，代表数据格式从ND转换为NZ，目前仅支持TPosition为A1或B1。",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,返回值"
  },
  {
    "API名称": "TBuf简介",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0160.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "InitSpmBuffer",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0166.html",
    "功能说明": "初始化SPM Buffer。 SPM Buffer的具体介绍和完整使用样例请参考 如何使用SPM Buffer 。",
    "函数原型": "template <typename T>\n__aicore__ inline void InitSpmBuffer(const GlobalTensor<T>& workspace, const int32_t bufferSize)",
    "参数说明": "参数名称 输入/输出 含义 wokspace 输入 workspace地址。 bufferSize 输入 SPM Buffer的大小，单位是字节。",
    "返回值": "无",
    "调用示例": "AscendC::TPipe pipe;\nint len = 1024; // 设置spm buffer为1024个类型为T的数据\nworkspace_gm.SetGlobalBuffer((__gm__ T *)usrWorkspace, len);  // 此处的usrWorkspace为用户自定义的workspace\nauto gm = workspace_gm[AscendC::GetBlockIdx() * len];\npipe.InitSpmBuffer(gm, len * sizeof(T));",
    "错误": null
  },
  {
    "API名称": "WriteSpmBuffer",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0167.html",
    "功能说明": "将需要溢出暂存的数据拷贝到SPM Buffer中。 SPM Buffer的具体介绍和完整使用样例请参考 如何使用SPM Buffer 。",
    "函数原型": "template <typename T>\n__aicore__ inline void WriteSpmBuffer(const LocalTensor<T>& writeLocal, const DataCopyParams& copyParams, int32_t writeOffset = 0)",
    "参数说明": "表1 接口参数说明 参数名称 输入/输出 含义 writeLocal 输入 需要溢出暂存的Local内存。 copyParams 输入 搬运参数，DataCopyParams类型，DataCopyParams结构定义请参考 表2 。 writeSize 输入 拷贝的元素个数。 writeOffset 输入 拷贝到SPM Buffer的偏移，单位为字节。 表2 DataCopyParams结构体参数定义 参数名称 含义 blockCount 指定该指令包含的连续传输数据块个数，取值范围：blockCount∈[1, 4095]。 blockLen 指定该指令每个连续传输数据块长度，单位为datablock(32B)。取值范围：blockLen∈[1, 65535]。 特别的，当dstLocal位于C2PIPE2GM时，单位为128B；当dstLocal位于C2时，表示源操作数的连续传输数据块长度，单位为64B。 srcStride 源操作数，相邻连续数据块的间隔（前面一个数据块的尾与后面数据块的头的间隔），单位为datablock(32B)。数据类型为uint16_t，srcStride不要超出该数据类型的取值范围。 dstStride 目的操作数，相邻连续数据块间的间隔（前面一个数据块的尾与后面数据块的头的间隔），单位为datablock(32B)。数据类型为uint16_t，dstStride不要超出该数据类型的取值范围。 特别的，当dstLocal位于C2PIPE2GM时，单位为128B；当dstLocal位于C2时，单位为64B。",
    "返回值": "无",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrcVecIn;\nint dataSize = 32; // 假设T为half类型，从ub上申请一块内存32 * sizeof(half)字节\nint offset = 32; // 拷贝到spmBuffer时偏移32字节\npipe.InitBuffer(inQueueSrcVecIn, 1, dataSize * sizeof(half));\nAscendC::LocalTensor<half> writeLocal = inQueueSrcVecIn.AllocTensor<half>();\nAscendC::DataCopyParams copyParams{1, 2, 0, 0}; // 从ub上搬运一个连续传输数据块，一个数据块的长度为2个datablock，一个datablock32bytes\npipe.WriteSpmBuffer(writeLocal, copyParams, offset);",
    "错误": null
  },
  {
    "API名称": "ReadSpmBuffer",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0168.html",
    "功能说明": "从SPM Buffer读回到local数据中。 SPM Buffer的具体介绍和完整使用样例请参考 如何使用SPM Buffer 。",
    "函数原型": "template <typename T>\n__aicore__ inline void ReadSpmBuffer(const LocalTensor<T>& readLocal, const DataCopyParams& copyParams, int32_t readOffset = 0)",
    "参数说明": "表1 接口参数说明 参数名称 输入/输出 含义 readLocal 输入 读回的目标local内存。 copyParams 输入 搬运参数，DataCopyParams类型，DataCopyParams结构定义请参考 表2 。 readSize 输入 读回的元素个数。 readOffset 输入 SPM Buffer的偏移，单位为字节。 表2 DataCopyParams结构体参数定义 参数名称 含义 blockCount 指定该指令包含的连续传输数据块个数，取值范围：blockCount∈[1, 4095]。 blockLen 指定该指令每个连续传输数据块长度，单位为datablock(32B)。取值范围：blockLen∈[1, 65535]。 特别的，当dstLocal位于C2PIPE2GM时，单位为128B；当dstLocal位于C2时，表示源操作数的连续传输数据块长度，单位为64B。 srcStride 源操作数，相邻连续数据块的间隔（前面一个数据块的尾与后面数据块的头的间隔），单位为datablock(32B)。数据类型为uint16_t，srcStride不要超出该数据类型的取值范围。 dstStride 目的操作数，相邻连续数据块间的间隔（前面一个数据块的尾与后面数据块的头的间隔），单位为datablock(32B)。数据类型为uint16_t，dstStride不要超出该数据类型的取值范围。 特别的，当dstLocal位于C2PIPE2GM时，单位为128B；当dstLocal位于C2时，单位为64B。",
    "返回值": "无",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrcVecIn;\nint dataSize = 32; // 假设T为half类型，从UB上申请一块内存32 * sizeof(half)字节\nint offset = 32; // 读回时在spmBuffer上偏移32字节\npipe.InitBuffer(inQueueSrcVecIn, 1, dataSize * sizeof(half));\nAscendC::LocalTensor<half> writeLocal = inQueueSrcVecIn.AllocTensor<half>();\nAscendC::DataCopyParams copyParams{1, 2, 0, 0};// 搬运一个连续传输数据块，连续传输数据块的长度为2个datablock，一个datablock32字节\npipe.ReadSpmBuffer(writeLocal, copyParams, offset);",
    "错误": null
  },
  {
    "API名称": "GetUserWorkspace",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0172.html",
    "功能说明": "获取用户使用的workspace指针。workspace的具体介绍请参考 如何使用workspace 。Kernel直调开发方式下，如果未开启 -DHAVE_WORKSPACE 编译选项，框架不会自动设置系统workspace。如果使用了 Matmul 等需要系统workspace的高阶API，kernel侧需要通过 SetSysWorkSpace 设置系统workspace，此时用户workspace需要通过该接口获取。",
    "函数原型": "__aicore__ inline GM_ADDR GetUserWorkspace(GM_ADDR workspace)",
    "参数说明": "表1 接口参数说明 参数名称 输入/输出 描述 workspace 输入 传入workspace的指针，包括系统workspace和用户使用的workspace。",
    "返回值": "用户使用workspace指针。 父主题： workspace 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "调用示例": "",
    "错误": null
  },
  {
    "API名称": "SetSysWorkSpace",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0171.html",
    "功能说明": "框架需要使用的workspace称之为系统workspace。 Matmul 等高阶API需要系统workspace，所以在使用该类API时，需要调用该接口，设置系统workspace的指针。采用工程化算子开发方式或者kernel直调方式（开启 -DHAVE_WORKSPACE 编译选项）时，不需要开发者手动设置，框架会自动设置。其他场景下，需要开发者调用SetSysWorkSpace进行设置。 在kernel侧调用该接口前，需要在host侧调用GetLibApiWorkSpaceSize获取系统workspace的大小，并在host侧设置workspacesize大小。样例如下： // 用户自定义的tiling函数 static ge :: graphStatus TilingFunc ( gert :: TilingContext * context ) { AddApiTiling tiling ; ... size_t usrSize = 256 ; // 设置用户需要使用的workspace大小。 // 如需要使用系统workspace需要调用GetLibApiWorkSpaceSize获取系统workspace的大小。 auto ascendcPlatform = platform_ascendc :: PlatformAscendC ( context -> GetPlatformInfo ()); uint32_t sysWorkspaceSize = ascendcPlatform . GetLibApiWorkSpaceSize (); size_t * currentWorkspace = context -> GetWorkspaceSizes ( 1 ); // 通过框架获取workspace的指针，GetWorkspaceSizes入参为所需workspace的块数。当前限制使用一块。 currentWorkspace [ 0 ] = usrSize + sysWorkspaceSize ; // 设置总的workspace的数值大小，总的workspace空间由框架来申请并管理。 ... }",
    "函数原型": "__aicore__ inline void SetSysWorkSpace(GM_ADDR workspace)",
    "参数说明": "表1 接口参数说明 参数名称 输入/输出 描述 workspace 输入 核函数传入的workspace的指针，包括系统workspace和用户使用的workspace。",
    "返回值": "无",
    "调用示例": "template<typename aType, typename bType, typename cType, typename biasType>\n__aicore__ inline void MatmulLeakyKernel<aType, bType, cType, biasType>::Init(\n    GM_ADDR a, GM_ADDR b, GM_ADDR bias, GM_ADDR c, GM_ADDR workspace, const TCubeTiling& tiling, float alpha)\n{\n    // 融合算子的初始化操作\n    // ...\n    AscendC::SetSysWorkspace(workspace);\n    if (GetSysWorkSpacePtr() == nullptr) {\n        return;\n    }\n}",
    "错误": null
  },
  {
    "API名称": "GetSysWorkSpacePtr",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0170.html",
    "功能说明": "获取系统workspace指针。部分高阶API如Matmul需要使用系统workspace，相关接口需要传入系统workspace指针，此时可以通过该接口获取。使用系统workspace时，host侧开发者需要自行申请系统workspace的空间，其预留空间大小可以通过 GetLibApiWorkSpaceSize 接口获取。具体内容请参考 如何使用workspace 。",
    "函数原型": "__aicore__ inline __gm__ uint8_t* __gm__ GetSysWorkSpacePtr()",
    "参数说明": "无",
    "返回值": "系统workspace指针。",
    "调用示例": "...\nREGIST_MATMUL_OBJ(&pipe, GetSysWorkSpacePtr(), mm, &tiling); // 初始化\n// CopyIn阶段：完成从GM到LocalMemory的搬运\nmm.SetTensorA(gm_a);    // 设置左矩阵A\nmm.SetTensorB(gm_b);    // 设置右矩阵B\nmm.SetBias(gm_bias);    // 设置Bias\n// Compute阶段：完成矩阵乘计算\nwhile (mm.Iterate()) { \n    // CopyOut阶段：完成从LocalMemory到GM的搬运\n    mm.GetTensorC(gm_c); \n}\n// 结束矩阵乘操作\nmm.End();",
    "错误": null
  },
  {
    "API名称": "同步控制简介",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0178.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "IBSet",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0202.html",
    "功能说明": "当不同核之间操作同一块全局内存且可能存在读后写、写后读以及写后写等数据依赖问题时，通过调用该函数来插入同步语句来避免上述数据依赖时可能出现的数据读写错误问题。调用IBSet设置某一个核的标志位，与IBWait成对出现配合使用，表示核之间的同步等待指令，等待某一个核操作完成。",
    "函数原型": "template <bool isAIVOnly = true>\n__aicore__ inline void IBSet(const GlobalTensor<int32_t>& gmWorkspace, const LocalTensor<int32_t>& ubWorkspace, int32_t blockIdx, int32_t eventID)",
    "参数说明": "表1 模板参数说明 参数名 描述 isAIVOnly 控制是否为AIVOnly模式，默认为true。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\nconstexpr int32_t TOTAL_LENGTH = 2 * 256;\nconstexpr int32_t USE_CORE_NUM = 2;\nconstexpr int32_t BLOCK_LENGTH = TOTAL_LENGTH / USE_CORE_NUM;\nclass KernelAdd {\npublic:\n    __aicore__ inline KernelAdd() {}\n    __aicore__ inline void Init(__gm__ uint8_t* x, __gm__ uint8_t* y, __gm__ uint8_t* sync, __gm__ uint8_t* z)\n    {\n        blockIdx = AscendC::GetBlockIdx();\n        xGm.SetGlobalBuffer((__gm__ half*)x);\n        yGm.SetGlobalBuffer((__gm__ half*)y);\n        sync_gm.SetGlobalBuffer((__gm__ int32_t *)(sync),256);\n        zGm.SetGlobalBuffer((__gm__ half*)z);\n\n        pipe.InitBuffer(inQueueX, 1, BLOCK_LENGTH * sizeof(half));\n        pipe.InitBuffer(inQueueY, 1, BLOCK_LENGTH * sizeof(half));\n        pipe.InitBuffer(vecIn, 1, 8 * sizeof(int32_t));\n        pipe.InitBuffer(outQueueZ, 1, BLOCK_LENGTH * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        if (blockIdx == 1) {\n            auto sync_buf = vecIn.AllocTensor<int32_t>();\n            AscendC::IBWait(sync_gm, sync_buf, 0, 0);\n            vecIn.FreeTensor(sync_buf);\n        }\n        CopyIn();\n        Compute();\n        CopyOut();\n        if (blockIdx == 0) {\n            auto sync_buf = vecIn.AllocTensor<int32_t>();\n            AscendC::IBSet(sync_gm, sync_buf, 0, 0);\n            vecIn.FreeTensor(sync_buf);\n        }\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> xLocal = inQueueX.AllocTensor<half>();\n        AscendC::LocalTensor<half> yLocal = inQueueY.AllocTensor<half>();\n        if (blockIdx == 1) {\n            AscendC::DataCopy(xLocal, zGm[0 * BLOCK_LENGTH], BLOCK_LENGTH);\n            AscendC::DataCopy(yLocal, yGm[1 * BLOCK_LENGTH], BLOCK_LENGTH);\n        } else {\n            AscendC::DataCopy(xLocal, xGm[0], BLOCK_LENGTH);\n            AscendC::DataCopy(yLocal, yGm[0], BLOCK_LENGTH);\n        }\n        inQueueX.EnQue(xLocal);\n        inQueueY.EnQue(yLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> xLocal = inQueueX.DeQue<half>();\n        AscendC::LocalTensor<half> yLocal = inQueueY.DeQue<half>();\n        AscendC::LocalTensor<half> zLocal = outQueueZ.AllocTensor<half>();\n        AscendC::Add(zLocal, xLocal, yLocal, BLOCK_LENGTH);\n        outQueueZ.EnQue<half>(zLocal);\n        inQueueX.FreeTensor(xLocal);\n        inQueueY.FreeTensor(yLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> zLocal = outQueueZ.DeQue<half>();\n        AscendC::DataCopy(zGm[blockIdx * BLOCK_LENGTH], zLocal, BLOCK_LENGTH);\n        outQueueZ.FreeTensor(zLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX, inQueueY, vecIn;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueZ;\n    AscendC::GlobalTensor<half> xGm, yGm, zGm;\n    AscendC::GlobalTensor<int32_t> sync_gm;\n    int32_t blockIdx = 0;\n};\n\nextern \"C\" __global__ __aicore__ void add_simple_kernel(__gm__ uint8_t* x, __gm__ uint8_t* y, __gm__ uint8_t* sync,\n    __gm__ uint8_t* z)\n{\n    KernelAdd op;\n    op.Init(x, y, sync, z);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "IBWait",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0203.html",
    "功能说明": "当不同核之间操作同一块全局内存且可能存在读后写、写后读以及写后写等数据依赖问题时，通过调用该函数来插入同步语句来避免上述数据依赖时可能出现的数据读写错误问题。IBWait与IBSet成对出现配合使用，表示核之间的同步等待指令，等待某一个核操作完成。",
    "函数原型": "template <bool isAIVOnly = true>\n__aicore__ inline void IBWait(const GlobalTensor<int32_t>& gmWorkspace, const LocalTensor<int32_t>& ubWorkspace, int32_t blockIdx, int32_t eventID)",
    "参数说明": "表1 模板参数说明 参数名 描述 isAIVOnly 控制是否为AIVOnly模式，默认为true。",
    "返回值": "无",
    "调用示例": "调用样例请参考 调用示例 。 父主题： 核间同步 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": null
  },
  {
    "API名称": "SyncAll",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0204.html",
    "功能说明": "当不同核之间操作同一块全局内存且可能存在读后写、写后读以及写后写等数据依赖问题时，通过调用该函数来插入同步语句来避免上述数据依赖时可能出现的数据读写错误问题。目前多核同步分为硬同步和软同步，硬件同步是利用硬件自带的全核同步指令由硬件保证多核同步，软件同步是使用软件算法模拟实现。",
    "函数原型": "template <bool isAIVOnly = true>\n__aicore__ inline void SyncAll(const GlobalTensor<int32_t>& gmWorkspace, const LocalTensor<int32_t>& ubWorkspace, const int32_t usedCores = 0)",
    "参数说明": "表1 模板参数说明 参数名 描述 isAIVOnly 控制SyncAll作用于纯Vector算子或融合（Cube和Vector融合）算子。可选值： true （默认值）：纯Vector算子的全核同步，仅执行Vector核的全核同步。 false ：融合算子的全核同步，先分别完成Vector核和Cube核的全核同步，再执行两者之间的同步。\n\n表2 参数说明 参数名称 输入/输出 含义 gmWorkspace 输入 gmWorkspace为用户定义的全局Global空间，作为所有核共用的缓存，用于保存每个核的状态标记，类型为GlobalTensor，支持的数据类型为int32_t。GlobalTensor数据结构的定义请参考 GlobalTensor 。 所需空间大小和使用注意项参见 约束说明 。 硬同步接口不支持该参数。 ubWorkspace 输入 ubWorkspace为用户定义的局部Local空间，每个核单独自用，用于标记当前核的状态。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT，支持的数据类型为int32_t。 所需空间大小参见 约束说明 。 硬同步接口不支持该参数。 usedCores 输入 指定多少个核之间的同步，传入数值不能超过算子调用时指定的逻辑blockDim。此参数为默认参数，不传此参数表示全核软同步。 仅在软同步接口中支持，硬同步接口不支持该参数。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\nconst int32_t DEFAULT_SYNCALL_NEED_SIZE = 8;\n\nclass KernelSyncAll {\npublic:\n    __aicore__ inline KernelSyncAll() {}\n    __aicore__ inline void Init(__gm__ uint8_t* srcGm, __gm__ uint8_t* dstGm, __gm__ uint8_t* workGm,\n        __gm__ uint8_t* syncGm)\n    {\n        blockNum = AscendC::GetBlockNum(); // 获取核总数\n        perBlockSize = srcDataSize / blockNum; // 每个核平分处理相同个数\n        blockIdx = AscendC::GetBlockIdx(); // 获取当前工作的核ID\n        srcGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ float*>(srcGm + blockIdx * perBlockSize * sizeof(float)),\n            perBlockSize);\n        dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ float*>(dstGm + blockIdx * perBlockSize * sizeof(float)),\n            perBlockSize);\n        workGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ float*>(workGm), srcDataSize);\n        syncGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ int32_t*>(syncGm), blockNum * DEFAULT_SYNCALL_NEED_SIZE);\n        pipe.InitBuffer(inQueueSrc1, 1, perBlockSize * sizeof(float));\n        pipe.InitBuffer(inQueueSrc2, 1, perBlockSize * sizeof(float));\n        pipe.InitBuffer(workQueue, 1, blockNum * DEFAULT_SYNCALL_NEED_SIZE * sizeof(int32_t));\n        pipe.InitBuffer(outQueueDst, 1, perBlockSize * sizeof(float));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        FirstCompute();\n        CopyToWorkGlobal(); // 当前工作核计算后的数据先保存到外部工作空间\n        // 等待所有核都完成计算\n        AscendC::LocalTensor<int32_t> workLocal = workQueue.AllocTensor<int32_t>();\n        AscendC::SyncAll(syncGlobal, workLocal);\n        workQueue.FreeTensor(workLocal);\n        // 最终累加结果需要等所有核都计算完成\n        AscendC::LocalTensor<float> srcLocal2 = inQueueSrc2.DeQue<float>();\n        AscendC::LocalTensor<float> dstLocal = outQueueDst.AllocTensor<float>();\n        AscendC::DataCopy(dstLocal,srcLocal2,perBlockSize); // 当前核计算结果先保存到目的空间\n        inQueueSrc2.FreeTensor(srcLocal2);\n        for (int i = 0; i < blockNum; i++) {\n            if (i != blockIdx) {\n                CopyFromOtherCore(i); // 从外部工作空间读取数据\n                Accumulate(dstLocal); // 所有数据都累加到目的空间\n            }\n        }\n        outQueueDst.EnQue(dstLocal);\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyToWorkGlobal()\n    {\n        AscendC::LocalTensor<float> dstLocal = outQueueDst.DeQue<float>();\n        AscendC::DataCopy(workGlobal[blockIdx * perBlockSize], dstLocal, perBlockSize);\n        outQueueDst.FreeTensor(dstLocal);\n    }\n    __aicore__ inline void CopyFromOtherCore(int index)\n    {\n        AscendC::LocalTensor<float> srcLocal = inQueueSrc1.AllocTensor<float>();\n        AscendC::DataCopy(srcLocal, workGlobal[index * perBlockSize], perBlockSize);\n        inQueueSrc1.EnQue(srcLocal);\n    }\n    __aicore__ inline void Accumulate(const AscendC::LocalTensor<float> &dstLocal)\n    {\n        AscendC::LocalTensor<float> srcLocal1 = inQueueSrc1.DeQue<float>();\n        AscendC::Add(dstLocal, dstLocal, srcLocal1, perBlockSize);\n        inQueueSrc1.FreeTensor(srcLocal1);\n    }\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<float> srcLocal = inQueueSrc1.AllocTensor<float>();\n        AscendC::DataCopy(srcLocal, srcGlobal, perBlockSize);\n        inQueueSrc1.EnQue(srcLocal);\n    }\n    __aicore__ inline void FirstCompute()\n    {\n        AscendC::LocalTensor<float> srcLocal1 = inQueueSrc1.DeQue<float>();\n        AscendC::LocalTensor<float> srcLocal2 = inQueueSrc2.AllocTensor<float>();\n        AscendC::LocalTensor<float> dstLocal = outQueueDst.AllocTensor<float>();\n        float scalarValue(2.0);\n        AscendC::Muls(dstLocal, srcLocal1, scalarValue, perBlockSize);\n        AscendC::PipeBarrier<PIPE_V>();\n        AscendC::DataCopy(srcLocal2,dstLocal,perBlockSize);\n        inQueueSrc1.FreeTensor(srcLocal1);\n        inQueueSrc2.EnQue(srcLocal2);\n        outQueueDst.EnQue(dstLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<float> dstLocal = outQueueDst.DeQue<float>();\n        AscendC::DataCopy(dstGlobal, dstLocal, perBlockSize);\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc2;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> workQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<float> srcGlobal;\n    AscendC::GlobalTensor<float> dstGlobal;\n    AscendC::GlobalTensor<float> workGlobal;\n    AscendC::GlobalTensor<int32_t> syncGlobal;\n    int srcDataSize = 256;\n    int32_t blockNum = 0;\n    int32_t blockIdx = 0;\n    uint32_t perBlockSize = 0;\n};\n\nextern \"C\" __global__ __aicore__ void kernel_syncAll_float(__gm__ uint8_t* srcGm, __gm__ uint8_t* dstGm,\n    __gm__ uint8_t* workGm, __gm__ uint8_t* syncGm)\n{\n    KernelSyncAll op;\n    op.Init(srcGm, dstGm, workGm, syncGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "InitDetermineComputeWorkspace",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0206.html",
    "功能说明": "初始化GM共享内存的值，完成初始化后才可以调用 WaitPreBlock 和 NotifyNextBlock 。",
    "函数原型": "__aicore__ inline void InitDetermineComputeWorkspace(GlobalTensor<int32_t>& gmWorkspace, LocalTensor<int32_t>& ubWorkspace)",
    "参数说明": "表1 接口参数说明 参数名称 输入/输出 含义 gmWorkspace 输入 临时空间，初始化核间同步的共享内存，类型为GlobalTensor。 ubWorkspace 输入 临时空间，用于操作gmWorkspace，类型为LocalTensor。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T>\nclass SyncTest {\npublic:\n    __aicore__ inline SyncTest() {}\n    __aicore__ inline void Init(GM_ADDR dstGm, GM_ADDR srcGm, GM_ADDR gmWorkspace,\n    const DetermineComputeSyncTilingData& tiling_data)\n    {\n        m_elementCount = tiling_data.size;\n        m_tileNum = tiling_data.tileNum;\n        m_tileCount = m_elementCount / m_tileNum;\n\n        m_dstGlobal.SetGlobalBuffer((__gm__ T*)dstGm);\n        m_srcGlobal.SetGlobalBuffer((__gm__ T*)srcGm);\n        m_gmWorkspace.SetGlobalBuffer((__gm__ int32_t*)gmWorkspace);\n\n        m_pipe.InitBuffer(m_que, 1, m_elementCount * sizeof(T));\n        m_pipe.InitBuffer(m_queTmp, 1, 8 * sizeof(int32_t));\n    }\n\n    __aicore__ inline void Process()\n    {\n        AscendC::LocalTensor<int32_t> ubWorkspace = m_queTmp.AllocTensor<int32_t>();\n        AscendC::InitDetermineComputeWorkspace(m_gmWorkspace, ubWorkspace);\n        for(int64_t i = 0; i < m_tileNum; i++) {\n            // copy in\n            AscendC::LocalTensor<T> srcLocal = m_que.AllocTensor<T>();\n            AscendC::DataCopy(srcLocal, m_srcGlobal[i * m_tileCount], m_tileCount);\n\n            // copy out\n            AscendC::WaitPreBlock(m_gmWorkspace, ubWorkspace);\n            AscendC::SetAtomicAdd<T>();\n            AscendC::DataCopy(m_dstGlobal[i * m_tileCount], srcLocal, m_tileCount);\n            AscendC::SetAtomicNone();\n            AscendC::NotifyNextBlock(m_gmWorkspace, ubWorkspace);\n            m_que.FreeTensor(srcLocal);\n        }\n        m_queTmp.FreeTensor(ubWorkspace);\n    }\n\nprivate:\n    AscendC::TPipe m_pipe;\n    int64_t m_elementCount;\n    int64_t m_tileNum;\n    int64_t m_tileCount;\n    AscendC::GlobalTensor<T> m_srcGlobal;\n    AscendC::GlobalTensor<T> m_dstGlobal;\n    AscendC::GlobalTensor<int32_t> m_gmWorkspace;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> m_que;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> m_queTmp;\n}; // class SyncTest\n\nextern \"C\" __global__ __aicore__ void determine_compute_sync(GM_ADDR x, GM_ADDR y, GM_ADDR workspace, GM_ADDR tiling)\n{\n    GET_TILING_DATA(tiling_data, tiling);\n    GM_ADDR usrWorkspace = AscendC::GetUserWorkspace(workspace); // 获取用户workspace指针\n\n    SyncTest<float> op;\n    op.Init(y, x, usrWorkspace, tiling_data);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "WaitPreBlock",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0207.html",
    "功能说明": "通过读GM地址中的值，确认是否需要继续等待，当GM的值满足当前核的等待条件时，该核即可往下执行，进行下一步操作。使用接口前，请确保已经调用 InitDetermineComputeWorkspace 接口，初始化共享内存。",
    "函数原型": "__aicore__ inline void WaitPreBlock(GlobalTensor<int32_t>& gmWorkspace, LocalTensor<int32_t>& ubWorkspace)",
    "参数说明": "表1 接口参数说明 参数名称 输入/输出 含义 gmWorkspace 输入 临时空间，通过读取gmWorkspace，判断当前核是否可以继续往下执行，类型为GlobalTensor。 ubWorkspace 输入 临时空间，用于操作gmWorkspace，类型为LocalTensor。",
    "返回值": "无",
    "调用示例": "请参考 调用示例 。 父主题： 核间同步 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": null
  },
  {
    "API名称": "NotifyNextBlock",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0208.html",
    "功能说明": "通过写GM地址，通知下一个核当前核的操作已完成，下一个核可以进行操作。使用接口前，请确保已经调用 InitDetermineComputeWorkspace 接口，初始化共享内存。",
    "函数原型": "__aicore__ inline void NotifyNextBlock(GlobalTensor<int32_t>& gmWorkspace, LocalTensor<int32_t>& ubWorkspace)",
    "参数说明": "表1 接口参数说明 参数名称 输入/输出 含义 gmWorkspace 输入 临时空间，通过写gmWorkspace通知其他核当前核已执行完成，其他核可以继续往下执行，类型为GlobalTensor。 ubWorkspace 输入 临时空间，用于操作gmWorkspace，类型为LocalTensor。",
    "返回值": "无",
    "调用示例": "请参考 调用示例 。 父主题： 核间同步 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": null
  },
  {
    "API名称": "SetNextTaskStart",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00087.html",
    "功能说明": "在SuperKernel的子Kernel中调用，调用后的指令可以和后续其他的子Kernel实现并行，提升整体性能。 如 图1 所示，SuperKernel按序调用子Kernel，为保证子Kernel之间数据互不干扰，会在子Kernel间插入算子间同步进行保序，子Kernel N-1 调用该接口后，之后的指令会和后续子Kernel N 实现并行。 SuperKernel是一种算子的二进制融合技术，与源码融合不同，它聚焦于内核函数 (Kernel) 的二进制的调度方案，展开深度优化，于已编译的二进制代码基础上融合创建一个超级Kernel函数（SuperKernel），以调用子函数的方式调用多个其他内核函数，也就是子Kernel。相对于单算子下发，SuperKernel技术可以减少任务调度等待时间和调度开销，同时利用Task间隙资源进一步优化算子头开销。 开发者需要自行保证调用此接口后的指令不会与后序算子互相干扰而导致精度问题，推荐在整个算子最后一条搬运指令后调用此接口。 图1 通过SetNextTaskStart实现并行示意图",
    "函数原型": "template<pipe_t AIV_PIPE = PIPE_MTE3, pipe_t AIC_PIPE = PIPE_FIX>\n__aicore__ inline void SetNextTaskStart()",
    "参数说明": "表1 模板参数说明 参数名 描述 AIV_PIPE SetNextTaskStart之后运行的指令，如果位于AIV上的AIV_PIPE流水，可以与后序算子并行。AIV_PIPE的取值范围为PIPE_MTE2、PIPE_MTE3、PIPE_S、PIPE_V，流水类型介绍可参考 硬件流水类型 。 AIC_PIPE SetNextTaskStart之后运行的指令，如果位于AIC上的AIC_PIPE流水，可以与后序算子并行。AIC_PIPE的取值范围为PIPE_MTE1、PIPE_MTE2、PIPE_MTE3、PIPE_FIX、PIPE_M，流水类型介绍可参考 硬件流水类型 。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\nclass KernelEarlyStart {\npublic:\n    __aicore__ inline KernelEarlyStart() {}\n    __aicore__ inline void Init(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n    {\n        src0Global.SetGlobalBuffer((__gm__ half*)src0Gm);\n        src1Global.SetGlobalBuffer((__gm__ half*)src1Gm);\n        dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm);\n        pipe.InitBuffer(inQueueSrc0, 1, 512 * sizeof(half));\n        pipe.InitBuffer(inQueueSrc1, 1, 512 * sizeof(half));\n        pipe.InitBuffer(outQueueDst, 1, 512 * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.AllocTensor<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.AllocTensor<half>();\n        AscendC::DataCopy(src0Local, src0Global, 512);\n        AscendC::DataCopy(src1Local, src1Global, 512);\n        inQueueSrc0.EnQue(src0Local);\n        inQueueSrc1.EnQue(src1Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.DeQue<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n        AscendC::Add(dstLocal, src0Local, src1Local, 512);\n        outQueueDst.EnQue<half>(dstLocal);\n        inQueueSrc0.FreeTensor(src0Local);\n        inQueueSrc1.FreeTensor(src1Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstLocal, 512);\n        // 算子最后一条搬运指令后插入，且保证只调用一次\n       AscendC::SetNextTaskStart();\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc0, inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<half> src0Global, src1Global, dstGlobal;\n};\nextern \"C\" __global__ __aicore__ void early_start_kernel(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n{\n    KernelEarlyStart op;\n    op.Init(src0Gm, src1Gm, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "WaitPreTaskEnd",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00088.html",
    "功能说明": "在SuperKernel的子Kernel中调用，调用前的指令可以和前序其他的子Kernel实现并行，提升整体性能。 如 图1 所示，SuperKernel按序调用子Kernel，为保证子Kernel之间数据互不干扰，会在子Kernel间插入算子间同步进行保序，子Kernel N+1 调用该接口之前的指令会和前序子Kernel N 实现并行。 SuperKernel是一种算子的二进制融合技术，与源码融合不同，它聚焦于内核函数 (Kernel) 的二进制的调度方案，展开深度优化，于已编译的二进制代码基础上融合创建一个超级Kernel函数（SuperKernel），以调用子函数的方式调用多个其他内核函数，也就是子Kernel。相对于单算子下发，SuperKernel技术可以减少任务调度等待时间和调度开销，同时利用Task间隙资源进一步优化算子头开销。 开发者需要自行保证调用此接口前的指令不会与前序算子互相干扰而导致精度问题，推荐在整个算子第一条搬运指令前调用此接口。 图1 通过WaitPreTaskEnd实现并行示意图",
    "函数原型": "__aicore__ inline void WaitPreTaskEnd()",
    "参数说明": "无",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\nclass KernelEarlyStart {\npublic:\n    __aicore__ inline KernelEarlyStart() {}\n    __aicore__ inline void Init(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n    {\n        src0Global.SetGlobalBuffer((__gm__ half*)src0Gm);\n        src1Global.SetGlobalBuffer((__gm__ half*)src1Gm);\n        dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm);\n        pipe.InitBuffer(inQueueSrc0, 1, 512 * sizeof(half));\n        pipe.InitBuffer(inQueueSrc1, 1, 512 * sizeof(half));\n        pipe.InitBuffer(outQueueDst, 1, 512 * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.AllocTensor<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.AllocTensor<half>();\n        // 算子第一条搬运指令前插入，且保证只调用一次\n        AscendC::WaitPreTaskEnd();\n        AscendC::DataCopy(src0Local, src0Global, 512);\n        AscendC::DataCopy(src1Local, src1Global, 512);\n        inQueueSrc0.EnQue(src0Local);\n        inQueueSrc1.EnQue(src1Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.DeQue<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n        AscendC::Add(dstLocal, src0Local, src1Local, 512);\n        outQueueDst.EnQue<half>(dstLocal);\n        inQueueSrc0.FreeTensor(src0Local);\n        inQueueSrc1.FreeTensor(src1Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstLocal, 512);\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc0, inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<half> src0Global, src1Global, dstGlobal;\n};\nextern \"C\" __global__ __aicore__ void early_start_kernel(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n{\n    KernelEarlyStart op;\n    op.Init(src0Gm, src1Gm, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "DataCachePreload",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0176.html",
    "功能说明": "从源地址所在的特定GM地址预加载数据到data cache中。",
    "函数原型": "template <typename T>\n__aicore__ inline void DataCachePreload(const GlobalTensor<uint64_t> &srcTensor, const T cacheOffset)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 srcTensor 输入 源操作数，类型为GlobalTensor。支持的数据类型为：uint64_t。 cacheOffset 输入 在源操作数上偏移cacheOffset大小开始加载数据，单位为byte，支持的数据类型为：int16_t/int64_t。",
    "返回值": "无",
    "调用示例": "AscendC::GlobalTensor<uint64_t> srcGlobal;\nint64_t cacheOffset = 0;\nAscendC::DataCachePreload(srcGlobal, cacheOffset);",
    "错误": null
  },
  {
    "API名称": "DataCacheCleanAndInvalid",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0177.html",
    "功能说明": "在AI Core内部，Scalar单元和DMA单元都可能对Global Memory进行访问。 图1 DataCache内存层次示意图 如上图所示： DMA搬运单元读写Global Memory，数据通过DataCopy等接口在UB等Local Memory和Global Memory间交互，没有Cache一致性问题； Scalar单元访问Global Memory，首先会访问每个核内的Data Cache，因此存在Data Cache与Global Memory的Cache一致性问题。 该接口用来刷新Cache，保证Cache的一致性，使用场景如下： 读取Global Memory的数据，但该数据可能在外部被其余核修改，此时需要使用DataCacheCleanAndInvalid接口，直接访问Global Memory，获取最新数据； 用户通过Scalar单元写Global Memory的数据，希望立刻写出，也需要使用DataCacheCleanAndInvalid接口。",
    "函数原型": "template <typename T, CacheLine entireType, DcciDst dcciDst>\n__aicore__ inline void DataCacheCleanAndInvalid(const GlobalTensor<T>& dstTensor)",
    "参数说明": "表1 模板参数说明 参数名 描述 T dstTensor的数据类型。 entireType 指令操作的模式： SINGLE_CACHE_LINE：只刷新传入地址所在的Cache Line， 注意如果该地址非64B对齐，只会操作传入地址到64B对齐的部分。 ENTIRE_DATA_CACHE：此时传入的地址无效，核内会刷新整个Data Cache，但是耗时较大， 性能敏感的场景慎用 。 dcciDst 表示使用该接口来保证Data Cache与哪一种存储保持一致性，类型为DcciDst枚举类。 CACHELINE_ALL：与CACHELINE_OUT效果一致; CACHELINE_UB：预留参数，暂未支持; CACHELINE_OUT：表示通过该接口来保证Data Cache与Global Memory的一致性; CACHELINE_ATOMIC：预留参数，暂未支持。\n\n表2 参数说明 参数名 输入/输出 描述 dstTensor 输入 需要刷新Cache的Tensor。",
    "返回值": "无",
    "调用示例": "// 示例1：SINGLE_CACHE_LINE 模式，假设mmAddr_为0x40（64B对齐）\nAscendC::GlobalTensor<uint64_t> global;\nglobal.SetGlobalBuffer((__gm__ uint64_t*)mmAddr_ + AscendC::GetBlockIdx() * 1024);\nfor( int i = 0; i < 8; i++) {\n   global.SetValue(i, AscendC::GetBlockIdx());\n}\n// 由于首地址64B对齐，调用DataCacheCleanAndInvalid指令后，会立刻刷新前8个数\nAscendC::DataCacheCleanAndInvalid<uint64_t, AscendC::CacheLine::SINGLE_CACHE_LINE, AscendC::DcciDst::CACHELINE_OUT>(global);\n// 示例2：SINGLE_CACHE_LINE 模式，假设mmAddr_为0x20（非64B对齐）\nAscendC::GlobalTensor<uint64_t> global;\nglobal.SetGlobalBuffer((__gm__ uint64_t*)mmAddr_ + AscendC::GetBlockIdx() * 1024);\nfor( int i = 0; i < 8; i++) {\n   global.SetValue(i, AscendC::GetBlockIdx());\n}\n// 由于首地址非64B对齐，调用1条指令，只会刷新起始地址至64B字节对齐的部分，即前4个数\nAscendC::DataCacheCleanAndInvalid<uint64_t, AscendC::CacheLine::SINGLE_CACHE_LINE, AscendC::DcciDst::CACHELINE_OUT>(global);\n// 需要再次调用DataCacheCleanAndInvalid指令，刷新后4个数\nAscendC::DataCacheCleanAndInvalid<uint64_t, AscendC::CacheLine::SINGLE_CACHE_LINE, AscendC::DcciDst::CACHELINE_OUT>(global[4]);\n// 示例3：SINGLE_CACHE_LINE 模式，假设mmAddr_为0x40（64B对齐），多核处理场景（本样例仅做示例说明，便于开发者理解使用限制，非正常使用样例）\nAscendC::GlobalTensor<uint64_t> global;\nglobal.SetGlobalBuffer((__gm__ uint64_t*)mmAddr_);\nglobal.SetValue(AscendC::GetBlockIdx(), AscendC::GetBlockIdx());\n// 算子中多核操作虽然不在同一个地址，但在同一个CacheLine, 会出现数据的随机覆盖，和通用CPU的行为不同\n// 调用DataCacheCleanAndInvalid指令后，由于多核操作的时间不一致，最终结果存在随机性，后执行的核会覆盖前面核的结果\nAscendC::DataCacheCleanAndInvalid<uint64_t, AscendC::CacheLine::SINGLE_CACHE_LINE, AscendC::DcciDst::CACHELINE_OUT>(global);\n// 示例4：ENTIRE_DATA_CACHE 模式，假设mmAddr_为0x20（非64B对齐）\n// 本样例仅做示例说明，便于开发者理解使用限制，非正常使用样例\nAscendC::GlobalTensor<uint64_t> global;\nglobal.SetGlobalBuffer((__gm__ uint64_t*)mmAddr_ + AscendC::GetBlockIdx() * 1024);\nfor( int i = 0; i < 8; i++) {\n   global.SetValue(i, AscendC::GetBlockIdx());\n}\n// 刷新整个Data Cache，性能较差\nAscendC::DataCacheCleanAndInvalid<uint64_t, AscendC::CacheLine::ENTIRE_DATA_CACHE, AscendC::DcciDst::CACHELINE_OUT>(global);",
    "错误": null
  },
  {
    "API名称": "GetBlockNum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0184.html",
    "功能说明": "获取当前任务配置的核数，用于代码内部的多核逻辑控制等。",
    "函数原型": "__aicore__ inline int64_t GetBlockNum()",
    "参数说明": "无",
    "返回值": "当前任务配置的核数。",
    "调用示例": "#include \"kernel_operator.h\"\n// 在核内做简单的tiling计算时使用block_num，复杂tiling建议在host侧完成\n__aicore__ inline void InitTilingParam(int32_t& totalSize, int32_t& loopSize)\n{\n    loopSize = totalSize / AscendC::GetBlockNum();\n};",
    "错误": null
  },
  {
    "API名称": "GetBlockIdx",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0185.html",
    "功能说明": "获取当前核的index，用于代码内部的多核逻辑控制及多核偏移量计算等。",
    "函数原型": "__aicore__ inline int64_t GetBlockIdx()",
    "参数说明": "无",
    "返回值": "当前核的index，index的范围为[0, 用户配置的BlockDim数量 - 1]",
    "调用示例": "#include \"kernel_operator.h\"\nconstexpr int32_t SINGLE_CORE_OFFSET = 256;\nclass KernelGetBlockIdx {\npublic:\n    __aicore__ inline KernelGetBlockIdx () {}\n    __aicore__ inline void Init(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n    {\n        // 根据index对每个核进行地址偏移\n        src0Global.SetGlobalBuffer((__gm__ float*)src0Gm + AscendC::GetBlockIdx() * SINGLE_CORE_OFFSET);\n        src1Global.SetGlobalBuffer((__gm__ float*)src1Gm + AscendC::GetBlockIdx() * SINGLE_CORE_OFFSET);\n        dstGlobal.SetGlobalBuffer((__gm__ float*)dstGm + AscendC::GetBlockIdx() * SINGLE_CORE_OFFSET);\n        pipe.InitBuffer(inQueueSrc0, 1, 256 * sizeof(float));\n        pipe.InitBuffer(inQueueSrc1, 1, 256 * sizeof(float));\n        pipe.InitBuffer(selMask, 1, 256);\n        pipe.InitBuffer(outQueueDst, 1, 256 * sizeof(float));\n    }\n    ......\n};",
    "错误": null
  },
  {
    "API名称": "GetDataBlockSizeInBytes",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0186.html",
    "功能说明": "获取当前芯片版本一个datablock的大小，单位为byte。开发者根据datablock的大小来计算API指令中待传入的repeatTimes 、 DataBlock Stride 、 Repeat Stride 等参数值。",
    "函数原型": "__aicore__ inline constexpr int16_t GetDataBlockSizeInBytes()",
    "参数说明": "无",
    "返回值": "当前芯片版本一个datablock的大小，单位为byte。",
    "调用示例": "int16_t dataBlockSize = AscendC::GetDataBlockSizeInBytes();\n// 每个repeat有8个datablock,可计算8 * dataBlockSize / sizeof(half)个数，mask配置为迭代内所有元素均参与计算\nuint64_t mask = 8 * dataBlockSize / sizeof(half);\n// 共计算512个数，除以每个repeat参与计算的元素个数，得到repeatTimes\nuint8_t repeatTimes = 512 / mask; \n// dstBlkStride, src0BlkStride, src1BlkStride = 1, 单次迭代内数据连续读取和写入\n// dstRepStride, src0RepStride, src1RepStride = 8, 相邻迭代间数据连续读取和写入\nAscendC::Add(dstLocal, src0Local, src1Local, mask, repeatTimes, { 1, 1, 1, 8, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "GetArchVersion",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0187.html",
    "功能说明": "获取当前AI处理器架构版本号。",
    "函数原型": "__aicore__ inline void GetArchVersion(uint32_t& coreVersion)",
    "参数说明": "参数名 输入/输出 描述 coreVersion 输出 AI处理器架构版本 数据类型：uint32_t",
    "返回值": "无",
    "调用示例": "uint32_t coreVersion = 0;//定义AI处理器版本\n    AscendC::GetArchVersion(coreVersion);\n    AscendC::PRINTF(\"core version is %x\", coreVersion);//需用%x将其打印成十六进制的数",
    "错误": null
  },
  {
    "API名称": "GetTaskRation",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0188.html",
    "功能说明": "适用于Cube/Vector分离架构，用来获取Cube/Vector的配比。",
    "函数原型": "__aicore__ inline int64_t GetTaskRation()",
    "参数说明": "无",
    "返回值": "Cube/Vector的配比： 针对分离架构，该接口返回算子执行时block（逻辑概念）内的Cube/Vector核数量。融合算子的1个block内通常有1个Cube+2个Vector，该接口在Cube上会返回block内Cube核数(通常为1)，在Vector上会返回Vector核数(通常为2)。对于纯Vector/纯Cube算子，1个block内只有1个Vector核/Core核，此时该接口固定返回1； 针对耦合架构，固定返回1。",
    "调用示例": "uint64_t ratio = AscendC::GetTaskRation();\n    // 在分离架构融合算子场景，可以查看Cube/Vector的配比\n    AscendC::PRINTF(\"task ratio is %u\", ratio);",
    "错误": null
  },
  {
    "API名称": "SetAtomicAdd",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0210.html",
    "功能说明": "调用该接口后，可对后续的从VECOUT/L0C/L1到GM的数据传输开启原子累加，通过模板参数设定不同的累加数据类型。",
    "函数原型": "template <typename T>\n__aicore__ inline void SetAtomicAdd() {}",
    "参数说明": "表1 模板参数说明 参数名 描述 T 设定不同的累加数据类型。 Atlas 训练系列产品 ，支持的数据类型为：float；支持的数据通路为VECOUT->GM。 Atlas 推理系列产品 AI Core ，支持的数据类型为float/half/int16_t；支持的数据通路为VECOUT->GM。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为float/half/int16_t/int32_t/int8_t/bfloat16_t；支持的数据通路为VECOUT/L0C/L1->GM。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为float/half/int16_t/int32_t/int8_t/bfloat16_t；支持的数据通路为VECOUT/L0C/L1->GM。 Atlas 200I/500 A2 推理产品 ，支持的数据类型为float/half/int16_t/int32_t；支持的数据通路为VECOUT/L0C/L1->GM",
    "返回值": "无",
    "调用示例": "...\n// x为输入，z为输出\nset_atomic_add_ops_kernel<<<3, nullptr, stream>>>(x, z);\n...",
    "错误": null
  },
  {
    "API名称": "SetAtomicType",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0211.html",
    "功能说明": "通过设置模板参数来设定原子操作不同的数据类型。",
    "函数原型": "template <typename T>\n__aicore__ inline void SetAtomicType()",
    "参数说明": "表1 模板参数说明 参数名 描述 T 设定不同的数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持float/half/int16_t/int32_t/int8_t/bfloat16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持float/half/int16_t/int32_t/int8_t/bfloat16_t Atlas 推理系列产品 AI Core ，支持float/half/int16_t Atlas 200I/500 A2 推理产品 ，支持float/half/int16_t/int32_t",
    "返回值": "无",
    "调用示例": "// 本演示示例使用DataCopy从VECOUT搬出到外部dstGlobal时进行原子最小，并调用SetAtomicType修改原子最小的数据类型。\n#include \"kernel_operator.h\"\n\nstatic const int data_size = 256;\ntemplate <typename T>\nclass KernelDataCopyAtomicMin {\npublic:\n    __aicore__ inline KernelDataCopyAtomicMin() {}\n    __aicore__ inline void Init(GM_ADDR src0_gm, GM_ADDR src1_gm, GM_ADDR dst_gm, uint32_t size)\n    {\n        this->size = size;\n        src0Global.SetGlobalBuffer((__gm__ T *)src0_gm);\n        src1Global.SetGlobalBuffer((__gm__ T *)src1_gm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dst_gm);\n        pipe.InitBuffer(queueSrc0, 1, size * sizeof(T));\n        pipe.InitBuffer(queueSrc1, 1, size * sizeof(T));\n        pipe.InitBuffer(queueDst0, 1, size * sizeof(T));\n        pipe.InitBuffer(queueDst1, 1, size * sizeof(T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> src0local = queueSrc0.AllocTensor<T>();\n        AscendC::LocalTensor<T> src1local = queueSrc1.AllocTensor<T>();\n        AscendC::DataCopy(src0local, src0Global, size);\n        AscendC::DataCopy(src1local, src1Global, size);\n        queueSrc0.EnQue(src0local);\n        queueSrc1.EnQue(src1local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> src0local = queueSrc0.DeQue<T>();\n        AscendC::LocalTensor<T> src1local = queueSrc1.DeQue<T>();\n        AscendC::LocalTensor<T> dst0Local = queueDst0.AllocTensor<T>();\n        AscendC::LocalTensor<T> dst1Local = queueDst1.AllocTensor<T>();\n        AscendC::Abs(dst0Local, src0local, size);\n        AscendC::Abs(dst1Local, src1local, size);\n        queueDst0.EnQue(dst0Local);\n        queueDst1.EnQue(dst1Local);\n        queueSrc0.FreeTensor(src0local);\n        queueSrc1.FreeTensor(src1local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dst0Local = queueDst0.DeQue<T>();\n        AscendC::LocalTensor<T> dst1Local = queueDst1.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dst1Local, size);\n        AscendC::PipeBarrier<PIPE_MTE3>();\n        AscendC::SetAtomicMin<int8_t>();  // 此处设置的类型可随意，此例中以int8_t为例\n        AscendC::SetAtomicType<T>();  // 此处设置真实的数据类型\n        AscendC::DataCopy(dstGlobal, dst0Local, size);\n        queueDst0.FreeTensor(dst0Local);\n        queueDst1.FreeTensor(dst1Local);\n        AscendC::SetAtomicNone();\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queueSrc0;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> queueDst0;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> queueDst1;\n    AscendC::GlobalTensor<T> src0Global, src1Global, dstGlobal;\n    uint32_t size;\n};\nextern \"C\" __global__ __aicore__ void data_copy_atomic_min_kernel(GM_ADDR src0_gm, GM_ADDR src1_gm, GM_ADDR dst_gm)\n{\n    KernelDataCopyAtomicMin<half> op;\n    op.Init(src0_gm, src1_gm, dst_gm, data_size);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "SetAtomicNone",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0212.html",
    "功能说明": "清空原子操作的状态。",
    "函数原型": "__aicore__ inline void SetAtomicNone()",
    "参数说明": "无",
    "返回值": "无",
    "调用示例": "AscendC::SetAtomicNone();",
    "错误": null
  },
  {
    "API名称": "GET_TILING_DATA",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0214.html",
    "功能说明": "用于获取算子kernel入口函数传入的Tiling信息，并填入注册的TilingData结构体中，此函数会以宏展开的方式进行编译。对应的算子host实现中需要定义TilingData结构体，实现并注册计算TilingData的Tiling函数，具体请参考 Host侧tiling实现 。如果用户通过 TilingData结构注册 注册了多个TilingData结构体，使用该接口返回默认注册的结构体。",
    "函数原型": "GET_TILING_DATA(tiling_data, tiling_arg)",
    "参数说明": "参数 输入/输出 说明 tiling_data 输出 返回默认TilingData结构体变量。 tiling_arg 输入 此参数为算子入口函数处传入的Tiling参数。",
    "返回值": "",
    "调用示例": "extern \"C\" __global__ __aicore__ void add_custom(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *z, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelAdd op;\n    op.Init(x, y, z, tilingData.blkDim, tilingData.totalSize, tilingData.splitTile);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "GET_TILING_DATA_WITH_STRUCT",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0215.html",
    "功能说明": "使用该接口指定结构体名称，可获取指定的tiling信息，并填入对应的Tiling结构体中，此函数会以宏展开的方式进行编译。与 GET_TILING_DATA 的区别是： GET_TILING_DATA 只能获取默认注册的结构体，该接口可以根据指定的结构体名称获取对应的结构体，常用于针对不同的TilingKey注册了不同结构体的情况下。",
    "函数原型": "GET_TILING_DATA_WITH_STRUCT(struct_name, tiling_data, tiling_arg)",
    "参数说明": "参数 输入/输出 说明 struct_name 输入 指定的结构体名称。 tiling_data 输出 返回指定Tiling结构体变量。 tiling_arg 输入 此参数为算子入口函数处传入的tiling参数。",
    "返回值": "",
    "调用示例": "extern \"C\" __global__ __aicore__ void add_custom(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *z, __gm__ uint8_t *tiling)\n{\n    KernelAdd op;\n    if (TILING_KEY_IS(1)) {\n        GET_TILING_DATA_WITH_STRUCT(Add_Struct_Special, tilingData, tiling); // 使用算子指定注册的结构体\n\top.Init(x, y, z, tilingData.totalLengthSpecial, tilingData.tileNumSpecial);\n    } else {\n        GET_TILING_DATA(tilingData, tiling);   // 使用算子默认注册的结构体\n\top.Init(x, y, z, tilingData.totalLength, tilingData.tileNum);\n    }\n    if (TILING_KEY_IS(1)) {\n        op.Process();\n    }  else  if (TILING_KEY_IS(2)) {\n        op.Process();\n    } else  if (TILING_KEY_IS(3)) {\n        op.Process();\n    }\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "GET_TILING_DATA_MEMBER",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0216.html",
    "功能说明": "用于获取tiling结构体的成员变量。",
    "函数原型": "GET_TILING_DATA_MEMBER(struct_name, mem_name, tiling_data, tiling_arg)",
    "参数说明": "参数 输入/输出 说明 struct_name 输入 指定的结构体名称。 mem_name 输入 指定的成员变量名称。 tiling_data 输出 返回指定Tiling结构体的成员变量。 tiling_arg 输入 此参数为算子入口函数处传入的tiling参数。",
    "返回值": "",
    "调用示例": "extern \"C\" __global__ __aicore__ void add_custom(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *z, __gm__ uint8_t *tiling)\n{\n    KernelAdd op;\n    if ASCEND_IS_AIV {\n        GET_TILING_DATA(tilingData, tiling);   // Vector侧使用算子默认注册的完整结构体\n\top.Init(x, y, z, tilingData.totalLength, tilingData.tileNum);\n        op.Process();\n    } else {\n        GET_TILING_DATA_MEMBER(Add_Struct, tCubeTiling, tCubeTilingVar, tiling); // Cube侧仅使用算子注册结构体的成员变量tCubeTiling\n\top.Init(x, y, z, tCubeTilingVar);\n\top.Process();\n    }\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "TILING_KEY_IS",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0217.html",
    "功能说明": "在核函数中判断本次执行时的tiling_key是否等于host侧运行时设置的某个key，从而标识tiling_key==key的一条kernel分支。",
    "函数原型": "TILING_KEY_IS(key)",
    "参数说明": "参数 输入/输出 说明 key 输入 key表示某个核函数的分支，必须是非负整数。",
    "返回值": "",
    "调用示例": "extern \"C\" __global__ __aicore__ void add_custom(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *z, __gm__ uint8_t *workspace, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    if (workspace == nullptr) {\n        return;\n    }\n    KernelAdd op;\n    op.Init(x, y, z, tilingData.blockDim, tilingData.totalLength, tilingData.tileNum);\n    // 当TilingKey为1时，执行Process1；为2时，执行Process2；为3时，执行Process3\n    if (TILING_KEY_IS(1)) {\n        op.Process1();\n    } else if (TILING_KEY_IS(2)) {\n        op.Process2();\n    } else if (TILING_KEY_IS(3)) {\n        op.Process3();\n    }\n    // 其他代码逻辑\n    ...\n    // 此处示例当TilingKey为3时，会执行ProcessOther\n    if (TILING_KEY_IS(3)) {\n        op.ProcessOther();\n    }\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "REGISTER_TILING_DEFAULT",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00003.html",
    "功能说明": "用于在kernel侧注册用户使用标准C++语法自定义的默认TilingData结构体。 注册TilingData结构体用于告知框架侧用户使用标准C++语法来定义TilingData，同时告知框架TilingData结构体类型，用于框架做tiling数据解析。",
    "函数原型": "REGISTER_TILING_DEFAULT(TILING_STRUCT)",
    "参数说明": "参数 输入/输出 说明 TILING_STRUCT 输入 用户注册的默认自定义TilingData结构体。",
    "返回值": "",
    "调用示例": "extern \"C\" __global__ __aicore__ void add_custom(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *z, __gm__ uint8_t *tiling)\n{\n    REGISTER_TILING_DEFAULT(optiling::TilingData);\n    GET_TILING_DATA(tilingData, tiling);\n    KernelAdd op;\n    op.Init(x, y, z, tilingData.blkDim, tilingData.totalSize, tilingData.splitTile);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "REGISTER_TILING_FOR_TILINGKEY",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00004.html",
    "功能说明": "用于在kernel侧注册与TilingKey相匹配的TilingData自定义结构体；该接口需提供一个逻辑表达式，逻辑表达式以字符串“TILING_KEY_VAR”代指实际TilingKey，表达TilingKey所满足的范围。",
    "函数原型": "REGISTER_TILING_FOR_TILINGKEY(EXPRESSION, TILING_STRUCT)",
    "参数说明": "参数 输入/输出 说明 EXPRESSION 输入 EXPRESSION为逻辑运算，其中用TILING_KEY_VAR指代TilingKey。 TILING_STRUCT 输入 用户注册的与TilingKey相匹配的TilingData自定义结构体。",
    "返回值": "",
    "调用示例": "extern \"C\" __global__ __aicore__ void add_custom(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *z, __gm__ uint8_t *tiling)\n{\n    REGISTER_TILING_DEFAULT(optiling::TilingData);  // 注册用户默认自定义TilingData结构体\n    REGISTER_TILING_FOR_TILINGKEY(\"TILING_KEY_VAR == 1\", optiling::TilingDataA); // 注册TilingKey为1的TilingData结构体\n    REGISTER_TILING_FOR_TILINGKEY(\"(TILING_KEY_VAR >= 10) && (TILING_KEY_VAR <= 15)\", optiling::TilingDataB); // 注册TilingKey在[10,15]之间的TilingData结构体\n    REGISTER_TILING_FOR_TILINGKEY(\"TILING_KEY_VAR & 0xFF\", optiling::TilingDataC); // 注册TilingKey低16位为1的TilingData结构体\n    if (TILING_KEY_IS(1)) {\n        GET_TILING_DATA_WITH_STRUCT(optiling::TilingDataA, tilingData, tiling);\n        ......\n    } else if (TILING_KEY_IS(11)) {\n        GET_TILING_DATA_WITH_STRUCT(optiling::TilingDataB, tilingData, tiling);\n        ......\n    } else if (TILING_KEY_IS(14)) {\n        GET_TILING_DATA_WITH_STRUCT(optiling::TilingDataB, tilingData, tiling);\n        ......\n    } else if (TILING_KEY_IS(255)) {\n        GET_TILING_DATA_WITH_STRUCT(optiling::TilingDataC, tilingData, tiling);\n        ......\n    } else {\n        GET_TILING_DATA(tilingData, tiling);\n        ......\n    }\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "设置kernel类型",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0218.html",
    "功能说明": "用于用户自定义设置kernel类型，控制算子执行时只启动该类型的核，避免启动不需要工作的核，缩短核启动开销。",
    "函数原型": "KERNEL_TASK_TYPE_DEFAULT(value)",
    "参数说明": "表1 参数说明 参数 输入/输出 说明 key 输入 tiling key的key值，此参数是正数，表示某个核函数的分支。 value 输入 设置的kernel类型，可选值范围，kernel类型具体说明请参考 表2 。 enum KernelMetaType { KERNEL_TYPE_AIV_ONLY , KERNEL_TYPE_AIC_ONLY , KERNEL_TYPE_MIX_AIV_1_0 , KERNEL_TYPE_MIX_AIC_1_0 , KERNEL_TYPE_MIX_AIC_1_1 , KERNEL_TYPE_MIX_AIC_1_2 , KERNEL_TYPE_AICORE , KERNEL_TYPE_VECTORCORE , KERNEL_TYPE_MIX_AICORE , KERNEL_TYPE_MIX_VECTOR_CORE , KERNEL_TYPE_MAX };",
    "返回值": "",
    "调用示例": "extern \"C\" __global__ __aicore__ void add_custom(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *z, __gm__ uint8_t *workspace, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    if (workspace == nullptr) {\n        return;\n    }\n    KernelAdd op;\n    op.Init(x, y, z, tilingData.blockDim, tilingData.totalLength, tilingData.tileNum);\n    KERNEL_TASK_TYPE_DEFAULT(KERNEL_TYPE_MIX_VECTOR_CORE); // 使能VectorCore\n    if (TILING_KEY_IS(1)) {\n        op.Process1();\n    } else if (TILING_KEY_IS(2)) {\n        op.Process2();\n    }\n    // ...\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "VectorPadding(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0221.html",
    "功能说明": "根据padMode（pad模式）与padSide（pad方向）对源操作数按照datablock进行填充操作。 假设源操作数的一个datablock有16个数，datablock[0:15]=a~p： padSide==false：从datablock的左边开始填充，即datablock的起始值方向(a->p) padSide==true：从datablock的右边开始填充，即datablock的结束值方向(p->a) padMode==0：用邻近数作为填充值，例：aaa|abc(padSide=false)、nop|ppp(padSide=true) padMode==1：用邻近datablock值对称填充，例：cba|abc(padSide=false)、nop|pon(padSide=true) padMode==2：用邻近datablock值填充，偏移一个数，做对称填充，例： padSide=false：xcb|abc，xcb被填充，填充过程描述：a被丢弃，对称填充，x处填充0 padSide=true：nop|onx，onx被填充，填充过程描述：p被丢弃，对称填充，x处填充0",
    "函数原型": "template <typename T>\n__aicore__ inline void VectorPadding(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint8_t padMode, const bool padSide, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float isSetMask 是否在接口内部设置mask。 true，表示在接口内部设置mask。 false，表示在接口外部设置mask，开发者需要使用 SetVectorMask 接口设置mask值。这种模式下，本接口入参中的mask值必须设置为占位符MASK_PLACEHOLDER。\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 padMode 输入 padding模式，类型为uint8_t，取值范围：[0,2]。 0：用邻近数作为填充值。 1：用邻近datablock值对称填充。 2：用邻近datablock值填充，偏移一个数，做对称填充。 padSide 输入 padding的方向，类型为bool。 false：左边。 true：右边。 calCount 输入 参与计算的元素个数。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 repeatTimes 输入 重复迭代次数。矢量计算单元，每次读取连续的256Bytes数据进行计算，为完成对输入数据的处理，必须通过多次迭代（repeat）才能完成所有数据的读取与计算。repeatTimes表示迭代的次数。 关于该参数的具体描述请参考 如何使用Tensor高维切分计算API 。 repeatParams 输入 控制操作数地址步长的参数。 UnaryRepeatParams 类型，包含操作数相邻迭代间相同 DataBlock 的地址步长，操作数同一迭代内不同 DataBlock 的地址步长等参数。 相邻迭代间的地址步长参数说明请参考 repeatStride ；同一迭代内DataBlock的地址步长参数说明请参考 dataBlockStride 。",
    "返回值": "无",
    "调用示例": "uint64_t mask = 256 / sizeof(half);\nuint8_t padMode = 0;\nbool padSide = false;\n// repeatTimes = 4, 128 elements one repeat, 512 elements total\n// dstBlkStride, srcBlkStride = 1, no gap between blocks in one repeat\n// dstRepStride, srcRepStride = 8, no gap between repeats\nAscendC::VectorPadding(dstLocal, srcLocal, padMode, padSide, mask, 4, { 1, 1, 8, 8 });",
    "错误": null
  },
  {
    "API名称": "BilinearInterpolation(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0222.html",
    "功能说明": "功能分为水平迭代和垂直迭代。每个水平迭代顺序地从src0Offset读取8个偏移值，表示src0的偏移，每个偏移值指向src0的一个 DataBlock 的起始地址，如果repeatMode=false，从src1中取一个值，与src0中8个 DataBlock 中每个值进行乘操作；如果repeatMode=true，从src1中取8个值，按顺序与src0中8个 DataBlock 中的值进行乘操作，最后当前迭代的dst结果与前一个dst结果按 DataBlock 进行累加，存入目的地址，在同一个水平迭代内dst地址不变。然后进行垂直迭代，垂直迭代的dst起始地址为上一轮垂直迭代的dst起始地址加上vROffset，本轮垂直迭代占用dst空间为dst起始地址之后的8个 DataBlock ，每轮垂直迭代进行hRepeat次水平迭代。",
    "函数原型": "template <typename T>\n__aicore__ inline void BilinearInterpolation(const LocalTensor<T> &dstLocal, const LocalTensor<T> &src0Local, const LocalTensor<uint32_t> &src0OffsetLocal, const LocalTensor<T> &src1Local, uint64_t mask[], uint8_t hRepeat, bool repeatMode, uint16_t dstBlkStride, uint16_t vROffset, uint8_t vRepeat, const LocalTensor<uint8_t> &sharedTmpBuffer)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half\n\n表2 参数说明 参数名 输入/输出 描述 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local、src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 两个源操作数的数据类型需要与目的操作数保持一致。 src0OffsetLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 mask[]/mask 输入 mask 用于控制每次迭代内参与计算的元素。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。 mask为数组形式，数组长度和数组元素的取值范围和操作数的数据类型有关。当操作数为16位时，数组长度为2，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，数组长度为1，mask[0]∈(0, 2 64 -1]；当操作数为64位时，数组长度为1，mask[0]∈(0, 2 32 -1]。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 hRepeat 输入 水平方向迭代次数，取值范围为[1, 255]。 repeatMode 输入 迭代模式 ： false ：每次迭代src0读取的8个datablock中每个值均与src1的单个数值相乘。 true ：每次迭代src0的每个datablock分别与src1的1个数值相乘，共消耗8个block和8个elements。 dstBlkStride 输入 单次迭代内，目的操作数不同 DataBlock 间地址步长，以32B为单位。 vROffset 输入 垂直迭代间，目的操作数地址偏移量，以元素为单位，取值范围为[128, 65535]。 vRepeat 输入 垂直方向迭代次数，取值范围为[1, 255]。 sharedTmpBuffer 输入 临时空间。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，需要保证至少分配了src0Local.GetSize() * 32 + src1Local.GetSize() * 32字节的空间。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，需要保证至少分配了src0Local.GetSize() * 32 + src1Local.GetSize() * 32字节的空间。 Atlas 推理系列产品 AI Core ，需要保证至少分配了src0OffsetLocal.GetSize() * sizeof(uint32_t)字节的空间。",
    "返回值": "无",
    "调用示例": "AscendC::LocalTensor<half> dstLocal, src0Local, src1Local;\nAscendC::LocalTensor<uint32_t> src0OffsetLocal;\nAscendC::LocalTensor<uint8_t> tmpLocal;\nuint64_t mask = 128;        // mask连续模式\nuint8_t hRepeat = 2;        // 水平迭代2次\nbool repeatMode = false;    // 迭代模式\nuint16_t dstBlkStride = 1;  // 单次迭代内数据连续写入\nuint16_t vROffset = 128;    // 相邻迭代间数据连续写入\nuint8_t vRepeat = 2;        // 垂直迭代2次\n\nAscendC::BilinearInterpolation(dstLocal, src0Local, src0OffsetLocal, src1Local, mask, hRepeat, repeatMode,\n            dstBlkStride, vROffset, vRepeat, tmpLocal);",
    "错误": null
  },
  {
    "API名称": "GetCmpMask(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0223.html",
    "功能说明": "此接口用于获取 Compare（结果存入寄存器） 指令的比较结果。 Compare（结果存入寄存器） 指令会将比较后的结果写入CmpMask寄存器中，使用GetCmpMask接口可以获取到CmpMask寄存器的值从而得到Compare的结果。",
    "函数原型": "template<typename T>\n__aicore__ inline void GetCmpMask(const LocalTensor<T>& dst)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。\n\n表2 参数说明 参数名 输入/输出 描述 dst 输出 Compare（结果存入寄存器） 指令的比较结果。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要16字节对齐。",
    "返回值": "无",
    "调用示例": "AscendC::LocalTensor<float> src0Local;\nAscendC::LocalTensor<float> src1Local;\nAscendC::LocalTensor<uint8_t> dstLocal;\nuint64_t mask = 256 / sizeof(float); // 256为每个迭代处理的字节数，结果为64\nAscendC::BinaryRepeatParams repeatParams = { 1, 1, 1, 8, 8, 8 };\nAscendC::Compare(src0Local, src1Local, AscendC::CMPMODE::LT, mask, repeatParams);\nAscendC::GetCmpMask(dstLocal);",
    "错误": null
  },
  {
    "API名称": "SetCmpMask(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0224.html",
    "功能说明": "为 Select 不传入mask参数的接口设置比较寄存器。配合不同的selMode传入不同的数据。 模式0（SELMODE::VSEL_CMPMASK_SPR） SetCmpMask中传入selMask LocalTensor。 模式1（SELMODE::VSEL_TENSOR_SCALAR_MODE） SetCmpMask中传入src1Local LocalTensor。 模式2（SELMODE::VSEL_TENSOR_TENSOR_MODE） SetCmpMask中传入LocalTensor，LocalTensor中存放的是selMask的地址。",
    "函数原型": "template <typename T>\n__aicore__ inline void SetCmpMask(const LocalTensor<T>& src)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。\n\n表2 参数说明 参数名 输入/输出 描述 src 输入 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要16字节对齐。",
    "返回值": "无",
    "调用示例": "uint32_t dataSize = 256;\nuint32_t selDataSize = 8;\nTPipe pipe;\nTQue<TPosition::VECIN, 1> inQueueX;\nTQue<TPosition::VECIN, 1> inQueueY;\nTQue<TPosition::VECIN, 1> inQueueSel;\nTQue<TPosition::VECOUT, 1> outQueue;\npipe.InitBuffer(inQueueX, 1, dataSize * sizeof(float));\npipe.InitBuffer(inQueueY, 1, dataSize * sizeof(float));\npipe.InitBuffer(inQueueSel, 1, selDataSize * sizeof(uint8_t));\npipe.InitBuffer(outQueue, 1, dataSize * sizeof(float));\nAscendC::LocalTensor<float> dst = outQueue.AllocTensor<float>();\nAscendC::LocalTensor<uint8_t> sel = inQueueSel.AllocTensor<uint8_t>();\nAscendC::LocalTensor<float> src0 = inQueueX.AllocTensor<float>();\nAscendC::LocalTensor<float> src1 = inQueueY.AllocTensor<float>();\nuint8_t repeat = 4;\nuint32_t mask = 64;\nAscendC::BinaryRepeatParams repeatParams = { 1, 1, 1, 8, 8, 8 };\n\n// selMode为模式0（SELMODE::VSEL_CMPMASK_SPR）\nAscendC::SetCmpMask(sel);\nAscendC::PipeBarrier<PIPE_V>();\nAscendC::SetVectorMask<float>(mask);\nAscendC::Select<float, AscendC::SELMODE::VSEL_CMPMASK_SPR>(dst, src0, src1, repeat, repeatParams);\n\n// selMode为模式2（SELMODE::VSEL_TENSOR_TENSOR_MODE）\nAscendC::LocalTensor<int32_t> tempBuf;\n#if defined(ASCENDC_CPU_DEBUG) && (ASCENDC_CPU_DEBUG == 1)  // cpu调试\ntempBuf.ReinterpretCast<int64_t>().SetValue(0, reinterpret_cast<int64_t>(reinterpret_cast<__ubuf__ int64_t*>(sel.GetPhyAddr())));\nevent_t eventIdSToV = static_cast<event_t>(AscendC::GetTPipePtr()->FetchEventID(AscendC::HardEvent::S_V));\nAscendC::SetFlag<AscendC::HardEvent::S_V>(eventIdSToV);\nAscendC::WaitFlag<AscendC::HardEvent::S_V>(eventIdSToV);\n#else // npu调试\nuint32_t selAddr = static_cast<uint32_t>(reinterpret_cast<int64_t>(reinterpret_cast<__ubuf__ int64_t*>(sel.GetPhyAddr())));\nAscendC::SetVectorMask<uint32_t>(32);\nAscendC::Duplicate<uint32_t, false>(tempBuf.ReinterpretCast<uint32_t>(), selAddr, AscendC::MASK_PLACEHOLDER, 1, 1, 8);\nAscendC::PipeBarrier<PIPE_V>();\n#endif\nAscendC::SetCmpMask<int64_t>(tempBuf.ReinterpretCast<int64_t>());\nAscendC::PipeBarrier<PIPE_V>();\nAscendC::SetVectorMask<float>(mask);\nAscendC::Select<float, AscendC::SELMODE::VSEL_TENSOR_TENSOR_MODE>(dst, src0, src1, repeat, repeatParams);",
    "错误": null
  },
  {
    "API名称": "GetAccVal(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0225.html",
    "功能说明": "获取 ReduceSum 接口（ T ensor前n个数据计算接口，n为接口的count参数）的计算结果。",
    "函数原型": "template <typename T>\n__aicore__ inline T GetAccVal()",
    "参数说明": "表1 模板参数说明 参数名 描述 T ReduceSum指令的数据类型，支持half/float。",
    "返回值": "ReduceSum接口（ T ensor前n个数据计算接口，n为接口的count参数）的计算结果。",
    "调用示例": "AscendC::LocalTensor<float> src;\nAscendC::LocalTensor<float> work;\nAscendC::LocalTensor<float> dst;\nAscendC::ReduceSum(dst, src, work, 128);\nfloat res = AscendC::GetAccVal<float>();",
    "错误": null
  },
  {
    "API名称": "GetReduceMaxMinCount(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0226.html",
    "功能说明": "获取 ReduceMax 、 ReduceMin 连续场景下的最大/最小值以及相应的索引值。",
    "函数原型": "template <typename T>\n__aicore__ inline void GetReduceMaxMinCount(T &maxMinValue, T &maxMinIndex)",
    "参数说明": "表1 模板参数说明 参数名 描述 T ReduceMax/ReduceMin指令的数据类型，支持half/float。\n\n表2 参数说明 参数名 输入/输出 描述 maxMinValue 输出 ReduceMax/ReduceMin指令的最大值/最小值。 maxMinIndex 输出 ReduceMax/ReduceMin指令的最值对应的索引值。",
    "返回值": "无",
    "调用示例": "AscendC::LocalTensor<float> src;\nAscendC::LocalTensor<float> work;\nAscendC::LocalTensor<float> dst;\nint32_t mask = 64;\nAscendC::ReduceMax(dst, src, work, mask, 1, 8, true); // 连续场景，srcRepStride = 8，且calIndex = true",
    "错误": null
  },
  {
    "API名称": "ProposalConcat",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0227.html",
    "功能说明": "将连续元素合入Region Proposal内对应位置，每次迭代会将16个连续元素合入到16个Region Proposals的对应位置里。 Region Proposal说明： 目前仅支持两种数据类型：half、float。 每个Region Proposal占用连续8个half/float类型的元素，约定其格式： [x1, y1, x2, y2, score, label, reserved_0, reserved_1] 对于数据类型half，每一个Region Proposal占16Bytes，Byte[15:12]是无效数据，Byte[11:0]包含6个half类型的元素，其中Byte[11:10]定义为label，Byte[9:8]定义为score，Byte[7:6]定义为y2，Byte[5:4]定义为x2，Byte[3:2]定义为y1，Byte[1:0]定义为x1。 如下图所示，总共包含16个Region Proposals。 对于数据类型float，每一个Region Proposal占32Bytes，Byte[31:24]是无效数据，Byte[23:0]包含6个float类型的元素，其中Byte[23:20]定义为label，Byte[19:16]定义为score，Byte[15:12]定义为y2，Byte[11:8]定义为x2，Byte[7:4]定义为y1，Byte[3:0]定义为x1。 如下图所示，总共包含16个Region Proposals。",
    "函数原型": "template <typename T>\n__aicore__ inline void ProposalConcat(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t repeatTimes, const int32_t modeNumber)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 repeatTimes 输入 重复迭代次数，int32_t类型，每次迭代完成16个元素合入到16个Region Proposals里，下次迭代跳至相邻的下一组16个Region Proposals和下一组16个元素。取值范围：repeatTimes∈[0,255]。 modeNumber 输入 合入位置参数，取值范围：modeNumber∈[0, 5]，int32_t类型，仅限于以下配置： 0 – 合入x1 1 – 合入y1 2 – 合入x2 3 – 合入y2 4 – 合入score 5 – 合入label",
    "返回值": "无",
    "调用示例": "// repeatTimes = 2, modeNumber = 4, 把32个数合入到32个Region Proposal中的score域中\nAscendC::ProposalConcat(dstLocal, srcLocal, 2, 4);",
    "错误": null
  },
  {
    "API名称": "ProposalExtract",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0228.html",
    "功能说明": "与ProposalConcat功能相反，从Region Proposals内将相应位置的单个元素抽取后重排，每次迭代处理16个Region Proposals，抽取16个元素后连续排列。",
    "函数原型": "template <typename T>\n__aicore__ inline void ProposalExtract(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t repeatTimes, const int32_t modeNumber)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 repeatTimes 输入 重复迭代次数，int32_t类型，每次迭代完成16个Region Proposals的元素抽取并排布到16个元素里，下次迭代跳至相邻的下一组16个Region Proposals和下一组16个元素。取值范围：repeatTimes∈[0,255]。 modeNumber 输入 抽取位置参数，取值范围：modeNumber∈[0, 5]，int32_t类型，仅限于以下配置： 0 – 从x1抽取 1 – 从y1抽取 2 – 从x2抽取 3 – 从y2抽取 4 – 从score抽取 5 – 从label抽取",
    "返回值": "无",
    "调用示例": "// repeatTimes = 2, modeNumber = 4, 把32个Region Proposal中的score域元素抽取出来排列成32个连续元素\nAscendC::ProposalExtract(dstLocal, srcLocal, 2, 4);",
    "错误": null
  },
  {
    "API名称": "RpSort16",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0229.html",
    "功能说明": "根据Region Proposals中的score域对其进行排序（score大的排前面），每次排16个Region Proposals。",
    "函数原型": "template <typename T>\n__aicore__ inline void RpSort16(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const int32_t repeatTimes)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，存储经过排序后的Region Proposals。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数，存储未经过排序的Region Proposals。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 repeatTimes 输入 重复迭代次数，int32_t类型，每次排16个Region Proposals。取值范围：repeatTimes∈[0,255]。",
    "返回值": "",
    "调用示例": "// repeatTimes = 2, 对2个Region Proposal进行排序\nAscendC::RpSort16(dstLocal, dstLocal, 2);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "MrgSort4",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0230.html",
    "功能说明": "将已经排好序的最多4条Region Proposals队列，排列并合并成1条队列，结果按照score域由大到小排序。",
    "函数原型": "template <typename T>\n__aicore__ inline void MrgSort4(const LocalTensor<T>& dstLocal, const MrgSortSrcList<T>& srcLocal, const MrgSort4Info& params)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float",
    "返回值": "",
    "调用示例": "// vconcatWorkLocal为已经创建并且完成排序的4个Region Proposals，每个Region Proposal数目是16个\nstruct MrgSortSrcList<half> srcList(vconcatWorkLocal[0], vconcatWorkLocal[1], vconcatWorkLocal[2], vconcatWorkLocal[3]);\nuint16_t elementLengths[4] = {16, 16, 16, 16};\nstruct MrgSort4Info srcInfo(elementLengths, false, 15, 1);\nAscendC::MrgSort4(dstLocal, srcList, srcInfo);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Sort32",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0231.html",
    "功能说明": "排序函数，一次迭代可以完成32个数的排序，数据需要按如下描述结构进行保存： score和index分别存储在src0Local和src1Local中，按score进行排序（score大的排前面），排序好的score与其对应的index一起以（score, index）的结构存储在dstLocal中。不论score为half还是float类型，dstLocal中的（score, index）结构总是占据8Bytes空间。 如下所示： 当score为float，index为uint32_t类型时，计算结果中index存储在高4Bytes，score存储在低4Bytes。 当score为half，index为uint32_t类型时，计算结果中index存储在高4Bytes，score存储在低2Bytes， 中间的2Bytes保留。",
    "函数原型": "template <typename T>\n__aicore__ inline void Sort32(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<uint32_t>& src1Local, const int32_t repeatTimes)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 此源操作数的数据类型需要与目的操作数保持一致。 src1Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 此源操作数固定为uint32_t数据类型。 repeatTimes 输入 重复迭代次数，int32_t类型，每次迭代完成32个元素的排序，下次迭代src0Local和src1Local各跳过32个elements，dstLocal跳过32*8 Byte空间。取值范围：repeatTimes∈[0,255]。",
    "返回值": "无",
    "调用示例": "// repeatTimes = 4, 对128个数分成4组进行排序，每次完成1组32个数的排序\nAscendC::Sort32<float>(dstLocal, srcLocal0, srcLocal1, 4);",
    "错误": null
  },
  {
    "API名称": "MrgSort",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0232.html",
    "功能说明": "将已经排好序的最多4条队列，合并排列成1条队列，结果按照score域由大到小排序。 MrgSort指令处理的数据一般是经过Sort32指令处理后的数据，也就是Sort32指令的输出，队列的结构如下所示： 数据类型为float，每个结构占据8Bytes。 数据类型为half，每个结构也占据8Bytes，中间有2Bytes保留。",
    "函数原型": "template <typename T>\n__aicore__ inline void MrgSort(const LocalTensor<T>& dstLocal, const MrgSortSrcList<T>& srcLocal, const MrgSort4Info& params)",
    "参数说明": "表1 模板参数说明 参数名 描述 T Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float",
    "返回值": "无",
    "调用示例": "// 对8个已排好序的队列进行合并排序，repeatTimes = 2，数据连续存放\n// 每个队列包含32个(score,index)的8Bytes结构\n// 最后输出对score域的256个数完成排序后的结果\nAscendC::MrgSort4Info params;\nparams.elementLengths[0] = 32;\nparams.elementLengths[1] = 32;\nparams.elementLengths[2] = 32;\nparams.elementLengths[3] = 32;\nparams.ifExhaustedSuspension = false;\nparams.validBit = 0b1111;\nparams.repeatTimes = 2;\n\nAscendC::MrgSortSrcList<float> srcList;\nsrcList.src1 = workLocal[0];\nsrcList.src2 = workLocal[64]; // workLocal为float类型，每个队列占据256Bytes空间\nsrcList.src3 = workLocal[128];\nsrcList.src4 = workLocal[192];\n\nAscendC::MrgSort<float>(dstLocal, srcList, params);",
    "错误": null
  },
  {
    "API名称": "GetMrgSortResult",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0233.html",
    "功能说明": "获取MrgSort已经处理过的队列里的Region Proposal个数，并依次存储在四个出参中。 本接口和MrgSort相关指令的配合关系如下： 配合 MrgSort4指令 使用，获取MrgSort4指令处理过的队列里的Region Proposal个数。使用时，需要将MrgSort4中的MrgSort4Info.ifExhaustedSuspension参数配置为true，该配置模式下某条队列耗尽后，MrgSort4指令即停止。 以上说明适用于如下型号： Atlas 推理系列产品 AI Core 配合 MrgSort指令 使用，获取MrgSort指令处理过的队列里的Region Proposal个数。使用时，需要将MrgSort中的MrgSort4Info.ifExhaustedSuspension参数配置为true，该配置模式下某条队列耗尽后，MrgSort指令即停止。 以上说明适用于如下型号： Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 Atlas 200I/500 A2 推理产品",
    "函数原型": "__aicore__ inline void GetMrgSortResult(uint16_t &mrgSortList1, uint16_t &mrgSortList2, uint16_t &mrgSortList3, uint16_t &mrgSortList4)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 mrgSortList1 输出 类型为uint16_t，表示MrgSort第一个队列里已经处理过的Region Proposal个数。 mrgSortList2 输出 类型为uint16_t，表示MrgSort第二个队列里已经处理过的Region Proposal个数。 mrgSortList3 输出 类型为uint16_t，表示MrgSort第三个队列里已经处理过的Region Proposal个数。 mrgSortList4 输出 类型为uint16_t，表示MrgSort第四个队列里已经处理过的Region Proposal个数。",
    "返回值": "无",
    "调用示例": "AscendC::LocalTensor<float> dstLocal;\nAscendC::LocalTensor<float> workLocal;\nAscendC::LocalTensor<float> src0Local;\nAscendC::LocalTensor<uint32_t> src1Local;\n\nAscendC::Sort32(workLocal, src0Local, src1Local, 1);\n\nuint16_t elementLengths[4] = { 0 };\nuint32_t sortedNum[4] = { 0 };\nelementLengths[0] = 32;\nelementLengths[1] = 32;\nelementLengths[2] = 32;\nelementLengths[3] = 32;\nuint16_t validBit = 0b1111;\n\nAscendC::MrgSortSrcList<float> srcList;\nsrcList.src1 = workLocal[0];\nsrcList.src2 = workLocal[32 * 1 * 2];\nsrcList.src3 = workLocal[32 * 2 * 2];\nsrcList.src4 = workLocal[32 * 3 * 2];\n\nAscendC::MrgSort4Info mrgSortInfo(elementLengths, true, validBit, 1);\nAscendC::MrgSort(dstLocal, srcList, mrgSortInfo);\n\nuint16_t mrgRes1 = 0;\nuint16_t mrgRes2 = 0;\nuint16_t mrgRes3 = 0;\nuint16_t mrgRes4 = 0;\nAscendC::GetMrgSortResult(mrgRes1, mrgRes2, mrgRes3, mrgRes4);",
    "错误": null
  },
  {
    "API名称": "Gatherb(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0234.html",
    "功能说明": "给定一个输入的张量和一个地址偏移张量，本接口根据偏移地址按照DataBlock的粒度将输入张量收集到结果张量中。",
    "函数原型": "template <typename T>\n__aicore__ inline void Gatherb(const LocalTensor<T>& dstLocal, const LocalTensor<T>& src0Local, const LocalTensor<uint32_t>& offsetLocal, const uint8_t repeatTimes, const GatherRepeatParams& repeatParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/uint32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/uint32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int8_t/uint8_t/int16_t/uint16_t/half/float/int32_t/uint32_t/bfloat16_t/int64_t\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 src0Local 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 offsetLocal 输入 每个datablock在源操作数中对应的地址偏移。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 该偏移量是相对于srcLocal的基地址而言的。每个元素值要大于等于0，单位为字节；且需要保证偏移后的地址满足32字节对齐。 repeatTimes 输入 重复迭代次数，每次迭代完成8个datablock的数据收集，数据范围：repeatTimes∈（0,255]。 repeatParams 输入 用于控制指令迭代的相关参数。 类型为GatherRepeatParams，具体定义可参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_gather.h。 ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 其中dstBlkStride、dstRepStride支持用户配置，参数说明参考 表3 。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass VgatherbCase {\npublic:\n    __aicore__ inline VgatherbCase() {}\n\n    __aicore__ inline void Init(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *offset)\n    {\n        x_gm.SetGlobalBuffer(reinterpret_cast<__gm__ uint16_t *>(x));\n        y_gm.SetGlobalBuffer(reinterpret_cast<__gm__ uint16_t *>(y));\n        offset_gm.SetGlobalBuffer(reinterpret_cast<__gm__ uint32_t *>(offset));\n\n        uint32_t len = 128;\n        bufferLen = len;\n        tpipe.InitBuffer(vecIn, 2, bufferLen * sizeof(uint16_t));\n        tpipe.InitBuffer(vecOffset, 2, 8 * sizeof(uint32_t));\n        tpipe.InitBuffer(vecOut, 2, bufferLen * sizeof(uint16_t));\n    }\n\n    __aicore__ inline void CopyIn(uint32_t index)\n    {\n        auto x_buf = vecIn.AllocTensor<uint16_t>();\n        auto offset_buf = vecOffset.AllocTensor<uint32_t>();\n        AscendC::DataCopy(x_buf, x_gm[index * bufferLen], bufferLen);\n        AscendC::DataCopy(offset_buf, offset_gm[0], 8);\n        vecIn.EnQue(x_buf);\n        vecOffset.EnQue(offset_buf);\n    }\n\n    __aicore__ inline void CopyOut(uint32_t index)\n    {\n        auto y_buf = vecOut.DeQue<uint16_t>();\n        AscendC::DataCopy(y_gm[index * bufferLen], y_buf, bufferLen);\n        vecOut.FreeTensor(y_buf);\n    }\n\n    __aicore__ inline void Compute()\n    {\n        auto x_buf = vecIn.DeQue<uint16_t>();\n        auto offset_buf = vecOffset.DeQue<uint32_t>();\n        auto y_buf = vecOut.AllocTensor<uint16_t>();\n        AscendC::GatherRepeatParams params{1, 8};\n        uint8_t repeatTime = bufferLen * sizeof(uint16_t) / 256;\n        AscendC::Gatherb<uint16_t>(y_buf, x_buf, offset_buf, repeatTime, params);\n        vecIn.FreeTensor(x_buf);\n        vecOffset.FreeTensor(offset_buf);\n        vecOut.EnQue(y_buf);\n    }\n\n    __aicore__ inline void Process()\n    {\n        for (int i = 0; i < 1; i++) {\n            CopyIn(i);\n            Compute();\n            CopyOut(i);\n        }\n    }\n\nprivate:\n    AscendC::GlobalTensor<uint16_t> x_gm;\n    AscendC::GlobalTensor<uint16_t> y_gm;\n    AscendC::GlobalTensor<uint32_t> offset_gm;\n\n    AscendC::TPipe tpipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 2> vecIn;\n    AscendC::TQue<AscendC::TPosition::VECIN, 2> vecOffset;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 2> vecOut;\n\n    uint32_t bufferLen = 0;\n};\n\nextern \"C\" __global__ __aicore__ void vgatherb_core(__gm__ uint8_t *x, __gm__ uint8_t *y, __gm__ uint8_t *offset)\n{\n    VgatherbCase op;\n    op.Init(x, y, offset);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Scatter(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0235.html",
    "功能说明": "给定一个连续的输入张量和一个目的地址偏移张量，Scatter指令根据偏移地址生成新的结果张量后将输入张量分散到结果张量中。 将源操作数src中的元素按照指定的位置（由dst_offset和base_addr共同作用）分散到目的操作数dst中。",
    "函数原型": "template <typename T>\n__aicore__ inline void Scatter(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<uint32_t>& dstOffsetLocal, const uint32_t dstBaseAddr, const uint32_t count)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：uint16_t/uint32_t/float/half Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/uint32_t/int32_t/float\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，类型为LocalTensor。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数，类型为LocalTensor。数据类型需与dstLocal保持一致。 dstOffsetLocal 输入 用于存储源操作数的每个元素在dstLocal中对应的地址偏移。偏移基于dstLocal的基地址dstBaseAddr计算，以字节为单位，取值应保证按dstLocal数据类型位宽对齐，否则会导致非预期行为。 针对以下型号，地址偏移的取值范围不超出uint32_t的范围即可。 Atlas 推理系列产品 AI Core 针对以下型号，地址偏移的取值范围如下：当操作数为8位时，取值范围为[0, 2 16 -1]；当操作数为16位时，取值范围为[0, 2 17 -1]，当操作数为32位或者64位时，不超过uint32_t的范围即可。超出取值范围可能导致非预期输出。 Atlas 200I/500 A2 推理产品 dstBaseAddr 输入 dstLocal的起始偏移地址，单位是字节。取值应保证按dstLocal数据类型位宽对齐，否则会导致非预期行为。 count 输入 执行处理的数据个数。 mask/mask[] 输入 mask 用于控制每次迭代内参与计算的元素。 连续模式：表示前面连续的多少个元素参与计算。取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask∈[1, 128]；当操作数为32位时，mask∈[1, 64]；当操作数为64位时，mask∈[1, 32]。 逐bit模式：可以按位控制哪些元素参与计算，bit位的值为1表示参与计算，0表示不参与。参数类型为长度为2的uint64_t类型数组。 例如，mask=[8, 0]，8=0b1000，表示仅第4个元素参与计算。 参数取值范围和操作数的数据类型有关，数据类型不同，每次迭代内能够处理的元素个数最大值不同。当操作数为8位或16位时，mask[0]、mask[1]∈[0, 2 64 -1]并且不同时为0；当操作数为32位时，mask[1]为0，mask[0]∈(0, 2 64 -1]；当操作数为64位时，mask[1]为0，mask[0]∈(0, 2 32 -1]。 repeatTimes 输入 指令迭代次数，每次迭代完成8个datablock的数据收集，数据范围：repeatTimes∈[0,255]。 特别地，针对以下型号： Atlas 200I/500 A2 推理产品 操作数为 8位 时，每次迭代完成 4个datablock （32Bytes）的数据收集。 srcRepStride 输入 相邻迭代间的地址步长，单位是datablock。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T>\nclass ScatterTest {\npublic:\n    __aicore__ inline ScatterTest() {}\n    __aicore__ inline void Init(__gm__ uint8_t* dstGm, __gm__ uint8_t* srcGm,\n        __gm__ uint8_t* dstOffsetGm, const uint32_t count)\n    {\n        m_elementCount = count;\n        m_dstGlobal.SetGlobalBuffer((__gm__ T*)dstGm);\n        m_srcGlobal.SetGlobalBuffer((__gm__ T*)srcGm);\n        m_dstOffsetGlobal.SetGlobalBuffer((__gm__ uint32_t*)dstOffsetGm);\n        m_pipe.InitBuffer(m_queIn, 2, m_elementCount * sizeof(uint32_t));\n        m_pipe.InitBuffer(m_queOut, 1, m_elementCount * sizeof(uint32_t));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = m_queIn.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, m_srcGlobal, m_elementCount);\n        m_queIn.EnQue(srcLocal);\n        AscendC::LocalTensor<uint32_t> dstOffsetLocal = m_queIn.AllocTensor<uint32_t>();\n        AscendC::DataCopy(dstOffsetLocal, m_dstOffsetGlobal, m_elementCount);\n        m_queIn.EnQue(dstOffsetLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal = m_queIn.DeQue<T>();\n        AscendC::LocalTensor<uint32_t> dstOffsetLocal = m_queIn.DeQue<uint32_t>();\n        AscendC::LocalTensor<T> dstLocal = m_queOut.AllocTensor<T>();\n        dstLocal.SetSize(m_elementCount);\n        AscendC::Scatter(dstLocal, srcLocal, dstOffsetLocal, (uint32_t)0, m_elementCount);\n        m_queIn.FreeTensor(srcLocal);\n        m_queIn.FreeTensor(dstOffsetLocal);\n        m_queOut.EnQue(dstLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = m_queOut.DeQue<T>();\n        AscendC::DataCopy(m_dstGlobal, dstLocal, m_elementCount);\n        m_queOut.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe m_pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> m_queCalc;\n    AscendC::GlobalTensor<T> m_valueGlobal;\n    uint32_t m_concatRepeatTimes;\n    uint32_t m_sortRepeatTimes;\n    uint32_t m_extractRepeatTimes;\n    uint32_t m_elementCount;\n    AscendC::GlobalTensor<uint32_t> m_dstOffsetGlobal;\n    AscendC::GlobalTensor<T> m_srcGlobal;\n    AscendC::GlobalTensor<T> m_dstGlobal;\n    AscendC::TQue<AscendC::TPosition::VECIN, 2> m_queIn;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> m_queOut;\n}; // class ScatterTest\n\n#define KERNEL_SCATTER(T, count)                                                                    \\\n    extern \"C\" __global__ __aicore__ void kernel_scatter_##T##_##count(GM_ADDR dstGm, GM_ADDR srcGm,\\\n        GM_ADDR dstOffsetGm)                                                                        \\\n    {                                                                                               \\\n        ScatterTest<T> op;                                                                          \\\n        op.Init(dstGm, srcGm, dstOffsetGm, count);                                                  \\\n        op.Process();                                                                               \\\n    }",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "InitConstValue",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0237.html",
    "功能说明": "将特定TPosition的LocalTensor初始化为某一具体数值。",
    "函数原型": "template <typename T, typename U = PrimT<T>, typename Std::enable_if<Std::is_same<PrimT<T>, U>::value, bool>::type = true>\n__aicore__ inline void InitConstValue(const LocalTensor<T> &dstLocal, const InitConstValueParams<U> &initConstValueParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T dstLocal的数据类型。 Atlas 训练系列产品 ，支持的数据类型为：half Atlas 推理系列产品 AI Core ，支持的数据类型为：half/int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/int16_t/uint16_t/bfloat16_t/float/int32_t/uint32_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/int16_t/uint16_t/bfloat16_t/float/int32_t/uint32_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/int16_t/uint16_t/bfloat16_t/float/int32_t/uint32_t U 初始化值的数据类型。 当dstLocal使用基础数据类型时， U和dstLocal的数据类型T需保持一致，否则编译失败。 当dstLocal使用 TensorTrait 类型时，U和dstLocal的数据类型T的LiteType需保持一致，否则编译失败。 最后一个模板参数仅用于上述数据类型检查，用户无需关注。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，结果矩阵，类型为LocalTensor。 Atlas 训练系列产品 ，支持的TPosition为A1/A2/B1/B2。 Atlas 推理系列产品 AI Core ，支持的TPosition为A1/A2/B1/B2。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的TPosition为A1/A2/B1/B2。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的TPosition为A1/A2/B1/B2。 Atlas 200I/500 A2 推理产品 ，支持的TPosition为A1/A2/B1/B2。 如果TPosition为A1/B1，起始地址需要满足32B对齐；如果TPosition为A2/B2，起始地址需要满足512B对齐。 InitConstValueParams 输入 初始化相关参数，类型为InitConstValueParams。 具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_mm.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 参数说明请参考 表3 。 Atlas 训练系列产品 ，仅支持配置迭代次数（repeatTimes）和初始化值（initValue）。 Atlas 推理系列产品 AI Core ，仅支持配置迭代次数（repeatTimes）和初始化值（initValue）。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持配置所有参数。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持配置所有参数。 Atlas 200I/500 A2 推理产品 ，支持配置所有参数。 仅支持配置迭代次数（repeatTimes）和初始化值（initValue）场景下，其他参数配置无效。每次迭代处理固定数据量（512字节），迭代间无间隔。 支持配置所有参数场景下，支持配置迭代次数（repeatTimes）、初始化值（initValue）、每个迭代处理的数据块个数（blockNum）和迭代间间隔（dstGap）。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename dst_T, typename fmap_T, typename weight_T, typename dstCO1_T> class KernelCubeMmad {\npublic:\n    __aicore__ inline KernelCubeMmad()\n    {\n        C0 = 32 / sizeof(fmap_T);\n        C1 = channelSize / C0;\n        coutBlocks = (Cout + 16 - 1) / 16;\n        ho = H - dilationH * (Kh - 1);\n        wo = W - dilationW * (Kw - 1);\n        howo = ho * wo;\n        howoRound = ((howo + 16 - 1) / 16) * 16;\n        featureMapA1Size = C1 * H * W * C0;      // shape: [C1, H, W, C0]\n        weightA1Size = C1 * Kh * Kw * Cout * C0; // shape: [C1, Kh, Kw, Cout, C0]\n        featureMapA2Size = howoRound * (C1 * Kh * Kw * C0);\n        weightB2Size = (C1 * Kh * Kw * C0) * coutBlocks * 16;\n        m = howo;\n        k = C1 * Kh * Kw * C0;\n        n = Cout;\n        biasSize = Cout;                  // shape: [Cout]\n        dstSize = coutBlocks * howo * 16; // shape: [coutBlocks, howo, 16]\n        dstCO1Size = coutBlocks * howoRound * 16;\n        fmRepeat = featureMapA2Size / (16 * C0);\n        weRepeat = weightB2Size / (16 * C0);\n    }\n    __aicore__ inline void Init(__gm__ uint8_t* fmGm, __gm__ uint8_t* weGm, __gm__ uint8_t* biasGm,\n        __gm__ uint8_t* dstGm)\n    {\n        fmGlobal.SetGlobalBuffer((__gm__ fmap_T*)fmGm);\n        weGlobal.SetGlobalBuffer((__gm__ weight_T*)weGm);\n        biasGlobal.SetGlobalBuffer((__gm__ dstCO1_T*)biasGm);\n        dstGlobal.SetGlobalBuffer((__gm__ dst_T*)dstGm);\n        pipe.InitBuffer(inQueueFmA1, 1, featureMapA1Size * sizeof(fmap_T));\n        pipe.InitBuffer(inQueueFmA2, 1, featureMapA2Size * sizeof(fmap_T));\n        pipe.InitBuffer(inQueueWeB1, 1, weightA1Size * sizeof(weight_T));\n        pipe.InitBuffer(inQueueWeB2, 1, weightB2Size * sizeof(weight_T));\n        pipe.InitBuffer(inQueueBiasA1, 1, biasSize * sizeof(dstCO1_T));\n        pipe.InitBuffer(outQueueCO1, 1, dstCO1Size * sizeof(dstCO1_T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Split();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<fmap_T> featureMapA1 = inQueueFmA1.AllocTensor<fmap_T>();\n        AscendC::LocalTensor<weight_T> weightB1 = inQueueWeB1.AllocTensor<weight_T>();\n        AscendC::LocalTensor<dstCO1_T> biasA1 = inQueueBiasA1.AllocTensor<dstCO1_T>();\n\n        AscendC::InitConstValue(featureMapA1, {1, static_cast<uint16_t>(featureMapA1Size * sizeof(fmap_T) / 32), 0, 1});\n        AscendC::InitConstValue(weightB1, {1, static_cast<uint16_t>(weightA1Size * sizeof(weight_T) / 32), 0, 2});\n        AscendC::DataCopy(biasA1, biasGlobal, { 1, static_cast<uint16_t>(biasSize * sizeof(dstCO1_T) / 32), 0, 0 });\n\n        inQueueFmA1.EnQue(featureMapA1);\n        inQueueWeB1.EnQue(weightB1);\n        inQueueBiasA1.EnQue(biasA1);\n    }\n    __aicore__ inline void Split()\n    {\n        AscendC::LocalTensor<fmap_T> featureMapA1 = inQueueFmA1.DeQue<fmap_T>();\n        AscendC::LocalTensor<weight_T> weightB1 = inQueueWeB1.DeQue<weight_T>();\n        AscendC::LocalTensor<fmap_T> featureMapA2 = inQueueFmA2.AllocTensor<fmap_T>();\n        AscendC::LocalTensor<weight_T> weightB2 = inQueueWeB2.AllocTensor<weight_T>();\n\n        AscendC::InitConstValue(featureMapA2, {1, static_cast<uint16_t>(featureMapA2Size * sizeof(fmap_T) / 512), 0, 1});\n        AscendC::InitConstValue(weightB2, { 1, static_cast<uint16_t>(weightB2Size * sizeof(weight_T) / 512), 0, 2});\n\n        inQueueFmA2.EnQue<fmap_T>(featureMapA2);\n        inQueueWeB2.EnQue<weight_T>(weightB2);\n        inQueueFmA1.FreeTensor(featureMapA1);\n        inQueueWeB1.FreeTensor(weightB1);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<fmap_T> featureMapA2 = inQueueFmA2.DeQue<fmap_T>();\n        AscendC::LocalTensor<weight_T> weightB2 = inQueueWeB2.DeQue<weight_T>();\n        AscendC::LocalTensor<dstCO1_T> dstCO1 = outQueueCO1.AllocTensor<dstCO1_T>();\n        AscendC::LocalTensor<dstCO1_T> biasA1 = inQueueBiasA1.DeQue<dstCO1_T>();\n        AscendC::Mmad(dstCO1, featureMapA2, weightB2, biasA1, { m, n, k, true, 0, false, false, false });\n\n        outQueueCO1.EnQue<dstCO1_T>(dstCO1);\n        inQueueFmA2.FreeTensor(featureMapA2);\n        inQueueWeB2.FreeTensor(weightB2);\n        inQueueBiasA1.FreeTensor(biasA1);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dstCO1_T> dstCO1 = outQueueCO1.DeQue<dstCO1_T>();\n        AscendC::FixpipeParamsV220 fixpipeParams;\n        fixpipeParams.nSize = coutBlocks * 16;\n        fixpipeParams.mSize = howo;\n        fixpipeParams.srcStride = howo;\n        fixpipeParams.dstStride = howo * AscendC::BLOCK_CUBE * sizeof(dst_T) / AscendC::ONE_BLK_SIZE;\n        fixpipeParams.quantPre = deqMode;\n        AscendC::Fixpipe<dst_T, dstCO1_T, AscendC::CFG_NZ>(dstGlobal, dstCO1, fixpipeParams);\n        outQueueCO1.FreeTensor(dstCO1);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    // feature map queue\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueFmA1;\n    AscendC::TQue<AscendC::TPosition::A2, 1> inQueueFmA2;\n    // weight queue\n    AscendC::TQue<AscendC::TPosition::B1, 1> inQueueWeB1;\n    AscendC::TQue<AscendC::TPosition::B2, 1> inQueueWeB2;\n    // bias queue\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueBiasA1;\n    // dst queue\n    AscendC::TQue<AscendC::TPosition::CO1, 1> outQueueCO1;\n\n    AscendC::GlobalTensor<fmap_T> fmGlobal;\n    AscendC::GlobalTensor<weight_T> weGlobal;\n    AscendC::GlobalTensor<dst_T> dstGlobal;\n    AscendC::GlobalTensor<dstCO1_T> biasGlobal;\n\n    uint16_t channelSize = 32;\n    uint16_t H = 4, W = 4;\n    uint8_t Kh = 2, Kw = 2;\n    uint16_t Cout = 16;\n    uint16_t C0, C1;\n    uint8_t dilationH = 2, dilationW = 2;\n    uint16_t coutBlocks, ho, wo, howo, howoRound;\n    uint32_t featureMapA1Size, weightA1Size, featureMapA2Size, weightB2Size, biasSize, dstSize, dstCO1Size;\n    uint16_t m, k, n;\n    uint8_t fmRepeat, weRepeat;\n    AscendC::QuantMode_t deqMode = AscendC::QuantMode_t::F322F16;\n};\n\nextern \"C\" __global__ __aicore__ void cube_mmad_simple_kernel(__gm__ uint8_t *fmGm, __gm__ uint8_t *weGm,\n    __gm__ uint8_t *biasGm, __gm__ uint8_t *dstGm)\n{\n    KernelCubeMmad<half, half, half, half> op;\n    op.Init(fmGm, weGm, biasGm, dstGm);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "LoadData",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0238.html",
    "功能说明": "LoadData分为Load2D和Load3D，其功能分别如下： Load2D： 源操作数/目的操作数的数据类型为uint8_t/int8_t时，分形矩阵大小在A1/A2上为16*32， 在B1/B2上为32*16。 源操作数/目的操作数的数据类型为uint16_t/int16_t/half/bfloat16_t时，分形矩阵在A1/B1/A2/B2上的大小为16*16。 源操作数/目的操作数的数据类型为uint32_t/int32_t/float时，分形矩阵大小在A1/A2上为16*8， 在B1/B2上为8*16。 支持如下数据通路： GM->A1; GM->B1; GM->A2; GM->B2; A1->A2; B1->B2。 Load3D： image to column操作，将多维feature map转为二维矩阵。 支持如下数据通路： A1->A2; B1->B2。",
    "函数原型": "template <typename T>\nvoid LoadData(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LoadData2DParams& loadDataParams)\ntemplate <typename T> \nvoid LoadData(const LocalTensor<T>& dstLocal, const GlobalTensor<T>& srcLocal, const LoadData2DParams& loadDataParams)",
    "参数说明": "表1 模板参数说明 参数名称 含义 T 源操作数和目的操作数的数据类型。 Load2D接口： Atlas 训练系列产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half Atlas 推理系列产品 AI Core ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Atlas 200I/500 A2 推理产品 ，支持数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float Load3Dv1接口： Atlas 训练系列产品 ，支持的数据类型为：uint8_t/int8_t/half Atlas 推理系列产品 AI Core ，支持的数据类型为：uint8_t/int8_t/half Load3Dv2接口： Atlas 推理系列产品 AI Core ，支持的数据类型为：uint8_t/int8_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ， TPosition为A1/A2时，支持数据类型为：uint8_t/int8_t/half/bfloat16_t/uint32_t/int32_t/float/int4b_t TPosition为B1/B2时，支持数据类型为：half/bfloat16_t/uint32_t/int32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ， TPosition为A1/A2时，支持数据类型为：uint8_t/int8_t/half/bfloat16_t/uint32_t/int32_t/float/int4b_t TPosition为B1/B2时，支持数据类型为：half/bfloat16_t/uint32_t/int32_t/float Atlas 200I/500 A2 推理产品 ， TPosition为A1/A2时，支持数据类型为：uint8_t/int8_t/half/bfloat16/uint32_t/int32_t/float/int4b_t TPosition为B1/B2时，支持数据类型为：half/bfloat16_t/uint32_t/int32_t/float defaultConfig 控制是否在Load3Dv1/Load3Dv2接口内部设置相关属性。 IsResetLoad3dConfig类型。IsResetLoad3dConfig结构定义如下： struct IsResetLoad3dConfig { bool isSetFMatrix = true ; bool isSetPadding = true ; };",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass KernelLoadData {\npublic:\n    __aicore__ inline KernelLoadData()\n    {\n        coutBlocks = (Cout + 16 - 1) / 16;\n        ho = (H + padTop + padBottom - dilationH * (Kh - 1) - 1) / strideH + 1;\n        wo = (W + padLeft + padRight - dilationW * (Kw - 1) - 1) / strideW + 1;\n        howo = ho * wo;\n        howoRound = ((howo + 16 - 1) / 16) * 16;\n        featureMapA1Size = C1 * H * W * C0;      // shape: [C1, H, W, C0]\n        weightA1Size = C1 * Kh * Kw * Cout * C0; // shape: [C1, Kh, Kw, Cout, C0]\n        featureMapA2Size = howoRound * (C1 * Kh * Kw * C0);\n        weightB2Size = (C1 * Kh * Kw * C0) * coutBlocks * 16;\n        m = howo;\n        k = C1 * Kh * Kw * C0;\n        n = Cout;\n        dstSize = coutBlocks * howo * 16; // shape: [coutBlocks, howo, 16]\n        dstCO1Size = coutBlocks * howoRound * 16;\n        fmRepeat = featureMapA2Size / (16 * C0);\n        weRepeat = weightB2Size / (16 * C0);\n    }\n    __aicore__ inline void Init(__gm__ uint8_t* fmGm, __gm__ uint8_t* weGm, __gm__ uint8_t* dstGm)\n    {\n        fmGlobal.SetGlobalBuffer((__gm__ half*)fmGm);\n        weGlobal.SetGlobalBuffer((__gm__ half*)weGm);\n        dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm);\n        pipe.InitBuffer(inQueueFmA1, 1, featureMapA1Size * sizeof(half));\n        pipe.InitBuffer(inQueueFmA2, 1, featureMapA2Size * sizeof(half));\n        pipe.InitBuffer(inQueueWeB1, 1, weightA1Size * sizeof(half));\n        pipe.InitBuffer(inQueueWeB2, 1, weightB2Size * sizeof(half));\n        pipe.InitBuffer(outQueue\n, 1, dstCO1Size * sizeof(float));\n        pipe.InitBuffer(outQueueUB, 1, dstSize * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Split();\n        Compute();\n        CopyUB();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> featureMapA1 = inQueueFmA1.AllocTensor<half>();\n        AscendC::LocalTensor<half> weightB1 = inQueueWeB1.AllocTensor<half>();\n        AscendC::DataCopy(featureMapA1, fmGlobal, { 1, static_cast<uint16_t>(featureMapA1Size * sizeof(half) / 32), 0, 0 });\n        AscendC::DataCopy(weightB1, weGlobal, { 1, static_cast<uint16_t>(weightA1Size * sizeof(half) / 32), 0, 0 });\n        inQueueFmA1.EnQue(featureMapA1);\n        inQueueWeB1.EnQue(weightB1);\n    }\n    __aicore__ inline void Split()\n    {\n        AscendC::LocalTensor<half> featureMapA1 = inQueueFmA1.DeQue<half>();\n        AscendC::LocalTensor<half> weightB1 = inQueueWeB1.DeQue<half>();\n        AscendC::LocalTensor<half> featureMapA2 = inQueueFmA2.AllocTensor<half>();\n        AscendC::LocalTensor<half> weightB2 = inQueueWeB2.AllocTensor<half>();\n        uint8_t padList[4] = {padLeft, padRight, padTop, padBottom};\n        AscendC::LoadData(featureMapA2, featureMapA1,\n            { padList, H, W, 0, 0, 0, -1, -1, strideW, strideH, Kw, Kh, dilationW, dilationH, 1, 0, fmRepeat, 0, (half)(0)});\n        AscendC::LoadData(weightB2, weightB1, { 0, weRepeat, 1, 0, 0, false, 0 });\n        inQueueFmA2.EnQue<half>(featureMapA2);\n        inQueueWeB2.EnQue<half>(weightB2);\n        inQueueFmA1.FreeTensor(featureMapA1);\n        inQueueWeB1.FreeTensor(weightB1);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> featureMapA2 = inQueueFmA2.DeQue<half>();\n        AscendC::LocalTensor<half> weightB2 = inQueueWeB2.DeQue<half>();\n        AscendC::LocalTensor<float> dstCO1 = outQueueCO1.AllocTensor<float>();\n        AscendC::Mmad(dstCO1, featureMapA2, weightB2, { m, n, k, 0, false, true });\n        outQueueCO1.EnQue<float>(dstCO1);\n        inQueueFmA2.FreeTensor(featureMapA2);\n        inQueueWeB2.FreeTensor(weightB2);\n    }\n    __aicore__ inline void CopyUB()\n    {\n        AscendC::LocalTensor<float> dstCO1 = outQueueCO1.DeQue<float>();\n        AscendC::LocalTensor<half> dstUB = outQueueUB.AllocTensor<half>();\n        AscendC::DataCopyParams dataCopyParams;\n        dataCopyParams.blockCount = 1;\n        dataCopyParams.blockLen = m * n * sizeof(float) / 1024;\n        AscendC::DataCopyEnhancedParams enhancedParams;\n        enhancedParams.blockMode = AscendC::BlockMode::BLOCK_MODE_MATRIX;\n        AscendC::DataCopy(dstUB, dstCO1, dataCopyParams, enhancedParams);\n        outQueueUB.EnQue<half>(dstUB);\n        outQueueCO1.FreeTensor(dstCO1);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstUB = outQueueUB.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstUB, m * n);\n        outQueueUB.FreeTensor(dstUB);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    // feature map queue\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueFmA1;\n    AscendC::TQue<AscendC::TPosition::A2, 1> inQueueFmA2;\n    // weight queue\n    AscendC::TQue<AscendC::TPosition::B1, 1> inQueueWeB1;\n    AscendC::TQue<AscendC::TPosition::B2, 1> inQueueWeB2;\n    // dst queue\n    AscendC::TQue<AscendC::TPosition::CO1, 1> outQueueCO1;\n    AscendC::TQue<AscendC::TPosition::CO2, 1> outQueueUB;\n    AscendC::GlobalTensor<half> fmGlobal, weGlobal, dstGlobal;\n    uint16_t C1 = 2;\n    uint16_t H = 4, W = 4;\n    uint8_t Kh = 2, Kw = 2;\n    uint16_t Cout = 16;\n    uint16_t C0 = 16;\n    uint8_t dilationH = 2, dilationW = 2;\n    uint8_t padTop = 1, padBottom = 1, padLeft = 1, padRight = 1;\n    uint8_t strideH = 1, strideW = 1;\n    uint16_t coutBlocks, ho, wo, howo, howoRound;\n    uint32_t featureMapA1Size, weightA1Size, featureMapA2Size, weightB2Size, dstSize, dstCO1Size;\n    uint16_t m, k, n;\n    uint8_t fmRepeat, weRepeat;\n};\n\nextern \"C\" __global__ __aicore__ void load_data_simple_kernel(__gm__ uint8_t* fmGm, __gm__ uint8_t* weGm,\n    __gm__ uint8_t* dstGm)\n{\n    KernelLoadData op;\n    op.Init(fmGm, weGm, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "LoadDataWithTranspose",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0239.html",
    "功能说明": "该接口实现带转置的2D格式数据从A1/B1到A2/B2的加载。 下面通过示例来讲解接口功能和关键参数：下文图中一个N形或者一个Z形代表一个分形。 对于uint8_t/int8_t数据类型，每次迭代处理32*32*1B数据，可处理2个分形(一个分形512B)，每次迭代中，源操作数中2个连续的16*32分形将被合并为1个32*32的方块矩阵，基于方块矩阵做转置，转置后分裂为2个16*32分形，根据目的操作数分形间隔等参数可以有不同的排布。 如下图示例： 因为每次迭代处理32*32*1B数据，需要3次迭代可以完成，repeatTimes = 3； srcStride = 1，表示相邻迭代间，源操作数前一个方块矩阵与后一个方块矩阵起始地址的间隔为1（单位：32*32*1B），这里的单位实际上是拼接后的方块矩阵的大小； dstGap = 1，表示相邻迭代间，目的操作数前一个迭代第一个分形的结束地址到下一个迭代第一个分形起始地址的间隔为1（单位：512B）； dstFracGap = 0，表示每个迭代内目的操作数前一个分形的结束地址与后一个分形起始地址的间隔为0（单位：512B）。 如下图示例： repeatTimes和srcStride的解释和上图示例一致。 dstGap = 0，表示相邻迭代间，目的操作数前一个迭代第一个分形的结束地址和下一个迭代第一个分形起始地址无间隔。 dstFracGap = 2，表示每个迭代内目的操作数前一个分形的结束地址与后一个分形起始地址的间隔为2（单位：512B）。 对于half/bfloat16_t数据类型，每次迭代处理16*16*2B数据，可处理1个分形(一个分形512B)，每次迭代中，源操作数中1个16*16分形将被转置。 因为每次迭代处理16*16*2B数据，需要3次迭代可以完成，repeatTimes = 3； srcStride = 1，表示相邻迭代间，源操作数前一个方块矩阵与后一个方块矩阵起始地址的间隔为1 （单位：16*16*2B）； dstGap = 0，表示相邻迭代间，目的操作数前一个迭代第一个分形的结束地址到下一个迭代第一个分形起始地址无间隔； 该场景下，因为其分形即为方块矩阵，每个迭代处理一个分形，不存在迭代内分形的间隔，该参数设置无效。 对于float/int32_t/uint32_t数据类型，每次迭代处理16*16*4B数据，可处理2个分形（一个分形512B），每次迭代中，源操作数2个连续的16*8分形将被合并为1个16*16的方块矩阵，基于方块矩阵做转置，转置后分裂为2个16*8分形，根据目的操作数分形间隔等参数可以有不同的排布。 如下图示例： 因为每次迭代处理16*16*4B数据，需要3次迭代可以完成，repeatTimes = 3； srcStride = 1，表示相邻迭代间，源操作数前一个方块矩阵与后一个方块矩阵起始地址的间隔为1（单位：16*16*4B），这里的单位实际上是拼接后的方块矩阵的大小； dstGap = 1，表示相邻迭代间，目的操作数前一个迭代第一个分形的结束地址到下一个迭代第一个分形起始地址的间隔为1（单位：512B）； dstFracGap = 0，表示每个迭代内目的操作数前一个分形结束地址与后一个分形起始地址的间隔为0（单位：512B）。 如下图示例： repeatTimes和srcStride的解释和上图示例一致。 dstGap = 0，表示相邻迭代间，目的操作数前一个迭代第一个分形的结束地址和下一个迭代第一个分形起始地址无间隔。 dstFracGap = 2，表示每个迭代内目的操作数前一个分形结束地址与后一个分形起始地址的间隔为2（单位：512B）。 对于int4b_t数据类型，每次迭代处理64*64*0.5B数据，可处理4个分形(一个分形512B)，每次迭代中，源操作数中4个连续的16*64分形将被合并为1个64*64的方块矩阵，基于方块矩阵做转置，转置后分裂为4个16*64分形，根据目的操作数分形间隔等参数可以有不同的排布。 int4b_t数据类型需要两个数拼成一个int8_t或uint8_t的数，拼凑的规则如下： 如下图示例： 因为每次迭代处理64*64*0.5B数据，需要3次迭代可以完成，repeatTimes = 3； srcStride = 1，表示相邻迭代间，源操作数前一个方块矩阵与后一个方块矩阵起始地址的间隔为1（单位：64*64*0.5B），这里的单位实际上是拼接后的方块矩阵的大小； dstGap = 1，表示相邻迭代间，目的操作数前一个迭代第一个分形的结束地址到下一个迭代第一个分形起始地址的间隔为1（单位：512B）； dstFracGap = 0，表示每个迭代内目的操作数前一个分形的结束地址与后一个分形起始地址的间隔为0（单位：512B）。 如下图示例： repeatTimes和srcStride的解释和上图示例一致。 dstGap = 0，表示相邻迭代间，目的操作数前一个迭代第一个分形的结束地址和下一个迭代第一个分形起始地址无间隔。 dstFracGap = 2，表示每个迭代内目的操作数前一个分形的结束地址与后一个分形起始地址的间隔为2（单位：512B）。",
    "函数原型": "template <typename T>\n__aicore__ inline void LoadDataWithTranspose(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LoadData2dTransposeParams& loadDataParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/bfloat16_t/float/int32_t/uint32_t/uint8_t/int8_t/int4b_t。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/bfloat16_t/float/int32_t/uint32_t/uint8_t/int8_t/int4b_t。 Atlas 200I/500 A2 推理产品 ，支持的数据类型为：uint8_t/int8_t/uint16_t/int16_t/half/bfloat16_t/uint32_t/int32_t/float/int4b_t。 其中int4b_t数据类型仅在LocalTensor的TPosition为B2时支持。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，结果矩阵，类型为LocalTensor。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的TPosition为A2/B2。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的TPosition为A2/B2。 Atlas 200I/500 A2 推理产品 ，支持的TPosition为A2/B2。 LocalTensor的起始地址需要保证512字节对齐。 数据类型和srcLocal的数据类型保持一致。 srcLocal 输入 源操作数，类型为LocalTensor。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的TPosition为A1/B1。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的TPosition为A1/B1。 Atlas 200I/500 A2 推理产品 ，支持的TPosition为A1/B1。 LocalTensor的起始地址需要保证32字节对齐。 数据类型和dstLocal的数据类型保持一致。 loadDataParams 输入 LoadDataWithTranspose相关参数，类型为LoadData2dTransposeParams。 具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_mm.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 参数说明请参考 表3 。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename dst_T, typename fmap_T, typename weight_T, typename dstCO1_T> class KernelMatmul {\npublic:\n    __aicore__ inline KernelMatmul()\n    {\n        aSize = m * k;\n        bSize = k * n;\n        cSize = m * n;\n        nBlocks = n / 16;\n    }\n    __aicore__ inline void Init(__gm__ uint8_t *a, __gm__ uint8_t *b, __gm__ uint8_t *c)\n    {\n        aGM.SetGlobalBuffer((__gm__ fmap_T *)a);\n        bGM.SetGlobalBuffer((__gm__ weight_T *)b);\n        cGM.SetGlobalBuffer((__gm__ dstCO1_T *)c);\n        pipe.InitBuffer(inQueueA1, 1, aSize * sizeof(fmap_T));\n        pipe.InitBuffer(inQueueA2, 1, aSize * sizeof(fmap_T));\n        pipe.InitBuffer(inQueueB1, 1, bSize * sizeof(weight_T));\n        pipe.InitBuffer(inQueueB2, 2, bSize * sizeof(weight_T));\n        pipe.InitBuffer(outQueueCO1, 1, cSize * sizeof(dstCO1_T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        SplitA();\n        SplitB();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<fmap_T> a1Local = inQueueA1.AllocTensor<fmap_T>();\n        AscendC::LocalTensor<weight_T> b1Local = inQueueB1.AllocTensor<weight_T>();\n\n        AscendC::Nd2NzParams dataCopyA1Params;\n        dataCopyA1Params.ndNum = 1;\n        dataCopyA1Params.nValue = m;\n        dataCopyA1Params.dValue = k;\n        dataCopyA1Params.srcNdMatrixStride = 0;\n        dataCopyA1Params.srcDValue = k;\n        dataCopyA1Params.dstNzC0Stride = m;\n        dataCopyA1Params.dstNzNStride = 1;\n        dataCopyA1Params.dstNzMatrixStride = 0;\n        AscendC::DataCopy(a1Local, aGM, dataCopyA1Params);\n\n        AscendC::Nd2NzParams dataCopyB1Params;\n        dataCopyB1Params.ndNum = 1;\n        dataCopyB1Params.nValue = k;\n        dataCopyB1Params.dValue = n;\n        dataCopyB1Params.srcNdMatrixStride = 0;\n        dataCopyB1Params.srcDValue = n;\n        dataCopyB1Params.dstNzC0Stride = k;\n        dataCopyB1Params.dstNzNStride = 1;\n        dataCopyB1Params.dstNzMatrixStride = 0;\n        AscendC::DataCopy(b1Local, bGM, dataCopyB1Params);\n\n        inQueueA1.EnQue(a1Local);\n        inQueueB1.EnQue(b1Local);\n    }\n    __aicore__ inline void SplitA()\n    {\n        AscendC::LocalTensor<fmap_T> a1Local = inQueueA1.DeQue<fmap_T>();\n        AscendC::LocalTensor<fmap_T> a2Local = inQueueA2.AllocTensor<fmap_T>();\n\n        AscendC::LoadData2DParams loadL0AParams;\n        loadL0AParams.repeatTimes = aSize * sizeof(fmap_T) / 512;\n        loadL0AParams.srcStride = 1;\n        loadL0AParams.ifTranspose = false;\n        AscendC::LoadData(a2Local, a1Local, loadL0AParams);\n\n        inQueueA2.EnQue<fmap_T>(a2Local);\n        inQueueA1.FreeTensor(a1Local);\n    }\n    __aicore__ inline void SplitB()\n    {\n        AscendC::LocalTensor<weight_T> b1Local = inQueueB1.DeQue<weight_T>();\n        AscendC::LocalTensor<weight_T> b2Local = inQueueB2.AllocTensor<weight_T>();\n\n        AscendC::LoadData2dTransposeParams loadDataParams;\n        loadDataParams.startIndex = 0;\n        nBlockSize = 32;\n        loadDataParams.repeatTimes = n / nBlockSize;\n        loadDataParams.srcStride = 1;\n        loadDataParams.dstGap = 1;\n        loadDataParams.dstFracGap = 0;\n        AscendC::LoadDataWithTranspose(b2Local, b1Local, loadDataParams);\n\n        inQueueB1.FreeTensor(b1Local);\n        inQueueB2.EnQue<weight_T>(b2Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<fmap_T> a2Local = inQueueA2.DeQue<fmap_T>();\n        AscendC::LocalTensor<weight_T> b2Local = inQueueB2.DeQue<weight_T>();\n        AscendC::LocalTensor<dstCO1_T> c1Local = outQueueCO1.AllocTensor<dstCO1_T>();\n\n        AscendC::MmadParams mmadParams;\n        mmadParams.m = m;\n        mmadParams.n = n;\n        mmadParams.k = k;\n        AscendC::Mmad(c1Local, a2Local, b2Local, mmadParams);\n\n        outQueueCO1.EnQue<dstCO1_T>(c1Local);\n        inQueueA2.FreeTensor(a2Local);\n        inQueueB2.FreeTensor(b2Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dstCO1_T> c1Local = outQueueCO1.DeQue<dstCO1_T>();\n        AscendC::FixpipeParamsV220 fixpipeParams;\n        fixpipeParams.nSize = n;\n        fixpipeParams.mSize = m;\n        fixpipeParams.srcStride = m;\n        fixpipeParams.dstStride = n;\n\n        fixpipeParams.ndNum = 1;\n        fixpipeParams.srcNdStride = 0;\n        fixpipeParams.dstNdStride = 0;\n        AscendC::Fixpipe(cGM, c1Local, fixpipeParams);\n        outQueueCO1.FreeTensor(c1Local);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueA1;\n    AscendC::TQue<AscendC::TPosition::A2, 1> inQueueA2;\n    AscendC::TQue<AscendC::TPosition::B1, 1> inQueueB1;\n    AscendC::TQue<AscendC::TPosition::B2, 1> inQueueB2;\n    // dst queue\n    AscendC::TQue<AscendC::TPosition::CO1, 1> outQueueCO1;\n\n    AscendC::GlobalTensor<fmap_T> aGM;\n    AscendC::GlobalTensor<weight_T> bGM;\n    AscendC::GlobalTensor<dst_T> cGM;\n\n    uint16_t m = 16, k = 32, n = 64;\n    uint8_t nBlockSize = 16;\n    uint16_t c0Size = 16;\n    uint16_t aSize, bSize, cSize, nBlocks;\n};\n\nextern \"C\" __global__ __aicore__ void cube_matmul_loaddata_operator_int8_t(__gm__ uint8_t *a, __gm__ uint8_t *b,\n    __gm__ uint8_t *c)\n{\n    KernelMatmul<dst_type, fmap_type, weight_type, dstCO1_type> op;\n    op.Init(a, b, c);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SetAippFunctions",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0240.html",
    "功能说明": "设置图片预处理（AIPP，AI core pre-process）相关参数。和 LoadImageToLocal 接口配合使用。设置后，调用 LoadImageToLocal 接口可在搬运过程中完成图像预处理操作：包括数据填充，通道交换，单行读取、数据类型转换、通道填充、色域转换。调用SetAippFunctions接口时需传入源图片在Global Memory上的矩阵、源图片的图片格式。 数据填充 ：在图片HW方向上padding。分为如下几种模式： 模式0：常量填充模式，padding区域各位置填充为常数，支持设置每个通道填充的常数。该模式下仅支持左右padding，不支持上下padding。 图1 常量填充模式（图片中间的绿色区域表示原始数据，其他为padding数据） 模式1：行列填充模式，padding区域各位置填充行/列上最邻近源图片位置的数据。 图2 行列填充模式（图片中间的绿色区域表示原始数据，其他为padding数据） 模式2：块填充模式，按照padding的宽高，从源图片拷贝数据块进行padding区域填充。 图3 块填充模式（图片中间的绿色区域表示原始数据，其他为padding数据） 模式3：镜像块填充模式，按照padding的宽高，从源图片拷贝数据块的镜像进行padding区域填充。 图4 镜像块填充模式（图片中间的绿色区域表示原始数据，其他为padding数据） 通道交换 ：将图片通道进行交换。 对于RGB888格式，支持交换R和B通道。 对于YUV420SP格式，支持交换U和V通道。 对于XRGB8888格式，支持X通道后移（XRGB->RGBX）、支持交换R和B通道。 例：对于XRGB格式的数据，芯片在处理的时候会默认丢弃掉第四个通道的数据留下XRG。因此如果要保留RGB通道的数据，对于XRGB输入的需要后移X通道，将输入的通道转换为RGBX即可。 单行读取 ：源图片中仅读取一行。 调用数据搬运接口时，开启单行读取后设置的目的图片高度参数无效，如 LoadImageToLocal 接口的loadImageToLocalParams.verSize。 数据类型转换 ：转换像素的数据类型，支持uint8转换为int8或fp16。 // 例1：实现uint8 ->int8 的类型转换，同时实现零均值化：设置每个通道mean值为该通道所有数据的平均值（min和var值无效，不用设置）。 output [ i ][ j ][ k ] = input [ i ][ j ][ k ] – mean [ k ] // 例2：实现uint8 -> fp16 的类型转换，同时实现归一化：设置每个通道mean值为该通道所有数据的平均值，min值为该通道所有数据零均值化后的最小值，var值为该通道所有数据的最大值减最小值的倒数。 uint8 -> fp16 : output [ i ][ j ][ k ] = ( input [ i ][ j ][ k ] – mean [ k ] – min [ k ]) * var [ k ] 转换后的数据类型是由模板参数U配置，U为uint8时数据类型转换功能不生效。 调用数据搬运接口时，目的Tensor的数据类型需要与本接口输出数据类型保持一致，如 LoadImageToLocal 的dstLocal参数的数据类型。 通道填充 ：在图片通道方向上padding。默认为模式0。 模式0：将通道padding至32Bytes。即输出数据类型为uint8/int8时，padding至32通道；输出数据类型为fp16时，padding至16通道。 模式1：将通道padding至4通道。 色域转换 ：RGB格式转换为YUV格式，或YUV模式转换为RGB格式。",
    "函数原型": "template<typename T, typename U>\nvoid SetAippFunctions(const GlobalTensor<T>& src0, AippInputFormat format, AippParams<U> config)",
    "参数说明": "表1 模板参数说明 参数名称 含义 T 输入的数据类型，需要与format中设置的数据类型保持一致。 U 输出的数据类型，需要在搬运接口配置同样的数据类型，如 LoadImageToLocal 的dstLocal参数数据类型。 如果不使能数据类型转换功能，需要与输入类型保持一致； 如果使能数据类型转换功能，需要与期望转换后的类型保持一致。\n\n表2 参数说明 参数名称 输入/输出 含义 src0 输入 源图片在Global Memory上的矩阵。 源图片格式为YUV420SP时，表示Y维度在Global Memory上的矩阵。 src1 输入 源图片格式为YUV420SP时，表示UV维度在Global Memory上的矩阵。 源图片格式为其他格式时，该参数无效。 format 输入 源图片的图片格式。AippInputFormat为枚举类型，取值为： AippInputFormat::YUV420SP_U8：图片格式为YUV420 Semi-Planar，数据类型为uint8_t AippInputFormat::XRGB8888_U8：图片格式为XRGB8888，数据类型为uint8_t AippInputFormat::RGB888_U8：图片格式为RGB888，数据类型为uint8_t AippInputFormat::YUV400_U8：图片格式为YUV400，数据类型为uint8_t enum class AippInputFormat : uint8_t { YUV420SP_U8 = 0, XRGB8888_U8 = 1, RGB888_U8 = 4, YUV400_U8 = 9, }; config 输入 图片预处理的相关参数，类型为AippParams，结构体具体定义为： template < typename U > struct AippParams { AippPaddingParams < U > paddingParams ; AippSwapParams swapParams ; AippSingleLineParams singleLineParams ; AippDataTypeConvParams dtcParams ; AippChannelPaddingParams < U > cPaddingParams ; AippColorSpaceConvParams cscParams ; };",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass KernelLoadImage {\npublic:\n    __aicore__ inline KernelLoadImage()\n    {\n        // YUV420SP 图片中，Y 维度的 size\n        gmSrc0Size = srcHorizSize * srcVertSize;\n        // YUV420SP 图片中，UV 维度的 size\n        gmSrc1Size = (srcHorizSize / 2) * (srcVertSize / 2) * 2;\n        dstSize = dstHorizSize * dstVertSize * cSize;\n    }\n    __aicore__ inline void Init(__gm__ uint8_t *fmGm, __gm__ uint8_t *dstGm)\n    {\n        fmGlobal.SetGlobalBuffer((__gm__ uint8_t *)fmGm);\n        dstGlobal.SetGlobalBuffer((__gm__ int8_t *)dstGm);\n        pipe.InitBuffer(inQueueA1, 1, (gmSrc0Size + gmSrc1Size) * sizeof(int8_t));\n        pipe.InitBuffer(outQueueUB, 1, dstSize * sizeof(int8_t));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        CopyToUB();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<int8_t> featureMapA1 = inQueueA1.AllocTensor<int8_t>();\n        uint64_t fm_addr = static_cast<uint64_t>(reinterpret_cast<uintptr_t>(fmGlobal.GetPhyAddr()));\n        // aipp config\n        AscendC::AippParams<int8_t> aippConfig;\n        aippConfig.cPaddingParams.cPaddingMode = cPadMode;\n        aippConfig.cPaddingParams.cPaddingValue = cPaddingValue;\n        // fmGlobal为整张输入图片，src1参数处填入图片UV维度的起始地址\n        AscendC::SetAippFunctions(fmGlobal, fmGlobal[gmSrc0Size], inputFormat, aippConfig);\n        AscendC::LoadImageToLocal(featureMapA1, { horizSize, vertSize, horizStartPos, vertStartPos, srcHorizSize, topPadSize, botPadSize, leftPadSize, rightPadSize });\n        inQueueA1.EnQue(featureMapA1);\n    }\n    __aicore__ inline void CopyToUB()\n    {\n        AscendC::LocalTensor<int8_t> featureMapA1 = inQueueA1.DeQue<int8_t>();\n        AscendC::LocalTensor<int8_t> featureMapUB = outQueueUB.AllocTensor<int8_t>();\n        AscendC::DataCopy(featureMapUB, featureMapA1, dstSize);\n        event_t eventIdMTE1ToMTE3 = static_cast<event_t>(GetTPipePtr()->FetchEventID(AscendC::HardEvent::MTE1_MTE3));\n        AscendC::SetFlag<AscendC::HardEvent::MTE1_MTE3>(eventIdMTE1ToMTE3);\n        AscendC::WaitFlag<AscendC::HardEvent::MTE1_MTE3>(eventIdMTE1ToMTE3);\n        outQueueUB.EnQue<int8_t>(featureMapUB);\n        inQueueA1.FreeTensor(featureMapA1);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<int8_t> featureMapUB = outQueueUB.DeQue<int8_t>();\n        AscendC::DataCopy(dstGlobal, featureMapUB, dstSize);\n        outQueueUB.FreeTensor(featureMapUB);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueA1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueUB;\n\n    AscendC::GlobalTensor<uint8_t> fmGlobal;\n    AscendC::GlobalTensor<int8_t> dstGlobal;\n\n    uint16_t horizSize = 32, vertSize = 32, horizStartPos = 0, vertStartPos = 0, srcHorizSize = 32, srcVertSize = 32, leftPadSize = 0, rightPadSize = 0;\n    uint32_t dstHorizSize = 32, dstVertSize = 32, cSize = 32;\n    uint8_t topPadSize = 0, botPadSize = 0;\n    uint32_t gmSrc0Size = 0, gmSrc1Size = 0, dstSize = 0;\n    AscendC::AippInputFormat inputFormat = AscendC::AippInputFormat::YUV420SP_U8;\n    uint32_t cPadMode = 0;\n    int8_t cPaddingValue = 0;\n};\n\nextern \"C\" __global__ __aicore__ void load_image_simple_kernel(__gm__ uint8_t *fmGm, __gm__ uint8_t *dstGm)\n{\n    KernelLoadImage op;\n    op.Init(fmGm, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "LoadImageToLocal",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0241.html",
    "功能说明": "将图像数据从GM搬运到A1/B1。 搬运过程中可以完成图像预处理操作：包括图像翻转，改变图像尺寸（抠图，裁边，缩放，伸展），以及色域转换，类型转换等。图像预处理的相关参数通过 SetAippFunctions 进行配置。",
    "函数原型": "template <typename T>\n__aicore__ inline void LoadImageToLocal(const LocalTensor<T>& dstLocal, const LoadImageToLocalParams& loadDataParams)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，类型为LocalTensor，支持的TPosition为A1/B1。 LocalTensor的起始地址 需要保证32字节对齐。 Atlas 推理系列产品 AI Core ，支持的数据类型为：uint8_t/int8_t/half Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持数据类型：int8_t/half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持数据类型：int8_t/half Atlas 200I/500 A2 推理产品 支持数据类型为： uint8_t/int8_t/half loadDataParams 输入 LoadData参数结构体，类型为LoadImageToLocalParams。 具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_mm.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 参数说明参考 表2 。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass KernelLoadImage {\npublic:\n    __aicore__ inline KernelLoadImage()\n    {\n        // YUV420SP 图片中，Y 维度的 size\n        gmSrc0Size = srcHorizSize * srcVertSize;\n        // YUV420SP 图片中，UV 维度的 size\n        gmSrc1Size = (srcHorizSize / 2) * (srcVertSize / 2) * 2;\n        dstSize = dstHorizSize * dstVertSize * cSize;\n    }\n    __aicore__ inline void Init(__gm__ uint8_t *fmGm, __gm__ uint8_t *dstGm)\n    {\n        fmGlobal.SetGlobalBuffer((__gm__ uint8_t *)fmGm);\n        dstGlobal.SetGlobalBuffer((__gm__ int8_t *)dstGm);\n        pipe.InitBuffer(inQueueA1, 1, (gmSrc0Size + gmSrc1Size) * sizeof(int8_t));\n        pipe.InitBuffer(outQueueUB, 1, dstSize * sizeof(int8_t));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        CopyToUB();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<int8_t> featureMapA1 = inQueueA1.AllocTensor<int8_t>();\n        uint64_t fm_addr = static_cast<uint64_t>(reinterpret_cast<uintptr_t>(fmGlobal.GetPhyAddr()));\n        // aipp config\n        AscendC::AippParams<int8_t> aippConfig;\n        aippConfig.cPaddingParams.cPaddingMode = cPadMode;\n        aippConfig.cPaddingParams.cPaddingValue = cPaddingValue;\n        // fmGlobal为整张输入图片，src1参数处填入图片UV维度的起始地址\n        AscendC::SetAippFunctions(fmGlobal, fmGlobal[gmSrc0Size], inputFormat, aippConfig);\n        AscendC::LoadImageToLocal(featureMapA1, { horizSize, vertSize, horizStartPos, vertStartPos, srcHorizSize, topPadSize, botPadSize, leftPadSize, rightPadSize });\n        inQueueA1.EnQue(featureMapA1);\n    }\n    __aicore__ inline void CopyToUB()\n    {\n        AscendC::LocalTensor<int8_t> featureMapA1 = inQueueA1.DeQue<int8_t>();\n        AscendC::LocalTensor<int8_t> featureMapUB = outQueueUB.AllocTensor<int8_t>();\n        AscendC::DataCopy(featureMapUB, featureMapA1, dstSize);\n        event_t eventIdMTE1ToMTE3 = static_cast<event_t>(GetTPipePtr()->FetchEventID(AscendC::HardEvent::MTE1_MTE3));\n        AscendC::SetFlag<AscendC::HardEvent::MTE1_MTE3>(eventIdMTE1ToMTE3);\n        AscendC::WaitFlag<AscendC::HardEvent::MTE1_MTE3>(eventIdMTE1ToMTE3);\n        outQueueUB.EnQue<int8_t>(featureMapUB);\n        inQueueA1.FreeTensor(featureMapA1);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<int8_t> featureMapUB = outQueueUB.DeQue<int8_t>();\n        AscendC::DataCopy(dstGlobal, featureMapUB, dstSize);\n        outQueueUB.FreeTensor(featureMapUB);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueA1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueUB;\n\n    AscendC::GlobalTensor<uint8_t> fmGlobal;\n    AscendC::GlobalTensor<int8_t> dstGlobal;\n\n    uint16_t horizSize = 32, vertSize = 32, horizStartPos = 0, vertStartPos = 0, srcHorizSize = 32, srcVertSize = 32, leftPadSize = 0, rightPadSize = 0;\n    uint32_t dstHorizSize = 32, dstVertSize = 32, cSize = 32;\n    uint8_t topPadSize = 0, botPadSize = 0;\n    uint32_t gmSrc0Size = 0, gmSrc1Size = 0, dstSize = 0;\n    AscendC::AippInputFormat inputFormat = AscendC::AippInputFormat::YUV420SP_U8;\n    uint32_t cPadMode = 0;\n    int8_t cPaddingValue = 0;\n};\n\nextern \"C\" __global__ __aicore__ void load_image_simple_kernel(__gm__ uint8_t *fmGm, __gm__ uint8_t *dstGm)\n{\n    KernelLoadImage op;\n    op.Init(fmGm, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "LoadUnzipIndex",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0242.html",
    "功能说明": "加载GM上的压缩索引表到内部寄存器。 索引表为LoadDataUnzip压缩信息，例如压缩长度等，以获取压缩后的数据。 索引表由压缩工具根据对应的权重数据离线生成。一个LoadUnzipIndex指令可以加载多个索引表，而每个LoadDataUnzip指令只能消耗一个索引表。因此，索引表之间的顺序应该由用户来确定，以确保其与压缩数据的对应性。",
    "函数原型": "template <typename T = int8_t, typename Std::enable_if<Std::is_same<PrimT<T>, int8_t>::value, bool>::type = true> \n__aicore__ inline void LoadUnzipIndex(const GlobalTensor<T>& srcTensor, uint32_t numOfIndexTabEntry)",
    "参数说明": "表1 模板参数说明 参数名 描述 T srcTensor的数据类型。 当srcTensor使用基础数据类型时， 其数据类型必须为uint8_t，否则编译失败。 当srcTensor使用 TensorTrait 类型时， srcTensor数据类型T的LiteType必须为int8_t，否则编译失败。 最后一个模板参数仅用于上述数据类型检查，用户无需关注。\n\n表2 参数说明 参数名称 输入/输出 含义 srcTensor 输入 源操作数，索引表地址，类型为GlobalTensor。 srcTensor地址必须2字节对齐。srcTensor长度必须是512字节的整数倍，最大为32KB。 numOfIndexTabEntry 输入 输入数据，表示加载的索引表个数。索引表个数必须大于0。",
    "返回值": "无",
    "调用示例": "indexGlobal.SetGlobalBuffer((__gm__ int8_t*)indexGm);\nAscendC::LoadUnzipIndex(indexGlobal, numOfIndexTabEntry);",
    "错误": null
  },
  {
    "API名称": "LoadDataUnzip",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0243.html",
    "功能说明": "将GM上的数据解压并搬运到A1/B1/B2上。执行该API前需要执行 LoadUnzipIndex 加载压缩索引表。",
    "函数原型": "template <typename T>\n__aicore__ inline void LoadDataUnzip(const LocalTensor<T>& dstLocal, const GlobalTensor<T>& srcLocal)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，类型为LocalTensor，支持的TPosition为A1/B1/B2。 LocalTensor的起始地址需要保证：TPosition为A1/B1时，32字节对齐；TPosition为B2时，512B对齐。 支持的数据类型为：int8_t。 srcLocal 输入 源操作数，类型为GlobalTensor。数据类型需要与dstLocal保持一致。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass KernelLoadUnzip {\npublic:\n    __aicore__ inline KernelLoadUnzip() {}\n    __aicore__ inline void Init(__gm__ int8_t *weGm, __gm__ int8_t *indexGm, __gm__ int8_t *dstGm)\n    {\n        weGlobal.SetGlobalBuffer((__gm__ int8_t *)weGm);\n        indexGlobal.SetGlobalBuffer((__gm__ int8_t *)indexGm);\n        dstGlobal.SetGlobalBuffer((__gm__ int8_t *)dstGm);\n        pipe.InitBuffer(inQueueB1, 1, dstLen * sizeof(int8_t));\n        pipe.InitBuffer(outQueueUB, 1, dstLen * sizeof(int8_t));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        CopyToUB();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<int8_t> weightB1 = inQueueB1.AllocTensor<int8_t>();\n        AscendC::LoadUnzipIndex(indexGlobal, numOfIndexTabEntry);\n        AscendC::LoadDataUnzip(weightB1, weGlobal);\n        inQueueB1.EnQue(weightB1);\n    }\n    __aicore__ inline void CopyToUB()\n    {\n        AscendC::LocalTensor<int8_t> weightB1 = inQueueB1.DeQue<int8_t>();\n        AscendC::LocalTensor<int8_t> featureMapUB = outQueueUB.AllocTensor<int8_t>();\n        AscendC::DataCopy(featureMapUB, weightB1, dstLen);\n        outQueueUB.EnQue<int8_t>(featureMapUB);\n        inQueueB1.FreeTensor(weightB1);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<int8_t> featureMapUB = outQueueUB.DeQue<int8_t>();\n        event_t eventIdMTE1ToMTE3 = static_cast<event_t>(GetTPipePtr()->FetchEventID(AscendC::HardEvent::MTE1_MTE3));\n        AscendC::SetFlag<AscendC::HardEvent::MTE1_MTE3>(eventIdMTE1ToMTE3);\n        AscendC::WaitFlag<AscendC::HardEvent::MTE1_MTE3>(eventIdMTE1ToMTE3);\n        AscendC::DataCopy(dstGlobal, featureMapUB, dstLen);\n        outQueueUB.FreeTensor(featureMapUB);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::B1, 1> inQueueB1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueUB;\n    AscendC::GlobalTensor<int8_t> weGlobal;\n    AscendC::GlobalTensor<int8_t> dstGlobal;\n    AscendC::GlobalTensor<int8_t> indexGlobal;\n    uint32_t srcLen = 896, dstLen = 1024, numOfIndexTabEntry = 1;\n};\nextern \"C\" __global__ __aicore__ void cube_load_unzip_simple_kernel(__gm__ int8_t *weightGm,\n    __gm__ int8_t *indexGm, __gm__ int8_t *dstGm)\n{\n    KernelLoadUnzip op;\n    op.Init(weightGm, indexGm, dstGm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "LoadDataWithSparse",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0244.html",
    "功能说明": "用于搬运存放在B1里的512B的稠密权重矩阵到B2里，同时读取128B的索引矩阵用于稠密矩阵的稀疏化。索引矩阵的数据类型为int2，需要拼成int8的数据类型，再传入接口。 索引矩阵在一个int8的地址中的排布是逆序排布的，例如：索引矩阵1 2 0 1 0 2 1 0，在地址中的排布为1 0 2 1 0 1 2 0，其中1 0 2 1（对应索引矩阵前四位1 2 0 1）为一个int8，0 1 2 0（对应索引矩阵后四位0 2 1 0）为一个int8。 索引矩阵的功能说明参考 MmadWithSparse 。",
    "函数原型": "template <typename T = int8_t, typename U = uint8_t, typename Std::enable_if<Std::is_same<PrimT<T>, int8_t>::value, bool>::type = true, typename Std::enable_if<Std::is_same<PrimT<U>, uint8_t>::value, bool>::type = true>\n__aicore__ inline void LoadDataWithSparse(const LocalTensor<T> &dstLocal, const LocalTensor<T> &srcLocal, const LocalTensor<U> &idxLocal, const LoadData2dParams &loadDataParam)",
    "参数说明": "表1 模板参数说明 参数名 描述 T dstLocal、srcLocal的数据类型。 U idxLocal的数据类型。 当dstLocal、srcLocal、idxLocal为基础数据类型时，T和U必须为uint8_t类型，否则编译失败。 当dstLocal、srcLocal、idxLocal为 TensorTrait 类型时，T和U的LiteType必须为int8_t类型，否则编译失败。 最后两个模板参数仅用于上述数据类型检查，用户无需关注。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，类型为LocalTensor，支持的TPosition为B2， LocalTensor的起始地址需要512字节对齐。 支持的数据类型为int8_t。 数据连续排列顺序要求为小N大Z格式。 srcLocal 输入 源操作数，类型为LocalTensor，支持的TPosition为B1， LocalTensor的起始地址需要32字节对齐。 支持的数据类型为int8_t。 idxLocal 输入 源操作数，类型为LocalTensor，支持的TPosition为B1， LocalTensor的起始地址需要32字节对齐。 支持的数据类型为int8_t。 loadDataParam 输入 LoadData参数结构体，LoadData2DParams类型，详细说明参考 LoadData2DParams结构体内参数说明 。",
    "返回值": "无",
    "调用示例": "详细用例请参考 MmadWithSparse 。 父主题： 矩阵计算(ISASI) 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": null
  },
  {
    "API名称": "SetFmatrix",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0245.html",
    "功能说明": "用于调用 Load3Dv1/Load3Dv2 时设置FeatureMap的属性描述。Load3Dv1/Load3Dv2的模板参数isSetFMatrix设置为false时，表示Load3Dv1/Load3Dv2传入的FeatureMap的属性（包括l1H、l1W、padList，参数介绍参考 表4 LoadData3DParamsV1结构体内参数说明 、 表5 LoadData3DParamsV2结构体内参数说明 ）描述不生效，开发者需要通过该接口进行设置。",
    "函数原型": "__aicore__ inline void SetFmatrix(uint16_t l1H, uint16_t l1W, const uint8_t padList[4], const FmatrixMode& fmatrixMode)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 l1H 输入 源操作数height，取值范围：l1H∈[1, 32767]。 l1W 输入 源操作数width，取值范围：l1W∈[1, 32767] 。 padList 输入 padding列表 [padding_left, padding_right, padding_top, padding_bottom]，每个元素取值范围：[0,255]。默认为{0, 0, 0, 0}。 fmatrixMode 输入 用于控制LoadData指令从left还是right寄存器获取信息。FmatrixMode类型，定义如下。当前只支持FMATRIX_LEFT，左右矩阵均使用该配置。 enum class FmatrixMode : uint8_t { FMATRIX_LEFT = 0 , FMATRIX_RIGHT = 1 , };",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename dst_T, typename fmap_T, typename weight_T, typename dstCO1_T> class KernelLoad3d {\npublic:\n    __aicore__ inline KernelLoad3d()\n    {\n        // ceiling of 16\n        C0 = 32 / sizeof(fmap_T);\n        C1 = channelSize / C0;\n        coutBlocks = (Cout + 16 - 1) / 16;\n        ho = H - dilationH * (Kh - 1);\n        wo = W - dilationW * (Kw - 1);\n        howo = ho * wo;\n        howoRound = ((howo + 16 - 1) / 16) * 16;\n\n        featureMapA1Size = C1 * H * W * C0;      // shape: [C1, H, W, C0]\n        weightA1Size = C1 * Kh * Kw * Cout * C0; // shape: [C1, Kh, Kw, Cout, C0]\n        featureMapA2Size = howoRound * (C1 * Kh * Kw * C0);\n        weightB2Size = (C1 * Kh * Kw * C0) * coutBlocks * 16;\n        m = howo;\n        k = C1 * Kh * Kw * C0;\n        n = Cout;\n        biasSize = Cout;                  // shape: [Cout]\n        dstSize = coutBlocks * howo * 16; // shape: [coutBlocks, howo, 16]\n        dstCO1Size = coutBlocks * howoRound * 16;\n\n        fmRepeat = featureMapA2Size / (16 * C0);\n        weRepeat = weightB2Size / (16 * C0);\n    }\n    __aicore__ inline void Init(__gm__ uint8_t* fmGm, __gm__ uint8_t* weGm, __gm__ uint8_t* biasGm,\n        __gm__ uint8_t* dstGm)\n    {\n        fmGlobal.SetGlobalBuffer((__gm__ fmap_T*)fmGm);\n        weGlobal.SetGlobalBuffer((__gm__ weight_T*)weGm);\n        biasGlobal.SetGlobalBuffer((__gm__ dstCO1_T*)biasGm);\n        dstGlobal.SetGlobalBuffer((__gm__ dst_T*)dstGm);\n        pipe.InitBuffer(inQueueFmA1, 1, featureMapA1Size * sizeof(fmap_T));\n        pipe.InitBuffer(inQueueFmA2, 1, featureMapA2Size * sizeof(fmap_T));\n        pipe.InitBuffer(inQueueWeB1, 1, weightA1Size * sizeof(weight_T));\n        pipe.InitBuffer(inQueueWeB2, 1, weightB2Size * sizeof(weight_T));\n        pipe.InitBuffer(outQueueCO1, 1, dstCO1Size * sizeof(dstCO1_T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Split();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<fmap_T> featureMapA1 = inQueueFmA1.AllocTensor<fmap_T>();\n        AscendC::LocalTensor<weight_T> weightB1 = inQueueWeB1.AllocTensor<weight_T>();\n\n        AscendC::DataCopy(featureMapA1, fmGlobal, { 1, static_cast<uint16_t>(featureMapA1Size * sizeof(fmap_T) / 32), 0, 0 });\n        AscendC::DataCopy(weightB1, weGlobal, { 1, static_cast<uint16_t>(weightA1Size * sizeof(weight_T) / 32), 0, 0 });\n\n        inQueueFmA1.EnQue(featureMapA1);\n        inQueueWeB1.EnQue(weightB1);\n    }\n    __aicore__ inline void Split()\n    {    \n        AscendC::LocalTensor<fmap_T> featureMapA1 = inQueueFmA1.DeQue<fmap_T>();\n        AscendC::LocalTensor<weight_T> weightB1 = inQueueWeB1.DeQue<weight_T>();\n        AscendC::LocalTensor<fmap_T> featureMapA2 = inQueueFmA2.AllocTensor<fmap_T>();\n        AscendC::LocalTensor<weight_T> weightB2 = inQueueWeB2.AllocTensor<weight_T>();\n\n        uint8_t padList[PAD_SIZE] = {0, 0, 0, 0};\n        AscendC::SetFmatrix(H, W, padList, FmatrixMode::FMATRIX_LEFT);\n        AscendC::SetLoadDataPaddingValue(0);\n        AscendC::SetLoadDataRepeat({0, 1, 0});\n        AscendC::SetLoadDataBoundary((uint32_t)0);\n        static constexpr AscendC::IsResetLoad3dConfig LOAD3D_CONFIG = {false,false};\n        AscendC::LoadData<fmap_T, LOAD3D_CONFIG>(featureMapA2, featureMapA1,\n            { padList, H, W, channelSize, k, howoRound, 0, 0, 1, 1, Kw, Kh, dilationW, dilationH, false, false, 0 });\n        AscendC::LoadData(weightB2, weightB1, { 0, weRepeat, 1, 0, 0, false, 0 });\n\n        inQueueFmA2.EnQue<fmap_T>(featureMapA2);\n        inQueueWeB2.EnQue<weight_T>(weightB2);\n        inQueueFmA1.FreeTensor(featureMapA1);\n        inQueueWeB1.FreeTensor(weightB1);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<fmap_T> featureMapA2 = inQueueFmA2.DeQue<fmap_T>();\n        AscendC::LocalTensor<weight_T> weightB2 = inQueueWeB2.DeQue<weight_T>();\n        AscendC::LocalTensor<dstCO1_T> dstCO1 = outQueueCO1.AllocTensor<dstCO1_T>();\n\n        AscendC::Mmad(dstCO1, featureMapA2, weightB2, { m, n, k, true, 0, false, false, false });\n\n        outQueueCO1.EnQue<dstCO1_T>(dstCO1);\n        inQueueFmA2.FreeTensor(featureMapA2);\n        inQueueWeB2.FreeTensor(weightB2);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dstCO1_T> dstCO1 = outQueueCO1.DeQue<dstCO1_T>();\n        AscendC::FixpipeParamsV220 fixpipeParams;\n        fixpipeParams.nSize = coutBlocks * 16;\n        fixpipeParams.mSize = howo;\n        fixpipeParams.srcStride = howo;\n        fixpipeParams.dstStride = howo * AscendC::BLOCK_CUBE * sizeof(dst_T) / AscendC::ONE_BLK_SIZE;\n        fixpipeParams.quantPre = deqMode;\n        AscendC::Fixpipe<dst_T, dstCO1_T, AscendC::CFG_NZ>(dstGlobal, dstCO1, fixpipeParams);\n        outQueueCO1.FreeTensor(dstCO1);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    // feature map queue\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueFmA1;\n    AscendC::TQue<AscendC::TPosition::A2, 1> inQueueFmA2;\n    // weight queue\n    AscendC::TQue<AscendC::TPosition::B1, 1> inQueueWeB1;\n    AscendC::TQue<AscendC::TPosition::B2, 1> inQueueWeB2;\n    // dst queue\n    AscendC::TQue<AscendC::TPosition::CO1, 1> outQueueCO1;\n\n    AscendC::GlobalTensor<fmap_T> fmGlobal;\n    AscendC::GlobalTensor<weight_T> weGlobal;\n    AscendC::GlobalTensor<dst_T> dstGlobal;\n    AscendC::GlobalTensor<dstCO1_T> biasGlobal;\n\n    uint16_t channelSize = 32;\n    uint16_t H = 4, W = 4;\n    uint8_t Kh = 2, Kw = 2;\n    uint16_t Cout = 16;\n    uint16_t C0, C1;\n    uint8_t dilationH = 2, dilationW = 2;\n\n    uint16_t coutBlocks, ho, wo, howo, howoRound;\n    uint32_t featureMapA1Size, weightA1Size, featureMapA2Size, weightB2Size, biasSize, dstSize, dstCO1Size;\n    uint16_t m, k, n;\n    uint8_t fmRepeat, weRepeat;\n    AscendC::QuantMode_t deqMode = AscendC::QuantMode_t::F322F16;\n};\n\nextern \"C\" __global__ __aicore__ void load3d_simple_kernel(__gm__ uint8_t *fmGm, __gm__ uint8_t *weGm,\n    __gm__ uint8_t *biasGm, __gm__ uint8_t *dstGm)\n{\n    KernelLoad3d<dst_type, fmap_type, weight_type, dstCO1_type> op;\n    op.Init(fmGm, weGm, biasGm, dstGm);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SetLoadDataBoundary",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0246.html",
    "功能说明": "设置 Load3D 时A1/B1边界值。 如果Load3D指令在处理源操作数时，源操作数在A1/B1上的地址超出设置的边界，则会从A1/B1起始地址开始读取数据。",
    "函数原型": "__aicore__ inline void SetLoadDataBoundary(uint32_t boundaryValue)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 boundaryValue 输入 边界值。 Load3Dv1指令：单位是32字节。 Load3Dv2指令：单位是字节。",
    "返回值": "",
    "调用示例": "参考 调用示例 。 父主题： 矩阵计算(ISASI) 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SetLoadDataRepeat",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0247.html",
    "功能说明": "用于设置 Load3Dv2接口 的repeat参数。设置repeat参数后，可以通过调用一次Load3Dv2接口完成多个迭代的数据搬运。",
    "函数原型": "__aicore__ inline void SetLoadDataRepeat(const LoadDataRepeatParam& repeatParams)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 repeatParams 输入 设置Load3Dv2接口的repeat参数，类型为LoadDataRepeatParam。 具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_mm.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 参数说明请参考 表2 。",
    "返回值": "",
    "调用示例": "参考 调用示例 父主题： 矩阵计算(ISASI) 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SetLoadDataPaddingValue",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0248.html",
    "功能说明": "用于调用 Load3Dv1接口 / Load3Dv2接口 时设置Pad填充的数值。Load3Dv1/Load3Dv2的模板参数isSetPadding设置为true时，用户需要通过本接口设置Pad填充的数值，设置为false时，本接口设置的填充值不生效。",
    "函数原型": "template <typename T>\n__aicore__ inline void SetLoadDataPaddingValue(const T padValue)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 padValue 输入 Pad填充值的数值。 Atlas 推理系列产品 AI Core ，支持的数据类型为：int8_t/uint8_t/half/int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持数据类型：int8_t/uint8_t/half/int16_t/uint16_t/bfloat16_t/int32_t/uint32_t/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持数据类型：int8_t/uint8_t/half/int16_t/uint16_t/bfloat16_t/int32_t/uint32_t/float Atlas 200I/500 A2 推理产品 ， 支持数据类型：int8_t/uint8_t/half/int16_t/uint16_t/bfloat16_t/int32_t/uint32_t/float",
    "返回值": "",
    "调用示例": "参考 调用示例 父主题： 矩阵计算(ISASI) 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Mmad",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0249.html",
    "功能说明": "完成矩阵乘加（C += A * B）操作。矩阵ABC分别为A2/B2/CO1中的数据。 ABC矩阵的数据排布格式分别为ZZ，ZN，NZ。 下图中每个小方格代表一个分形矩阵，Z字形的黑色线条代表数据的排列顺序，起始点是左上角，终点是右下角。 矩阵A：每个分形矩阵内部是行主序，分形矩阵之间是行主序。简称小Z大Z格式。分形shape为16 x (32B/sizeof(AType))，大小为512Byte。 矩阵B：每个分形矩阵内部是列主序，分形矩阵之间是行主序。简称小N大Z格式。分形shape为 (32B/sizeof(BType)) x 16，大小为512Byte。 矩阵C：每个分形矩阵内部是行主序，分形矩阵之间是列主序。简称小Z大N格式。分形shape为16 x 16，大小为256个元素。 以下是一个简单的例子，假设分形矩阵的大小是2x2（并不符合真实情况，仅作为示例），矩阵ABC的大小都是4x4。 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 矩阵A的排列顺序：0，1，4，5，2，3，6，7，8，9，12，13，10，11，14，15。 矩阵B的排列顺序：0，4，1，5，2，6，3，7，8，12，9，13，10，14，11，15。 矩阵C的排列顺序：0，1，4，5，8，9，12，13，2，3，6，7，10，11，14，15。",
    "函数原型": "template <typename DstT, typename Src0T, typename Src1T>\n__aicore__ inline void Mmad(const LocalTensor<DstT>& dstLocal, const LocalTensor<Src0T>& fmLocal, const LocalTensor<Src1T>& filterLocal, const MmadParams& mmadParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 DstT 目的操作数的数据类型。 Src0T 左矩阵的数据类型。 Src1T 右矩阵的数据类型。 BiasT Bias矩阵的数据类型。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，结果矩阵，类型为LocalTensor，支持的TPosition为CO1。 LocalTensor的起始地址需要256个元素对齐。 fmLocal 输入 源操作数，左矩阵a，类型为LocalTensor，支持的TPosition为A2。 LocalTensor的起始地址需要512字节对齐。 filterLocal 输入 源操作数，右矩阵b，类型为LocalTensor，支持的TPosition为B2。 LocalTensor的起始地址需要512字节对齐。 biasLocal 输入 源操作数，bias矩阵，类型为LocalTensor，支持的TPosition为C2、CO1。 LocalTensor的起始地址需要128字节对齐。 mmadParams 输入 矩阵乘相关参数，类型为MmadParams。 具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_mm.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 参数说明请参考 表3 。",
    "返回值": "",
    "调用示例": "不含矩阵乘偏置的样例请参考 Mmad样例 。 包含矩阵乘偏置的样例请参考 包含矩阵乘偏置的Mmad样例 。 父主题： 矩阵计算(ISASI) 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "MmadWithSparse",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0250.html",
    "功能说明": "完成矩阵乘加操作，传入的左矩阵A为稀疏矩阵， 右矩阵B为稠密矩阵 。对于矩阵A，在MmadWithSparse计算时完成稠密化；对于矩阵B，在计算执行前的输入数据准备时自行完成稠密化（按照下文中介绍的稠密算法进行稠密化），所以输入本接口的B矩阵为稠密矩阵。B稠密矩阵需要通过调用 LoadDataWithSparse 载入，同时加载索引矩阵，索引矩阵在矩阵B稠密化的过程中生成，再用于A矩阵的稠密化。",
    "函数原型": "template <typename T = int32_t, typename U = int8_t, typename Std::enable_if<Std::is_same<PrimT<T>, int32_t>::value, bool>::type = true, typename Std::enable_if<Std::is_same<PrimT<U>, int8_t>::value, bool>::type = true>\n__aicore__ inline void MmadWithSparse(const LocalTensor<T>& dstLocal, const LocalTensor<U>& fmLocal, const LocalTensor<U>& filterLocal, const MmadParams& mmadParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T dstLocal的数据类型。 U fmLocal、filterLocal的数据类型。 当dstLocal、fmLocal、filterLocal为基础数据类型时， T必须为int32_t类型，U必须为int8_t类型，否则编译失败。 当dstLocal、fmLocal、filterLocal为 TensorTrait 类型时，T的LiteType必须为int32_t类型，U的LiteType必须为int8_t类型，否则编译失败。 最后两个模板参数仅用于上述数据类型检查，用户无需关注。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数，结果矩阵，类型为LocalTensor，支持的TPosition为CO1。 LocalTensor的起始地址需要256个元素（ 1024字节 ）对齐。 fmLocal 输入 源操作数，左矩阵A，类型为LocalTensor，支持的TPosition为A2。 LocalTensor的起始地址需要512字节对齐。 filterLocal 输入 源操作数，右矩阵B，类型为LocalTensor，支持的TPosition为B2。 LocalTensor的起始地址需要512字节对齐。 mmadParams 输入 矩阵乘相关参数，类型为MmadParams。 具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_mm.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 参数说明请参考 表3 。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass KernelMatmul {\npublic:\n    __aicore__ inline KernelMatmul() {}\n    __aicore__ inline void Init(__gm__ uint8_t* a, __gm__ uint8_t* b, __gm__ uint8_t* idx, __gm__ uint8_t* c, uint16_t m, uint16_t k, uint16_t n)\n    {\n        this->m = m;\n        this->k = k;\n        this->n = n;\n\n        aSize = m * k;\n        bSize = k / 2 * n;\n        cSize = m * n;\n        mBlocks = m / 16;\n        nBlocks = n / 16;\n        kBlocks = k / 32;\n\n        aGM.SetGlobalBuffer((__gm__ int8_t*)a);\n        bGM.SetGlobalBuffer((__gm__ int8_t*)b);\n        idxGM.SetGlobalBuffer((__gm__ uint8_t*)idx);\n        cGM.SetGlobalBuffer((__gm__ int32_t*)c);\n        pipe.InitBuffer(inQueueA1, 1, aSize * sizeof(int8_t));\n        pipe.InitBuffer(inQueueA2, 1, aSize * sizeof(int8_t));\n        pipe.InitBuffer(inQueueB1, 1, bSize * sizeof(int8_t));\n        pipe.InitBuffer(inQueueIdxB1, 1, (bSize / 4) * sizeof(int8_t));\n        pipe.InitBuffer(inQueueB2, 1, bSize * sizeof(int8_t));\n        pipe.InitBuffer(outQueueCO1, 1, cSize * sizeof(int32_t));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        SplitA();\n\n        AscendC::LocalTensor<int8_t> b1Local = inQueueB1.DeQue<int8_t>();\n        AscendC::LocalTensor<uint8_t> idexb1Local = inQueueIdxB1.DeQue<uint8_t>();\n        AscendC::LocalTensor<int8_t> a2Local = inQueueA2.DeQue<int8_t>();\n        SplitB(b1Local, idexb1Local);\n        Compute(a2Local);\n        inQueueB1.FreeTensor(b1Local);\n        inQueueIdxB1.FreeTensor(idexb1Local);\n        inQueueA2.FreeTensor(a2Local);\n\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<int8_t> a1Local = inQueueA1.AllocTensor<int8_t>();\n        AscendC::LocalTensor<int8_t> b1Local = inQueueB1.AllocTensor<int8_t>();\n        AscendC::LocalTensor<uint8_t> idxb1Local = inQueueIdxB1.AllocTensor<uint8_t>();\n        AscendC::DataCopy(a1Local, aGM, { 1, static_cast<uint16_t>(aSize * sizeof(int8_t) / 32), 0, 0 });\n        AscendC::DataCopy(b1Local, bGM, { 1, static_cast<uint16_t>(bSize * sizeof(int8_t) / 32), 0, 0 });\n        AscendC::DataCopy(idxb1Local, idxGM, { 1, static_cast<uint16_t>(bSize / 4 * sizeof(int8_t) / 32), 0, 0 });\n\n        inQueueA1.EnQue(a1Local);\n        inQueueB1.EnQue(b1Local);\n        inQueueIdxB1.EnQue(idxb1Local);\n    }\n    __aicore__ inline void SplitA()\n    {\n        int srcOffset = 0;\n        int dstOffset = 0;\n        AscendC::LocalTensor<int8_t> a1Local = inQueueA1.DeQue<int8_t>();\n        AscendC::LocalTensor<int8_t> a2Local = inQueueA2.AllocTensor<int8_t>();\n\n        AscendC::LoadData2DParams loadDataParams;\n        loadDataParams.repeatTimes = kBlocks * mBlocks;\n        loadDataParams.srcStride = 1;\n        loadDataParams.ifTranspose = false;\n\n        AscendC::LoadData(a2Local, a1Local, loadDataParams);\n\n        inQueueA2.EnQue<int8_t>(a2Local);\n        inQueueA1.FreeTensor(a1Local);\n    }\n    __aicore__ inline void SplitB(AscendC::LocalTensor<int8_t>& b1Local, AscendC::LocalTensor<uint8_t>& idxb1Local)\n    {\n        AscendC::LocalTensor<int8_t> b2Local = inQueueB2.AllocTensor<int8_t>();\n\n        // transform nz to zn\n        AscendC::LoadData2DParams loadDataParams;\n        loadDataParams.repeatTimes = kBlocks * nBlocks / 2;\n        loadDataParams.srcStride = 0;\n        loadDataParams.ifTranspose = false;\n\n        AscendC::LoadDataWithSparse(b2Local, b1Local, idxb1Local, loadDataParams);\n\n        inQueueB2.EnQue<int8_t>(b2Local);\n    }\n    __aicore__ inline void Compute(const AscendC::LocalTensor<int8_t>& a2Local)\n    {\n        AscendC::LocalTensor<int8_t> b2Local = inQueueB2.DeQue<int8_t>();\n        AscendC::LocalTensor<int32_t> c1Local = outQueueCO1.AllocTensor<int32_t>();\n\n        AscendC::MmadWithSparse(c1Local, a2Local, b2Local, { m, n, k, false, 0, false, false, false });\n\n        outQueueCO1.EnQue<int32_t>(c1Local);\n        inQueueB2.FreeTensor(b2Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<int32_t> c1Local = outQueueCO1.DeQue<int32_t>();\n\n        AscendC::FixpipeParamsV220 fixpipeParams;\n        fixpipeParams.nSize = n;\n        fixpipeParams.mSize = m;\n        fixpipeParams.srcStride = m;\n        fixpipeParams.dstStride = n;\n\n        fixpipeParams.ndNum = 1;\n        fixpipeParams.srcNdStride = 0;\n        fixpipeParams.dstNdStride = 0;\n\n        AscendC::Fixpipe(cGM, c1Local, fixpipeParams);\n\n        outQueueCO1.FreeTensor(c1Local);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueA1;\n    AscendC::TQue<AscendC::TPosition::A2, 1> inQueueA2;\n    AscendC::TQue<AscendC::TPosition::B1, 1> inQueueB1;\n    AscendC::TQue<AscendC::TPosition::B1, 1> inQueueIdxB1;\n    AscendC::TQue<AscendC::TPosition::B2, 1> inQueueB2;\n    // dst queue\n    AscendC::TQue<AscendC::TPosition::CO1, 1> outQueueCO1;\n\n    AscendC::GlobalTensor<int8_t> aGM, bGM;\n    AscendC::GlobalTensor<uint8_t> idxGM;\n    AscendC::GlobalTensor<int32_t> cGM;\n\n    uint16_t m;\n    uint16_t n;\n    uint16_t k;\n\n    uint16_t aSize, bSize, cSize, mBlocks, nBlocks, kBlocks;\n};\n\n#define KERNEL_MMAD_WITH_SPARSE_OPERATOR_TEST(m, k, n)                                        \\\n    extern \"C\" __global__ __aicore__ void kernel_mmad_with_sparse_operator##_##m##_##k##_##n( \\\n        GM_ADDR a, GM_ADDR b, GM_ADDR idx, GM_ADDR c)                                         \\\n    {                                                                                         \\\n        KernelMatmul op;                                                                      \\\n        op.Init(a, b, idx, c, m, k, n);                                                       \\\n        op.Process();                                                                         \\\n    }\n\nKERNEL_MMAD_WITH_SPARSE_OPERATOR_TEST(16, 64, 16)",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Fixpipe",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0251.html",
    "功能说明": "矩阵计算完成后，对结果进行处理，例如对计算结果进行量化操作，并把数据从CO1搬迁到Global Memory中。",
    "函数原型": "template <typename DstT, typename SrcT, const FixpipeConfig& config = CFG_ROW_MAJOR>\nvoid Fixpipe(const GlobalTensor<DstT>& dstGlobal, const LocalTensor<SrcT>& srcLocal, const FixpipeParamsV220& intriParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 DstT 目的操作数数据类型。 SrcT 源操作数数据类型。 config Fixpipe相关配置参数，类型为FixpipeConfig。取值如下： CFG_ROW_MAJOR（默认取值） ：使能NZ2ND，输出数据格式为ND格式。 CFG_NZ: 不使能NZ2ND，输出数据格式为NZ格式。 struct FixpipeConfig { CO2Layout format ; }; enum class CO2Layout : uint8_t { NZ = 0 , // 不使能NZ2ND，输出数据格式仍为NZ格式。 ROW_MAJOR , // 使能NZ2ND，输出数据格式为ND格式。 }; constexpr FixpipeConfig CFG_NZ = { CO2Layout :: NZ }; constexpr FixpipeConfig CFG_ROW_MAJOR = { CO2Layout :: ROW_MAJOR };\n\n表2 参数说明 参数名称 输入/输出 含义 dstGlobal 输出 目的操作数，类型为 GlobalTensor 。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int8_t、uint8_t、half、bfloat16_t、int32_t、float。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int8_t、uint8_t、half、bfloat16_t、int32_t、float。 Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int8_t、uint8_t、half、bfloat16_t、int32_t、float。 数据格式为NZ或ND格式。经过Fixpipe处理，在量化操作之后，会将矩阵计算中多申请的数据删除。 srcLocal 输入 源操作数，支持的TPosition为CO1，为Mmad接口计算的结果，类型为LocalTensor数据结构的定义请参考 LocalTensor 。支持的数据类型为float/int32_t，支持的TPosition为CO1，数据格式为NZ格式。起始地址需要满足64B对齐。 intriParams 输入 Fixpipe搬运参数，具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_fixpipe.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 参数说明请参考 表3 。 cbufWorkspace 输入 量化参数，类型为LocalTensor<uint64_t>，支持的TPosition为A1。仅当quantPre为VDEQF16/VQF322B8_PRE/VREQ8时支持，quantPre介绍请参考FixpipeParamsV220/FixpipeParamsM300/FixpipeParamsM310结构体中quantPre部分。",
    "返回值": "",
    "调用示例": "#ifdef ASCENDC_CPU_DEBUG\n#include \"tikicpulib.h\"\n#endif\n#include \"kernel_operator.h\"\n\ntemplate <typename C_T, typename A_T, typename B_T, typename dstCO1_T>\nclass KernelMatmul {\npublic:\n    __aicore__ inline KernelMatmul(uint16_t mIn, uint8_t kIn, uint8_t nIn)\n    {\n        m = mIn;\n        k = kIn;\n        n = nIn;\n        aSize = m * k;\n        bSize = k * n;\n        cSize = m * n;\n        mBlocks = m / AscendC::BLOCK_CUBE;\n        nBlocks = n / AscendC::BLOCK_CUBE;\n        kBlocks = k / (AscendC::ONE_BLK_SIZE / sizeof(A_T));\n    }\n    __aicore__ inline void Init(__gm__ uint8_t *a, __gm__ uint8_t *b, __gm__ uint8_t *c)\n    {\n        aGM.SetGlobalBuffer((__gm__ A_T *)a);\n        bGM.SetGlobalBuffer((__gm__ B_T *)b);\n        cGM.SetGlobalBuffer((__gm__ C_T *)c);\n        pipe.InitBuffer(inQueueA1, 1, aSize * sizeof(A_T));\n        pipe.InitBuffer(inQueueA2, 1, aSize * sizeof(A_T));\n        pipe.InitBuffer(inQueueB1, 1, bSize * sizeof(B_T));\n        pipe.InitBuffer(inQueueB2, 2, bSize * sizeof(B_T));\n        pipe.InitBuffer(outQueueCO1, 1, cSize * sizeof(dstCO1_T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        SplitA();\n        SplitB();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<A_T> a1Local = inQueueA1.AllocTensor<A_T>();\n        AscendC::LocalTensor<B_T> b1Local = inQueueB1.AllocTensor<B_T>();\n\n        AscendC::Nd2NzParams dataCopyA1Params;\n        dataCopyA1Params.ndNum = 1;\n        dataCopyA1Params.nValue = m;\n        dataCopyA1Params.dValue = k;\n        dataCopyA1Params.srcNdMatrixStride = 0;\n        dataCopyA1Params.srcDValue = k;\n        dataCopyA1Params.dstNzC0Stride = m;\n        dataCopyA1Params.dstNzNStride = 1;\n        dataCopyA1Params.dstNzMatrixStride = 0;\n\n        AscendC::Nd2NzParams dataCopyB1Params;\n        dataCopyB1Params.ndNum = 1;\n        dataCopyB1Params.nValue = k;\n        dataCopyB1Params.dValue = n;\n        dataCopyB1Params.srcNdMatrixStride = 0;\n        dataCopyB1Params.srcDValue = n;\n        dataCopyB1Params.dstNzC0Stride = k;\n        dataCopyB1Params.dstNzNStride = 1;\n        dataCopyB1Params.dstNzMatrixStride = 0;\n\n        // AscendC::DataCopy GM->L1:ND->大N小z\n        AscendC::DataCopy(a1Local, aGM, dataCopyA1Params);\n        AscendC::DataCopy(b1Local, bGM, dataCopyB1Params);\n\n        inQueueA1.EnQue(a1Local);\n        inQueueB1.EnQue(b1Local);\n    }\n    __aicore__ inline void SplitA()\n    {\n        AscendC::LocalTensor<A_T> a1Local = inQueueA1.DeQue<A_T>();\n        AscendC::LocalTensor<A_T> a2Local = inQueueA2.AllocTensor<A_T>();\n        // AscendC::LoadData L1->L0A\n        AscendC::LoadData2dParams loadL0AParams;\n        loadL0AParams.repeatTimes = mBlocks;\n        loadL0AParams.srcStride = 1;\n        loadL0AParams.dstGap = kBlocks - 1;\n        loadL0AParams.ifTranspose = false;\n        for (int i = 0; i < kBlocks; i++) {\n            AscendC::LoadData(a2Local[i * 16 * (32 / sizeof(A_T))], a1Local[i * m * (32 / sizeof(A_T))], loadL0AParams);\n        }\n        inQueueA2.EnQue<A_T>(a2Local);\n        inQueueA1.FreeTensor(a1Local);\n    }\n    __aicore__ inline void SplitB()\n    {\n        AscendC::LocalTensor<B_T> b1Local = inQueueB1.DeQue<B_T>();\n        AscendC::LocalTensor<B_T> b2Local = inQueueB2.AllocTensor<B_T>();\n\n        // Load2d transpose L1->L0B\n        AscendC::LoadData2dTransposeParams loadDataParams;\n        loadDataParams.startIndex = 0;\n        loadDataParams.srcStride = 1;\n        loadDataParams.addrMode = 0;\n        loadDataParams.repeatTimes = k * n / B32_B16_SIZE;\n        loadDataParams.dstGap = 0;\n        loadDataParams.dstFracGap = n / n_block - 1;\n        AscendC::LoadDataWithTranspose(b2Local, b1Local, loadDataParams);\n        inQueueB1.FreeTensor(b1Local);\n        inQueueB2.EnQue<B_T>(b2Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<A_T> a2Local = inQueueA2.DeQue<A_T>();\n        AscendC::LocalTensor<B_T> b2Local = inQueueB2.DeQue<B_T>();\n        AscendC::LocalTensor<dstCO1_T> c1Local = outQueueCO1.AllocTensor<dstCO1_T>();\n        AscendC::MmadParams mmadParams;\n        mmadParams.m = m;\n        mmadParams.n = n;\n        mmadParams.k = k;\n        AscendC::Mmad(c1Local, a2Local, b2Local, mmadParams);  // m*n\n        outQueueCO1.EnQue<dstCO1_T>(c1Local);\n        inQueueA2.FreeTensor(a2Local);\n        inQueueB2.FreeTensor(b2Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dstCO1_T> c1Local = outQueueCO1.DeQue<dstCO1_T>();\n        AscendC::FixpipeParamsV220 fixpipeParams;\n        fixpipeParams.nSize = n;\n        fixpipeParams.mSize = m;\n        fixpipeParams.srcStride = m;\n        fixpipeParams.dstStride = n;\n        fixpipeParams.ndNum = 1;\n        fixpipeParams.srcNdStride = 2;\n        fixpipeParams.dstNdStride = m*n;\n        fixpipeParams.quantPre = QuantMode_t::F322F16;\n        AscendC::Fixpipe(cGM, c1Local, fixpipeParams);\n        outQueueCO1.FreeTensor(c1Local);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueA1;\n    AscendC::TQue<AscendC::TPosition::A2, 1> inQueueA2;\n    AscendC::TQue<AscendC::TPosition::B1, 1> inQueueB1;\n    AscendC::TQue<AscendC::TPosition::B2, 1> inQueueB2;\n    AscendC::TQue<AscendC::TPosition::CO1, 1> outQueueCO1;\n    AscendC::GlobalTensor<A_T> aGM;\n    AscendC::GlobalTensor<B_T> bGM;\n    AscendC::GlobalTensor<C_T> cGM;\n    uint16_t m, k, n;\n    uint16_t B32_B16_SIZE = 16 * 16;\n    uint8_t n_block = 16;\n\n    uint16_t aSize, bSize, cSize, mBlocks, nBlocks, kBlocks;\n};\n#define KERNEL_MATMUL(c_type, a_type, b_type, co1_type, mIn, kIn, nIn)   \\\n    extern \"C\" __global__ __aicore__ void cube_matmul_loaddata_operator( \\\n        __gm__ uint8_t *a, __gm__ uint8_t *b, __gm__ uint8_t *c)         \\\n    {                                                                    \\\n        if (g_coreType == AscendC::AIV) {                                \\\n            return;                                                      \\\n        }                                                                \\\n        KernelMatmul<c_type, a_type, b_type, co1_type> op(mIn, kIn, nIn);\\\n        op.Init(a, b, c);                                                \\\n        op.Process();                                                    \\\n    }\n\nKERNEL_MATMUL(half, half, half, float, 32, 32, 16);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SetHF32Mode",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0258.html",
    "功能说明": "用于设置Mmad计算是否开启HF32模式，开启该模式后L0A/L0B中的FP32数据将在参与Mmad计算之前被舍入为HF32。",
    "函数原型": "__aicore__ inline void SetHF32Mode(bool hf32Mode)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 hf32Mode 输入 Mmad HF32模式控制入参，bool类型。支持如下两种取值： true：L0A/L0B中的FP32数据将在矩阵乘法之前被舍入为HF32。 false：将执行常规的FP32矩阵乘法。",
    "返回值": "无",
    "调用示例": "bool hf32Mode = true;\nAscendC::SetHF32Mode(hf32Mode);",
    "错误": null
  },
  {
    "API名称": "SetHF32TransMode",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0259.html",
    "功能说明": "设置HF32模式取整的具体方式，需要先使用 SetHF32Mode 开启HF32取整模式。",
    "函数原型": "__aicore__ inline void SetHF32TransMode(bool hf32TransMode)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 hf32TransMode 输入 Mmad HF32取整模式控制入参，bool类型。支持如下两种取值： true：则FP32将以向零靠近的方式四舍五入为HF32。 false：则FP32将以最接近偶数的方式四舍五入为HF32。",
    "返回值": "无",
    "调用示例": "bool hf32TransMode = true;\nAscendC::SetHF32TransMode(hf32TransMode);",
    "错误": null
  },
  {
    "API名称": "SetMMLayoutTransform",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0260.html",
    "功能说明": "设置Mmad计算时优先通过M/N中的哪个方向。",
    "函数原型": "__aicore__ inline void SetMMLayoutTransform(bool mmLayoutMode)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 mmLayoutMode 输入 控制Mmad 优先通过M/N的哪个方向，bool型，支持如下两种取值： true：代表CUBE将首先通过N方向，然后通过M方向产生结果。 false：代表CUBE将首先通过M方向，然后通过N方向生成结果。",
    "返回值": "无",
    "调用示例": "bool mmLayoutMode = true;\nAscendC::SetMMLayoutTransform(mmLayoutMode);",
    "错误": null
  },
  {
    "API名称": "CheckLocalMemoryIA",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0261.html",
    "功能说明": "check设定范围内的UB读写行为，如果有设定范围的读写行为则会出现EXCEPTION报错，无设定范围的读写行为则不会报错。",
    "函数原型": "__aicore__ inline void CheckLocalMemoryIA(const CheckLocalMemoryIAParam& checkParams)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 checkParams 输入 用于配置对UB访问的检查行为，类型为CheckLocalMemoryIAParam。 具体定义请参考 ${INSTALL_DIR} /include/ascendc/basic_api/interface/kernel_struct_mm.h， ${INSTALL_DIR} 请替换为CANN软件安装后文件存储路径。 参数说明请参考 表2 。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass KernelAdd {\npublic:\n    __aicore__ inline KernelAdd() {}\n    __aicore__ inline void Init(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n    {\n        src0Global.SetGlobalBuffer((__gm__ half*)src0Gm);\n        src1Global.SetGlobalBuffer((__gm__ half*)src1Gm);\n        dstGlobal.SetGlobalBuffer((__gm__ half*)dstGm);\n        pipe.InitBuffer(inQueueSrc0, 1, 512 * sizeof(half));\n        pipe.InitBuffer(inQueueSrc1, 1, 512 * sizeof(half));\n        pipe.InitBuffer(outQueueDst, 1, 512 * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.AllocTensor<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.AllocTensor<half>();\n        AscendC::DataCopy(src0Local, src0Global, 512);\n        AscendC::DataCopy(src1Local, src1Global, 512);\n        inQueueSrc0.EnQue(src0Local);\n        inQueueSrc1.EnQue(src1Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> src0Local = inQueueSrc0.DeQue<half>();\n        AscendC::LocalTensor<half> src1Local = inQueueSrc1.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n        AscendC::CheckLocalMemoryIA({ 0, (uint32_t)(dstLocal.GetPhyAddr() / 32),\n            (uint32_t)((dstLocal.GetPhyAddr() + 512 * sizeof(half)) / 32), false, false, false, true, false, false,\n            true });\n        AscendC::Add(dstLocal, src0Local, src1Local, 512);\n\n        outQueueDst.EnQue<half>(dstLocal);\n        inQueueSrc0.FreeTensor(src0Local);\n        inQueueSrc1.FreeTensor(src1Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, dstLocal, 512);\n        outQueueDst.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc0, inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<half> src0Global, src1Global, dstGlobal;\n};\n\nextern \"C\" __global__ __aicore__ void add_simple_kernel(__gm__ uint8_t* src0Gm, __gm__ uint8_t* src1Gm, __gm__ uint8_t* dstGm)\n{\n    KernelAdd op;\n    op.Init(src0Gm, src1Gm, dstGm);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Conv2D",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0262.html",
    "功能说明": "该接口废弃，并将在后续版本移除，请不要使用该接口。 计算给定输入张量和权重张量的2-D卷积，输出结果张量。Conv2d卷积层多用于图像识别，使用过滤器提取图像中的特征。",
    "函数原型": "template <typename dst_T, typename src_T>\n__aicore__ inline void Conv2D(const LocalTensor<dst_T>& dstLocal, const LocalTensor<src_T>& featureMap, const LocalTensor<src_T>& weight, Conv2dParams& conv2dParams, Conv2dTilling& tilling)",
    "参数说明": "表1 接口参数说明 参数名称 类型 说明 dstLocal 输出 目的操作数。 Atlas 训练系列产品 ，支持的TPosition为：CO1，CO2 Atlas 推理系列产品 AI Core ，支持的TPosition为：CO1，CO2 结果中有效张量格式为[Cout/16, Ho, Wo, 16]，大小为Cout * Ho * Wo，Ho与Wo可以根据其他数据计算得出。 Ho = floor((H + pad_top + pad_bottom - dilation_h * (Kh - 1) - 1) / stride_h + 1) Wo = floor((W + pad_left + pad_right - dilation_w * (Kw - 1) - 1) / stride_w + 1) 由于硬件要求Ho*Wo需为16倍数，在申请dst Tensor时，shape应向上16对齐，实际申请shape大小应为Cout * round_howo。 round_howo = ceil(Ho * Wo /16) * 16。 featureMap 输入 输入张量，Tensor的TPosition为A1。 输入张量“feature_map”的形状，格式是[C1, H, W, C0]。 C1*C0为输入的channel数，要求如下： 当feature_map的数据类型为half时，C0=16。 当feature_map的数据类型为int8_t时，C0=32。 C1取值范围：[1,4], 输入的channel的范围：[16，32，64，128]。 H为高，取值范围：[1,40]。 W为宽，取值范围：[1,40]。 weight 输入 卷积核（权重）张量，Tensor的TPosition为B1。 卷积核张量“weight”的形状，格式是[C1, Kh, Kw, Cout, C0]。 C1*C0为输入的channel数，对于C0要求如下： 当feature_map的数据类型为half时，C0=16。 当feature_map的数据类型为int8_t时，C0=32。 C1取值范围：[1,4]。 kernel_shape输入的channel数需与fm_shape输入的channel数保持一致。 Cout为卷积核数目，取值范围：[16，32，64，128]， Cout必须为16的倍数。 Kh为卷积核高；值的范围：[1,5]。 Kw表示卷积核宽；值的范围：[1,5]。 conv2dParams 输入 输入矩阵形状等状态参数，类型为Conv2dParams。结构体具体定义为： struct Conv2dParams { uint32_t imgShape [ kConv2dImgSize ]; // [H, W] uint32_t kernelShape [ kConv2dkernelSize ]; // [Kh, Kw] uint32_t stride [ kConv2dStride ]; // [stride_h, stride_w] uint32_t cin ; // cin = C0 * C1; uint32_t cout ; uint32_t padList [ kConv2dPad ]; // [pad_left, pad_right, pad_top, pad_bottom] uint32_t dilation [ kConv2dDilation ]; // [dilation_h, dilation_w] uint32_t initY ; uint32_t partialSum ; }; tilling 输入 分形控制参数，类型为Conv2dTilling。结构体具体定义为： struct Conv2dTilling { const uint32_t blockSize = 16 ; // # M block size is always 16 LoopMode loopMode = LoopMode :: MODE_NM ; uint32_t c0Size = 32 ; uint32_t dTypeSize = 1 ; uint32_t strideH = 0 ; uint32_t strideW = 0 ; uint32_t dilationH = 0 ; uint32_t dilationW = 0 ; uint32_t hi = 0 ; uint32_t wi = 0 ; uint32_t ho = 0 ; uint32_t wo = 0 ; uint32_t height = 0 ; uint32_t width = 0 ; uint32_t howo = 0 ; uint32_t mNum = 0 ; uint32_t nNum = 0 ; uint32_t kNum = 0 ; uint32_t mBlockNum = 0 ; uint32_t kBlockNum = 0 ; uint32_t nBlockNum = 0 ; uint32_t roundM = 0 ; uint32_t roundN = 0 ; uint32_t roundK = 0 ; uint32_t mTileBlock = 0 ; uint32_t nTileBlock = 0 ; uint32_t kTileBlock = 0 ; uint32_t mIterNum = 0 ; uint32_t nIterNum = 0 ; uint32_t kIterNum = 0 ; uint32_t mTileNums = 0 ; bool mHasTail = false ; bool nHasTail = false ; bool kHasTail = false ; uint32_t kTailBlock = 0 ; uint32_t mTailBlock = 0 ; uint32_t nTailBlock = 0 ; uint32_t mTailNums = 0 ; }; 表2 Conv2DParams结构体内参数说明： 参数名称 类型 说明 imgShape vector<int> 输入张量“feature_map”的形状，格式是[ H, W]。 H为高，取值范围：[1,40]。 W为宽，取值范围：[1,40]。 kernelShape vector<int> 卷积核张量“weight”的形状，格式是[Kh, Kw]。 Kh为高，取值范围：[1,5]。 Kw为宽，取值范围：[1,5]。 stride vector<int> 卷积步长，格式是[stride_h, stride_w]。 stride_h表示步长高， 值的范围：[1,4]。 stride_w表示步长宽， 值的范围：[1,4]。 cin int 分形排布参数，Cin = C1 * C0，Cin为输入的channel数，C1取值范围：[1,4]。 当feature_map的数据类型为float时，C0=8。输入的channel的范围：[8，16，24，32]。 当feature_map的数据类型为half时，C0=16。输入的channel的范围：[16，32，48，64]。 当feature_map的数据类型为int8_t时，C0=32。输入的channel的范围：[32，64，96，128]。 cout int Cout为卷积核数目，取值范围：[16，32，64，128]， Cout必须为16的倍数。 padList vector<int> padding行数/列数，格式是[pad_left, pad_right, pad_top, pad_bottom]。 pad_left为feature_map左侧pad列数，范围[0,4]。pad_right为feature_map右侧pad列数，范围[0,4]。 pad_top为feature_map顶部pad行数，范围[0,4]。 pad_bottom为feature_map底部pad行数，范围[0,4]。 dilation vector<int> 空洞卷积参数，格式[dilation_h, dilation_w]。 dilation_h为空洞高，范围：[1,4]。 dilation_w为空洞宽，范围：[1,4]。 膨胀后卷积核宽为dilation_w * (Kw - 1) + 1，高为dilation_h * (Kh - 1) + 1。 initY uint32_t 表示dstLocal是否需要初始化。 取值0：不使用bias，L0C需要初始化，dstLocal初始矩阵保存有之前结果，新计算结果会累加前一次conv2d计算结果。 取值1：不使用bias，L0C不需要初始化，dstLocal初始矩阵中数据无意义，计算结果直接覆盖dstLocal中的数据。 partialSum uint32_t 当dstLocal参数所在的TPosition为CO2时，通过该参数控制计算结果是否搬出。 取值0：搬出计算结果 取值1：不搬出计算结果，可以进行后续计算 表3 Conv2dTilling结构体内参数说明 参数名称 类型 说明 blockSize uint32_t 固定值，恒为16，一个维度内存放的元素个数。 loopMode LoopMode 遍历模式，结构体具体定义为： enum class LoopMode { MODE_NM = 0 , MODE_MN = 1 , MODE_KM = 2 , MODE_KN = 3 }; c0Size uint32_t 一个block的字节长度，范围[16或者32]。 dtypeSize uint32_t 传入的数据类型的字节长度，范围[1, 2]。 strideH uint32_t 卷积步长-高，范围:[1,4]。 strideW uint32_t 卷积步长-宽，范围:[1,4]。 dilationH uint32_t 空洞卷积参数-高，范围：[1,4]。 dilationW uint32_t 空洞卷积参数-宽，范围：[1,4]。 hi uint32_t feature_map形状-高，范围：[1,40]。 wi uint32_t feature_map形状-宽，范围：[1,40]。 ho uint32_t feature_map形状-高，范围：[1,40]。 wo uint32_t feature_map形状-宽，范围：[1,40]。 height uint32_t weight形状-高，[1,5]。 width uint32_t weight形状-宽，[1,5]。 howo uint32_t feature_map形状大小，为ho * wo。 mNum uint32_t M轴等效数据长度参数值，范围：[1,4096]。 nNum uint32_t N轴等效数据长度参数值，范围：[1,4096]。 kNum uint32_t K轴等效数据长度参数值，范围：[1,4096]。 roundM uint32_t M轴等效数据长度参数值且以blockSize为倍数向上取整，范围：[1,4096]。 roundN uint32_t N轴等效数据长度参数值且以blockSize为倍数向上取整，范围：[1,4096]。 roundK uint32_t K轴等效数据长度参数值且以c0Size为倍数向上取整，范围：[1,4096]。 mBlockNum uint32_t M轴Block个数，mBlockNum = mNum / blockSize，范围：[1,4096]。 nBlockNum uint32_t N轴Block个数，nBlockNum = nNum / blockSize，范围：[1,4096]。 kBlockNum uint32_t K轴Block个数，kBlockNum = kNum / blockSize，范围：[1,4096]。 mIterNum uint32_t 遍历M轴维度数量，范围：[1,4096]。 nIterNum uint32_t 遍历N轴维度数量，范围：[1,4096]。 kIterNum uint32_t 遍历K轴维度数量，范围：[1,4096]。 mTileBlock uint32_t M轴切分块个数，范围：[1,4096]。 nTileBlock uint32_t N轴切分块个数，范围：[1,4096]。 kTileBlock uint32_t K轴切分块个数，范围：[1,4096]。 kTailBlock uint32_t K轴尾块个数，范围：[1,4096]。 mTailBlock uint32_t M轴尾块个数，范围：[1,4096]。 nTailBlock uint32_t N轴尾块个数，范围：[1,4096]。 kHasTail bool K轴是否存在尾块。 mHasTail bool M轴是否存在尾块。 nHasTail bool N轴是否存在尾块。 mTileNums uint32_t M轴切分块个数的长度，范围：[1,4096]。 mTailNums uint32_t M轴尾块个数的长度，范围：[1,4096]。 表4 imgShape、kernelShape和dstLocal的数据类型组合 feature_map.dtype weight.dtype dst.dtype int8_t int8_t int32_t half half float half half half",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Gemm",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0263.html",
    "功能说明": "该接口废弃，并将在后续版本移除，请不要使用该接口。 根据输入的切分规则，将给定的两个输入张量做矩阵乘，输出至结果张量。将A和B两个输入矩阵乘法在一起，得到一个输出矩阵C。",
    "函数原型": "template <typename dst_T, typename src0_T, typename src1_T>\n__aicore__ inline void Gemm(const LocalTensor<dst_T>& dstLocal, const LocalTensor<src0_T>& src0Local, const LocalTensor<src1_T>& src1Local, const uint32_t m, const uint32_t k, const uint32_t n, GemmTiling tilling, bool partialsum = true, int32_t initValue = 0)",
    "参数说明": "表1 接口参数说明 参数名称 类型 说明 dstLocal 输出 目的操作数。 Atlas 训练系列产品 ，支持的TPosition为：CO1，CO2 Atlas 推理系列产品 AI Core ，支持的TPosition为：CO1，CO2 src0Local 输入 源操作数，TPosition为A1。 src1Local 输入 源操作数，TPosition为B1。 m 输入 左矩阵Src0Local有效Height，范围：[1, 4096]。 注意：m可以不是16的倍数。 k 输入 左矩阵Src0Local有效Width、右矩阵Src1Local有效Height。 当输入张量Src0Local的数据类型为float时，范围：[1, 8192] 当输入张量Src0Local的数据类型为half时，范围：[1, 16384] 当输入张量Src0Local的数据类型为int8_t时，范围：[1, 32768] 注意：k可以不是16的倍数。 n 输入 右矩阵Src1Local有效Width，范围：[1, 4096]。 注意：n可以不是16的倍数。 tilling 输入 切分规则，类型为GemmTiling，结构体具体定义为： struct GemmTiling { const uint32_t blockSize = 16 ; LoopMode loopMode = LoopMode :: MODE_NM ; uint32_t mNum = 0 ; uint32_t nNum = 0 ; uint32_t kNum = 0 ; uint32_t roundM = 0 ; uint32_t roundN = 0 ; uint32_t roundK = 0 ; uint32_t c0Size = 32 ; uint32_t dtypeSize = 1 ; uint32_t mBlockNum = 0 ; uint32_t nBlockNum = 0 ; uint32_t kBlockNum = 0 ; uint32_t mIterNum = 0 ; uint32_t nIterNum = 0 ; uint32_t kIterNum = 0 ; uint32_t mTileBlock = 0 ; uint32_t nTileBlock = 0 ; uint32_t kTileBlock = 0 ; uint32_t kTailBlock = 0 ; uint32_t mTailBlock = 0 ; uint32_t nTailBlock = 0 ; bool kHasTail = false ; bool mHasTail = false ; bool nHasTail = false ; bool kHasTailEle = false ; uint32_t kTailEle = 0 ; }; 参数说明请参考 表3 。 partialsum 输入 当dstLocal参数所在的TPosition为CO2时，通过该参数控制计算结果是否搬出。 取值0：搬出计算结果 取值1：不搬出计算结果，可以进行后续计算 initValue 输入 表示dstLocal是否需要初始化。 取值0: dstLocal需要初始化，dstLocal初始矩阵保存有之前结果，新计算结果会累加前一次conv2d计算结果。 取值1: dstLocal不需要初始化，dstLocal初始矩阵中数据无意义，计算结果直接覆盖dstLocal中的数据。 表2 feature_map、weight和dst的数据类型组合 src0Local.dtype src1Local.dtype dstLocal.dtype int8_t int8_t int32_t half half float half half half 表3 GemmTiling结构内参数说明 参数名称 类型 说明 blockSize uint32_t 固定值，恒为16，一个维度内存放的元素个数。 loopMode LoopMode 遍历模式，结构体具体定义为： enum class LoopMode { MODE_NM = 0 , MODE_MN = 1 , MODE_KM = 2 , MODE_KN = 3 }; mNum uint32_t M轴等效数据长度参数值，范围：[1, 4096]。 nNum uint32_t N轴等效数据长度参数值，范围：[1, 4096]。 kNum uint32_t K轴等效数据长度参数值。 当输入张量Src0Local的数据类型为float时，范围：[1, 8192] 当输入张量Src0Local的数据类型为half时，范围：[1, 16384] 当输入张量Src0Local的数据类型为int8_t时，范围：[1, 32768] roundM uint32_t M轴等效数据长度参数值且以blockSize为倍数向上取整，范围：[1, 4096] roundN uint32_t N轴等效数据长度参数值且以blockSize为倍数向上取整，范围：[1, 4096] roundK uint32_t K轴等效数据长度参数值且以c0Size为倍数向上取整。 当输入张量Src0Local的数据类型为float时，范围：[1, 8192] 当输入张量Src0Local的数据类型为half时，范围：[1, 16384] 当输入张量Src0Local的数据类型为int8_t时，范围：[1, 32768] c0Size uint32_t 一个block的字节长度，范围：[16或者32]。 dtypeSize uint32_t 传入的数据类型的字节长度，范围：[1, 2]。 mBlockNum uint32_t M轴Block个数，mBlockNum = mNum / blockSize。 nBlockNum uint32_t N轴Block个数，nBlockNum = nNum / blockSize。 kBlockNum uint32_t K轴Block个数，kBlockNum = kNum / blockSize。 mIterNum uint32_t 遍历维度数量，范围：[1, 4096]。 nIterNum uint32_t 遍历维度数量，范围：[1, 4096]。 kIterNum uint32_t 遍历维度数量，范围：[1, 4096]。 mTileBlock uint32_t M轴切分块个数，范围：[1, 4096]。 nTileBlock uint32_t N轴切分块个数，范围：[1, 4096]。 kTileBlock uint32_t K轴切分块个数，范围：[1, 4096]。 kTailBlock uint32_t K轴尾块个数，范围：[1, 4096]。 mTailBlock uint32_t M轴尾块个数，范围：[1, 4096]。 nTailBlock uint32_t N轴尾块个数，范围：[1, 4096]。 kHasTail bool K轴是否存在尾块。 mHasTail bool M轴是否存在尾块。 nHasTail bool N轴是否存在尾块。 kHasTailEle bool 是否存在尾块元素。 kTailEle uint32_t K轴尾块元素，范围：[1, 4096]。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass KernelCubeGEMM {\npublic:\n    __aicore__ inline KernelCubeGEMM() {}\n    __aicore__ inline void Init(__gm__ uint8_t* fmGm, __gm__ uint8_t* weGm, __gm__ uint8_t* dstGm, uint32_t mInput,\n        uint32_t kInput, uint32_t nInput, bool initVal, AscendC::LoopMode mode)\n    {\n        m = mInput;\n        k = kInput;\n        n = nInput;\n\n        initValue = initVal;\n        loopMode = mode;\n\n        featureMapA1Size = m * k;\n        weightA1Size = k * n;\n        dstCO1Size = m * n;\n\n        roundm = AscendC::DivCeil(m, 16) * 16;\n        roundn = AscendC::DivCeil(n, 16) * 16;\n        roundk = AscendC::DivCeil(k, c0Size) * c0Size;\n\n        fmGlobal.SetGlobalBuffer((__gm__ half*)fmGm);\n        weGlobal.SetGlobalBuffer((__gm__ half*)weGm);\n        dstGlobal.SetGlobalBuffer((__gm__ float*)dstGm);\n\n        pipe.InitBuffer(inQueueFmA1, 1, featureMapA1Size * sizeof(half));\n        pipe.InitBuffer(inQueueWeB1, 1, weightA1Size * sizeof(half));\n        pipe.InitBuffer(outQueueCO1, 1, dstCO1Size * sizeof(float));\n        pipe.InitBuffer(outQueueUB, 1, dstCO1Size * sizeof(float));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyUB();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> featureMapA1 = inQueueFmA1.AllocTensor<half>();\n        AscendC::LocalTensor<half> weightB1 = inQueueWeB1.AllocTensor<half>();\n\n        AscendC::DataCopy(featureMapA1, fmGlobal, featureMapA1Size);\n        AscendC::DataCopy(weightB1, weGlobal, weightA1Size);\n\n        inQueueFmA1.EnQue(featureMapA1);\n        inQueueWeB1.EnQue(weightB1);\n    }\n\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> featureMapA1 = inQueueFmA1.DeQue<half>();\n        AscendC::LocalTensor<half> weightB1 = inQueueWeB1.DeQue<half>();\n        AscendC::LocalTensor<float> dstCO1 = outQueueCO1.AllocTensor<float>();\n\n        AscendC::GemmTiling tilling = GetGemmTiling<half>(m, k, n);\n        tilling.loopMode = loopMode;\n        // 左矩阵形状为[m,k],右矩阵形状为[k,n]，计算结果搬出至GM，目的矩阵无需初始化\n        AscendC::Gemm(dstCO1, featureMapA1, weightB1, m, k, n, tilling, false, initValue);\n\n        outQueueCO1.EnQue<float>(dstCO1);\n        inQueueFmA1.FreeTensor(featureMapA1);\n        inQueueWeB1.FreeTensor(weightB1);\n    }\n\n    __aicore__ inline void CopyUB()\n    {\n        AscendC::LocalTensor<float> dstCO1 = outQueueCO1.DeQue<float>();\n        AscendC::LocalTensor<float> dstUB = outQueueUB.AllocTensor<float>();\n\n        AscendC::DataCopyParams dataCopyParams;\n        dataCopyParams.blockCount = 1;\n        dataCopyParams.blockLen = roundm * roundn * sizeof(float) / 1024;\n        AscendC::DataCopyEnhancedParams enhancedParams;\n        enhancedParams.blockMode = BlockMode::BLOCK_MODE_MATRIX;\n\n        AscendC::DataCopy(dstUB, dstCO1, dataCopyParams, enhancedParams);\n\n        outQueueUB.EnQue<float>(dstUB);\n        outQueueCO1.FreeTensor(dstCO1);\n    }\n\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<float> dstUB = outQueueUB.DeQue<float>();\n        AscendC::DataCopy(dstGlobal, dstUB, roundm * roundn);\n        outQueueUB.FreeTensor(dstUB);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    // feature map queue\n    AscendC::TQue<AscendC::TPosition::A1, 1> inQueueFmA1;\n    // weight queue\n    AscendC::TQue<AscendC::TPosition::B1, 1> inQueueWeB1;\n    // dst queue\n    AscendC::TQue<AscendC::TPosition::CO1, 1> outQueueCO1;\n\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueUB;\n\n    AscendC::GlobalTensor<half> fmGlobal, weGlobal;\n    AscendC::GlobalTensor<float> dstGlobal;\n\n    uint16_t m;\n    uint16_t k;\n    uint16_t n;\n    uint32_t roundm, roundk, roundn;\n\n    uint32_t c0Size = 16;\n    bool initValue = false;\n    AscendC::LoopMode loopMode = AscendC::LoopMode::MODE_NM;\n\n    uint32_t featureMapA1Size, weightA1Size, dstCO1Size;\n};\n\nextern \"C\" __global__ __aicore__ void cube_gemm_simple_kernel(__gm__ uint8_t* fmGm, __gm__ uint8_t* weGm,\n    __gm__ uint8_t* dstGm, uint32_t m, uint32_t k, uint32_t n, bool initValue, LoopMode mode)\n{\n    KernelCubeGEMM op;\n    // 上方示例结果入参为：m = 32, k = 64, n = 32, initValue = false, mode = LoopMode::MODE_NM\n    op.Init(fmGm, weGm, dstGm, m, k, n, initValue, mode);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "DataCopyPad(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0265.html",
    "功能说明": "该接口提供数据非对齐搬运的功能，其中从Global Memory搬运数据至Local Memory时，可以根据开发者的需要自行填充数据。",
    "函数原型": "template <typename T>\n__aicore__ inline void DataCopyPad(const LocalTensor<T> &dstLocal, const GlobalTensor<T> &srcGlobal, const DataCopyExtParams &dataCopyParams, const DataCopyPadExtParams<T> &padParams)",
    "参数说明": "表2 模板参数说明 参数名 描述 T 操作数以及paddingValue（待填充数据值）的数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/bfloat16_t/int16_t/uint16_t/float/int32_t/uint32_t/int8_t/uint8_t/int64_t/uint64_t/double Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/bfloat16_t/int16_t/uint16_t/float/int32_t/uint32_t/int8_t/uint8_t/int64_t/uint64_t/double Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int8_t/uint8_t/half/bfloat16_t/int16_t/uint16_t/float/int32_t/uint32_t",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\nclass TestDataCopyPad {\npublic:\n    __aicore__ inline TestDataCopyPad() {}\n    __aicore__ inline void Init(__gm__ uint8_t* srcGm, __gm__ uint8_t* dstGm)\n    {\n        srcGlobal.SetGlobalBuffer((__gm__ half *)srcGm);\n        dstGlobal.SetGlobalBuffer((__gm__ half *)dstGm);\n        pipe.InitBuffer(inQueueSrc, 1, 32 * sizeof(half));\n        pipe.InitBuffer(outQueueDst, 1, 32 * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.AllocTensor<half>();\n        AscendC::DataCopyExtParams copyParams{1, 20 * sizeof(half), 0, 0, 0}; // 结构体DataCopyExtParams最后一个参数是rsv保留位\n        AscendC::DataCopyPadExtParams<half> padParams{true, 0, 2, 0};\n        AscendC::DataCopyPad(srcLocal, srcGlobal, copyParams, padParams); // 从GM->VECIN搬运40Bytes\n        inQueueSrc.EnQue<half>(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrc.DeQue<half>();\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.AllocTensor<half>();\n        AscendC::Adds(dstLocal, srcLocal, scalar, 20);\n        outQueueDst.EnQue(dstLocal);\n        inQueueSrc.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> dstLocal = outQueueDst.DeQue<half>();\n        AscendC::DataCopyExtParams copyParams{1, 20 * sizeof(half), 0, 0, 0};\n        AscendC::DataCopyPad(dstGlobal, dstLocal, copyParams); // 从VECIN->GM搬运40Bytes\n        outQueueDst.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<half> srcGlobal;\n    AscendC::GlobalTensor<half> dstGlobal;\n    AscendC::DataCopyPadExtParams<half> padParams;\n    AscendC::DataCopyExtParams copyParams;\n    half scalar = 0;\n};\n\nextern \"C\" __global__ __aicore__ void kernel_data_copy_pad_kernel(__gm__ uint8_t* src_gm, __gm__ uint8_t* dst_gm)\n{\n    TestDataCopyPad op;\n    op.Init(src_gm, dst_gm);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "SetPadValue(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0266.html",
    "功能说明": "设置DataCopyPad需要填充的数值。支持的通路如下： GM->VECIN/GM->VECOUT",
    "函数原型": "template <typename T, TPosition pos = TPosition::MAX>\n__aicore__ inline void SetPadValue(T paddingValue)",
    "参数说明": "表1 模板参数说明 参数名 输入/输出 描述 T 输入 填充值的数据类型，与DataCopyPad接口搬运的数据类型一致。 pos 输入 用于指定DataCopyPad接口搬运过程中从GM搬运数据到哪一个目的地址，目的地址通过逻辑位置来表达。默认值为TPosition::MAX，等效于TPosition::VECIN或TPosition::VECOUT。 支持的取值为： TPosition::VECIN、TPosition::VECOUT、TPosition::MAX\n\n表2 参数说明 参数名 输入/输出 描述 paddingValue 输入 DataCopyPad接口填充的数值，数据与DataCopyPad接口搬运的数据类型一致。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T>\nclass SetPadValueTest {\npublic:\n    __aicore__ inline SetPadValueTest() {}\n    __aicore__ inline void Init(__gm__ uint8_t* dstGm, __gm__ uint8_t* srcGm, uint32_t n1, uint32_t n2)\n    {\n        m_n1 = n1;\n        m_n2 = n2;\n        m_n2Align = n2 % 32 == 0 ? n2 : (n2 / 32 + 1) * 32;\n        m_srcGlobal.SetGlobalBuffer((__gm__ T*)srcGm);\n        m_dstGlobal.SetGlobalBuffer((__gm__ T*)dstGm);\n\n        m_pipe.InitBuffer(m_queInSrc, 1, m_n1 * m_n2Align * sizeof(T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = m_queInSrc.AllocTensor<T>();\n        AscendC::DataCopyExtParams dataCopyExtParams;\n        AscendC::DataCopyPadExtParams<T> padParams;\n\n        dataCopyExtParams.blockCount = m_n1;\n        dataCopyExtParams.blockLen = m_n2 * sizeof(T);\n        dataCopyExtParams.srcStride = 0;\n        dataCopyExtParams.dstStride = 0;\n\n        padParams.isPad = false;\n        padParams.leftPadding = 0;\n        padParams.rightPadding = 1;\n\n        AscendC::SetPadValue((T)37);\n        AscendC::PipeBarrier<PIPE_ALL>();\n        AscendC::DataCopyPad(srcLocal, m_srcGlobal, dataCopyExtParams, padParams);\n        m_queInSrc.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        ;\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = m_queInSrc.DeQue<T>();\n        AscendC::DataCopy(m_dstGlobal, dstLocal, m_n1 * m_n2Align);\n        m_queInSrc.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::TPipe m_pipe;\n    uint32_t m_n1;\n    uint32_t m_n2;\n    uint32_t m_n2Align;\n    AscendC::GlobalTensor<T> m_srcGlobal;\n    AscendC::GlobalTensor<T> m_dstGlobal;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> m_queInSrc;\n}; // class SetPadValueTest\n\ntemplate <typename T>\n__global__ __aicore__ void testSetPadValue(GM_ADDR dstGm, GM_ADDR srcGm, uint32_t n1, uint32_t n2)\n{\n    SetPadValueTest<T> op;\n    op.Init(dstGm, srcGm, n1, n2);\n    op.Process();\n}",
    "错误": null
  },
  {
    "API名称": "SetFixPipeConfig(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0252.html",
    "功能说明": "DataCopy （CO1->GM、CO1->A1）过程中进行随路量化时，通过调用该接口设置量化流程中tensor量化参数。",
    "函数原型": "template <typename T>\n__aicore__ inline void SetFixPipeConfig(const LocalTensor<T> &reluPre, const LocalTensor<T> &quantPre, bool isUnitFlag = false)\ntemplate <typename T, bool setRelu = false>\n__aicore__ inline void SetFixPipeConfig(const LocalTensor<T> &preTensor, bool isUnitFlag = false)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 setRelu 针对设置一个tensor的情况，当setRelu为true时，设置reluPreTensor；反之设置quantPreTensor。当前仅支持设置为false。\n\n表2 参数说明 参数名称 输入/输出 含义 reluPre 输入 源操作数，relu tensor，类型为LocalTensor，支持的TPosition为C2PIPE2GM。 预留参数，暂未启用，为后续的功能扩展做保留，传入一个空LocalTensor即可。 quantPre 输入 源操作数，quant tensor，量化操作时参与计算的tensor，类型为LocalTensor，支持的TPosition为C2PIPE2GM。 isUnitFlag 输入 UnitFlag配置项，类型为bool。预留参数，暂未启用，为后续的功能扩展做保留，保持默认值false即可。 preTensor 输入 支持设置一个Tensor，通过开关控制是relu Tensor还是quantTensor，支持的TPosition为C2PIPE2GM。当前仅支持传入quantTensor。",
    "返回值": "无",
    "调用示例": "__aicore__inline void SetFPC(const LocalTensor <int32_t>& reluPreTensor, const LocalTensor <int32_t>& quantPreTensor)\n{\n    // reluPreTensor为空tensor\n    AscendC::SetFixPipeConfig<int32_t>(reluPreTensor, quantPreTensor);\n\n    // 等效调用:\n    // AscendC::SetFixPipeConfig<int32_t>(quantPreTensor);\n}",
    "错误": null
  },
  {
    "API名称": "随路格式转换",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0105.html",
    "功能说明": "随路格式转换数据搬运，适用于在搬运时进行格式转换。",
    "函数原型": "template <typename T>\n__aicore__ inline void DataCopy(const LocalTensor<T>& dstLocal, const GlobalTensor<T>& srcGlobal, const Nd2NzParams& intriParams);",
    "参数说明": "表6 模板参数说明 参数名 描述 T 源操作数或者目的操作数的数据类型。 U 源操作数的数据类型。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\nclass KernelDataCopyUb2GmNz2Nd {\npublic:\n    __aicore__ inline KernelDataCopyUb2GmNz2Nd()\n    {}\n    __aicore__ inline void Init(__gm__ uint8_t* dstGm, __gm__ uint8_t* srcGm)\n    {\n        AscendC::Nz2NdParamsFull intriParamsIn{1, 32, 32, 1, 32, 32, 1};\n        intriParams = intriParamsIn;\n        srcGlobal.SetGlobalBuffer((__gm__ half *)srcGm);\n        dstGlobal.SetGlobalBuffer((__gm__ half *)dstGm);\n        pipe.InitBuffer(inQueueSrcVecIn, 1, intriParams.nValue * intriParams.dValue * sizeof(half));\n        pipe.InitBuffer(inQueueSrcVecOut, 1, intriParams.nValue * intriParams.dValue * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> srcLocal = inQueueSrcVecIn.AllocTensor<half>();\n        AscendC::DataCopy(srcLocal, srcGlobal, intriParams.nValue * intriParams.dValue);\n        inQueueSrcVecIn.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> dstLocal = inQueueSrcVecIn.DeQue<half>();\n        AscendC::LocalTensor<half> srcOutLocal = inQueueSrcVecOut.AllocTensor<half>();\n        AscendC::DataCopy(srcOutLocal, dstLocal, intriParams.nValue * intriParams.dValue);\n        inQueueSrcVecOut.EnQue(srcOutLocal);\n        inQueueSrcVecIn.FreeTensor(dstLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> srcOutLocalDe = inQueueSrcVecOut.DeQue<half>();\n        AscendC::DataCopy(dstGlobal, srcOutLocalDe, intriParams);\n        inQueueSrcVecOut.FreeTensor(srcOutLocalDe);\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrcVecIn;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> inQueueSrcVecOut;\n    AscendC::GlobalTensor<half> srcGlobal;\n    AscendC::GlobalTensor<half> dstGlobal;\n    AscendC::Nz2NdParamsFull intriParams;\n};\nextern \"C\" __global__ __aicore__ void kernel_data_copy_nz2nd_ub2out(__gm__ uint8_t* src_gm, __gm__ uint8_t* dst_gm)\n{\n    KernelDataCopyUb2GmNz2Nd op;\n    op.Init(dst_gm, src_gm);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SetFixpipeNz2ndFlag(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0253.html",
    "功能说明": "DataCopy （CO1->GM、CO1->A1）过程中进行随路格式转换（NZ格式转换为ND格式）时，通过调用该接口设置格式转换的相关配置。",
    "函数原型": "__aicore__ inline void SetFixpipeNz2ndFlag(uint16_t ndNum, uint16_t srcNdStride, uint16_t dstNdStride)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 ndNum 输入 nd的数量，类型是uint16_t，取值范围：ndNum∈[1, 65535]。 srcNdStride 输入 以分形大小为单位的源步长，源相邻nz矩阵的偏移（头与头）。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，srcNdStride∈[1, 512]，单位：fractal_size 1024B。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，srcNdStride∈[1, 512]，单位：fractal_size 1024B。 Atlas 200I/500 A2 推理产品 ，srcNdStride∈[1, 512]，单位：fractal_size 1024B。 dstNdStride 输入 目的相邻nd矩阵的偏移（头与头）。单位为元素。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，dstNdStride∈[1, 65535]。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，dstNdStride∈[1, 65535]。 Atlas 200I/500 A2 推理产品 ，dstNdStride∈[1, 65535]。",
    "返回值": "无",
    "调用示例": "uint16_t ndNum = 2;\nuint16_t srcNdStride = 2;\nuint16_t dstNdStride = 1;\nAscendC::SetFixpipeNz2ndFlag(ndNum, srcNdStride, dstNdStride);",
    "错误": null
  },
  {
    "API名称": "SetFixpipePreQuantFlag(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0254.html",
    "功能说明": "DataCopy （CO1->GM、CO1->A1）过程中进行随路量化时，通过调用该接口设置量化流程中标量量化参数。",
    "函数原型": "__aicore__ inline void SetFixpipePreQuantFlag(uint64_t config)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 config 输入 量化过程中使用到的标量量化参数，类型为uint64_t。",
    "返回值": "无",
    "调用示例": "uint64_t deqScalar = 11;\nAscendC::SetFixpipePreQuantFlag(deqScalar);",
    "错误": null
  },
  {
    "API名称": "SetFixPipeClipRelu(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0255.html",
    "功能说明": "DataCopy （CO1->GM）过程中进行随路量化后，通过调用该接口设置ClipRelu操作的最大值。 ClipRelu计算公式为min(clipReluMaxVal，srcData)，clipReluMaxVal为通过该接口设置的最大值，srcData为源数据。",
    "函数原型": "__aicore__ inline void SetFixPipeClipRelu(uint64_t config)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 config 输入 clipReluMaxVal，ClipRelu操作中的最大值。clipReluMaxVal只占用0-15bit，必须大于0，不能为INF/NAN。",
    "返回值": "无",
    "调用示例": "uint64_t clipReluMaxVal = 0x3c00; // value 1, half类型转换成uint64_t类型\nSetFixPipeClipRelu(clipReluMaxVal);",
    "错误": null
  },
  {
    "API名称": "SetFixPipeAddr(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0256.html",
    "功能说明": "DataCopy （CO1->GM）过程中进行随路量化后，通过调用该接口设置Elementwise操作时LocalTensor的地址。",
    "函数原型": "template <typename T>\n__aicore__ inline void SetFixPipeAddr(const LocalTensor<T> &eleWiseTensor, uint16_t c0ChStride)",
    "参数说明": "表1 参数说明 参数名称 输入/输出 含义 eleWiseTensor 输入 L1 Buffer 上的源操作数。类型为LocalTensor。 支持的TPosition为A1/B1/C1。起始地址需要保证32字节对齐，仅支持half数据类型。 c0ChStride 输入 在 L1 Buffer 上的C0 channel stride，单位是C0_SIZE（32B）。 eleWiseTensor沿N方向以C0为单位切分得到的数据块称为C0 channel，两块C0 channel的间隔称之为C0 channel stride。",
    "返回值": "无",
    "调用示例": "__aicore__inline void SetEleSrcPara(const LocalTensor <half>& eleWiseTensor, uint16_t c0ChStride)\n{\n    AscendC::SetFixPipeAddr(eleWiseTensor, c0ChStride);\n}",
    "错误": null
  },
  {
    "API名称": "SetFlag/WaitFlag(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0270.html",
    "功能说明": "同一核内不同流水之间的同步指令。具有数据依赖的不同流水指令之间需要插此同步。",
    "函数原型": "template <HardEvent event>\n__aicore__ inline void SetFlag(int32_t eventID)\ntemplate <HardEvent event>\n__aicore__ inline void WaitFlag(int32_t eventID)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 event 输入 模板参数。 同步事件，数据类型为HardEvent。详细内容参考下文中的同步类型说明。 eventID 输入 事件ID。数据类型为int32_t类型。其定义如下： eventID需要通过 AllocEventID 或者 FetchEventID 来获取。 Atlas 训练系列产品 ，数据范围为：0-3 Atlas 推理系列产品 AI Core ，数据范围为：0-7 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，数据范围为：0-7 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，数据范围为：0-7",
    "返回值": "无",
    "调用示例": "AscendC::GlobalTensor<half> dstGlobal;\nAscendC::LocalTensor<half> dstLocal;\ndstLocal.SetValue(0, 0);\nuint32_t dataSize = 512;\nint32_t eventIDSToMTE3 = static_cast<int32_t>(GetTPipePtr()->FetchEventID(AscendC::HardEvent::S_MTE3));\nAscendC::SetFlag<AscendC::HardEvent::S_MTE3>(eventIDSToMTE3);\nAscendC::WaitFlag<AscendC::HardEvent::S_MTE3>(eventIDSToMTE3);\nAscendC::DataCopy(dstGlobal, dstLocal, dataSize);",
    "错误": null
  },
  {
    "API名称": "PipeBarrier(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0271.html",
    "功能说明": "阻塞相同流水，具有数据依赖的相同流水之间需要插入此同步。",
    "函数原型": "template <pipe_t pipe>\n__aicore__ inline void PipeBarrier()",
    "参数说明": "表1 模板参数说明 参数名 描述 pipe 模板参数，表示阻塞的流水类别。 支持的流水参考 硬件流水类型 。 如果不关注流水类别，希望阻塞所有流水，可以传入PIPE_ALL。",
    "返回值": "无",
    "调用示例": "AscendC::LocalTensor<half> src0Local;\nAscendC::LocalTensor<half> src1Local;\nAscendC::LocalTensor<half> src2Local;\nAscendC::LocalTensor<half> dst0Local;\nAscendC::LocalTensor<half> dst1Local;\n\nAscendC::Add(dst0Local, src0Local, src1Local, 512);\nAscendC::PipeBarrier<PIPE_V>();\nAscendC::Mul(dst1Local, dst0Local, src2Local, 512);",
    "错误": null
  },
  {
    "API名称": "DataSyncBarrier(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0272.html",
    "功能说明": "用于阻塞后续的指令执行，直到所有之前的内存访问指令（需要等待的内存位置可通过参数控制）执行结束。",
    "函数原型": "template <MemDsbT arg0>\n__aicore__ inline void DataSyncBarrier()",
    "参数说明": "表1 模板参数说明 参数名 描述 arg0 模板参数，表示需要等待的内存位置，类型为MemDsbT，可取值为： ALL，等待所有内存访问指令。 DDR，等待GM访问指令。 UB，等待UB访问指令。 SEQ，预留参数，暂未启用，为后续的功能扩展做保留。",
    "返回值": "无",
    "调用示例": "AscendC::Mmad(...);\nAscendC::DataSyncBarrier<MemDsbT::ALL>();\nAscendC::Fixpipe(...);",
    "错误": null
  },
  {
    "API名称": "CrossCoreSetFlag(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0273.html",
    "功能说明": "面向分离架构的核间同步控制接口。 该接口和 CrossCoreWaitFlag 接口配合使用。使用时需传入核间同步的标记ID(flagId)，每个ID对应一个初始值为0的计数器。执行CrossCoreSetFlag后ID对应的计数器增加1；执行CrossCoreWaitFlag时如果对应的计数器数值为0则阻塞不执行；如果对应的计数器大于0，则计数器减一，同时后续指令开始执行。 同步控制分为以下几种模式，如 图1 所示： 模式0：AI Core核间的同步控制。对于AIC场景，同步所有的AIC核，直到所有的AIC核都执行到CrossCoreSetFlag时，CrossCoreWaitFlag后续的指令才会执行；对于AIV场景，同步所有的AIV核，直到所有的AIV核都执行到CrossCoreSetFlag时，CrossCoreWaitFlag后续的指令才会执行。 模式1：AI Core内部，AIV核之间的同步控制。如果两个AIV核都运行了CrossCoreSetFlag，CrossCoreWaitFlag后续的指令才会执行。 模式2：AI Core内部，AIC与AIV之间的同步控制。在AIC核执行CrossCoreSetFlag之后， 两个AIV上CrossCoreWaitFlag后续的指令才会继续执行；两个AIV都执行CrossCoreSetFlag后，AIC上CrossCoreWaitFlag后续的指令才能执行。 图1 同步控制模式示意图",
    "函数原型": "template <uint8_t modeId, pipe_t pipe>\n__aicore__ inline void CrossCoreSetFlag(uint16_t flagId)",
    "参数说明": "表1 模板参数说明 参数名 描述 modeId 核间同步的模式，取值如下： 模式0：AI Core核间的同步控制。 模式1：AI Core内部，Vector核（AIV）之间的同步控制。 模式2：AI Core内部，Cube核（AIC）与Vector核（AIV）之间的同步控制。 pipe 设置这条指令所在的流水类型，流水类型可参考 硬件流水类型 。\n\n表2 参数说明 参数名 输入/输出 描述 flagId 输入 核间同步的标记。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，取值范围是0-10。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，取值范围是0-10。",
    "返回值": "无",
    "调用示例": "// 使用模式0的方式同步所有的AIV核\nif (g_coreType == AscendC::AIV) {\n    AscendC::CrossCoreSetFlag<0x0, PIPE_MTE3>(0x8);\n    AscendC::CrossCoreWaitFlag(0x8);\n}\n\n// 使用模式1的方式同步当前AICore内的所有AIV子核\nif (g_coreType == AscendC::AIV) {\n    AscendC::CrossCoreSetFlag<0x1, PIPE_MTE3>(0x8);\n    AscendC::CrossCoreWaitFlag(0x8);\n}\n\n// 注意：如果调用高阶API,无需开发者处理AIC和AIV的同步\n// AIC侧做完Matmul计算后通知AIV进行后处理\nif (g_coreType == AscendC::AIC) {\n    // Matmul处理\n    AscendC::CrossCoreSetFlag<0x2, PIPE_FIX>(0x8);\n}\n\n// AIV侧等待AIC Set消息, 进行Vector后处理\nif (g_coreType == AscendC::AIV) {\n    AscendC::CrossCoreWaitFlag(0x8);\n    // Vector后处理\n}",
    "错误": null
  },
  {
    "API名称": "CrossCoreWaitFlag(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0274.html",
    "功能说明": "面向分离架构的核间同步控制接口。该接口和 CrossCoreSetFlag 接口配合使用。具体使用方法请参考 CrossCoreSetFlag 。",
    "函数原型": "template <uint8_t modeId, pipe_t pipe>\n__aicore__ inline void CrossCoreWaitFlag(uint16_t flagId)",
    "参数说明": "表1 模板参数说明 参数名 描述 modeId 核间同步的模式，取值如下： 模式0：AI Core核间的同步控制。 模式1：AI Core内部，Vector核（AIV）之间的同步控制。 模式2：AI Core内部，Cube核（AIC）与Vector核（AIV）之间的同步控制。 pipe 设置这条指令所在的流水类型，流水类型可参考 硬件流水类型 。\n\n表2 参数说明 参数名 输入/输出 描述 flagId 输入 核间同步的标记。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，取值范围是0-10。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，取值范围是0-10。",
    "返回值": "无",
    "调用示例": "请参考 调用示例 。 父主题： 核间同步 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": null
  },
  {
    "API名称": "ICachePreLoad(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0276.html",
    "功能说明": "从指令所在DDR地址预加载指令到ICache中。",
    "函数原型": "__aicore__ inline void ICachePreLoad(const int64_t preFetchLen)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 preFetchLen 输入 预取长度。 针对 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ：preFetchLen参数单位为2K Byte, 取值应小于ICache的大小/2K。AIC和AIV的ICache大小分别为32KB和16KB。 针对 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ：preFetchLen参数单位为2K Byte, 取值应小于ICache的大小/2K。AIC和AIV的ICache大小分别为32KB和16KB。 针对 Atlas 推理系列产品 AI Core ：传入该参数无效，预取长度均为128Byte。",
    "返回值": "无",
    "调用示例": "int64_t preFetchLen = 2;\nAscendC::ICachePreLoad(preFetchLen);",
    "错误": null
  },
  {
    "API名称": "GetICachePreloadStatus(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0277.html",
    "功能说明": "获取ICACHE的PreLoad的状态。",
    "函数原型": "__aicore__ inline int64_t GetICachePreloadStatus()",
    "参数说明": "无",
    "返回值": "int64_t类型，0表示空闲，1表示忙。",
    "调用示例": "int64_t cachePreloadStatus = AscendC::GetICachePreloadStatus();",
    "错误": null
  },
  {
    "API名称": "GetProgramCounter(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0279.html",
    "功能说明": "获取程序计数器的指针，程序计数器用于记录当前程序执行的位置。",
    "函数原型": "__aicore__ inline int64_t GetProgramCounter()",
    "参数说明": "无",
    "返回值": "返回int64_t类型的程序计数器指针。",
    "调用示例": "int64_t pc = AscendC::GetProgramCounter();",
    "错误": null
  },
  {
    "API名称": "GetSubBlockNum(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0280.html",
    "功能说明": "获取AI Core上Vector核的数量。",
    "函数原型": "__aicore__ inline int64_t GetSubBlockNum()",
    "参数说明": "无",
    "返回值": "返回int64_t类型的Vector核数量。",
    "调用示例": "int64_t subBlockNum = AscendC::GetSubBlockNum();",
    "错误": null
  },
  {
    "API名称": "GetSubBlockIdx(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0281.html",
    "功能说明": "获取AI Core上Vector核的ID。",
    "函数原型": "__aicore__ inline int64_t GetSubBlockIdx()",
    "参数说明": "无",
    "返回值": "返回int64_t类型的Vector核ID。",
    "调用示例": "int64_t subBlockID = AscendC::GetSubBlockIdx();",
    "错误": null
  },
  {
    "API名称": "GetSystemCycle(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0282.html",
    "功能说明": "获取当前系统cycle数，若换算成时间需要按照50MHz的频率，时间单位为us，换算公式为：time = (cycle数/50) us 。",
    "函数原型": "__aicore__ inline int64_t GetSystemCycle()",
    "参数说明": "无",
    "返回值": "返回int64_t类型的系统cycle数。",
    "调用示例": "#include \"kernel_operator.h\"\n\n__aicore__ inline void InitTilingParam(int32_t& totalSize, int32_t& loopSize)\n{\n    int64_t systemCycleBefore = AscendC::GetSystemCycle(); // 调用GetBlockNum指令前的cycle数\n    loopSize = totalSize / AscendC::GetBlockNum();\n    int64_t systemCycleAfter = AscendC::GetSystemCycle(); // 调用GetBlockNum指令后的cycle数\n    int64_t GetBlockNumCycle = systemCycleAfter - systemCycleBefore; // 执行GetBlockNum指令所用的cycle数\n    int64_t CycleToTimeBase = 50; // cycle数转换成时间的基准单位，固定为50\n    int64_t GetBlockNumTime = GetBlockNumCycle/CycleToTimeBase; // 执行GetBlockNum指令所用时间，单位为us\n};",
    "错误": null
  },
  {
    "API名称": "SetAtomicMax(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0284.html",
    "功能说明": "原子操作函数，设置后续从VECOUT传输到GM的数据是否执行原子比较：将待拷贝的内容和GM已有内容进行比较，将最大值写入GM。 可通过设置模板参数来设定不同的数据类型。",
    "函数原型": "template <typename T>\n__aicore__ inline void SetAtomicMax() {}",
    "参数说明": "表1 模板参数说明 参数名 描述 T 设定不同的数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持float/half/int16_t/int32_t/int8_t/bfloat16_t Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持float/half/int16_t/int32_t/int8_t/bfloat16_t",
    "返回值": "无",
    "调用示例": "// 本演示示例使用DataCopy从VECOUT搬出到外部dstGlobal时进行原子最大。\n#include \"kernel_operator.h\"\nstatic const int data_size = 256;\n\ntemplate <typename T>\nclass KernelDataCopyAtomicMax {\npublic:\n    __aicore__ inline KernelDataCopyAtomicMax() {}\n    __aicore__ inline void Init(GM_ADDR src0_gm, GM_ADDR src1_gm, GM_ADDR dst_gm, uint32_t size)\n    {\n        this->size = size;\n        src0Global.SetGlobalBuffer((__gm__ T *)src0_gm);\n        src1Global.SetGlobalBuffer((__gm__ T *)src1_gm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dst_gm);\n        pipe.InitBuffer(queueSrc0, 1, size * sizeof(T));\n        pipe.InitBuffer(queueSrc1, 1, size * sizeof(T));\n        pipe.InitBuffer(queueDst0, 1, size * sizeof(T));\n        pipe.InitBuffer(queueDst1, 1, size * sizeof(T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> src0local = queueSrc0.AllocTensor<T>();\n        AscendC::LocalTensor<T> src1local = queueSrc1.AllocTensor<T>();\n        AscendC::DataCopy(src0local, src0Global, size);\n        AscendC::DataCopy(src1local, src1Global, size);\n        queueSrc0.EnQue(src0local);\n        queueSrc1.EnQue(src1local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> src0local = queueSrc0.DeQue<T>();\n        AscendC::LocalTensor<T> src1local = queueSrc1.DeQue<T>();\n        AscendC::LocalTensor<T> dst0Local = queueDst0.AllocTensor<T>();\n        AscendC::LocalTensor<T> dst1Local = queueDst1.AllocTensor<T>();\n        AscendC::Abs(dst0Local, src0local, size);\n        AscendC::Abs(dst1Local, src1local, size);\n        queueDst0.EnQue(dst0Local);\n        queueDst1.EnQue(dst1Local);\n        queueSrc0.FreeTensor(src0local);\n        queueSrc1.FreeTensor(src1local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dst0Local = queueDst0.DeQue<T>();\n        AscendC::LocalTensor<T> dst1Local = queueDst1.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dst1Local, size);\n        AscendC::PipeBarrier<PIPE_MTE3>();\n        AscendC::SetAtomicMax<T>();\n        AscendC::DataCopy(dstGlobal, dst0Local, size);\n        queueDst0.FreeTensor(dst0Local);\n        queueDst1.FreeTensor(dst1Local);\n        AscendC::SetAtomicNone();\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queueSrc0;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> queueDst0;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> queueDst1;\n    AscendC::GlobalTensor<T> src0Global, src1Global, dstGlobal;\n    uint32_t size;\n};\nextern \"C\" __global__ __aicore__ void data_copy_atomic_max_kernel(GM_ADDR src0_gm, GM_ADDR src1_gm, GM_ADDR dst_gm)\n{\n    KernelDataCopyAtomicMax<half> op;\n    op.Init(src0_gm, src1_gm, dst_gm, data_size);\n    op.Process();\n}\n每个核的输入数据为: \nSrc0: [1,1,1,1,1,...,1] // 256个1\nSrc1: [2,2,2,2,2,...,2] // 256个2\n最终输出数据: [2,2,2,2,2,...,2] // 256个2",
    "错误": null
  },
  {
    "API名称": "SetAtomicMin(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0285.html",
    "功能说明": "原子操作函数，设置后续从VECOUT传输到GM的数据是否执行原子比较，将待拷贝的内容和GM已有内容进行比较，将最小值写入GM。 可通过设置模板参数来设定不同的数据类型。",
    "函数原型": "template <typename T>\n__aicore__ inline void SetAtomicMin() {}",
    "参数说明": "表1 模板参数说明 参数名 描述 T 设定不同的数据类型。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持int8_t、 int16_t、int32_t、half、bfloat16_t、float。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持int8_t、int16_t、int32_t、half、bfloat16_t、float。",
    "返回值": "无",
    "调用示例": "// 本演示示例使用DataCopy从VECOUT搬出到外部dstGlobal时进行原子最小。\n#include \"kernel_operator.h\"\nstatic const int data_size = 256;\n\ntemplate <typename T>\nclass KernelDataCopyAtomicMin {\npublic:\n    __aicore__ inline KernelDataCopyAtomicMin() {}\n    __aicore__ inline void Init(GM_ADDR src0_gm, GM_ADDR src1_gm, GM_ADDR dst_gm, uint32_t size)\n    {\n        this->size = size;\n        src0Global.SetGlobalBuffer((__gm__ T *)src0_gm);\n        src1Global.SetGlobalBuffer((__gm__ T *)src1_gm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dst_gm);\n        pipe.InitBuffer(queueSrc0, 1, size * sizeof(T));\n        pipe.InitBuffer(queueSrc1, 1, size * sizeof(T));\n        pipe.InitBuffer(queueDst0, 1, size * sizeof(T));\n        pipe.InitBuffer(queueDst1, 1, size * sizeof(T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> src0local = queueSrc0.AllocTensor<T>();\n        AscendC::LocalTensor<T> src1local = queueSrc1.AllocTensor<T>();\n        AscendC::DataCopy(src0local, src0Global, size);\n        AscendC::DataCopy(src1local, src1Global, size);\n        queueSrc0.EnQue(src0local);\n        queueSrc1.EnQue(src1local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> src0local = queueSrc0.DeQue<T>();\n        AscendC::LocalTensor<T> src1local = queueSrc1.DeQue<T>();\n        AscendC::LocalTensor<T> dst0Local = queueDst0.AllocTensor<T>();\n        AscendC::LocalTensor<T> dst1Local = queueDst1.AllocTensor<T>();\n        AscendC::Abs(dst0Local, src0local, size);\n        AscendC::Abs(dst1Local, src1local, size);\n        queueDst0.EnQue(dst0Local);\n        queueDst1.EnQue(dst1Local);\n        queueSrc0.FreeTensor(src0local);\n        queueSrc1.FreeTensor(src1local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dst0Local = queueDst0.DeQue<T>();\n        AscendC::LocalTensor<T> dst1Local = queueDst1.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dst1Local, size);\n        AscendC::PipeBarrier<PIPE_MTE3>();\n        AscendC::SetAtomicMin<T>();\n        AscendC::DataCopy(dstGlobal, dst0Local, size);\n        queueDst0.FreeTensor(dst0Local);\n        queueDst1.FreeTensor(dst1Local);\n        AscendC::SetAtomicNone();\n    }\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queueSrc0;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> queueDst0;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> queueDst1;\n    AscendC::GlobalTensor<T> src0Global, src1Global, dstGlobal;\n    uint32_t size;\n};\nextern \"C\" __global__ __aicore__ void data_copy_atomic_min_kernel(GM_ADDR src0_gm, GM_ADDR src1_gm, GM_ADDR dst_gm)\n{\n    KernelDataCopyAtomicMin<half> op;\n    op.Init(src0_gm, src1_gm, dst_gm, data_size);\n    op.Process();\n}\n\n每个核的输入数据为: \nSrc0: [1,1,1,1,1,...,1] // 256个1\nSrc1: [2,2,2,2,2,...,2] // 256个2\n最终输出数据: [1,1,1,1,1,...,1] // 256个1",
    "错误": null
  },
  {
    "API名称": "SetStoreAtomicConfig(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0286.html",
    "功能说明": "设置原子操作使能位与原子操作类型。",
    "函数原型": "template <AtomicDtype type, AtomicOp op>\n__aicore__ inline void SetStoreAtomicConfig()",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 type 输入 原子操作使能位，AtomicDtype枚举类的定义如下： enum class AtomicDtype { ATOMIC_NONE = 0 , // 无原子操作 ATOMIC_F32 , // 使能原子操作，进行原子操作的数据类型为float ATOMIC_F16 , // 使能原子操作，进行原子操作的数据类型为half ATOMIC_S16 , // 使能原子操作，进行原子操作的数据类型为int16_t ATOMIC_S32 , // 使能原子操作，进行原子操作的数据类型为int32_t ATOMIC_S8 , // 使能原子操作，进行原子操作的数据类型为int8_t ATOMIC_BF16 // 使能原子操作，进行原子操作的数据类型为bfloat16_t };",
    "返回值": "无",
    "调用示例": "// 设置原子操作为求和操作，支持的数据类型为half\nAscendC::SetStoreAtomicConfig<AscendC::AtomicDtype::ATOMIC_F16, AscendC::AtomicOp::ATOMIC_SUM>();",
    "错误": null
  },
  {
    "API名称": "GetStoreAtomicConfig(ISASI)",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0287.html",
    "功能说明": "获取原子操作使能位与原子操作类型的值，详细说明见 表1 。",
    "函数原型": "__aicore__ inline void GetStoreAtomicConfig(uint16_t &atomicType, uint16_t &atomicOp)",
    "参数说明": "表1 参数说明 参数名 输入/输出 描述 atomicType 输出 原子操作使能位。 0：无原子操作 1：使能原子操作，进行原子操作的数据类型为float 2：使能原子操作，进行原子操作的数据类型为half 3：使能原子操作，进行原子操作的数据类型为int16_t 4：使能原子操作，进行原子操作的数据类型为int32_t 5：使能原子操作，进行原子操作的数据类型为int8_t 6：使能原子操作，进行原子操作的数据类型为bfloat16_t atomicOp 输出 原子操作类型。 0：求和操作",
    "返回值": "无",
    "调用示例": "AscendC::SetStoreAtomicConfig<AscendC::AtomicDtype::ATOMIC_F16, AscendC::AtomicOp::ATOMIC_SUM>();\nuint16_t type = 0;       // 原子操作使能位\nuint16_t op = 0;         // 原子操作类型\nAscendC::GetStoreAtomicConfig(type, op);",
    "错误": null
  },
  {
    "API名称": "使用说明",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0289.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "表3 模板参数说明 参数 说明 MatmulApiCfg 用户自定义的AIC上计算所需要对象的数据类型，参考 步骤1 ，该模板参数必须填入。 CubeMsgBody 用户自定义的消息结构体 ，该模板参数必须填入。",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,返回值"
  },
  {
    "API名称": "使用说明",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0301.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "构造函数与析构函数",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0307.html",
    "功能说明": "用于创建KfcWorkspace对象，Kfc全称为kernel function call，表示核间通信调用。",
    "函数原型": "class KfcWorkspace;\n__aicore__ inline KfcWorkspace(GM_ADDR workspace)\n__aicore__ inline ~KfcWorkspace()",
    "参数说明": "表1 KfcWorkspace构造函数参数说明 参数 输入/输出 说明 workspace 输入 Global Memory上的消息空间地址，用户需保证地址对齐和清零。",
    "返回值": "KfcWorkspace对象实例。",
    "调用示例": "AscendC::KfcWorkspace desc(workspaceGM);",
    "错误": null
  },
  {
    "API名称": "Acos",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0504.html",
    "功能说明": "按元素做反余弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Acos(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize); // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Acos(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Acosh",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0564.html",
    "功能说明": "按元素做双曲反余弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Acosh(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Acosh(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Asin",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0496.html",
    "功能说明": "按元素做反正弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Asin(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。\n\n表2 参数说明 参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Asin内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考 GetAsinMaxMinTmpSize 。 calCount 输入 参与计算的元素个数。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize); // bufferSize 通过Host侧tiling参数获取\nLocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Asin(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Asinh",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0560.html",
    "功能说明": "按元素做反双曲正弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Asinh(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Asinh(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Atan",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0516.html",
    "功能说明": "按元素做三角函数反正切运算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Atan(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。\n\n表2 参数说明 参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考 GetAtanMaxMinTmpSize 。 calCount 输入 参与计算的元素个数。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize); // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Atan(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Atanh",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0556.html",
    "功能说明": "按元素做反双曲正切余弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Atanh(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Atanh(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Axpy",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0585.html",
    "功能说明": "源操作数(srcTensor)中每个元素与标量求积后和目的操作数(dstTensor)中的对应元素相加，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 该接口功能同基础API Axpy，区别在于此接口指令是通过Muls和Add组合计算，从而提供更优的精度。",
    "函数原型": "template <typename T, typename U, bool isReuseSource = false>\n__aicore__ inline void Axpy(const LocalTensor<T>& dstTensor, const LocalTensor<U>& srcTensor, const U scalarValue, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 目的操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float U 源操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Axpy(dstLocal, srcLocal, static_cast<half>(3.0), sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Ceil",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0572.html",
    "功能说明": "获取大于或等于x的最小的整数值，即向正无穷取整操作。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 举例如下： Ceil(3.9) = 4.0 Ceil (-3.9) = -3.0",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Ceil(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Ceil(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ClampMax",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0576.html",
    "功能说明": "将srcTensor中大于scalar的数替换为scalar，小于等于scalar的数保持不变，作为dstTensor输出。",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void ClampMax(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const T scalar, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入shape信息为128\nAscendC::ClampMax<half>(dstLocal, srcLocal, sharedTmpBuffer, static_cast<half>(2), 128);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ClampMin",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0577.html",
    "功能说明": "将srcTensor中小于scalar的数替换为scalar，大于等于scalar的数保持不变，作为dstTensor输出。",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void ClampMin(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const T scalar, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入shape信息为128\nAscendC::ClampMin<half>(dstLocal, srcLocal, sharedTmpBuffer, static_cast<half>(2), 128);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Cos",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0508.html",
    "功能说明": "按元素做三角函数余弦运算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： Cos(x)的泰勒展开式为：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Cos(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。该参数仅在输入的数据类型为float时生效。 true：开发者允许源操作数被改写，可以使能该参数，使能后本接口内部计算时 复用 srcTensor的内存空间，节省部分内存空间； false：本接口内部计算时 不复用 srcTensor的内存空间。 isReuseSource的使用样例请参考 更多样例 。\n\n表2 参数说明 参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考 GetCosMaxMinTmpSize 。 calCount 输入 参与计算的元素个数。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize); // bufferSize 通过Host侧tiling参数获取\nLocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Cos(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Cosh",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0528.html",
    "功能说明": "按元素做双曲余弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Cosh(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Cosh(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "CumSum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0605.html",
    "功能说明": "用于对输入张量按行或列进行累加和操作，输出结果中每个元素都是输入张量中对应位置及之前所有行或列的元素累加和。 计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： First轴处理，按行累加和操作，即第一行不变，后面的行依次累加，输出结果的第i行第j列计算公式如下： 以tensor([[0, 1, 2], [3, 4, 5]])为例，输出结果是tensor([[0, 1, 2], [3, 5, 7]]) Last轴处理，按列累加和操作，即第一列不变，后面的列依次累加，输出结果的第i行第j列计算公式如下： 以tensor([[0, 1, 2], [3, 4, 5]])为例，输出结果是tensor([[0, 1, 3], [3, 7, 12]])",
    "函数原型": "template <typename T, const CumSumConfig &config = defaultCumSumConfig>\n__aicore__ inline void CumSum(LocalTensor<T> &dstTensor, LocalTensor<T> &lastRowTensor, const LocalTensor<T> &srcTensor, LocalTensor<uint8_t> &sharedTmpBuffer, const CumSumInfo &cumSumInfo)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float config 定义CumSum接口编译时config参数。 struct CumSumConfig { bool isLastAxis { true }; bool isReuseSource { false }; bool outputLastRow { true }; };",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T>\nclass KernelCumSum\n{\npublic:\n    __aicore__ inline KernelCumSum(){}\n    __aicore__ inline void Init(\n        GM_ADDR srcGm, GM_ADDR dstGm, GM_ADDR lastRowGm, const AscendC::CumSumInfo& cumSumParams)\n    {\n        outer = cumSumParams.outter;\n        inner = cumSumParams.inner;\n        srcGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ T *>(srcGm), outer * inner);\n        dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ T *>(dstGm), outer * inner);\n        lastRowGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ T *>(lastRowGm), inner);\n        pipe.InitBuffer(inQueueX, 1, outer * inner * sizeof(T));\n        pipe.InitBuffer(outQueue, 1, outer * inner * sizeof(T));\n        pipe.InitBuffer(lastRowQueue, 1, inner * sizeof(T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueX.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, srcGlobal, outer * inner);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> lastRowLocal = lastRowQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> srcLocal = inQueueX.DeQue<T>();\n        static constexpr AscendC::CumSumConfig cumSumConfig{true, false, true};\n        const AscendC::CumSumInfo cumSumInfo{outer, inner};\n        AscendC::CumSum<T, cumSumConfig>(dstLocal, lastRowLocal, srcLocal, cumSumInfo);\n        outQueue.EnQue<T>(dstLocal);\n        lastRowQueue.EnQue<T>(lastRowLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueue.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, outer * inner);\n        outQueue.FreeTensor(dstLocal);\n        AscendC::LocalTensor<T> lastRowLocal = lastRowQueue.DeQue<T>();\n        AscendC::DataCopy(lastRowGlobal, lastRowLocal, inner);\n        lastRowQueue.FreeTensor(lastRowLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<T> srcGlobal;\n    AscendC::GlobalTensor<T> dstGlobal;\n    AscendC::GlobalTensor<T> lastRowGlobal;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> lastRowQueue;\n    uint32_t outer{1};\n    uint32_t inner{1};\n};\n\ntemplate <typename T>\n__aicore__ inline void kernel_cumsum_operator(\n    GM_ADDR srcGm, GM_ADDR dstGm, GM_ADDR lastRowGm, const AscendC::CumSumInfo &cumSumParams)\n{\n    KernelCumSum<T> op;\n    op.Init(srcGm, dstGm, lastRowGm, cumSumParams);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Digamma",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0597.html",
    "功能说明": "按元素计算x的gamma函数的对数导数，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数， 为伽玛函数。 计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Digamma(LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。该参数仅在输入的数据类型为float时生效。 true：开发者允许源操作数被改写，可以使能该参数，使能后本接口内部计算时 复用 srcTensor的内存空间，节省部分内存空间； false：本接口内部计算时 不复用 srcTensor的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为float, 实际计算个数为前1024\nAscendC::Digamma<float, false>(dstLocal, srcLocal, sharedTmpBuffer, 1024);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Erf",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0544.html",
    "功能说明": "按元素做误差函数计算（也称为高斯误差函数，error function or Gauss error function）。计算公式如下：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Erf(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename srcType>\nclass KernelErf {\npublic:\n    __aicore__ inline KernelErf()\n    {}\n    __aicore__ inline void Init(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t srcSize)\n    {\n        srcGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(srcGm), srcSize);\n        dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), srcSize);\n\n        pipe.InitBuffer(inQueueX, 1, srcSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, srcSize * sizeof(srcType));\n    }\n    __aicore__ inline void Process(uint32_t offset, uint32_t calSize)\n    {\n        bufferSize = calSize;\n        CopyIn(offset);\n        Compute();\n        CopyOut(offset);\n    }\nprivate:\n    __aicore__ inline void CopyIn(uint32_t offset)\n    {\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.AllocTensor<srcType>();\n        AscendC::DataCopy(srcLocal, srcGlobal[offset], bufferSize);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.DeQue<srcType>();\n        AscendC::Erf<srcType, false>(dstLocal, srcLocal);\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut(uint32_t offset)\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dstGlobal[offset], dstLocal, bufferSize);\n        outQueue.FreeTensor(dstLocal);\n    }\nprivate:\n    AscendC::GlobalTensor<srcType> srcGlobal;\n    AscendC::GlobalTensor<srcType> dstGlobal;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    uint32_t bufferSize = 0;\n};\n\ntemplate <typename dataType>\n__aicore__ void kernel_erf_operator(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t srcSize)\n{\n    KernelErf<dataType> op;\n    op.Init(srcGm, dstGm, srcSize);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Erfc",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0548.html",
    "功能说明": "返回输入x的互补误差函数结果，积分区间为x到无穷大。原始的理论计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 由于Erfc函数没有初等函数表达方式，一般通过函数逼近的方式计算，近似计算公式如下所示： 其中， R(z) = (((((((z * R0 + R1) * z + R2) * z + R3) * z + R4) * z + R5) * z + R6) * z + R7) * z + R8是关于z的8次多项式； S(z) = (((((z + S1) * z + S2) * z + S3) * z + S4) * z + S5是关于z的4次多项式。",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Erfc(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Erfc(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Exp",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0589.html",
    "功能说明": "按元素取自然指数，用户可以选择是否使用泰勒展开公式进行计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 设置泰勒展开项数为0，即不使用泰勒展开公式进行计算，公式如下： 设置泰勒展开项数不为0，即使用泰勒展开公式进行计算，公式如下： xA i 代表源操作数的整数部分，xB i 代表源操作数的小数部分。 泰勒展开公式如下：",
    "函数原型": "template <typename T, uint8_t taylorExpandLevel, bool isReuseSource = false>\n__aicore__ inline void Exp(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float taylorExpandLevel 泰勒展开项数，项数为0表示不使用泰勒公式进行计算。项数太少时，精度会有一定误差。项数越多，精度相对而言更高，但是性能会更差。取值范围为[0, 255]，推荐取值为[10, 15] isReuseSource 是否允许修改源操作数，默认值为false。该参数仅在输入的数据类型为float时生效。 true：开发者允许源操作数被改写，可以使能该参数，使能后本接口内部计算时 复用 srcLocal的内存空间，节省部分内存空间； false：本接口内部计算时 不复用 srcLocal的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Exp<half, 15, false>(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Floor",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0568.html",
    "功能说明": "获取小于或等于x的最小的整数值，即向负无穷取整操作。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 举例如下： Floor(3.9) = 3.0 Floor(-3.9) = -4.0",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Floor(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Floor(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Fmod",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0608.html",
    "功能说明": "按元素计算两个浮点数a, b相除后的余数。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 其中，Trunc为向零取整操作。举例如下： Fmod(2.0, 1.5) = 0.5 Fmod(-3.0, 1.1) = -0.8",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Fmod(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const LocalTensor<T>& src1Tensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Fmod(dstLocal, src0Local, src1Local, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Frac",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0540.html",
    "功能说明": "按元素做取小数计算。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 举例如下： Frac(-258.41888) = -0.41888428 Frac(5592.625) = 0.625",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Frac(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\ntemplate <typename srcType>\nclass KernelFrac\n{\npublic:\n    __aicore__ inline KernelFrac(){}\n    __aicore__ inline void Init(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t srcSize)\n    {\n        srcGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(srcGm), srcSize);\n        dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), srcSize);\n\n        pipe.InitBuffer(inQueueX, 1, srcSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, srcSize * sizeof(srcType));\n        bufferSize = srcSize;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.AllocTensor<srcType>();\n        AscendC::DataCopy(srcLocal, srcGlobal, bufferSize);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.DeQue<srcType>();\n        AscendC::Frac<srcType, false>(dstLocal, srcLocal);\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dstGlobal, dstLocal, bufferSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> srcGlobal;\n    AscendC::GlobalTensor<srcType> dstGlobal;\n\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    uint32_t bufferSize = 0;\n};\n\ntemplate <typename dataType>\n__aicore__ void kernel_frac_operator(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t srcSize)\n{\n    KernelFrac<dataType> op;\n    op.Init(srcGm, dstGm, srcSize);\n    op.Process();\n}\n\nextern \"C\" __global__ __aicore__ void kernel_frac_operator(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t srcSize)\n{\n    kernel_frac_operator<half>(srcGm, dstGm, srcSize);\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Lgamma",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0593.html",
    "功能说明": "按元素计算x的gamma函数的绝对值并求自然对数，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Lgamma(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。该参数仅在输入的数据类型为float时生效。 true：开发者允许源操作数被改写，可以使能该参数，使能后本接口内部计算时 复用 srcTensor的内存空间，节省部分内存空间； false：本接口内部计算时 不复用 srcTensor的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Lgamma(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Log",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0512.html",
    "功能说明": "按元素以e、2、10为底做对数运算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template<typename T, bool isReuseSource = false>\n__aicore__ inline void Log(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。\n\n表2 参数说明 参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考 GetLogMaxMinTmpSize 。 calCount 输入 参与计算的元素个数。",
    "返回值": "",
    "调用示例": "Log(dstLocal, srcLocal);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Power",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0520.html",
    "功能说明": "实现按元素做幂运算功能，提供3类接口，处理逻辑如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Power(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const LocalTensor<T>& src1Tensor, const LocalTensor<uint8_t>& sharedTmpBuffer, uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float/int32_t Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float/int32_t isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "Power(dstLocal, srcLocal1, srcLocal2)",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Round",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0581.html",
    "功能说明": "将输入的元素四舍五入到最接近的整数，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 举例如下： Round(3.5) = 4.0 Round(-3.4) = -3.0",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Round(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Round(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Sign",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0552.html",
    "功能说明": "按元素执行Sign操作，Sign是指返回输入数据的符号，如果为0则返回0，如果为正数则返回1，如果为负数则返回-1。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Sign(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "// 通过sharedTmpBuffer入参传入临时空间\nAscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\nAscendC::Sign(yLocal, xLocal, tmpLocal, calCount);  // 源操作数Tensor全部/部分参与计算\nAscendC::Sign(yLocal, xLocal, tmpLocal);            // 源操作数Tensor全部参与计算\n// 接口框架申请临时空间\nAscendC::Sign(yLocal, xLocal, this->mcount);    // 源操作数Tensor全部/部分参与计算\nAscendC::Sign(yLocal, xLocal);                  // 源操作数Tensor全部参与计算",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Sin",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0500.html",
    "功能说明": "按元素做正弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： Sin(x)的泰勒展开式为：",
    "函数原型": "template<typename T, bool isReuseSource = false>\n__aicore__ inline void Sin(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。该参数仅在输入的数据类型为float时生效。 true：开发者允许源操作数被改写，可以使能该参数，使能后本接口内部计算时 复用 srcTensor的内存空间，节省部分内存空间； false：本接口内部计算时 不复用 srcTensor的内存空间。\n\n表2 参数说明 参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 用于Sin内部复杂计算时存储中间变量，由开发者提供。 临时空间大小BufferSize的获取方式请参考 GetSinMaxMinTmpSize 。 calCount 输入 参与计算的元素个数。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize); // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Sin(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Sinh",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0524.html",
    "功能说明": "按元素做双曲正弦函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Sinh(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。\n\n表2 参数说明 参数名 输入/输出 描述 dstTensor 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 srcTensor 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 源操作数的数据类型需要与目的操作数保持一致。 sharedTmpBuffer 输入 临时缓存。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 临时空间大小BufferSize的获取方式请参考 GetSinhMaxMinTmpSize 。 calCount 输入 参与计算的元素个数。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Sinh(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Tan",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0532.html",
    "功能说明": "按元素做正切函数计算，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： Tan(x)的泰勒展开式为： 其中B 2n 是伯努利数。",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Tan(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Tan(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Tanh",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0492.html",
    "功能说明": "按元素做逻辑回归Tanh，计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Tanh(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入tensor长度为1024, 算子输入的数据类型为half，实际计算个数为512\nAscendC::Tanh(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Trunc",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0536.html",
    "功能说明": "按元素做浮点数截断，即向零取整操作。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数： 举例如下： Trunc(3.9) = 3 Trunc(-3.9) = -3",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Trunc(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename srcType>\nclass KernelTrunc\n{\npublic:\n    __aicore__ inline KernelTrunc(){}\n    __aicore__ inline void Init(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t srcSize)\n    {\n        src_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(srcGm), srcSize);\n        dst_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), srcSize);\n        pipe.InitBuffer(inQueueX, 1, srcSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, srcSize * sizeof(srcType));\n        bufferSize = srcSize;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.AllocTensor<srcType>();\n        AscendC::DataCopy(srcLocal, src_global, bufferSize);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.DeQue<srcType>();\n        AscendC::Trunc<srcType, false>(dstLocal, srcLocal);\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dst_global, dstLocal, bufferSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> src_global;\n    AscendC::GlobalTensor<srcType> dst_global;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    uint32_t bufferSize = 0;\n};\ntemplate <typename dataType>\n__aicore__ void kernel_trunc_operator(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t srcSize)\n{\n    KernelTrunc<dataType> op;\n    op.Init(srcGm, dstGm, srcSize);\n    op.Process();\n}\n\nextern \"C\" __global__ __aicore__ void trunc_operator(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t srcSize)\n{\n    kernel_trunc_operator<half>(srcGm, dstGm, srcSize);\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Xor",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0601.html",
    "功能说明": "按元素执行Xor运算，Xor（异或）的概念和运算规则如下： 概念：参加运算的两个数据，按二进制位进行“异或”运算。 运算规则：0^0=0；0^1=1；1^0=1；1^1=0；即：参加运算的两个对象，如果两个相应位为“异”（值不同），则该位结果为1，否则为 0【同0异1】。 计算公式如下： 例如： 3 ^ 5 = 6 ，即 0000 0011 ^ 0000 0101 = 0000 0110",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Xor(const LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const LocalTensor<T>& src1Tensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t Atlas 200I/500 A2 推理产品 ，支持的数据类型为：int16_t/uint16_t Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/uint16_t isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\nconstexpr int32_t BUFFER_NUM = 1;\nclass KernelXor {\npublic:\n    __aicore__ inline KernelXor() {}\n    __aicore__ inline void Init(GM_ADDR x, GM_ADDR y, GM_ADDR z, uint32_t totalLength, uint32_t totalLength2, uint32_t tilenum, uint32_t tmpSize, uint32_t mcount)\n    {\n        this->totalLength = totalLength;\n        this->blockLength = totalLength / AscendC::GetBlockNum();\n        this->blockLength2 = totalLength2 / AscendC::GetBlockNum();\n        this->tilenum = tilenum;\n        this->tmpSize = tmpSize;\n        this->mcount = mcount;\n        this->tileLength = this->blockLength / tilenum / BUFFER_NUM;\n        this->tileLength2 = this->blockLength2 / tilenum / BUFFER_NUM;\n\n        xGm.SetGlobalBuffer((__gm__ int16_t *)x + this->blockLength * AscendC::GetBlockIdx(), this->blockLength);\n        yGm.SetGlobalBuffer((__gm__ int16_t *)y + this->blockLength2 * AscendC::GetBlockIdx(), this->blockLength2);\n        zGm.SetGlobalBuffer((__gm__ int16_t *)z + this->blockLength * AscendC::GetBlockIdx(), this->blockLength);\n\n        if (this->tmpSize != 0) {\n            pipe.InitBuffer(tmpQueue, BUFFER_NUM, this->tmpSize);\n        }\n        pipe.InitBuffer(inQueueX, BUFFER_NUM, this->tileLength * sizeof(int16_t));\n        pipe.InitBuffer(inQueueY, BUFFER_NUM, this->tileLength2 * sizeof(int16_t));\n        pipe.InitBuffer(outQueueZ, BUFFER_NUM, this->tileLength * sizeof(int16_t));\n    }\n    __aicore__ inline void Process()\n    {\n        int32_t loopCount = this->tilenum * BUFFER_NUM;\n        for (int32_t i = 0; i < loopCount; i++) {\n            CopyIn(i);\n            Compute(i);\n            CopyOut(i);\n        }\n    }\n\nprivate:\n    __aicore__ inline void CopyIn(int32_t progress)\n    {\n        AscendC::LocalTensor<int16_t> xLocal = inQueueX.AllocTensor<int16_t>();\n        AscendC::DataCopy(xLocal, xGm[progress * this->tileLength], this->tileLength);\n        inQueueX.EnQue(xLocal);\n        AscendC::LocalTensor<int16_t> yLocal = inQueueY.AllocTensor<int16_t>();\n        AscendC::DataCopy(yLocal, yGm[progress * this->tileLength2], this->tileLength2);\n        inQueueY.EnQue(yLocal);\n    }\n    __aicore__ inline void Compute(int32_t progress)\n    {\n        AscendC::LocalTensor<int16_t> xLocal = inQueueX.DeQue<int16_t>();\n        AscendC::LocalTensor<int16_t> yLocal = inQueueY.DeQue<int16_t>();\n        AscendC::LocalTensor<int16_t> zLocal = outQueueZ.AllocTensor<int16_t>();\n        if (this->tmpSize != 0) {\n            AscendC::LocalTensor<uint8_t> tmpLocal = tmpQueue.AllocTensor<uint8_t>();\n            if (this->mcount != this->totalLength) {\n                AscendC::Xor(zLocal, xLocal, yLocal, tmpLocal, this->mcount);\n            } else {\n                AscendC::Xor(zLocal, xLocal, yLocal, tmpLocal);\n            }\n            tmpQueue.FreeTensor(tmpLocal);\n        } else {\n            if (this->mcount != this->totalLength) {\n                AscendC::Xor(zLocal, xLocal, yLocal, this->mcount);\n            } else {\n                AscendC::Xor(zLocal, xLocal, yLocal);\n            }\n        }\n        outQueueZ.EnQue<int16_t>(zLocal);\n        inQueueX.FreeTensor(xLocal);\n        inQueueY.FreeTensor(yLocal);\n    }\n    __aicore__ inline void CopyOut(int32_t progress)\n    {\n        AscendC::LocalTensor<int16_t> zLocal = outQueueZ.DeQue<int16_t>();\n        AscendC::DataCopy(zGm[progress * this->tileLength], zLocal, this->tileLength);\n        outQueueZ.FreeTensor(zLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueY;\n    AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> tmpQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, BUFFER_NUM> outQueueZ;\n    AscendC::GlobalTensor<int16_t> xGm;\n    AscendC::GlobalTensor<int16_t> yGm;\n    AscendC::GlobalTensor<int16_t> zGm;\n    uint32_t blockLength;\n    uint32_t blockLength2;\n    uint32_t tilenum;\n    uint32_t tileLength;\n    uint32_t tileLength2;\n    uint32_t tmpSize;\n    uint32_t mcount;\n    uint32_t totalLength;\n};\n\nextern \"C\" __global__ __aicore__ void xor_custom(GM_ADDR x, GM_ADDR y, GM_ADDR z, GM_ADDR workspace, GM_ADDR tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelXor op;\n    op.Init(x, y, z, tilingData.totalLength, tilingData.totalLength2, tilingData.tilenum, tilingData.tmpSize, tilingData.mcount);\n    if (TILING_KEY_IS(1)) {\n        op.Process();\n    }\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "AscendAntiQuant",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0822.html",
    "功能说明": "按元素做伪量化计算，比如将int8_t数据类型伪量化为half数据类型，计算公式如下： PER_CHANNEL场景（按通道量化） 不使能输入转置 groupSize = src.shape[0] / offset.shape[0] dst[i][j] = scale[i / groupSize][j] * (src[i][j] + offset[i / groupSize][j]) 使能输入转置 groupSize = src.shape[1] / offset.shape[1] dst[i][j] = scale[i][j / groupSize] * (src[i][j] + offset[i][j / groupSize]) PER_TENSOR场景 （按张量量化） dst[i][j] = scale * (src[i][j] + offset) l",
    "函数原型": "template <typename InputDataType, typename OutputDataType, bool isTranspose>\n__aicore__ inline void AscendAntiQuant(const LocalTensor<OutputDataType> &dst, const LocalTensor<InputDataType> &src, const LocalTensor<OutputDataType> &offset, const LocalTensor<OutputDataType> &scale, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t K, const AntiQuantShapeInfo& shapeInfo = {})",
    "参数说明": "表1 模板参数说明 参数名 描述 InputDataType 输入的数据类型。 OutputDataType 输出的数据类型。 isTranspose 是否使能输入数据转置。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename InputType, typename OutType>\nclass AntiQuantTest\n{\npublic:\n    __aicore__ inline AntiQuantTest() {}\n    __aicore__ inline void Init(GM_ADDR dstGm, GM_ADDR srcGm, GM_ADDR offsetGm, GM_ADDR scaleGm,\n                                uint32_t elementCountOfInput, uint32_t elementCountOfOffset, uint32_t K)\n    {\n        elementCountOfInput = elementCountOfInput;\n        elementCountOfOffset = elementCountOfOffset;\n        k = K;\n\n        dstGlobal.SetGlobalBuffer((__gm__ OutType *)dstGm);\n        srcGlobal.SetGlobalBuffer((__gm__ InputType *)srcGm);\n        offsetGlobal.SetGlobalBuffer((__gm__ OutType *)offsetGm);\n        scaleGlobal.SetGlobalBuffer((__gm__ OutType *)scaleGm);\n\n        pipe.InitBuffer(queInSrc, 1, elementCountOfInput * sizeof(InputType));\n        pipe.InitBuffer(queInOffset, 1, elementCountOfOffset * sizeof(OutType));\n        pipe.InitBuffer(queInScale, 1, elementCountOfOffset * sizeof(OutType));\n        pipe.InitBuffer(queOut, 1, elementCountOfInput * sizeof(OutType));\n        pipe.InitBuffer(queTmp, 1, 67584);\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<InputType> srcLocal = queInSrc.AllocTensor<InputType>();\n        AscendC::DataCopy(srcLocal, srcGlobal, elementCountOfInput);\n        queInSrc.EnQue(srcLocal);\n\n        AscendC::LocalTensor<OutType> offsetLocal = queInOffset.AllocTensor<OutType>();\n        AscendC::DataCopy(offsetLocal, offsetGlobal, elementCountOfOffset);\n        queInOffset.EnQue(offsetLocal);\n\n        AscendC::LocalTensor<OutType> scaleLocal = queInScale.AllocTensor<OutType>();\n        AscendC::DataCopy(scaleLocal, scaleGlobal, elementCountOfOffset);\n        queInScale.EnQue(scaleLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<InputType> srcLocal = queInSrc.DeQue<InputType>();\n        AscendC::LocalTensor<OutType> offsetLocal = queInOffset.DeQue<OutType>();\n        AscendC::LocalTensor<OutType> scaleLocal = queInScale.DeQue<OutType>();\n        AscendC::LocalTensor<OutType> dstLocal = queOut.AllocTensor<OutType>();\n        AscendC::LocalTensor<uint8_t> sharedTmpBuffer = queTmp.AllocTensor<uint8_t>();\n\n        AscendC::AntiQuantShapeInfo shapeInfo = {1, elementCountOfOffset, 1, elementCountOfOffset};\n        AscendC::AscendAntiQuant<InputType, OutType, false>(dstLocal, srcLocal, offsetLocal, scaleLocal, sharedTmpBuffer, k, shapeInfo);\n        queInSrc.FreeTensor(srcLocal);\n        queInOffset.FreeTensor(offsetLocal);\n        queInScale.FreeTensor(scaleLocal);\n        queTmp.FreeTensor(sharedTmpBuffer);\n        queOut.EnQue(dstLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<OutType> dstLocal = queOut.DeQue<OutType>();\n        AscendC::DataCopy(dstGlobal, dstLocal, elementCountOfInput);\n        queOut.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queInSrc;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queInOffset;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queInScale;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> queTmp;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> queOut;\n    AscendC::GlobalTensor<OutType> dstGlobal;\n    AscendC::GlobalTensor<InputType> srcGlobal;\n    AscendC::GlobalTensor<OutType> offsetGlobal;\n    AscendC::GlobalTensor<OutType> scaleGlobal;\n    uint32_t elementCountOfInput;\n    uint32_t elementCountOfOffset;\n    uint32_t k;\n}; // class AntiQuantTest\n\nextern \"C\" __global__ __aicore__ void kernel_anti_quant(GM_ADDR dst, GM_ADDR src, GM_ADDR offset, GM_ADDR scale,\n                                                        uint32_t elementCountOfInput, uint32_t elementCountOfOffset, uint32_t K)\n{\n    AscendC::AntiQuantTest<InputType, OutType> op;\n    op.Init(dst, src, offset, scale, elementCountOfInput, elementCountOfOffset, K);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "AscendDequant",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0820.html",
    "功能说明": "按元素做反量化计算，比如将int32_t数据类型反量化为half/float等数据类型。 本接口最多支持输入为二维数据，不支持更高维度的输入。 假设输入srcTensor的shape为 （m, n） ，每行数据（即n个输入数据）所占字节数要求 32字节对齐 ，每行中进行反量化的元素个数为 calCount ； 反量化系数deqScale可以为标量或者向量，为向量的情况下，calCount <= deqScale的元素个数，只有前CalCount个反量化系数生效； 输出dstTensor的shape为 （m, n_dst） ， n * sizeof(dstT)不满足32字节对齐时，需要 向上补齐为32字节 ，n_dst为向上补齐后的列数。 下面通过两个具体的示例来解释参数的配置和计算逻辑（下文中DequantParams类型为存储shape信息的结构体{m, n, calCount}）： 如下图示例中，srcTensor的数据类型为int32_t，m = 4，n = 8，calCount = 4，表明srcTensor中每行进行反量化的元素个数为4，deqScale中的前4个数生效，后12个数不参与反量化计算；dstTensor的数据类型为bfloat16_t，m = 4，n_dst = 16 (16 * sizeof(bfloat16_t) % 32 = 0)。计算逻辑是srcTensor的每n个数为一行，对于每行中的前calCount个元素，该行srcTensor的第i个元素与deqScale的第i个元素进行相乘写入dstTensor对应行的第i个元素，dstTensor对应行的第calCount + 1个元素~第n_dst个元素均为不确定的值。 如下示例中，srcTensor的数据类型为int32_t，m = 4，n = 8， calCount = 4，表明srcTensor中每行进行反量化的元素个数为4；dstTensor的数据类型为float，m = 4，n_dst = 8 (8 * sizeof(float) % 32 = 0)。对于srcTensor每行中的前4个元素都和标量deqScale相乘并写入dstTensor中每行的对应位置。 当用户将模板参数中的mode配置为 DEQUANT_WITH_SINGLE_ROW 时： 针对DequantParams {m, n, calCount}， 若同时满足以下3个条件： m = 1 calCount为 32 / sizeof(dstT)的倍数 n % calCount = 0 此时 {1, n, calCount}会被视作为 {n / calCount, calCount, calCount} 进行反量化的计算。 具体效果可看下图所示，传入的DequantParams为 {1, 16, 8}。因为dstT为float，所以calCount满足为8的倍数，在 DEQUANT_WITH_SINGLE_ROW 模式下会将{1, 2 * 8, 8}转换为 {2, 8, 8}进行计算。",
    "函数原型": "template <typename dstT, typename scaleT, DeQuantMode mode = DeQuantMode::DEQUANT_WITH_SINGLE_ROW>\n__aicore__ inline void AscendDequant(const LocalTensor<dstT>& dstTensor, const LocalTensor<int32_t>& srcTensor, const LocalTensor<scaleT>& deqScale, const LocalTensor<uint8_t>& sharedTmpBuffer, DequantParams params)",
    "参数说明": "表1 模板参数说明 参数名 描述 dstT 目的操作数的数据类型。 scaleT deqScale的数据类型。 mode 决定当DequantParams为{1, n, calCount}时的计算逻辑，传入enum DeQuantMode，支持以下 2 种配置： DEQUANT_WITH_SINGLE_ROW ：当DequantParams {m, n, calCount} 同时满足以下条件：1、m = 1；2、calCount为 32 / sizeof(dstT)的倍数；3、n % calCount = 0时，即 {1, n, calCount} 会当作 {n / calCount, calCount, calCount} 进行计算。 DEQUANT_WITH_MULTI_ROW ：即使满足上述所有条件，{1, n, calCount} 依然只会当作 {1, n, calCount} 进行计算， 即总共n个数，前calCount个数进行反量化的计算。",
    "返回值": "",
    "调用示例": "rowLen = m;                 // m = 4\ncolLen = n;                 // n = 8\n//输入srcLocal的shape为4*8，类型为int32_t，deqScaleLocal的shape为8，类型为float，预留临时空间\nAscendC::AscendDequant(dstLocal, srcLocal, deqScaleLocal, {rowLen, colLen, deqScaleLocal.GetSize()});",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "AscendQuant",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0818.html",
    "功能说明": "按元素做量化计算，比如将half/float数据类型量化为int8_t数据类型。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数，round表示四舍六入五成双取整： PER_TENSOR量化：整个srcTensor对应一个量化参数，量化参数的shape为[1]。 PER_CHANNEL量化：srcTensor的shape为[m, n], 每个channel维度对应一个量化参数，量化参数的shape为[n]。",
    "函数原型": "template <typename T, bool isReuseSource = false, const AscendQuantConfig& config = ASCEND_QUANT_DEFAULT_CFG>\n__aicore__ inline void AscendQuant(const LocalTensor<int8_t>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const float scale, const float offset, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas 训练系列产品 ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 config 结构体模板参数，此参数可选配，AscendQuantConfig类型，具体定义如下。 struct AscendQuantConfig { uint32_t calcCount = 0 ; uint32_t offsetCount = 0 ; uint32_t scaleCount = 0 ; uint32_t workLocalSize = 0 ; };",
    "返回值": "",
    "调用示例": "// 输入shape为1024\nuint32_t dataSize = 1024; \n// 输入类型为float/half, scale=2.0, offset=0.9，预留临时空间\nAscendC::AscendQuant<srcType>(dstLocal, srcLocal, 2.0f, 0.9f, dataSize);\n// 使用模板参数使能参数常量化的示例\n// static constexpr AscendC::AscendQuantConfig static_config = {1024, 0, 0, 0};\n// 使用AscendQuantConfig类型的参数static_config，传入模板参数将参数常量化\n// AscendC::AscendQuant<srcType, false, static_config>(dstLocal, srcLocal, 2.0f, 0.9f, dataSize);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "BatchNorm",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0806.html",
    "功能说明": "BatchNorm是对于每一层的输入做规范化处理，使得每一层的分布尽可能的相同，从而加速训练过程和提高模型的泛化能力（有效减少梯度消失和梯度爆炸问题）。基本思想是对于每个batch中的样本，对其输入的每个特征在batch的维度上进行归一化。具体来说，对于输入特征x，BatchNorm的计算过程可以表示为： 对输入特征x，在batch维度上计算均值μ和方差σ： 对于每个特征i，对输入特征x进行归一化： 对归一化后的特征进行缩放和平移：",
    "函数原型": "template <typename T, bool isReuseSource = false, bool isBasicBlock = false>\n__aicore__ inline void BatchNorm(const LocalTensor<T>& output, const LocalTensor<T>& outputMean, const LocalTensor<T>& outputVariance, const LocalTensor<T>& inputX, const LocalTensor<T>& gamm, const LocalTensor<T>& beta, const T epsilon, BatchNormTiling& tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 isBasicBlock inputX、output的shape信息和Tiling切分策略满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。基本块要求如下： originB是8的倍数； S*H是64的倍数，但小于2048。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename dataType, bool isReuseSource = false, bool isBasicBlock = false>\nclass KernelBatchnorm {\npublic:\n    __aicore__ inline KernelBatchnorm()\n    {}\n    __aicore__ inline void Init(GM_ADDR inputXGm, GM_ADDR gammGm, GM_ADDR betaGm, GM_ADDR outputGm,\n        GM_ADDR outputMeanGm, GM_ADDR outputVariance_gm, const TilingData &tiling)\n    {\n        bLength = tiling.bLength;\n        sLength = tiling.sLength;\n        hLength = tiling.hLength;\n        batchNormTilling = tiling.batchNormTilingData;\n        originalBLength = tiling.originalBLength;\n        bshLength = originalBLength * sLength * hLength;\n        shLength = sLength * hLength;\n        inputXGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(inputXGm), bshLength);\n        gammGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(gammGm), bLength);\n        betaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(betaGm), bLength);\n        outputGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputGm), bshLength);\n        outputMeanGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputMeanGm), shLength);\n        outputVarianceGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputVariance_gm), shLength);\n        pipe.InitBuffer(inQueueX, 1, sizeof(dataType) * bshLength);\n        pipe.InitBuffer(inQueueGamma, 1, sizeof(dataType) * bLength);\n        pipe.InitBuffer(inQueueBeta, 1, sizeof(dataType) * bLength);\n        pipe.InitBuffer(outQueue, 1, sizeof(dataType) * bshLength);\n        pipe.InitBuffer(outQueueMean, 1, sizeof(dataType) * shLength);\n        pipe.InitBuffer(outQueueVariance, 1, sizeof(dataType) * shLength);\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> betaLocal = inQueueBeta.AllocTensor<dataType>();\n        AscendC::DataCopy(inputXLocal, inputXGlobal, bshLength);\n        AscendC::DataCopy(gammaLocal, gammGlobal, bLength);\n        AscendC::DataCopy(betaLocal, betaGlobal, bLength);\n        inQueueX.EnQue(inputXLocal);\n        inQueueGamma.EnQue(gammaLocal);\n        inQueueBeta.EnQue(betaLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> betaLocal = inQueueBeta.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> meanLocal = outQueueMean.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> varianceLocal = outQueueVariance.AllocTensor<dataType>();\n        AscendC::BatchNorm<dataType, isReuseSource, isBasicBlock>(outputLocal,\n            meanLocal,\n            varianceLocal,\n            inputXLocal,\n            gammaLocal,\n            betaLocal,\n            (dataType)epsilon,\n            batchNormTilling);\n        outQueue.EnQue<dataType>(outputLocal);\n        outQueueMean.EnQue<dataType>(meanLocal);\n        outQueueVariance.EnQue<dataType>(varianceLocal);\n        inQueueX.FreeTensor(inputXLocal);\n        inQueueGamma.FreeTensor(gammaLocal);\n        inQueueBeta.FreeTensor(betaLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> meanLocal = outQueueMean.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> varianceLocal = outQueueVariance.DeQue<dataType>();\n\n        AscendC::DataCopy(outputGlobal, outputLocal, bshLength);\n        AscendC::DataCopy(outputMeanGlobal, meanLocal, shLength);\n        AscendC::DataCopy(outputVarianceGlobal, varianceLocal, shLength);\n\n        outQueue.FreeTensor(outputLocal);\n        outQueueMean.FreeTensor(meanLocal);\n        outQueueVariance.FreeTensor(varianceLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<dataType> inputXGlobal;\n    AscendC::GlobalTensor<dataType> gammGlobal;\n    AscendC::GlobalTensor<dataType> betaGlobal;\n    AscendC::GlobalTensor<dataType> outputGlobal;\n    AscendC::GlobalTensor<dataType> outputMeanGlobal;\n    AscendC::GlobalTensor<dataType> outputVarianceGlobal;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueGamma;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueBeta;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueMean;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueVariance;\n    uint32_t bLength;\n    uint32_t sLength;\n    uint32_t hLength;\n    uint32_t originalBLength;\n    dataType epsilon = 0.001;\n    uint32_t bshLength;\n    uint32_t shLength;\n    BatchNormTiling batchNormTilling;\n};\n\nextern \"C\" __global__ __aicore__ void kernel_batchnorm_operator(GM_ADDR inputXGm, GM_ADDR gammGm, GM_ADDR betaGm,\n    GM_ADDR outputGm, GM_ADDR outputMeanGm, GM_ADDR outputVariance_gm, GM_ADDR tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelBatchnorm<half, false, false> op;\n    op.Init(inputXGm, gammGm, betaGm, outputGm, outputMeanGm, outputVariance_gm, tilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "DeepNorm",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0808.html",
    "功能说明": "在深层神经网络训练过程中，执行层LayerNorm归一化时，可以使用DeepNorm进行替代，通过扩大残差连接来提高Transformer的稳定性。 本接口实现了对shape大小为[B，S，H]的输入数据的DeepNorm归一化，其计算公式如下： DeepNorm(x) = LayerNorm(α * X + SubLayer(X)) SubLayer(X)通常是指在DeepNorm模型中的一个子层（sub-layer），用于实现自注意力机制（self-attention mechanism）。本接口中会整体作为一个输入Tensor传入。",
    "函数原型": "template <typename T, bool isReuseSrc = false, bool isBasicBlock = false>\n__aicore__ inline void DeepNorm(const LocalTensor<T>& dstLocal, const LocalTensor<T>& meanLocal, const LocalTensor<T>& rstdLocal, const LocalTensor<T>& srcLocal, const LocalTensor<T>& gxLocal, const LocalTensor<T>& betaLocal, const LocalTensor<T>& gammaLocal, const LocalTensor<uint8_t>& sharedTmpBuffer, const T alpha, const T epsilon, DeepNormTiling& tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSrc 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 srcLocal的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 srcLocal的内存空间。 对于float数据类型输入支持开启该参数，half数据类型输入不支持开启该参数。 isReuseSrc的使用样例请参考 更多样例 。 isBasicBlock srcTensor的shape信息满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。基本块要求srcTensor的shape需要满足如下条件： 尾轴即H的长度为64的倍数，但不超过2040； 非尾轴长度（B*S）为8的倍数。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename dataType, bool isReuseSrc = false, bool isBasicBlock = false>\nclass KernelDeepNorm {\npublic:\n    __aicore__ inline KernelDeepNorm()\n    {}\n    __aicore__ inline void Init(GM_ADDR inputGm, GM_ADDR inputGxGm, GM_ADDR betaGm, GM_ADDR gammaGm, GM_ADDR outputGm,\n        GM_ADDR outputMeanGm, GM_ADDR outputVarianceGm, const DeepNormCustomTiling &customTiling)\n    {\n        this->tiling = customTiling.tiling;  // DeepNormTiling\n        alpha = customTiling.alpha;\n        epsilon = customTiling.epsilon;\n        const uint32_t bLength = tiling.bLength;\n        const uint32_t sLength = tiling.sLength;\n        hLength = tiling.hLength;\n        bshLength = bLength * sLength * hLength;\n        bsLength = bLength * sLength;\n        inputXGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(inputGm), bshLength);\n        inputGxGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(inputGxGm), bshLength);\n        betaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(betaGm), hLength);\n        gammaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(gammaGm), hLength);\n        outputGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputGm), bshLength);\n        outputMeanGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputMeanGm), bsLength);\n        outputVarianceGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputVarianceGm), bsLength);\n        constexpr uint32_t typeSize = sizeof(dataType);\n        pipe.InitBuffer(inQueueX, 1, bshLength * typeSize);\n        pipe.InitBuffer(inQueueGx, 1, bshLength * typeSize);\n        pipe.InitBuffer(inQueueBeta, 1, hLength * typeSize);\n        pipe.InitBuffer(inQueueGamma, 1, hLength * typeSize);\n        pipe.InitBuffer(outQueue, 1, bshLength * typeSize);\n        pipe.InitBuffer(outMeanQueue, 1, bsLength * typeSize);\n        pipe.InitBuffer(outVarianceQueue, 1, bsLength * typeSize);\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> inputGxLocal = inQueueGx.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> betaLocal = inQueueBeta.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.AllocTensor<dataType>();\n        AscendC::DataCopy(inputXLocal, inputXGlobal, bshLength);\n        AscendC::DataCopy(inputGxLocal, inputGxGlobal, bshLength);\n        AscendC::DataCopy(betaLocal, betaGlobal, hLength);\n        AscendC::DataCopy(gammaLocal, gammaGlobal, hLength);\n        inQueueX.EnQue(inputXLocal);\n        inQueueGx.EnQue(inputGxLocal);\n        inQueueBeta.EnQue(betaLocal);\n        inQueueGamma.EnQue(gammaLocal);\n    }\n\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> inputGxLocal = inQueueGx.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> betaLocal = inQueueBeta.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> outputMeanLocal = outMeanQueue.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> outputVarianceLocal = outVarianceQueue.AllocTensor<dataType>();\n\n        AscendC::DeepNorm<dataType, isReuseSrc, isBasicBlock>(outputLocal,\n            outputMeanLocal,\n            outputVarianceLocal,\n            inputXLocal,\n            inputGxLocal,\n            betaLocal,\n            gammaLocal,\n            alpha,\n            epsilon,\n            tiling);\n\n        inQueueX.FreeTensor(inputXLocal);\n        inQueueGx.FreeTensor(inputGxLocal);\n        inQueueBeta.FreeTensor(betaLocal);\n        inQueueGamma.FreeTensor(gammaLocal);\n        outQueue.EnQue(outputLocal);\n        outMeanQueue.EnQue(outputMeanLocal);\n        outVarianceQueue.EnQue(outputVarianceLocal);\n    }\n\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> outputMeanLocal = outMeanQueue.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> outputVarianceLocal = outVarianceQueue.DeQue<dataType>();\n        AscendC::DataCopy(outputGlobal, outputLocal, bshLength);\n        AscendC::DataCopy(outputMeanGlobal, outputMeanLocal, bsLength);\n        AscendC::DataCopy(outputVarianceGlobal, outputVarianceLocal, bsLength);\n        outQueue.FreeTensor(outputLocal);\n        outMeanQueue.FreeTensor(outputMeanLocal);\n        outVarianceQueue.FreeTensor(outputVarianceLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<dataType> inputXGlobal;\n    AscendC::GlobalTensor<dataType> inputGxGlobal;\n    AscendC::GlobalTensor<dataType> betaGlobal;\n    AscendC::GlobalTensor<dataType> gammaGlobal;\n    AscendC::GlobalTensor<dataType> outputGlobal;\n    AscendC::GlobalTensor<dataType> outputMeanGlobal;\n    AscendC::GlobalTensor<dataType> outputVarianceGlobal;\n\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueGx;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueBeta;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueGamma;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outMeanQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outVarianceQueue;\n\n    DeepNormTiling tiling;\n    uint32_t bshLength;\n    uint32_t bsLength;\n    uint32_t hLength;\n    dataType alpha;\n    dataType epsilon;\n};\n\ntemplate <typename dataType, bool isReuseSrc = false, bool isBasicBlock = false>\n__aicore__ inline void kernel_deepnorm_operator(GM_ADDR inputGm, GM_ADDR inputGxGm, GM_ADDR betaGm, GM_ADDR gammaGm,\n    GM_ADDR outputGm, GM_ADDR outputMeanGm, GM_ADDR outputVarianceGm, GM_ADDR customTiling)\n{\n    GET_TILING_DATA(tilingData, customTiling)\n    KernelDeepNorm<dataType, isReuseSrc, isBasicBlock> op;\n    op.Init(inputGm, inputGxGm, betaGm, gammaGm, outputGm, outputMeanGm, outputVarianceGm, tilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "GroupNorm",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0816.html",
    "功能说明": "对一个特征进行标准化的一般公式如下所示： 其中，i表示特征中的索引， 和 表示特征中每个值标准化前后的值，μ和σ表示特征的均值和标准差，计算公式如下所示： 其中，ε是一个很小的常数，S表示参与计算的数据的集合，m表示集合的大小。不同类型的特征标准化方法（BatchNorm、LayerNorm、InstanceNorm、GroupNorm等）的主要区别在于参与计算的数据集合的选取上。不同Norm类算子参与计算的数据集合的选取方式如下： 对于一个shape为[N, C, H, W]的输入，GroupNorm将每个[C, H, W]在C维度上分为groupNum组，然后对每一组进行标准化。最后对标准化后的特征进行缩放和平移。其中缩放参数γ和平移参数β是可训练的。",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void GroupNorm(const LocalTensor<T>& output, const LocalTensor<T>& outputMean, const LocalTensor<T>& outputVariance, const LocalTensor<T>& inputX, const LocalTensor<T>& gamma, const LocalTensor<T>& beta, const T epsilon, GroupNormTiling& tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 inputX的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 inputX的内存空间。 对于float数据类型的输入支持开启该参数，half数据类型的输入不支持开启该参数。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "template <typename dataType, bool isReuseSource = false>\n__aicore__ inline void MainGroupnormTest(GM_ADDR inputXGm, GM_ADDR gammGm, GM_ADDR betaGm, GM_ADDR outputGm,\n    uint32_t n, uint32_t c, uint32_t h, uint32_t w, uint32_t g)\n{\n    dataType epsilon = 0.001;\n    DataFormat dataFormat = DataFormat::ND;\n\n    GlobalTensor<dataType> inputXGlobal;\n    GlobalTensor<dataType> gammGlobal;\n    GlobalTensor<dataType> betaGlobal;\n    GlobalTensor<dataType> outputGlobal;\n    uint32_t bshLength = n*c*h*w;\n    uint32_t bsLength = g*n;\n\n    inputXGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType*>(inputXGm), bshLength);\n    gammGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType*>(gammGm), c);\n    betaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType*>(betaGm), c);\n    outputGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType*>(outputGm), bshLength);\n\n    TPipe pipe;\n    TQue<TPosition::VECIN, 1>  inQueueX;\n    TQue<TPosition::VECIN, 1>  inQueueGamma;\n    TQue<TPosition::VECIN, 1>  inQueueBeta;\n    TQue<TPosition::VECOUT, 1> outQueue;\n    TBuf<TPosition::VECCALC> meanBuffer, varBuffer;\n\n    uint32_t hwAlignSize = (sizeof(dataType) * h * w + ONE_BLK_SIZE - 1) / ONE_BLK_SIZE * ONE_BLK_SIZE / sizeof(dataType);\n    pipe.InitBuffer(inQueueX, 1, sizeof(dataType) * n * c * hwAlignSize);\n    pipe.InitBuffer(inQueueGamma, 1, (sizeof(dataType) * c + 31) / 32 * 32);\n    pipe.InitBuffer(inQueueBeta, 1, (sizeof(dataType) * c + 31) / 32 * 32);\n    pipe.InitBuffer(outQueue, 1, sizeof(dataType) * n * c * hwAlignSize);\n    pipe.InitBuffer(meanBuffer, (sizeof(dataType) * g * n + 31) / 32 * 32);\n    pipe.InitBuffer(varBuffer, (sizeof(dataType) * g * n + 31) / 32 * 32);\n\n    LocalTensor<dataType> inputXLocal = inQueueX.AllocTensor<dataType>();\n    LocalTensor<dataType> gammaLocal = inQueueGamma.AllocTensor<dataType>();\n    LocalTensor<dataType> betaLocal = inQueueBeta.AllocTensor<dataType>();\n    LocalTensor<dataType> outputLocal = outQueue.AllocTensor<dataType>();\n    LocalTensor<dataType> meanLocal = meanBuffer.Get<dataType>();\n    LocalTensor<dataType> varianceLocal = varBuffer.Get<dataType>();\n\n    DataCopyParams copyParams{static_cast<uint16_t>(n*c), static_cast<uint16_t>(h*w*sizeof(dataType)), 0, 0};\n    DataCopyPadParams padParams{true, 0, static_cast<uint8_t>(hwAlignSize - h * w), 0};\n    DataCopyPad(inputXLocal, inputXGlobal, copyParams, padParams);\n    DataCopyParams copyParamsGamma{1, static_cast<uint16_t>(c*sizeof(dataType)), 0, 0};\n    DataCopyPadParams padParamsGamma{false, 0, 0, 0};\n    DataCopyPad(gammaLocal, gammGlobal, copyParamsGamma, padParamsGamma);\n    DataCopyPad(betaLocal, betaGlobal, copyParamsGamma, padParamsGamma);\n\n    PipeBarrier<PIPE_ALL>();\n\n    uint32_t stackBufferSize = 0;\n    {\n        LocalTensor<float> stackBuffer;\n        bool ans = PopStackBuffer<float, TPosition::LCM>(stackBuffer);\n        stackBufferSize = stackBuffer.GetSize();\n    }\n\n    GroupNormTiling groupNormTiling;\n    uint32_t inputShape[4] = {n, c, h, w};\n    ShapeInfo shapeInfo{ (uint8_t)4, inputShape, (uint8_t)4, inputShape, dataFormat };\n\n    GetGroupNormNDTillingInfo(shapeInfo, stackBufferSize, sizeof(dataType), isReuseSource, g, groupNormTiling);\n\n    GroupNorm<dataType, isReuseSource>(outputLocal, meanLocal, varianceLocal, inputXLocal, gammaLocal, betaLocal, (dataType)epsilon, groupNormTiling);\n    PipeBarrier<PIPE_ALL>();\n\n    DataCopyPad(outputGlobal, outputLocal, copyParams);\n    inQueueX.FreeTensor(inputXLocal);\n    inQueueGamma.FreeTensor(gammaLocal);\n    inQueueBeta.FreeTensor(betaLocal);\n    outQueue.FreeTensor(outputLocal);\n    PipeBarrier<PIPE_ALL>();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "LayerNorm",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0796.html",
    "功能说明": "根据接口输出的不同，本节介绍如下两种LayerNorm接口。 输出归一化结果、均值和方差 在深层神经网络训练过程中，前面层训练参数的更新，会引起后面层输入数据分布的变化，导致权重更新不均衡及学习效率变慢。通过采用归一化策略，将网络层输入数据收敛到[0, 1]之间，可以规范网络层输入输出数据分布，加速训练参数收敛过程，使学习效率提升更加稳定。 LayerNorm是许多归一化方法中的一种。 本接口实现了对shape大小为[B，S，H]输入数据的LayerNorm归一化，其计算公式如下，其中γ为缩放系数，β为平移系数，ε为防除零的权重系数： 其中，如下两个参数分别代表输入在H轴的均值和方差。 输出归一化结果、均值和标准差的倒数 本接口实现了对shape为[A，R]输入数据的LayerNorm归一化，其计算公式如下，其中γ为缩放系数，β为平移系数，ε为防除零的权重系数： 其中，如下三个参数分别代表输入在R轴的均值，方差和标准差的倒数。",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void LayerNorm(const LocalTensor<T>& output, const LocalTensor<T>& outputMean, const LocalTensor<T>& outputVariance, const LocalTensor<T>& inputX, const LocalTensor<T>& gamma, const LocalTensor<T>& beta, const LocalTensor<uint8_t>& sharedTmpBuffer, const T epsilon, LayerNormTiling& tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 inputX的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 inputX的内存空间。 对于float数据类型输入支持开启该参数，half数据类型输入不支持开启该参数。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename dataType, bool isReuseSource = false>\nclass KernelLayernorm {\npublic:\n    __aicore__ inline KernelLayernorm()\n    {}\n    __aicore__ inline void Init(GM_ADDR inputXGm, GM_ADDR gammGm, GM_ADDR betaGm, GM_ADDR outputGm,\n        GM_ADDR outputMeanGm, GM_ADDR outputVarianceGm, const LayerNormTiling &tiling)\n    {\n        this->bLength = tiling.bLength;\n        this->sLength = tiling.sLength;\n        this->hLength = tiling.hLength;\n        this->tiling = tiling;\n\n        bshLength = bLength * sLength * hLength;\n        bsLength = bLength * sLength;\n\n        inputXGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(inputXGm), bshLength);\n        gammGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(gammGm), hLength);\n        betaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(betaGm), hLength);\n\n        outputGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputGm), bshLength);\n        outputMeanGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputMeanGm), bsLength);\n        outputVarianceGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputVarianceGm), bsLength);\n\n        pipe.InitBuffer(inQueueX, 1, sizeof(dataType) * bshLength);\n        pipe.InitBuffer(inQueueGamma, 1, sizeof(dataType) * hLength);\n        pipe.InitBuffer(inQueueBeta, 1, sizeof(dataType) * hLength);\n        pipe.InitBuffer(outQueue, 1, sizeof(dataType) * bshLength);\n        pipe.InitBuffer(outQueueMean, 1, sizeof(dataType) * bsLength);\n        pipe.InitBuffer(outQueueVariance, 1, sizeof(dataType) * bsLength);\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> betaLocal = inQueueBeta.AllocTensor<dataType>();\n\n        AscendC::DataCopy(inputXLocal, inputXGlobal, bshLength);\n        AscendC::DataCopy(gammaLocal, gammGlobal, hLength);\n        AscendC::DataCopy(betaLocal, betaGlobal, hLength);\n\n        inQueueX.EnQue(inputXLocal);\n        inQueueGamma.EnQue(gammaLocal);\n        inQueueBeta.EnQue(betaLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> betaLocal = inQueueBeta.DeQue<dataType>();\n\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> meanLocal = outQueueMean.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> varianceLocal = outQueueVariance.AllocTensor<dataType>();\n\n        AscendC::LayerNorm<dataType, isReuseSource>(\n            outputLocal, meanLocal, varianceLocal, inputXLocal, gammaLocal, betaLocal, (dataType)epsilon, tiling);\n\n        outQueue.EnQue<dataType>(outputLocal);\n        outQueueMean.EnQue<dataType>(meanLocal);\n        outQueueVariance.EnQue<dataType>(varianceLocal);\n\n        inQueueX.FreeTensor(inputXLocal);\n        inQueueGamma.FreeTensor(gammaLocal);\n        inQueueBeta.FreeTensor(betaLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> meanLocal = outQueueMean.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> varianceLocal = outQueueVariance.DeQue<dataType>();\n\n        AscendC::DataCopy(outputGlobal, outputLocal, bshLength);\n        AscendC::DataCopy(outputMeanGlobal, meanLocal, bsLength);\n        AscendC::DataCopy(outputVarianceGlobal, varianceLocal, bsLength);\n\n        outQueue.FreeTensor(outputLocal);\n        outQueueMean.FreeTensor(meanLocal);\n        outQueueVariance.FreeTensor(varianceLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<dataType> inputXGlobal;\n    AscendC::GlobalTensor<dataType> gammGlobal;\n    AscendC::GlobalTensor<dataType> betaGlobal;\n    AscendC::GlobalTensor<dataType> outputGlobal;\n    AscendC::GlobalTensor<dataType> outputMeanGlobal;\n    AscendC::GlobalTensor<dataType> outputVarianceGlobal;\n\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueGamma;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueBeta;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueMean;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueVariance;\n\n    uint32_t bLength;\n    uint32_t sLength;\n    uint32_t hLength;\n    dataType epsilon = 0.001;\n\n    uint32_t bshLength;\n    uint32_t bsLength;\n\n    LayerNormTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void kernel_layernorm_operator(GM_ADDR inputXGm, GM_ADDR gammGm, GM_ADDR betaGm,\n    GM_ADDR outputGm, GM_ADDR outputMeanGm, GM_ADDR outputVarianceGm, GM_ADDR tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelLayernorm<half, false> op;\n    op.Init(inputXGm, gammGm, betaGm, outputGm, outputMeanGm, outputVarianceGm, tilingData.layernormTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "LayerNorm",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0797.html",
    "功能说明": "根据接口输出的不同，本节介绍如下两种LayerNorm接口。 输出归一化结果、均值和方差 在深层神经网络训练过程中，前面层训练参数的更新，会引起后面层输入数据分布的变化，导致权重更新不均衡及学习效率变慢。通过采用归一化策略，将网络层输入数据收敛到[0, 1]之间，可以规范网络层输入输出数据分布，加速训练参数收敛过程，使学习效率提升更加稳定。 LayerNorm是许多归一化方法中的一种。 本接口实现了对shape大小为[B，S，H]输入数据的LayerNorm归一化，其计算公式如下，其中γ为缩放系数，β为平移系数，ε为防除零的权重系数： 其中，如下两个参数分别代表输入在H轴的均值和方差。 输出归一化结果、均值和标准差的倒数 本接口实现了对shape为[A，R]输入数据的LayerNorm归一化，其计算公式如下，其中γ为缩放系数，β为平移系数，ε为防除零的权重系数： 其中，如下三个参数分别代表输入在R轴的均值，方差和标准差的倒数。",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void LayerNorm(const LocalTensor<T>& output, const LocalTensor<T>& outputMean, const LocalTensor<T>& outputVariance, const LocalTensor<T>& inputX, const LocalTensor<T>& gamma, const LocalTensor<T>& beta, const LocalTensor<uint8_t>& sharedTmpBuffer, const T epsilon, LayerNormTiling& tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 inputX的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 inputX的内存空间。 对于float数据类型输入支持开启该参数，half数据类型输入不支持开启该参数。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename dataType, bool isReuseSource = false>\nclass KernelLayernorm {\npublic:\n    __aicore__ inline KernelLayernorm()\n    {}\n    __aicore__ inline void Init(GM_ADDR inputXGm, GM_ADDR gammGm, GM_ADDR betaGm, GM_ADDR outputGm,\n        GM_ADDR outputMeanGm, GM_ADDR outputVarianceGm, const LayerNormTiling &tiling)\n    {\n        this->bLength = tiling.bLength;\n        this->sLength = tiling.sLength;\n        this->hLength = tiling.hLength;\n        this->tiling = tiling;\n\n        bshLength = bLength * sLength * hLength;\n        bsLength = bLength * sLength;\n\n        inputXGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(inputXGm), bshLength);\n        gammGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(gammGm), hLength);\n        betaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(betaGm), hLength);\n\n        outputGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputGm), bshLength);\n        outputMeanGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputMeanGm), bsLength);\n        outputVarianceGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputVarianceGm), bsLength);\n\n        pipe.InitBuffer(inQueueX, 1, sizeof(dataType) * bshLength);\n        pipe.InitBuffer(inQueueGamma, 1, sizeof(dataType) * hLength);\n        pipe.InitBuffer(inQueueBeta, 1, sizeof(dataType) * hLength);\n        pipe.InitBuffer(outQueue, 1, sizeof(dataType) * bshLength);\n        pipe.InitBuffer(outQueueMean, 1, sizeof(dataType) * bsLength);\n        pipe.InitBuffer(outQueueVariance, 1, sizeof(dataType) * bsLength);\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> betaLocal = inQueueBeta.AllocTensor<dataType>();\n\n        AscendC::DataCopy(inputXLocal, inputXGlobal, bshLength);\n        AscendC::DataCopy(gammaLocal, gammGlobal, hLength);\n        AscendC::DataCopy(betaLocal, betaGlobal, hLength);\n\n        inQueueX.EnQue(inputXLocal);\n        inQueueGamma.EnQue(gammaLocal);\n        inQueueBeta.EnQue(betaLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> betaLocal = inQueueBeta.DeQue<dataType>();\n\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> meanLocal = outQueueMean.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataType> varianceLocal = outQueueVariance.AllocTensor<dataType>();\n\n        AscendC::LayerNorm<dataType, isReuseSource>(\n            outputLocal, meanLocal, varianceLocal, inputXLocal, gammaLocal, betaLocal, (dataType)epsilon, tiling);\n\n        outQueue.EnQue<dataType>(outputLocal);\n        outQueueMean.EnQue<dataType>(meanLocal);\n        outQueueVariance.EnQue<dataType>(varianceLocal);\n\n        inQueueX.FreeTensor(inputXLocal);\n        inQueueGamma.FreeTensor(gammaLocal);\n        inQueueBeta.FreeTensor(betaLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> meanLocal = outQueueMean.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> varianceLocal = outQueueVariance.DeQue<dataType>();\n\n        AscendC::DataCopy(outputGlobal, outputLocal, bshLength);\n        AscendC::DataCopy(outputMeanGlobal, meanLocal, bsLength);\n        AscendC::DataCopy(outputVarianceGlobal, varianceLocal, bsLength);\n\n        outQueue.FreeTensor(outputLocal);\n        outQueueMean.FreeTensor(meanLocal);\n        outQueueVariance.FreeTensor(varianceLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<dataType> inputXGlobal;\n    AscendC::GlobalTensor<dataType> gammGlobal;\n    AscendC::GlobalTensor<dataType> betaGlobal;\n    AscendC::GlobalTensor<dataType> outputGlobal;\n    AscendC::GlobalTensor<dataType> outputMeanGlobal;\n    AscendC::GlobalTensor<dataType> outputVarianceGlobal;\n\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueGamma;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueBeta;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueMean;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueVariance;\n\n    uint32_t bLength;\n    uint32_t sLength;\n    uint32_t hLength;\n    dataType epsilon = 0.001;\n\n    uint32_t bshLength;\n    uint32_t bsLength;\n\n    LayerNormTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void kernel_layernorm_operator(GM_ADDR inputXGm, GM_ADDR gammGm, GM_ADDR betaGm,\n    GM_ADDR outputGm, GM_ADDR outputMeanGm, GM_ADDR outputVarianceGm, GM_ADDR tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelLayernorm<half, false> op;\n    op.Init(inputXGm, gammGm, betaGm, outputGm, outputMeanGm, outputVarianceGm, tilingData.layernormTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "LayerNormGradBeta",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0799.html",
    "功能说明": "LayerNormGradBeta接口用于获取反向beta/gamma的数值，和LayerNormGrad共同输出pdx, gamma和beta： 算法公式为:",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void LayerNormGradBeta(const LocalTensor<T> &outputPdGamma, const LocalTensor<T> &outputPdBeta, const LocalTensor<T> &resForGamma, const LocalTensor<T> &inputDy, const LocalTensor<uint8_t> &sharedTmpBuffer, const LayerNormGradBetaTiling &tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 inputDy的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 inputDy的内存空间。 对于float数据类型输入支持开启该参数，half数据类型输入不支持开启该参数。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T, bool isReuseSource = false>\nclass KernelLayernormGradBeta {\npublic:\n    __aicore__ inline KernelLayernormGradBeta()\n    {}\n    __aicore__ inline void Init(__gm__ uint8_t *resForGammaGm, __gm__ uint8_t *inputDyGm,\n        __gm__ uint8_t *outputPdGammaGm, __gm__ uint8_t *outputPdBetaGm, const LayerNormGradBetaTiling &tiling)\n    {\n        this->bLength = tiling.bLength;\n        this->sLength = tiling.sLength;\n        this->hLength = tiling.hLength;\n        this->tiling = tiling;\n        bshLength = bLength * sLength * hLength;\n        bsLength = bLength * sLength;\n        resForGammaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ T *>(resForGammaGm), bshLength);\n        inputDyGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ T *>(inputDyGm), bshLength);\n        outputPdGammaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ T *>(outputPdGammaGm), hLength);\n        outputPdBetaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ T *>(outputPdBetaGm), hLength);\n        pipe.InitBuffer(inQueueResForGamma, 1, sizeof(T) * bshLength);\n        pipe.InitBuffer(inQueueDy, 1, sizeof(T) * bshLength);\n        pipe.InitBuffer(outQueuePdGamma, 1, sizeof(T) * hLength);\n        pipe.InitBuffer(outQueuePdBeta, 1, sizeof(T) * hLength);\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> resForGammaLocal = inQueueResForGamma.AllocTensor<T>();\n        AscendC::LocalTensor<T> inputDyLocal = inQueueDy.AllocTensor<T>();\n        AscendC::DataCopy(resForGammaLocal, resForGammaGlobal, bshLength);\n        AscendC::DataCopy(inputDyLocal, inputDyGlobal, bshLength);\n        inQueueResForGamma.EnQue(resForGammaLocal);\n        inQueueDy.EnQue(inputDyLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> resForGammaLocal = inQueueResForGamma.DeQue<T>();\n        AscendC::LocalTensor<T> inputDyLocal = inQueueDy.DeQue<T>();\n        AscendC::LocalTensor<T> outputPdGammaLocal = outQueuePdGamma.AllocTensor<T>();\n        AscendC::LocalTensor<T> outputPdBetaLocal = outQueuePdBeta.AllocTensor<T>();\n\n        AscendC::LayerNormGradBeta<T, isReuseSource>(\n            outputPdGammaLocal, outputPdBetaLocal, resForGammaLocal, inputDyLocal, tiling);\n\n        outQueuePdGamma.EnQue<T>(outputPdGammaLocal);\n        outQueuePdBeta.EnQue<T>(outputPdBetaLocal);\n        inQueueResForGamma.FreeTensor(resForGammaLocal);\n        inQueueDy.FreeTensor(inputDyLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> outputPdGammaLocal = outQueuePdGamma.DeQue<T>();\n        AscendC::LocalTensor<T> outputPdBetaLocal = outQueuePdBeta.DeQue<T>();\n        AscendC::DataCopy(outputPdGammaGlobal, outputPdGammaLocal, hLength);\n        AscendC::DataCopy(outputPdBetaGlobal, outputPdBetaLocal, hLength);\n        outQueuePdGamma.FreeTensor(outputPdGammaLocal);\n        outQueuePdBeta.FreeTensor(outputPdBetaLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueResForGamma, inQueueDy;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueuePdGamma, outQueuePdBeta;\n    AscendC::GlobalTensor<T> resForGammaGlobal;\n    AscendC::GlobalTensor<T> inputDyGlobal;\n    AscendC::GlobalTensor<T> outputPdGammaGlobal;\n    AscendC::GlobalTensor<T> outputPdBetaGlobal;\n    uint32_t bLength;\n    uint32_t sLength;\n    uint32_t hLength;\n    uint32_t bshLength;\n    uint32_t bsLength;\n    LayerNormGradBetaTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void kernel_layernorm_grad_beta_operator(\n    GM_ADDR outputPdGammaGm, GM_ADDR outputPdBetaGm, GM_ADDR resForGammaGm, GM_ADDR inputDyGm, GM_ADDR tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelLayernormGradBeta<half, false> op;\n    op.Init(resForGammaGm, inputDyGm, outputPdGammaGm, outputPdBetaGm, tilingData.layerNormGradBetaTiling);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Normalize",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0810.html",
    "功能说明": "LayerNorm 中，已知均值和方差，计算shape为[A，R]的输入数据的标准差的倒数rstd和y，其计算公式如下： 其中，E和Var分别代表输入在R轴的均值，方差，γ为缩放系数，β为平移系数，ε为防除零的权重系数。",
    "函数原型": "template < typename U, typename T, bool isReuseSource = false, const NormalizeConfig& config = NLCFG_NORM>\n__aicore__ inline void Normalize(const LocalTensor<T>& output, const LocalTensor<float>& outputRstd, const LocalTensor<float>& inputMean, const LocalTensor<float>& inputVariance, const LocalTensor<T>& inputX, const LocalTensor<U>& gamma, const LocalTensor<U>& beta, const LocalTensor<uint8_t>& sharedTmpBuffer, const float epsilon, const NormalizePara& para)",
    "参数说明": "表1 模板参数说明 参数名 描述 U beta，gamma操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为: half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为: half/float Atlas 推理系列产品 AI Core ，支持的数据类型为: half/float T output，inputX操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为: half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为: half/float Atlas 推理系列产品 AI Core ，支持的数据类型为: half/float isReuseSource 该参数预留，传入默认值false即可。 config 配置Normalize接口中输入输出相关信息。NormalizeConfig类型，定义如下。 struct NormalizeConfig { ReducePattern reducePattern = ReducePattern :: AR ; int32_t aLength = -1 ; bool isNoBeta = false ; bool isNoGamma = false ; bool isOnlyOutput = false ; };",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\nconstexpr int32_t BUFFER_NUM = 1;  // tensor num for each queue\n\ntemplate <const AscendC::NormalizeConfig& CONFIG>\nclass KernelNormalize {\n public:\n  __aicore__ inline KernelNormalize() {}\n\n  __aicore__ inline void Init(GM_ADDR x, GM_ADDR mean, GM_ADDR variance, GM_ADDR gamma, GM_ADDR beta, GM_ADDR rstd, GM_ADDR y, const float epsilon, const AscendC::NormalizePara& para) {\n    this->meanRstdSize = (para.aLength + 7) / 8 * 8;  // 此时进行32B对齐处理\n    // get start index for current core, core parallel\n    xGm.SetGlobalBuffer((__gm__ DTYPE_X*)x, para.aLength * para.rLengthWithPadding);\n    meanGm.SetGlobalBuffer((__gm__ float*)mean, this->meanRstdSize);\n    varianceGm.SetGlobalBuffer((__gm__ float*)variance, this->meanRstdSize);\n    gammaGm.SetGlobalBuffer((__gm__ DTYPE_GAMMA*)gamma, para.rLengthWithPadding);\n    betaGm.SetGlobalBuffer((__gm__ DTYPE_BETA*)beta, para.rLengthWithPadding);\n\n    rstdGm.SetGlobalBuffer((__gm__ float*)rstd, this->meanRstdSize);\n    yGm.SetGlobalBuffer((__gm__ DTYPE_Y*)y, para.aLength * para.rLengthWithPadding);\n\n    // pipe alloc memory to queue, the unit is Bytes\n    pipe.InitBuffer(inQueueX, BUFFER_NUM, para.aLength * para.rLengthWithPadding * sizeof(DTYPE_X));\n    pipe.InitBuffer(inQueueMean, BUFFER_NUM, this->meanRstdSize * sizeof(float));\n    pipe.InitBuffer(inQueueVariance, BUFFER_NUM, this->meanRstdSize * sizeof(float));\n    pipe.InitBuffer(inQueueGamma, BUFFER_NUM, para.rLengthWithPadding * sizeof(DTYPE_GAMMA));\n    pipe.InitBuffer(inQueueBeta, BUFFER_NUM, para.rLengthWithPadding * sizeof(DTYPE_BETA));\n\n    pipe.InitBuffer(outQueueRstd, BUFFER_NUM, this->meanRstdSize * sizeof(float));\n    pipe.InitBuffer(outQueueY, BUFFER_NUM, para.aLength * para.rLengthWithPadding * sizeof(DTYPE_Y));\n\n    this->epsilon = epsilon;\n    this->para = para;\n  }\n\n  __aicore__ inline void Compute() {\n    AscendC::LocalTensor<DTYPE_X> xLocal = inQueueX.DeQue<DTYPE_X>();\n    AscendC::LocalTensor<float> meanLocal = inQueueMean.DeQue<float>();\n    AscendC::LocalTensor<float> varianceLocal = inQueueVariance.DeQue<float>();\n    AscendC::LocalTensor<DTYPE_GAMMA> gammaLocal = inQueueGamma.DeQue<DTYPE_GAMMA>();\n    AscendC::LocalTensor<DTYPE_BETA> betaLocal = inQueueBeta.DeQue<DTYPE_BETA>();\n\n    AscendC::LocalTensor<float> rstdLocal = outQueueRstd.AllocTensor<float>();\n    AscendC::LocalTensor<DTYPE_Y> yLocal = outQueueY.AllocTensor<DTYPE_Y>();\n\n    AscendC::Duplicate(rstdLocal, (float)0, this->meanRstdSize);\n    AscendC::Duplicate(yLocal, (DTYPE_Y)0, para.aLength * para.rLengthWithPadding);\n\n    AscendC::Normalize<DTYPE_Y, DTYPE_X, false, CONFIG>(yLocal, rstdLocal, meanLocal, varianceLocal, xLocal, gammaLocal, betaLocal, epsilon, para);\n\n    outQueueRstd.EnQue<float>(rstdLocal);\n    outQueueY.EnQue<DTYPE_Y>(yLocal);\n    inQueueX.FreeTensor(xLocal);\n    inQueueMean.FreeTensor(meanLocal);\n    inQueueVariance.FreeTensor(varianceLocal);\n    inQueueGamma.FreeTensor(gammaLocal);\n    inQueueBeta.FreeTensor(betaLocal);\n\n  }\n  __aicore__ inline void Process() {\n    CopyIn();\n    Compute();\n    CopyOut();\n  }\n\n private:\n  __aicore__ inline void CopyIn() {\n    // alloc tensor from queue memory\n    AscendC::LocalTensor<DTYPE_X> xLocal = inQueueX.AllocTensor<DTYPE_X>();\n    AscendC::LocalTensor<float> meanLocal = inQueueMean.AllocTensor<float>();\n    AscendC::LocalTensor<float> varianceLocal = inQueueVariance.AllocTensor<float>();\n    AscendC::LocalTensor<DTYPE_GAMMA> gammaLocal = inQueueGamma.AllocTensor<DTYPE_GAMMA>();\n    AscendC::LocalTensor<DTYPE_BETA> betaLocal = inQueueBeta.AllocTensor<DTYPE_BETA>();\n    // copy progress_th tile from global tensor to local tensor\n    AscendC::DataCopy(xLocal, xGm, para.aLength * para.rLengthWithPadding);\n    AscendC::DataCopy(meanLocal, meanGm, this->meanRstdSize);\n    AscendC::DataCopy(varianceLocal, varianceGm, this->meanRstdSize);\n    AscendC::DataCopy(gammaLocal, gammaGm, para.rLengthWithPadding);\n    AscendC::DataCopy(betaLocal, betaGm, para.rLengthWithPadding);\n\n    // enque input tensors to VECIN queue\n    inQueueX.EnQue(xLocal);\n    inQueueMean.EnQue(meanLocal);\n    inQueueVariance.EnQue(varianceLocal);\n    inQueueGamma.EnQue(gammaLocal);\n    inQueueBeta.EnQue(betaLocal);\n  }\n\n  __aicore__ inline void CopyOut() {\n    // deque output tensor from VECOUT queue\n    AscendC::LocalTensor<float> rstdLocal = outQueueRstd.DeQue<float>();\n    AscendC::LocalTensor<DTYPE_Y> yLocal = outQueueY.DeQue<DTYPE_Y>();\n    // copy progress_th tile from local tensor to global tensor\n    AscendC::DataCopy(rstdGm, rstdLocal, this->meanRstdSize);\n    AscendC::DataCopy(yGm, yLocal, para.aLength * para.rLengthWithPadding);\n    // free output tensor for reuse\n    outQueueRstd.FreeTensor(rstdLocal);\n    outQueueY.FreeTensor(yLocal);\n  }\n\n private:\n  AscendC::TPipe pipe;\n  // create queues for input, in this case depth is equal to buffer num\n  AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueX;\n  AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueMean;\n  AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueVariance;\n  AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueGamma;\n  AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueBeta;\n  // create queue for output, in this case depth is equal to buffer num\n  AscendC::TQue<AscendC::TPosition::VECOUT, BUFFER_NUM> outQueueRstd;\n  AscendC::TQue<AscendC::TPosition::VECOUT, BUFFER_NUM> outQueueY;\n\n  AscendC::GlobalTensor<float> meanGm;\n  AscendC::GlobalTensor<float> varianceGm;\n  AscendC::GlobalTensor<DTYPE_X> xGm;\n  AscendC::GlobalTensor<DTYPE_GAMMA> gammaGm;\n  AscendC::GlobalTensor<DTYPE_BETA> betaGm;\n\n  AscendC::GlobalTensor<float> rstdGm;\n  AscendC::GlobalTensor<DTYPE_Y> yGm;\n\n  float epsilon;\n  uint32_t meanRstdSize;\n  AscendC::NormalizePara para;\n};\n__aicore__ constexpr AscendC::NormalizeConfig GenConfig(bool isNoBeta, bool isNoGamma)\n{\n    return {.reducePattern = AscendC::ReducePattern::AR,\n        .aLength = -1,\n        .isNoBeta = isNoBeta,\n        .isNoGamma = isNoGamma,\n        .isOnlyOutput = false};\n}\n// with beta and gamma\nconstexpr AscendC::NormalizeConfig CONFIG1 = GenConfig(false, false);\nconstexpr AscendC::NormalizeConfig CONFIG2 = GenConfig(false, true);\nconstexpr AscendC::NormalizeConfig CONFIG3 = GenConfig(true, false);\nconstexpr AscendC::NormalizeConfig CONFIG4 = GenConfig(true, true);\n\nextern \"C\" __global__ __aicore__ void normalize_custom(GM_ADDR x, GM_ADDR mean, GM_ADDR variance, GM_ADDR gamma, GM_ADDR beta, GM_ADDR rstd, GM_ADDR y, GM_ADDR workspace, GM_ADDR tiling) {\n    GET_TILING_DATA(tilingData, tiling);\n    float epsilon = tilingData.epsilon;\n    AscendC::NormalizePara para(tilingData.aLength, tilingData.rLength, tilingData.rLengthWithPadding);\n    if (TILING_KEY_IS(1)) {\n      if (!tilingData.isNoBeta && !tilingData.isNoGamma) {\n          KernelNormalize<CONFIG1> op;\n          op.Init(x, mean, variance, gamma, beta, rstd, y, epsilon, para);\n          op.Process();\n      } else if (!tilingData.isNoBeta && tilingData.isNoGamma) {\n          KernelNormalize<CONFIG2> op;\n          op.Init(x, mean, variance, gamma, beta, rstd, y, epsilon, para);\n          op.Process();\n      } else if (tilingData.isNoBeta && !tilingData.isNoGamma) {\n          KernelNormalize<CONFIG3> op;\n          op.Init(x, mean, variance, gamma, beta, rstd, y, epsilon, para);\n          op.Process();\n      } else if (tilingData.isNoBeta && tilingData.isNoGamma) {\n          KernelNormalize<CONFIG4> op;\n          op.Init(x, mean, variance, gamma, beta, rstd, y, epsilon, para);\n          op.Process();\n      }\n    }\n  }",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "RmsNorm",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0804.html",
    "功能说明": "实现对shape大小为[B，S，H]的输入数据的RmsNorm归一化，其计算公式如下： 其中，γ为缩放系数，ε为防除零的权重系数。",
    "函数原型": "template <typename T, bool isBasicBlock = false>\n__aicore__ inline void RmsNorm(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<T>& gammaLocal, const LocalTensor<uint8_t>& sharedTmpBuffer, const T epsilon, const RmsNormTiling& tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isBasicBlock srcTensor和dstTensor的shape信息和Tiling切分策略满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。基本块要求srcTensor和dstTensor的shape需要满足如下条件： last轴即H的长度为64的倍数，但小于2048； 非last轴长度（B*S）为8的倍数。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ninline __aicore__ uint32_t AlignToBlock(const uint32_t inputValue, const uint32_t typeSize)\n{\n    constexpr uint32_t ONE_BLK_SIZE = 32;\n    uint32_t alignUnit = ONE_BLK_SIZE / typeSize;\n    return (inputValue + alignUnit - 1) / alignUnit * alignUnit;\n}\n\ntemplate <typename dataType, bool isBasicBlock = false>\nclass KernelRmsNorm {\npublic:\n    __aicore__ inline KernelRmsNorm()\n    {}\n    __aicore__ inline void Init(\n        GM_ADDR inputGm, GM_ADDR gammaGm, GM_ADDR outputGm, const RmsNormCustomTiling &customTiling)\n    {\n        tiling = customTiling.tiling;\n        const uint32_t bLength = tiling.bLength;\n        const uint32_t sLength = tiling.sLength;\n        hLength = tiling.hLength;\n        bshLength = bLength * sLength * hLength;\n        constexpr uint32_t typeSize = sizeof(dataType);\n        const uint32_t bsLength = AlignToBlock(bLength * sLength, typeSize);\n        const uint32_t tmpBufferSize = bshLength * 2 + bsLength;\n        epsilon = customTiling.epsilon;\n        inputGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(inputGm), bshLength);\n        gammaGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(gammaGm), hLength);\n        outputGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(outputGm), bshLength);\n        pipe.InitBuffer(inQueue, 1, bshLength * typeSize);\n        pipe.InitBuffer(inQueueGamma, 1, hLength * typeSize);\n        pipe.InitBuffer(outQueue, 1, bshLength * typeSize);\n        pipe.InitBuffer(tmpQueue, 1, tmpBufferSize);\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<dataType> inputLocal = inQueue.AllocTensor<dataType>();\n        AscendC::DataCopy(inputLocal, inputGlobal, bshLength);\n        inQueue.EnQue(inputLocal);\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.AllocTensor<dataType>();\n        AscendC::DataCopy(gammaLocal, gammaGlobal, hLength);\n        inQueueGamma.EnQue(gammaLocal);\n    }\n\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<dataType> inputLocal = inQueue.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> gammaLocal = inQueueGamma.DeQue<dataType>();\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.AllocTensor<dataType>();\n        AscendC::LocalTensor<uint8_t> stackBuffer = tmpQueue.AllocTensor<uint8_t>();\n        AscendC::RmsNorm<dataType, isBasicBlock>(outputLocal, inputLocal, gammaLocal, stackBuffer, epsilon, tiling);\n        inQueue.FreeTensor(inputLocal);\n        inQueueGamma.FreeTensor(gammaLocal);\n        tmpQueue.FreeTensor(stackBuffer);\n        outQueue.EnQue(outputLocal);\n    }\n\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dataType> outputLocal = outQueue.DeQue<dataType>();\n        AscendC::DataCopy(outputGlobal, outputLocal, bshLength);\n        outQueue.FreeTensor(outputLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<dataType> inputGlobal;\n    AscendC::GlobalTensor<dataType> gammaGlobal;\n    AscendC::GlobalTensor<dataType> outputGlobal;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueGamma;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    AscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQueue;\n    RmsNormTiling tiling;\n    uint32_t hLength;\n    dataType epsilon;\n    uint32_t bshLength;\n};\n\ntemplate <typename dataType, bool isBasicBlock = false>\n__aicore__ inline void kernel_rmsnorm_operator(GM_ADDR inputGm, GM_ADDR gammaGm, GM_ADDR outputGm, GM_ADDR tiling)\n{\n    GET_TILING_DATA(customTilingData, tiling)\n    KernelRmsNorm<dataType, isBasicBlock> op;\n    op.Init(inputGm, gammaGm, outputGm, customTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "WelfordUpdate",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0812.html",
    "功能说明": "Welford是一种在线计算均值和方差的方法。一方面，它可以在不存储所有样本的情况下，逐步计算所有样本的均值和方差，更适合处理海量数据；另一方面，它只需要对数据进行一次遍历，能减少访存次数，提高计算性能。本接口为Welford算法的前处理。 LayerNorm算法中Reduce轴较大的场景，可以通过切分Reduce轴，联合使用本接口与 WelfordFinalize ，实现等效计算LayerNorm。 如下图所示，切分数据的Reduce轴，假设切分后每块数据的形状为[1, k]，每块数据标号为1，2，3，…，n。 图1 Reduce轴切分示意图 本接口的计算公式如下。进行上述的数据切分后，分n次调用本接口，切分后的每块数据均完成如下公式的计算。 上式中，x i 、Meant i 、M i 的形状均为[1, k]，x i 表示切分后的第i块数据，Meant i 表示第i次调用本接口得到的前i块数据的均值，M i 表示第i次调用本接口得到的前i块数据的方差中间结果（即为求方差而保存的中间计算结果，本节后续内容中写作方差中间结果）。其中，第一次调用本接口，即i=1时，公式中的Meant 0 和M 0 由用户定义为形状[1, k]、取值全0的数据。 Meant n 的计算过程示意如下图，调用n次本接口后，得到形状为[1, k]的Meant n 和M n ，Meant n 和M n 用于后续 WelfordFinalize 接口的计算。 图2 均值Meant n 计算过程示意图",
    "函数原型": "template <typename T, typename U,bool isReuseSource = false, const WelfordUpdateConfig& config = WFUPDATE_DEFAULT_CFG>\n__aicore__ inline void WelfordUpdate(const LocalTensor<U>& outputMean, const LocalTensor<U>& outputVariance, const LocalTensor<U>& inputMean, const LocalTensor<U>& inputVariance, const LocalTensor<T>& inputX, const LocalTensor<uint8_t>& sharedTmpBuffer, const WelfordUpdateParam& para)",
    "参数说明": "表1 模板参数说明 参数名 描述 T inputX操作数的数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float U outputMean、outputVariance、inputMean、inputVariance操作数的数据类型。 Atlas 推理系列产品 AI Core ，支持的数据类型为：float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：float Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：float isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 inputX的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 inputX的内存空间。 在 Atlas 推理系列产品 AI Core 中，该参数预留，传入默认值false即可。 isReuseSource的使用样例请参考 更多样例 。 config 配置非指定计算范围内的目的操作数与源操作数的复用关系。WelfordUpdateConfig类型，定义如下： struct WelfordUpdateConfig { bool isInplace = false ; // 目的操作数是否复用源操作数。 };",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\nconstexpr AscendC::WelfordUpdateConfig WELFORD_UPDATE_ENABLE_INPLACE_CFG = { true };\nconstexpr AscendC::WelfordUpdateConfig WELFORD_UPDATE_UNENABLE_INPLACE_CFG = { false };\n\ntemplate <typename dataType, typename dataTypeU, bool isInplace = false> class KernelWelfordUpdate {\npublic:\n    __aicore__ inline KernelWelfordUpdate() {}\n    __aicore__ inline void Init(GM_ADDR inputX_gm, GM_ADDR inputmean_gm, GM_ADDR inputvar_gm, GM_ADDR outputMean_gm,\n        GM_ADDR outputVariance_gm, uint32_t nLength, uint32_t rLength, uint32_t abComputeLength)\n    {\n        this->nLength = nLength;\n        this->rLength = rLength;\n        this->abComputeLength = abComputeLength;\n        totalLength = nLength * rLength;\n\n        inputX_global.SetGlobalBuffer(reinterpret_cast<__gm__ dataType *>(inputX_gm), totalLength);\n        inputmean_global.SetGlobalBuffer(reinterpret_cast<__gm__ dataTypeU *>(inputmean_gm), totalLength);\n        inputvar_global.SetGlobalBuffer(reinterpret_cast<__gm__ dataTypeU *>(inputvar_gm), totalLength);\n\n        outputMean_global.SetGlobalBuffer(reinterpret_cast<__gm__ dataTypeU *>(outputMean_gm), totalLength);\n        outputVariance_global.SetGlobalBuffer(reinterpret_cast<__gm__ dataTypeU *>(outputVariance_gm), totalLength);\n\n        pipe.InitBuffer(inQueueX, 1, sizeof(dataType) * totalLength);\n        pipe.InitBuffer(inQueueMean, 1, sizeof(dataTypeU) * totalLength);\n        pipe.InitBuffer(inQueueVar, 1, sizeof(dataTypeU) * totalLength);\n        pipe.InitBuffer(outQueueMean, 1, sizeof(dataTypeU) * totalLength);\n        pipe.InitBuffer(outQueueVariance, 1, sizeof(dataTypeU) * totalLength);\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.AllocTensor<dataType>();\n        AscendC::LocalTensor<dataTypeU> inmeanLocal = inQueueMean.AllocTensor<dataTypeU>();\n        AscendC::LocalTensor<dataTypeU> invarLocal = inQueueVar.AllocTensor<dataTypeU>();\n\n        AscendC::DataCopy(inputXLocal, inputX_global, totalLength);\n        AscendC::DataCopy(inmeanLocal, inputmean_global, totalLength);\n        AscendC::DataCopy(invarLocal, inputvar_global, totalLength);\n\n        inQueueX.EnQue(inputXLocal);\n        inQueueMean.EnQue(inmeanLocal);\n        inQueueVar.EnQue(invarLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<dataType> inputXLocal = inQueueX.DeQue<dataType>();\n        AscendC::LocalTensor<dataTypeU> inmeanLocal = inQueueMean.DeQue<dataTypeU>();\n        AscendC::LocalTensor<dataTypeU> invarLocal = inQueueVar.DeQue<dataTypeU>();\n\n        AscendC::LocalTensor<dataTypeU> meanLocal = outQueueMean.AllocTensor<dataTypeU>();\n        AscendC::LocalTensor<dataTypeU> varianceLocal = outQueueVariance.AllocTensor<dataTypeU>();\n\n        struct AscendC::WelfordUpdateParam para = { nLength, rLength, abComputeLength, 0.3 };\n        if constexpr (isInplace) {\n            AscendC::WelfordUpdate<dataType, dataTypeU, false, WELFORD_UPDATE_ENABLE_INPLACE_CFG>(meanLocal, varianceLocal,\n                inmeanLocal, invarLocal, inputXLocal, para);\n        } else {\n            AscendC::WelfordUpdate<dataType, dataTypeU, false, WELFORD_UPDATE_UNENABLE_INPLACE_CFG>(meanLocal, varianceLocal,\n                inmeanLocal, invarLocal, inputXLocal, para);\n        }\n\n        outQueueMean.EnQue<dataTypeU>(meanLocal);\n        outQueueVariance.EnQue<dataTypeU>(varianceLocal);\n\n        inQueueX.FreeTensor(inputXLocal);\n        inQueueMean.FreeTensor(inmeanLocal);\n        inQueueVar.FreeTensor(invarLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<dataTypeU> meanLocal = outQueueMean.DeQue<dataTypeU>();\n        AscendC::LocalTensor<dataTypeU> varianceLocal = outQueueVariance.DeQue<dataTypeU>();\n\n        AscendC::DataCopy(outputMean_global, meanLocal, totalLength);\n        AscendC::DataCopy(outputVariance_global, varianceLocal, totalLength);\n\n        outQueueMean.FreeTensor(meanLocal);\n        outQueueVariance.FreeTensor(varianceLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<dataType> inputX_global;\n    AscendC::GlobalTensor<dataTypeU> inputmean_global;\n    AscendC::GlobalTensor<dataTypeU> inputvar_global;\n    AscendC::GlobalTensor<dataTypeU> outputMean_global;\n    AscendC::GlobalTensor<dataTypeU> outputVariance_global;\n\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueMean;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueVar;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueMean;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueVariance;\n\n    uint32_t nLength;\n    uint32_t rLength;\n    uint32_t abComputeLength;\n    uint32_t totalLength;\n};",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "WelfordFinalize",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0814.html",
    "功能说明": "Welford计算是一种在线计算均值和方差的方法。一方面，它可以在不存储所有样本的情况下，逐步计算所有样本的均值和方差，更适合处理海量数据；另一方面，它只需要对数据进行一次遍历，能减少访存次数，提高计算性能。本接口为Welford算法的后处理。 LayerNorm算法中Reduce轴较大的场景，可以通过切分Reduce轴，联合使用本接口与 WelfordUpdate ，能够实现等效计算LayerNorm。根据Reduce轴切分后是否有尾块，本接口分为如下两种计算公式： 不带尾块/不带counts参数场景： 其中，Mean为均值输出，Var为方差输出。 Mean i 代表输入的第i个均值，Var i 代表输入的第i个方差。Ab代表Reduce轴切分后一次计算的大小，Rn代表Reduce轴按Ab拆分的次数， 代表方差系数rRec。 带尾块/带counts参数场景： 除上述参数含义外，counts i 代表Mean i 对应的系数，R代表未切分的原始Reduce轴长度， 代表方差系数rRec。",
    "函数原型": "template <bool isReuseSource = false>\n__aicore__ inline void WelfordFinalize(const LocalTensor<float>& outputMean, const LocalTensor<float>& outputVariance, const LocalTensor<float>& inputMean, const LocalTensor<float>& inputVariance, const LocalTensor<uint8_t>& sharedTmpBuffer, WelfordFinalizePara& para)",
    "参数说明": "表1 模板参数说明 参数名 描述 isReuseSource 该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "pipe.InitBuffer(sharedTmpBuffer, stackBufferSize);        \nAscendC::LocalTensor<uint8_t> tmpLocalTensor = sharedTmpBuffer.Get<uint8_t>();         \nstruct AscendC::WelfordFinalizePara para = {rnLength, abLength, head, headLength, tail, tailLength, abRec, rRec};\nAscendC::WelfordFinalize<false>(meanLocal, varianceLocal, inputMeanLocal, inputVarianceLocal, inputCountsLocal, tmpLocalTensor, para);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "AdjustSoftMaxRes",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0760.html",
    "功能说明": "本接口用于调整SoftMax的计算结果为指定的值。主要用于对SoftMax相关计算结果做后处理。当输入的max中存在指定的值的时候，会调整对应的softmaxres中的结果为输入的自定义的值。以上调整方式为按行进行，即当max某一行的值为某个值时，调整当前softmaxres对应一行的值都为输入的值。 为方便理解，通过Python脚本实现的方式，表达其计算公式如下，其中res是输入也是输出，max\\from\\to\\res_shape都为输入。 def adjust_softmax_res ( res , max , from , to , res_shape ): for i in res_shape [ 0 ]: if max [ i ] == from : for j in res_shape [ 1 ]: res [ i ][ j ] = to return",
    "函数原型": "template <typename T1, typename T2, bool isDataFormatNZ = false, uint8_t stepSizeMode = 0>\n__aicore__ inline bool AdjustSoftMaxRes(const LocalTensor<T1>& softMaxRes, const LocalTensor<T2>& maxTensor, const uint32_t from, const T1 to, const SoftMaxShapeInfo& softmaxShapeInfo)",
    "参数说明": "表1 模板参数说明 参数名 描述 T1 softMaxRes的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float T2 maxTensor的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isDataFormatNZ 当前输入输出的数据格式是否为NZ格式，默认数据格式为ND，即默认取值为false。 stepSizeMode maxTensor取元素的步进长度的模式。参数取值如下： 0：默认值，每个BlockSize（32字节）内，取第一个元素的数值与输入from的数值作对比。即，maxTensor的数据类型为float时，按照输入shape为(m, 8)的格式，每8个数取一个数，maxTensor的数据类型为half时，按照输入shape为(m, 16)的格式，每16个数取一个数。 非0：取maxTensor每个元素的数值与输入from的数值作对比。即，按照输入shape为(m, 1)的格式，每次取一个元素的数值与输入from的数值作对比。该参数取值非0时仅支持maxTensor为ND格式。",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<float> srcLocal = inQueueSrc.DeQue<float>();\nAscendC::LocalTensor<float> maxLocal = inQueueMax.DeQue<float>();\nAscendC::LocalTensor<float> dstLocal = outQueueDst.AllocTensor<float>();\nAscendC::LocalTensor<float> tmpTensor = calcBuf.Get<float>();\nAscendC::SoftMaxShapeInfo srcShape = {height, width, height, width};\nAscendC::AdjustSoftMaxRes<float, float>(srcLocal, maxLocal, FROM, TO, srcShape);\nAscendC::DataCopy(tmpTensor, srcLocal, height * width);\nAscendC::DataCopy(dstLocal, tmpTensor, height * width);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "FasterGelu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0772.html",
    "功能说明": "在神经网络中，GELU是一个重要的激活函数，其灵感来源于relu和dropout，在激活中引入了随机正则的思想。为了降低GELU的算力需求，业界提出了FastGelu等版本。本接口FasterGelu是针对FastGelu的化简版本，公式化简可以大幅度提升计算性能。计算公式如下: ，化简后可得",
    "函数原型": "template <typename T, bool highPrecision = false, bool highPerformance = false>\n__aicore__ inline void FasterGelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t dataSize)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float highPrecision 是否使能高精度模式，以提升运算准确度。默认值为false，表示不使能高精度模式。 注意：高精度模式只在half数据类型下使能后生效，该参数的取值不影响float数据类型下的接口精度和性能。 highPerformance 是否使能高性能模式，以提升运算效率。默认值为false，表示不使能高性能模式。 注意：开启高性能模式相比于默认不开启高精度和高性能模式会有精度下降，同时开启高精度和高性能模式相比于仅开启高性能模式可能会有性能下降。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename srcType>\nclass KernelFasterGelu\n{\npublic:\n    __aicore__ inline KernelFasterGelu() {}\n    __aicore__ inline void Init(GM_ADDR src_gm, GM_ADDR dst_gm, uint32_t inputSize)\n    {\n        dataSize = inputSize;\n        src_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src_gm), dataSize);\n        dst_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dst_gm), dataSize);\n        pipe.InitBuffer(inQueueX, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, dataSize * sizeof(srcType));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.AllocTensor<srcType>();\n        AscendC::DataCopy(srcLocal, src_global, dataSize);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.DeQue<srcType>();\n        AscendC::FasterGelu(dstLocal, srcLocal, dataSize);\n        // AscendC::FasterGelu<srcType, true, false>(dstLocal, srcLocal, dataSize);开启高精度模式\n        // AscendC::FasterGelu<srcType, false, true>(dstLocal, srcLocal, dataSize);开启高性能模式\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dst_global, dstLocal, dataSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> src_global;\n    AscendC::GlobalTensor<srcType> dst_global;\n\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n\n    uint32_t dataSize = 0;\n};\n\ntemplate <typename dataType>\n__aicore__ void kernel_FasterGelu_operator(GM_ADDR src_gm, GM_ADDR dst_gm, uint32_t dataSize)\n{\n    KernelFasterGelu<dataType> op;\n    op.Init(src_gm, dst_gm, dataSize);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "FasterGeluV2",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0773.html",
    "功能说明": "在神经网络中，GELU是一个重要的激活函数，其灵感来源于relu和dropout，在激活中引入了随机正则的思想。为了降低GELU的算力需求，业界提出了FastGeluV2版本。本接口实现了FastGeluV2，计算公式如下： 其中，",
    "函数原型": "template <typename T, bool highPrecision = false, bool highPerformance = false>\n__aicore__ inline void FasterGeluV2(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t dataSize)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float highPrecision 是否使能高精度模式，以提升运算准确度。默认值为false，表示不使能高精度模式。 注意：高精度模式只在half数据类型下使能后生效，该参数的取值不影响float数据类型下的接口精度和性能。 highPerformance 是否使能高性能模式，以提升运算效率。默认值为false，表示不使能高性能模式。 注意：开启高性能模式相比于默认不开启高精度和高性能模式会有精度下降，同时开启高精度和高性能模式相比于仅开启高性能模式可能会有性能下降。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename srcType>\nclass KernelFasterGelu\n{\npublic:\n    __aicore__ inline KernelFasterGelu() {}\n    __aicore__ inline void Init(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t inputSize)\n    {\n        dataSize = inputSize;\n        src_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(srcGm), dataSize);\n        dst_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), dataSize);\n        pipe.InitBuffer(inQueueX, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, dataSize * sizeof(srcType));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.AllocTensor<srcType>();\n        AscendC::DataCopy(srcLocal, src_global, dataSize);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.DeQue<srcType>();\n        AscendC::FasterGeluV2(dstLocal, srcLocal, dataSize);\n        // AscendC::FasterGeluV2<srcType, true, false>(dstLocal, srcLocal, dataSize);开启高精度模式\n        // AscendC::FasterGeluV2<srcType, false, true>(dstLocal, srcLocal, dataSize);开启高性能模式\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dst_global, dstLocal, dataSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> src_global;\n    AscendC::GlobalTensor<srcType> dst_global;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    uint32_t dataSize = 0;\n};\n\ntemplate <typename dataType>\n__aicore__ void kernel_FasterGelu_operator(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t dataSize)\n{\n    KernelFasterGelu<dataType> op;\n    op.Init(srcGm, dstGm, dataSize);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "GeGLU",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0786.html",
    "功能说明": "GeGLU是采用GELU作为激活函数的GLU变体。具体计算公式如下： 其中GELU激活函数的计算公式如下： 上述公式中的erf为误差函数： 误差函数没有解析表达式，按照业界普遍使用的tanh近似表达式： 将GELU近似公式带入可得GeGLU表达式为： 其中 a =-0.0713548162726, b =2.2363860002236e1，x1和x0代表srcTensor1和srcTensor0中的元素。",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void GeGLU(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor0, const LocalTensor<T> &srcTensor1, const LocalTensor<uint8_t> &sharedTmpBuffer, uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename srcType>\nclass KernelGeGLU\n{\npublic:\n    __aicore__ inline KernelGeGLU() {}\n    __aicore__ inline void Init(GM_ADDR src0Gm, GM_ADDR src1Gm, GM_ADDR dstGm, uint32_t inputSize,\n                                uint32_t tmpBufSize)\n    {\n        dataSize = inputSize;\n        uint32_t bufSize = 4 * tmpBufSize;\n        src0Global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src0Gm), dataSize);\n        src1Global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src1Gm), dataSize);\n        dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), dataSize);\n        pipe.InitBuffer(inQueue0, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(inQueue1, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, dataSize * sizeof(srcType));\n        if ((sizeof(srcType) == sizeof(half)) && (tmpBufSize > 0))\n        {\n            pipe.InitBuffer(buf, bufSize * sizeof(srcType));\n        }\n    }\n    __aicore__ inline void Process(uint32_t tmpBufSize, uint32_t calCount)\n    {\n        CopyIn();\n        Compute(tmpBufSize, calCount);\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> src0Local = inQueue0.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> src1Local = inQueue1.AllocTensor<srcType>();\n        AscendC::DataCopy(src0Local, src0Global, dataSize);\n        AscendC::DataCopy(src1Local, src1Global, dataSize);\n        inQueue0.EnQue(src0Local);\n        inQueue1.EnQue(src1Local);\n    }\n    __aicore__ inline void Compute(uint32_t tmpBufSize, uint32_t calCount)\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> src0Local = inQueue0.DeQue<srcType>();\n        AscendC::LocalTensor<srcType> src1Local = inQueue1.DeQue<srcType>();\n        AscendC::LocalTensor<uint8_t> temp;\n        if ((sizeof(srcType) == sizeof(half)) && (tmpBufSize > 0)) {\n            temp = buf.Get<uint8_t>();\n        }\n        if ((tmpBufSize > 0) && (calCount > 0)) {\n            AscendC::GeGLU<srcType, false>(dstLocal, src0Local, src1Local, temp, calCount);\n        } else if (tmpBufSize > 0) {\n            AscendC::GeGLU<srcType, false>(dstLocal, src0Local, src1Local, temp);\n        } else if (calCount > 0) {\n            AscendC::GeGLU<srcType, false>(dstLocal, src0Local, src1Local, calCount);\n        } else {\n            AscendC::GeGLU<srcType, false>(dstLocal, src0Local, src1Local);\n        }\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueue0.FreeTensor(src0Local);\n        inQueue1.FreeTensor(src1Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dstGlobal, dstLocal, dataSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> src0Global;\n    AscendC::GlobalTensor<srcType> src1Global;\n    AscendC::GlobalTensor<srcType> dstGlobal;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueue0;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueue1;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    AscendC::TBuf<AscendC::TPosition::VECCALC> buf;\n    uint32_t dataSize = 0;\n};\ntemplate <typename dataType>\n__aicore__ void kernel_geglu_operator(GM_ADDR src0Gm, GM_ADDR src1Gm, GM_ADDR dstGm, uint32_t srcSize,\n                                      uint32_t tmpBufSize, uint32_t calCount)\n{\n    KernelGeGLU<dataType> op;\n    op.Init(src0Gm, src1Gm, dstGm, srcSize, tmpBufSize);\n    op.Process(tmpBufSize, calCount);\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Gelu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0771.html",
    "功能说明": "在神经网络中，GELU是一个重要的激活函数，其灵感来源于Relu和Dropout，在激活中引入了随机正则的思想。计算公式如下 ： ，化简后可得",
    "函数原型": "template <typename T, bool highPrecision = false, bool highPerformance = false>\n__aicore__ inline void Gelu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const uint32_t dataSize)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float highPrecision 是否使能高精度接口，以提升运算准确度。 注意：高精度模式只在half数据类型下使能后生效，该参数的取值不影响float数据类型下的接口精度和性能。 highPerformance 是否使能高性能接口，以提升运算效率。 注意：开启高性能模式相比于默认不开启高精度和高性能模式会有精度下降，同时开启高精度和高性能模式相比于仅开启高性能模式可能会有性能下降。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename srcType>\nclass KernelGelu\n{\npublic:\n    __aicore__ inline KernelGelu() {}\n    __aicore__ inline void Init(GM_ADDR src_gm, GM_ADDR dst_gm, uint32_t inputSize)\n    {\n        dataSize = inputSize;\n        src_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src_gm), dataSize);\n        dst_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dst_gm), dataSize);\n        pipe.InitBuffer(inQueueX, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, dataSize * sizeof(srcType));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.AllocTensor<srcType>();\n        AscendC::DataCopy(srcLocal, src_global, dataSize);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.DeQue<srcType>();\n        AscendC::Gelu(dstLocal, srcLocal, dataSize);\n        // AscendC::Gelu<srcType, true, false>(dstLocal, srcLocal, dataSize);\n        // AscendC::Gelu<srcType, false, true>(dstLocal, srcLocal, dataSize);\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dst_global, dstLocal, dataSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> src_global;\n    AscendC::GlobalTensor<srcType> dst_global;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    uint32_t dataSize = 0;\n};\n\ntemplate <typename dataType>\n__aicore__ void kernel_Gelu_operator(GM_ADDR src_gm, GM_ADDR dst_gm, uint32_t dataSize)\n{\n    KernelGelu<dataType> op;\n    op.Init(src_gm, dst_gm, dataSize);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "LogSoftMax",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0768.html",
    "功能说明": "对输入tensor做LogSoftmax计算。计算公式如下，其中PAR表示矢量计算单元一个迭代能够处理的元素个数 ： 为方便理解，通过Python脚本实现的方式表达计算公式如下，其中src是源操作数（输入），dst、sum、max为目的操作数（输出）。 def log_softmax ( src ): #基于last轴进行rowmax(按行取最大值)处理 max = np . max ( src , axis =- 1 , keepdims = True ) sub = src - max exp = np . exp ( sub ) #基于last轴进行rowsum(按行求和)处理 sum = np . sum ( exp , axis =- 1 , keepdims = True ) dst = exp / sum dst = np . log10 ( dst ) return dst , max , sum",
    "函数原型": "template <typename T, bool isReuseSource = false, bool isDataFormatNZ = false>\n__aicore__ inline void LogSoftMax(LocalTensor<T>& dst, const LocalTensor<T>& sumTensor, const LocalTensor<T>& maxTensor, const LocalTensor<T>& src, const LocalTensor<uint8_t>& sharedTmpBuffer, const LogSoftMaxTiling& tiling, const SoftMaxShapeInfo& softmaxShapeInfo = {})",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 isDataFormatNZ 源操作数是否为NZ格式。默认值为false。",
    "返回值": "",
    "调用示例": "//DTYPE_X、DTYPE_A、DTYPE_B、DTYPE_C分别表示源操作数、目的操作数、maxLocal、sumLocal操作数数据类型\npipe.InitBuffer(inQueueX, BUFFER_NUM, totalLength * sizeof(DTYPE_X));\npipe.InitBuffer(outQueueA, BUFFER_NUM, totalLength * sizeof(DTYPE_A));\npipe.InitBuffer(outQueueB, BUFFER_NUM, outsize * sizeof(DTYPE_B));\npipe.InitBuffer(outQueueC, BUFFER_NUM, outsize * sizeof(DTYPE_C));\npipe.InitBuffer(tmpQueue, BUFFER_NUM, tmpsize);\nAscendC::LocalTensor<DTYPE_X> srcLocal = inQueueX.DeQue<DTYPE_X>();\nAscendC::LocalTensor<DTYPE_A> dstLocal = outQueueA.AllocTensor<DTYPE_A>();\nAscendC::LocalTensor<DTYPE_B> maxLocal = outQueueB.AllocTensor<DTYPE_B>();\nAscendC::LocalTensor<DTYPE_C> sumLocal = outQueueC.AllocTensor<DTYPE_C>();\nAscendC::SoftMaxShapeInfo softmaxInfo = {outter, inner, outter, inner};\nAscendC::LocalTensor<uint8_t> tmpLocal = tmpQueue.AllocTensor<uint8_t>();\nAscendC::LogSoftMax<DTYPE_X, false>(dstLocal, sumLocal, maxLocal, srcLocal, tmpLocal, softmaxTiling, softmaxInfo);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ReGlu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0790.html",
    "功能说明": "ReGlu是一种GLU变体，使用Relu作为激活函数，计算公式如下： 其中Relu激活函数的计算公式如下：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void ReGlu(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor0, const LocalTensor<T>& srcTensor1, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float/bfloat16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float/bfloat16_t Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\ntemplate <typename srcType>\nclass KernelReGlu\n{\npublic:\n    __aicore__ inline KernelReGlu() {}\n    __aicore__ inline void Init(GM_ADDR src0Gm, GM_ADDR src1Gm, GM_ADDR dstGm, uint32_t srcSize)\n    {\n        dataSize = srcSize;\n        src0Global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src0Gm), dataSize);\n        src1Global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src1Gm), dataSize);\n        dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), dataSize);\n        pipe.InitBuffer(inQueueX, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(inQueueY, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, dataSize * sizeof(srcType));\n        if (sizeof(srcType) != sizeof(float))\n        {\n            pipe.InitBuffer(calcBufs, dataSize * (sizeof(float) / sizeof(uint8_t)) * 3);\n        }\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> src0Local = inQueueX.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> src1Local = inQueueY.AllocTensor<srcType>();\n        AscendC::DataCopy(src0Local, src0Global, dataSize);\n        AscendC::DataCopy(src1Local, src1Global, dataSize);\n        inQueueX.EnQue(src0Local);\n        inQueueY.EnQue(src1Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> src0Local = inQueueX.DeQue<srcType>();\n        AscendC::LocalTensor<srcType> src1Local = inQueueY.DeQue<srcType>();\n        AscendC::LocalTensor<uint8_t> tmpLocal;\n        if (sizeof(srcType) != sizeof(float))\n        {\n            tmpLocal = calcBufs.Get<uint8_t>();\n            AscendC::ReGlu<srcType, false>(dstLocal, src0Local, src1Local, tmpLocal, dataSize);\n        }\n        else\n        {\n            AscendC::ReGlu<srcType, false>(dstLocal, src0Local, src1Local, dataSize);\n        }\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(src0Local);\n        inQueueY.FreeTensor(src1Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dstGlobal, dstLocal, dataSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> src0Global;\n    AscendC::GlobalTensor<srcType> src1Global;\n    AscendC::GlobalTensor<srcType> dstGlobal;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueY;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    AscendC::TBuf<AscendC::TPosition::VECCALC> calcBufs;\n    uint32_t dataSize = 0;\n};\ntemplate <typename dataType>\n__aicore__ void kernel_reglu_operator(GM_ADDR src0Gm, GM_ADDR src1Gm, GM_ADDR dstGm, uint32_t srcSize)\n{\n    KernelReGlu<dataType> op;\n    op.Init(src0Gm, src1Gm, dstGm, srcSize);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Sigmoid",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0793.html",
    "功能说明": "按元素做逻辑回归Sigmoid，计算公式如下 ：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Sigmoid(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas 训练系列产品 ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n// 输入shape信息为1024, 算子输入的数据类型为half, 实际计算个数为512\nAscendC::Sigmoid(dstLocal, srcLocal, sharedTmpBuffer, 512);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Silu",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0780.html",
    "功能说明": "按元素做Silu运算，计算公式如下：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Silu(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, uint32_t dataSize)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename srcType>\nclass KernelSilu\n{\npublic:\n    __aicore__ inline KernelSilu() {}\n    __aicore__ inline void Init(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t inputSize)\n    {\n        dataSize = inputSize;\n        srcGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(srcGm), dataSize);\n        dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), dataSize);\n\n        pipe.InitBuffer(inQueueX, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, dataSize * sizeof(srcType));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.AllocTensor<srcType>();\n        AscendC::DataCopy(srcLocal, srcGlobal, dataSize);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.DeQue<srcType>();\n        AscendC::Silu(dstLocal, srcLocal, dataSize);\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dstGlobal, dstLocal, dataSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> srcGlobal;\n    AscendC::GlobalTensor<srcType> dstGlobal;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    uint32_t dataSize = 0;\n};\n\ntemplate <typename dataType>\n__aicore__ void kernel_Silu_operator(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t dataSize)\n{\n    KernelSilu<dataType> op;\n    op.Init(srcGm, dstGm, dataSize);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SimpleSoftMax",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0755.html",
    "功能说明": "将输入tensor[m 0 , m 1 , ...m t , n]（t大于等于0）的非尾轴长度相乘的结果看作m，则输入tensor的shape看作[m, n]。对输入tensor[m,n]按行做如下计算，与 SoftMax 接口不同，该接口内部没有reduce过程计算sum和max数据，而是使用计算好的sum和max数据对输入tensor做Softmax计算。计算公式如下： 为方便理解，通过Python脚本实现的方式，表达其计算公式如下，其中src、max、sum是源操作数（输入），dst为目的操作数（输出）。 def simple_softmax ( src , max , sum ): dst = np . exp ( src - max ) / sum return dst",
    "函数原型": "template <typename T, bool isReuseSource = false, bool isBasicBlock = false, bool isDataFormatNZ = false, const SoftmaxConfig& config = SOFTMAX_DEFAULT_CFG> \n__aicore__ inline void SimpleSoftMax(const LocalTensor<T>& dstTensor, const LocalTensor<T>& inSumTensor, const LocalTensor<T>& inMaxTensor, const LocalTensor<T>& srcTensor, const SoftMaxTiling& tiling, const SoftMaxShapeInfo& softmaxShapeInfo = {})",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isReuseSource 该参数预留，传入默认值false即可。 isBasicBlock srcTensor和dstTensor的shape信息和Tiling切分策略满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。是否满足基本块的要求，可以采用如下两种方式之一判断： srcTensor和dstTensor的shape信息[m,n]需要满足如下条件： 尾轴长度n小于2048并且大于等于256/sizeof(T)（即half场景下n最小为128，float场景下n最小为64），同时n是64的倍数； 非尾轴长度的乘积m为8的倍数。 在Tiling实现中，通过调用 IsBasicBlockInSoftMax 判断Tiling切分策略是否满足基本块的切分要求。 针对 Atlas 200/500 A2推理产品 ，该参数为预留参数，暂未启用，为后续的功能扩展做保留，保持默认值即可。 isDataFormatNZ 当前输入输出的数据格式是否为NZ格式，默认数据格式为ND，即默认取值为false。 针对 Atlas 200/500 A2推理产品 ，不支持配置为NZ格式。 config 结构体模板参数，此参数可选配，SoftmaxConfig类型，具体定义如下。 struct SoftmaxConfig { bool isCheckTiling = true ; // 是否需要检查shape和tiling的一致性；若不一致，API内会根据shape重新计算所需tiling。默认取值true：API内部会检查一致性 uint32_t oriSrcM = 0 ; // 原始非尾轴长度的乘积。设置该参数后，将shape常量化，编译过程中使用常量化的shape uint32_t oriSrcK = 0 ; // 原始尾轴长度。设置该参数后，将shape常量化，编译过程中使用常量化的shape };",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\n// constexpr AscendC::SoftmaxConfig static_config = {true, 320, 64}; shape常量化使用\ntemplate <typename T>\nclass KernelSimpleSoftmax {\npublic:\n    __aicore__ inline KernelSimpleSoftmax()\n    {}\n    __aicore__ inline void Init(__gm__ uint8_t *srcGm, __gm__ uint8_t *inMaxGm, __gm__ uint8_t *inSumGm,\n        __gm__ uint8_t *dstGm, const SoftMaxTiling &tilingData)\n    {\n        elementNumPerBlk = 32 / sizeof(T);\n        srcGlobal.SetGlobalBuffer((__gm__ T *)srcGm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dstGm);\n        maxGlobal.SetGlobalBuffer((__gm__ T *)inMaxGm);\n        sumGlobal.SetGlobalBuffer((__gm__ T *)inSumGm);\n\n        pipe.InitBuffer(inQueueSrc, 1, height * width * sizeof(T));\n        pipe.InitBuffer(maxQueue, 1, height * elementNumPerBlk * sizeof(T));\n        pipe.InitBuffer(sumQueue, 1, height * elementNumPerBlk * sizeof(T));\n        pipe.InitBuffer(outQueueDst, 1, height * width * sizeof(T));\n        tiling = tilingData;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrc.AllocTensor<T>();\n        AscendC::LocalTensor<T> sumTempLocal = sumQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> maxTempLocal = maxQueue.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, srcGlobal, height * width);\n        AscendC::DataCopy(sumTempLocal, sumGlobal, height * elementNumPerBlk);\n        AscendC::DataCopy(maxTempLocal, maxGlobal, height * elementNumPerBlk);\n        inQueueSrc.EnQue(srcLocal);\n        sumQueue.EnQue(sumTempLocal);\n        maxQueue.EnQue(maxTempLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrc.DeQue<T>();\n        AscendC::LocalTensor<T> sumTempLocal = sumQueue.DeQue<T>();\n        AscendC::LocalTensor<T> maxTempLocal = maxQueue.DeQue<T>();\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.AllocTensor<T>();\n\n        AscendC::SoftMaxShapeInfo srcShape = {height, width, height, width};\n        AscendC::SimpleSoftMax<T>(dstLocal, sumTempLocal, maxTempLocal, srcLocal, tiling, srcShape);\n        //AscendC::SimpleSoftMax<T, false, false, static_config>(dstLocal, sumTempLocal, maxTempLocal, srcLocal, tiling, //srcShape);使用SoftmaxConfig类型的参数static_config，传入模板参数将shape常量化\n\n        outQueueDst.EnQue<T>(dstLocal);\n        maxQueue.FreeTensor(maxTempLocal);\n        sumQueue.FreeTensor(sumTempLocal);\n        inQueueSrc.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, height * width);\n        outQueueDst.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> maxQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> sumQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<T> srcGlobal, dstGlobal;\n    AscendC::GlobalTensor<T> maxGlobal, sumGlobal;\n    uint32_t elementNumPerBlk = 0;\n    uint32_t width = 64;\n    uint32_t height = 320;\n    SoftMaxTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void simple_softmax_kernel_half(__gm__ uint8_t *srcGm, __gm__ uint8_t *inMaxGm,\n    __gm__ uint8_t *inSumGm, __gm__ uint8_t *dstGm, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelSimpleSoftmax<half> op;\n    op.Init(srcGm, inMaxGm, inSumGm, dstGm, tilingData.softmaxTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SoftMax",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0754.html",
    "功能说明": "将输入tensor[m 0 , m 1 , ...m t , n]（t大于等于0）的非尾轴长度相乘的结果看作m，则输入tensor的shape看作[m, n]。对输入tensor[m, n]按行做如下SoftMax计算： 为方便理解，通过Python脚本实现的方式，表达其计算公式（以输入为ND格式为例）如下，其中src是源操作数（输入），dst、sum、max为目的操作数（输出）。 def softmax ( src ): #基于last轴进行rowmax（按行取最大值）处理 max = np . max ( src , axis =- 1 , keepdims = True ) sub = src - max exp = np . exp ( sub ) #基于last轴进行rowsum（按行求和）处理 sum = np . sum ( exp , axis =- 1 , keepdims = True ) dst = exp / sum return dst , max , sum 当输入的数据排布格式不同时，内部的reduce过程会有所不同：当输入为ND格式时，内部的reduce过程按last轴进行；当输入为NZ格式时，内部的reduce过程按照last轴和first轴进行，reduce过程如下图所示： 图1 ND格式的reduce过程 图2 NZ格式的reduce过程",
    "函数原型": "template <typename T, bool isReuseSource = false, bool isBasicBlock = false, bool isDataFormatNZ = false, const SoftmaxConfig& config = SOFTMAX_DEFAULT_CFG>\n__aicore__ inline void SoftMax(const LocalTensor<T>& dstTensor, const LocalTensor<T>& sumTensor, const LocalTensor<T>& maxTensor, const LocalTensor<T>& srcTensor, const SoftMaxTiling& tiling, const SoftMaxShapeInfo& softmaxShapeInfo = {})",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 该参数预留，传入默认值false即可。 isBasicBlock srcTensor和dstTensor的shape信息和Tiling切分策略满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。是否满足基本块的要求，可以采用如下两种方式之一判断： srcTensor和dstTensor的shape信息[m,n]需要满足如下条件： 尾轴长度n小于2048并且大于等于256/sizeof(T)（即half场景下n最小为128，float场景下n最小为64），同时n是64的倍数； 非尾轴长度的乘积m为8的倍数。 在Tiling实现中，通过调用 IsBasicBlockInSoftMax 判断Tiling切分策略是否满足基本块的切分要求。 针对 Atlas 200I/500 A2 推理产品 ，该参数为预留参数，暂未启用，为后续的功能扩展做保留，保持默认值即可。 isDataFormatNZ 当前输入输出的数据格式是否为NZ格式，默认数据格式为ND，即默认取值为false。 针对 Atlas 200I/500 A2 推理产品 ，不支持配置为NZ格式。 config 结构体模板参数，此参数可选配，SoftmaxConfig类型，具体定义如下。 struct SoftmaxConfig { bool isCheckTiling = true ; // 是否需要检查shape和tiling的一致性；若不一致，API内会根据shape重新计算所需tiling。默认取值true：API内部会检查一致性 uint32_t oriSrcM = 0 ; // 原始非尾轴长度的乘积。设置该参数后，将shape常量化，编译过程中使用常量化的shape uint32_t oriSrcK = 0 ; // 原始尾轴长度。设置该参数后，将shape常量化，编译过程中使用常量化的shape };",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\n// static constexpr AscendC::SoftmaxConfig static_config = {true, 320, 64}; shape常量化使用\ntemplate <typename T>\nclass KernelSoftmax {\npublic:\n    __aicore__ inline KernelSoftmax()\n    {}\n    __aicore__ inline void Init(__gm__ uint8_t *srcGm, __gm__ uint8_t *dstGm, const SoftMaxTiling &tilingData)\n    {\n        elementNumPerBlk = 32 / sizeof(T);\n        src1Global.SetGlobalBuffer((__gm__ T *)srcGm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dstGm);\n        pipe.InitBuffer(inQueueSrc, 1, height * width * sizeof(T));\n        pipe.InitBuffer(maxQueue, 1, height * elementNumPerBlk * sizeof(T));\n        pipe.InitBuffer(sumQueue, 1, height * elementNumPerBlk * sizeof(T));\n        pipe.InitBuffer(outQueueDst, 1, height * width * sizeof(T));\n        tiling = tilingData;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrc.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, src1Global, height * width);\n        inQueueSrc.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrc.DeQue<T>();\n        AscendC::LocalTensor<T> sumTempLocal = sumQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> maxTempLocal = maxQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.AllocTensor<T>();\n\n        AscendC::SoftMaxShapeInfo srcShape = {height, width, height, width};\n        AscendC::SoftMax<T>(dstLocal, sumTempLocal, maxTempLocal, srcLocal, tiling, srcShape);\n        // AscendC::SoftMax<T, false, false, false, static_config>(dstLocal, sumTempLocal,\n        // maxTempLocal, srcLocal, tiling, srcShape); 使用SoftmaxConfig类型的参数static_config，传入模板参数将shape常量化\n\n        outQueueDst.EnQue<T>(dstLocal);\n        maxQueue.FreeTensor(maxTempLocal);\n        sumQueue.FreeTensor(sumTempLocal);\n        inQueueSrc.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, height * width);\n        outQueueDst.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> maxQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> sumQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<T> src1Global, dstGlobal;\n    uint32_t elementNumPerBlk = 0;\n    uint32_t width = 64;\n    uint32_t height = 320;\n    SoftMaxTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void softmax_kernel_half(\n    __gm__ uint8_t *srcGm, __gm__ uint8_t *dstGm, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelSoftmax<half> op;\n    op.Init(srcGm, dstGm, tilingData.softmaxTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SoftmaxFlash",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0756.html",
    "功能说明": "注意：该接口后续即将废弃，请使用精度和性能更好的SoftmaxFlashV2接口 。 Softmax增强版本，除了可以对输入tensor做SoftmaxFlash计算，还可以根据上一次Softmax计算的sum和max来更新本次的Softmax计算结果。last轴切轴的情况，每次计算的reduce结果并非是全轴的，需要根据上一次Softmax计算的sum和max来更新本次的Softmax计算结果，可以使用该增强接口。不支持NZ格式。 当前仅支持传入shape为ND格式，内部的reduce过程都是按last轴进行。不使能update时，该接口等同于 SoftMax 。 为方便理解，通过Python脚本实现的方式，表达其计算公式如下，其中src、inmax、 insum、update为输入，dst、x_sum、x_max、exp_max为输出。 def softmax_flash ( src , inmax = None , insum = None , update = None ): if update == None : #基于last轴进行rowmax(按行取最大值)处理 x_max = np . max ( src , axis =- 1 , keepdims = True ) x_sub = src - x_max x_exp = np . exp ( x_sub ) #基于last轴进行rowsum(按行求和)处理 x_sum = np . sum ( x_exp , axis =- 1 , keepdims = True ) dst = x_exp / x_sum exp_max = None return dst , x_max , x_sum , exp_max else : #将inmax和src拼接后求rowmax x_max = np . max ( np . concatenate (( inmax , src ), axis =- 1 ), axis =- 1 , keepdims = True ) x_exp = np . exp ( src - x_max ) x_sum = np . sum ( x_exp , axis =- 1 , keepdims = True ) exp_max = np . exp ( inmax - x_max ) x_sum = exp_max * insum + x_sum exp_max = exp_max * insum / x_sum dst = x_exp / x_sum return dst , x_max , x_sum , exp_max",
    "函数原型": "template <typename T, bool isReuseSource = false, bool isBasicBlock = false>\nvoid SoftmaxFlash(const LocalTensor<T> &dstTensor, const LocalTensor<T> &sumTensor, const LocalTensor<T> &maxTensor, const LocalTensor<T> &srcTensor, const LocalTensor<T> &expMaxTensor, const LocalTensor<T> &inSumTensor, const LocalTensor<T> &inMaxTensor, const SoftMaxTiling &tiling, bool isUpdate = false, const SoftMaxShapeInfo &softmaxShapeInfo = {})",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 该参数预留，传入默认值false即可。 isBasicBlock srcTensor和dstTensor的shape信息和Tiling切分策略满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。是否满足基本块的要求，可以采用如下两种方式之一判断： srcTensor和dstTensor的shape信息[m,n]需要满足如下条件： 尾轴长度n小于2048并且大于等于256/sizeof(T)（即half场景下n最小为128，float场景下n最小为64），同时n是64的倍数； 非尾轴长度的乘积m为8的倍数。 在Tiling实现中，通过调用 IsBasicBlockInSoftMax 判断Tiling切分策略是否满足基本块的切分要求。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T>\nclass KernelSoftmaxFlash {\npublic:\n    __aicore__ inline KernelSoftmaxFlash()\n    {}\n    __aicore__ inline void Init(\n        __gm__ uint8_t *src1Gm, __gm__ uint8_t *src2Gm, __gm__ uint8_t *dstGm, const SoftMaxTiling &tilingData)\n    {\n        elementNumPerBlk = 32 / sizeof(T);\n        src1Global.SetGlobalBuffer((__gm__ T *)src1Gm);\n        src2Global.SetGlobalBuffer((__gm__ T *)src2Gm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dstGm);\n        pipe.InitBuffer(inQueueSrc1, 1, height * width * sizeof(T));\n        pipe.InitBuffer(inQueueSrc2, 1, height * width * sizeof(T));\n        pipe.InitBuffer(outQueueDst, 1, height * width * sizeof(T));\n        pipe.InitBuffer(inMaxQueue, 1, height * elementNumPerBlk * sizeof(T));\n        pipe.InitBuffer(inSumQueue, 1, height * elementNumPerBlk * sizeof(T));\n        pipe.InitBuffer(expMaxQueue, 1, height * elementNumPerBlk * sizeof(T));\n        tiling = tilingData;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal1 = inQueueSrc1.AllocTensor<T>();\n        AscendC::LocalTensor<T> srcLocal2 = inQueueSrc2.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal1, src1Global, height * width);\n        AscendC::DataCopy(srcLocal2, src2Global, height * width);\n        inQueueSrc1.EnQue(srcLocal1);\n        inQueueSrc2.EnQue(srcLocal2);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal1 = inQueueSrc1.DeQue<T>();\n        AscendC::LocalTensor<T> srcLocal2 = inQueueSrc2.DeQue<T>();\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.AllocTensor<T>();\n\n        AscendC::LocalTensor<T> inmaxLocal = inMaxQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> insumLocal = inSumQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> expMaxTensor = expMaxQueue.AllocTensor<T>();\n        AscendC::SoftMaxShapeInfo srcShape = {height, width, height, width};\n        AscendC::SoftmaxFlash<T, false>(srcLocal2,\n            insumLocal,\n            inmaxLocal,\n            srcLocal2,\n            expMaxTensor,\n            insumLocal,\n            inmaxLocal,\n            tiling,\n            false,\n            srcShape);\n\n        AscendC::DataCopy(dstLocal, srcLocal2, height * width);\n\n        outQueueDst.EnQue<T>(dstLocal);\n        inMaxQueue.FreeTensor(inmaxLocal);\n        inSumQueue.FreeTensor(insumLocal);\n        inQueueSrc1.FreeTensor(srcLocal1);\n        inQueueSrc2.FreeTensor(srcLocal2);\n        expMaxQueue.FreeTensor(expMaxTensor);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, height * width);\n        outQueueDst.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc2;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inMaxQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inSumQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> expMaxQueue;\n\n    AscendC::GlobalTensor<T> src1Global, src2Global, dstGlobal;\n    uint32_t elementNumPerBlk = 0;\n    uint32_t width = 144;\n    uint32_t height = 80;\n    SoftMaxTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void softmax_flash_kernel_half(\n    __gm__ uint8_t *src1Gm, __gm__ uint8_t *src2Gm, __gm__ uint8_t *dstGm, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelSoftmaxFlash<half> op;\n    op.Init(src1Gm, src2Gm, dstGm, tilingData.softmaxTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SoftmaxFlashV2",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0758.html",
    "功能说明": "SoftmaxFlash增强版本，对应FlashAttention-2算法。将输入tensor[m 0 , m 1 , ...m t , n]（t大于等于0）的非尾轴长度相乘的结果看作m，则输入tensor的shape看作[m, n]。对输入tensor[m,n]按行做如下计算，不同的update值对应不同的计算公式，其中x、inmax和insum为输入，M、S、E均为输出。 update为false： update为true： 当输入shape为ND格式时，内部的reduce过程按last轴进行；当输入shape为NZ格式时，内部的reduce过程按照last轴和first轴进行，reduce过程可以参考 SoftMax 中的图示说明。 为方便理解，通过Python脚本实现的方式，表达其计算公式如下，其中src、inmax、 insum、update为输入，dst、x_sum、x_max、exp_max为输出。 def softmax_flash_2 ( src , inmax = None , insum = None , update = None ): if update == None : x_max = np . max ( src , axis =- 1 , keepdims = True ) x_sub = src - x_max dst = np . exp ( x_sub ) x_sum = np . sum ( dst , axis =- 1 , keepdims = True ) exp_max = None return dst , x_max , x_sum , exp_max else : x_max = np . max ( np . concatenate (( inmax , src ), axis =- 1 ), axis =- 1 , keepdims = True ) dst = np . exp ( src - x_max ) exp_max = np . exp ( inmax - x_max ) x_sum = np . sum ( dst , axis =- 1 , keepdims = True ) x_sum = exp_max * insum + x_sum return dst , x_max , x_sum , exp_max",
    "函数原型": "template <typename T, bool isUpdate = false, bool isReuseSource = false, bool isBasicBlock = false, bool isDataFormatNZ = false, const SoftmaxConfig& config = SOFTMAX_DEFAULT_CFG>\n__aicore__ inline void SoftmaxFlashV2(const LocalTensor<T>& dstTensor, const LocalTensor<T>& expSumTensor, const LocalTensor<T>& maxTensor, const LocalTensor<T>& srcTensor, const LocalTensor<T>& expMaxTensor, const LocalTensor<T>& inExpSumTensor, const LocalTensor<T>& inMaxTensor, const SoftMaxTiling& tiling, const SoftMaxShapeInfo& softmaxShapeInfo = {})",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isUpdate 是否使能update部分中的计算。 isReuseSource 该参数预留，传入默认值false即可。 isBasicBlock srcTensor和dstTensor的shape信息和Tiling切分策略满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。是否满足基本块的要求，可以采用如下两种方式之一判断： srcTensor和dstTensor的shape信息[m,n]需要满足如下条件： 尾轴长度n小于2048并且大于等于256/sizeof(T)（即half场景下n最小为128，float场景下n最小为64），同时n是64的倍数； 非尾轴长度的乘积m为8的倍数。 在Tiling实现中，通过调用 IsBasicBlockInSoftMax 判断Tiling切分策略是否满足基本块的切分要求。 针对 Atlas 200I/500 A2 推理产品 ，该参数为预留参数，暂未启用，为后续的功能扩展做保留，保持默认值即可。 isDataFormatNZ 当前输入输出的数据格式是否为NZ格式，默认数据格式为ND，即默认取值为false。 针对 Atlas 200I/500 A2 推理产品 ，不支持配置为NZ格式。 config 结构体模板参数，此参数可选配，SoftmaxConfig类型，具体定义如下。 struct SoftmaxConfig { bool isCheckTiling = true ; // 是否需要检查shape和tiling的一致性；若不一致，API内会根据shape重新计算所需tiling。默认取值true：API内部会检查一致性 uint32_t oriSrcM = 0 ; // 原始非尾轴长度的乘积。设置该参数后，将shape常量化，编译过程中使用常量化的shape uint32_t oriSrcK = 0 ; // 原始尾轴长度。设置该参数后，将shape常量化，编译过程中使用常量化的shape SoftmaxMode mode = SoftmaxMode :: SOFTMAX_NORMAL ; // 输出shape的处理模式 };",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\n// constexpr AscendC::SoftmaxConfig static_config = {true, 320, 64}; shape常量化使用\ntemplate <typename T>\nclass KernelSoftmaxFlashV2 {\npublic:\n    __aicore__ inline KernelSoftmaxFlashV2()\n    {}\n    __aicore__ inline void Init(__gm__ uint8_t *srcGm, __gm__ uint8_t *inMaxGm, __gm__ uint8_t *inSumGm,\n        __gm__ uint8_t *dstGm, const SoftMaxTiling &tilingData)\n    {\n        elementNumPerBlk = 32 / sizeof(T);\n        srcGlobal.SetGlobalBuffer((__gm__ T *)srcGm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dstGm);\n        maxGlobal.SetGlobalBuffer((__gm__ T *)inMaxGm);\n        sumGlobal.SetGlobalBuffer((__gm__ T *)inSumGm);\n        pipe.InitBuffer(inQueueSrc, 1, height * width * sizeof(T));\n        pipe.InitBuffer(maxQueue, 1, height * elementNumPerBlk * sizeof(T));\n        pipe.InitBuffer(sumQueue, 1, height * elementNumPerBlk * sizeof(T));\n        pipe.InitBuffer(expMaxQueue, 1, height * elementNumPerBlk * sizeof(T));\n        pipe.InitBuffer(outQueueDst, 1, height * width * sizeof(T));\n        tiling = tilingData;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrc.AllocTensor<T>();\n        AscendC::LocalTensor<T> insumLocal = sumQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> inmaxLocal = maxQueue.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, srcGlobal, height * width);\n        AscendC::DataCopy(insumLocal, sumGlobal, height * elementNumPerBlk);\n        AscendC::DataCopy(inmaxLocal, maxGlobal, height * elementNumPerBlk);\n        inQueueSrc.EnQue(srcLocal);\n        sumQueue.EnQue(insumLocal);\n        maxQueue.EnQue(inmaxLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrc.DeQue<T>();\n        AscendC::LocalTensor<T> insumLocal = sumQueue.DeQue<T>();\n        AscendC::LocalTensor<T> inmaxLocal = maxQueue.DeQue<T>();\n        AscendC::LocalTensor<T> expMaxTensor = expMaxQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.AllocTensor<T>();\n        AscendC::SoftMaxShapeInfo srcShape = {height, width, height, width};\n        AscendC::SoftmaxFlashV2<T, true>(\n            dstLocal, insumLocal, inmaxLocal, srcLocal, expMaxTensor, insumLocal, inmaxLocal, tiling, srcShape);\n        //AscendC::SoftmaxFlashV2<T, true, false, false, false, static_config>(dstLocal, insumLocal, inmaxLocal, srcLocal,\n//expMaxTensor, insumLocal, inmaxLocal, tiling, srcShape);使用SoftmaxConfig类型的参数static_config,传入模板参数将shape常量化\n        outQueueDst.EnQue<T>(dstLocal);\n        maxQueue.FreeTensor(inmaxLocal);\n        sumQueue.FreeTensor(insumLocal);\n        inQueueSrc.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, height * width);\n        outQueueDst.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> maxQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> sumQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> expMaxQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<T> srcGlobal, dstGlobal;\n    AscendC::GlobalTensor<T> maxGlobal, sumGlobal;\n    uint32_t elementNumPerBlk = 0;\n    uint32_t width = 64;\n    uint32_t height = 320;\n    SoftMaxTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void softmax_flashv2_generic_kernel_half(__gm__ uint8_t *srcGm,\n    __gm__ uint8_t *inMaxGm, __gm__ uint8_t *inSumGm, __gm__ uint8_t *dstGm, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelSoftmaxFlashV2<half> op;\n    op.Init(srcGm, inMaxGm, inSumGm, dstGm, tilingData.softmaxTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SoftmaxFlashV3",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10001.html",
    "功能说明": "SoftmaxFlash增强版本，对应Softmax PASA算法。将输入tensor[m 0 , m 1 , ..., m t , n]（t大于或等于0）的非尾轴长度m 0 , m 1 , ..., m t 相乘的结果看作m，则输入tensor的shape看作[m, n]。对输入tensor x的尾轴进行切分，分块个数为splitMeanCnt，切分后的tensor为x_cnt i 。按如下公式进行计算，其中x、inmax、insum、inmean为输入，M、S、E均为输出。 update为false： update为true： 本接口当前只支持ND格式的输入，内部的reduce过程按last轴处理。 为方便理解，通过Python伪代码实现的方式，表达其计算公式如下。其中，repeatSize为64，elementNumPerBlk/BlkcntPerRepeat为8，splitMeanCnt为8，src、inmean、inmax、 insum、update为输入，dst、x_mean、x_sum、x_max、exp_max为输出。 def softmax_flash_3 ( src , height , width , loopCnt , alpha , baseK , inmax = None , insum = None , inmean = None , update = False ): scalar = alpha / ( 1 - alpha ) #(m,n)->(m,64) tmpbuffer0 = BlockReduceSum ( repeatSize , repeatSize , elementNumPerBlk ) remain = int ( width / repeatSize - BlkcntPerRepeat ) tmpbuffer0 = Add ( tmpbuffer0 , src , remain , repeatSize * elementNumPerBlk , width ) #(m,64)->(m,8) tmpbuffer0 = BlockReduceSum ( 1 , elementNumPerBlk , elementNumPerBlk ) #width = baseK * splitMeanCnt rowMeanLocal = tmpbuffer0 / baseK rowMeanGlobal = np . mean ( src , axis = ( - 1 ), keepdims = True ) rowMeanGlobalTmp = ( rowMeanGlobal - rowMeanLocal ) * scalar src = src - rowMeanGlobalTmp if update == False : x_mean = rowMeanGlobal maxTmp = np . max ( src , axis =- 1 , keepdims = True ) shiftCurr = ( rowMeanGlobal - x_mean ) * scalar x_max = shiftCurr + maxTmp maxTmp = x_max - shiftCurr x_sub = src - maxTmp dst = np . exp ( x_sub ) x_sum = np . sum ( dst , axis =- 1 , keepdims = True ) exp_max = None return dst , x_max , x_sum , x_mean , exp_max else : x_mean = ( rowMeanGlobal + inmean * ( loopCnt - 1 )) / loopCnt maxTmp = np . max ( src , axis =- 1 , keepdims = True ) shiftCurr = ( rowMeanGlobal - x_mean ) * scalar shiftPrev = ( inmean - x_mean ) * scalar x_max = shiftCurr + maxTmp maxTmp = shiftPrev + inmax x_max = np . max ( np . concatenate (( x_max , maxTmp ), axis = ( - 1 )), axis = ( - 1 ), keepdims = True ) maxTmp = x_max - shiftCurr x_sub = src - maxTmp dst = np . exp ( x_sub ) exp_max = np . exp ( inmax - x_max + shiftPrev ) x_sum = np . sum ( x_exp , axis =- 1 , keepdims = True ) x_sum = exp_max * insum + x_sum return x_exp , x_max , x_sum , x_mean , exp_max",
    "函数原型": "template <typename T, typename U, bool isUpdate = false, bool isReuseSource = false, bool isBasicBlock = false, bool isDataFormatNZ = false, const SoftmaxConfig& config = SOFTMAX_DEFAULT_CFG>\n__aicore__ inline void SoftmaxFlashV3(const LocalTensor<T>& dstTensor, const LocalTensor<U>& meanTensor, const LocalTensor<U>& expSumTensor, const LocalTensor<U>& maxTensor, const LocalTensor<T>& srcTensor, const LocalTensor<T>& expMaxTensor, const LocalTensor<U>& inMeanTensor, const LocalTensor<U>& inExpSumTensor, const LocalTensor<U>& inMaxTensor, const SoftMaxTiling& tiling, const SoftMaxParams& params)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 输入srcTensor及输出dstTensor、expMaxTensor操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half U 输入inMeanTensor、inExpSumTensor、inMaxTensor及输出meanTensor、expSumTensor、maxTensor操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：float isUpdate 是否使能update为true的计算。 isReuseSource 该参数预留，传入默认值false即可。 isBasicBlock 该参数预留，传入默认值false即可。 isDataFormatNZ 该参数预留，传入默认值false即可。 config 该参数预留，传入默认值SOFTMAX_DEFAULT_CFG即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T, typename U>\nclass KernelSoftmaxFlashV3 {\npublic:\n    __aicore__ inline KernelSoftmaxFlashV3() {}\n    __aicore__ inline void Init(__gm__ uint8_t *srcGm, __gm__ uint8_t *inMaxGm, __gm__ uint8_t *inSumGm,\n       __gm__ uint8_t *inMeanGm, __gm__ uint8_t *dstGm, const SoftMaxTiling &tilingData)\n    {\n        srcGlobal.SetGlobalBuffer((__gm__ T *)srcGm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dstGm);\n        maxGlobal.SetGlobalBuffer((__gm__ U *)inMaxGm);\n        sumGlobal.SetGlobalBuffer((__gm__ U *)inSumGm);\n        meanGlobal.SetGlobalBuffer((__gm__ U *)inMeanGm);\n        pipe.InitBuffer(inQueueSrc, 1, height * width * sizeof(T));\n        elementNumPerBlk1 = 32 / sizeof(U);\n        pipe.InitBuffer(maxQueue, 1, height * elementNumPerBlk1 * sizeof(U));\n        pipe.InitBuffer(sumQueue, 1, height * elementNumPerBlk1 * sizeof(U));\n        pipe.InitBuffer(meanQueue, 1, height * elementNumPerBlk1 * sizeof(U));\n        elementNumPerBlk2 = 32 / sizeof(T);\n        pipe.InitBuffer(expMaxQueue, 1, height * elementNumPerBlk2 * sizeof(T));\n        pipe.InitBuffer(outQueueDst, 1, height * width * sizeof(T));\n        tiling = tilingData;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrc.AllocTensor<T>();\n        AscendC::LocalTensor<U> insumLocal = sumQueue.AllocTensor<U>();\n        AscendC::LocalTensor<U> inmaxLocal = maxQueue.AllocTensor<U>();\n        AscendC::LocalTensor<U> inmeanLocal = meanQueue.AllocTensor<U>();\n        AscendC::DataCopy(srcLocal, srcGlobal, height * width);\n        AscendC::DataCopy(insumLocal, sumGlobal, height * elementNumPerBlk1);\n        AscendC::DataCopy(inmaxLocal, maxGlobal, height * elementNumPerBlk1);\n        AscendC::DataCopy(inmeanLocal, meanGlobal, height * elementNumPerBlk1);\n        inQueueSrc.EnQue(srcLocal);\n        sumQueue.EnQue(insumLocal);\n        maxQueue.EnQue(inmaxLocal);\n        meanQueue.EnQue(inmeanLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrc.DeQue<T>();\n        AscendC::LocalTensor<U> insumLocal = sumQueue.DeQue<U>();\n        AscendC::LocalTensor<U> inmaxLocal = maxQueue.DeQue<U>();\n        AscendC::LocalTensor<U> inmeanLocal = meanQueue.DeQue<U>();\n        AscendC::LocalTensor<T> expMaxTensor = expMaxQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.AllocTensor<T>();\n        AscendC::SoftMaxParams params = {height, width, height, width, loopCnt, splitMeanCnt, alpha};\n        AscendC::SoftmaxFlashV3<T, U, true>(dstLocal, inmeanLocal, insumLocal, inmaxLocal, srcLocal, expMaxTensor, inmeanLocal, insumLocal, inmaxLocal, tiling, params);\n\n        outQueueDst.EnQue<T>(dstLocal);\n        maxQueue.FreeTensor(inmaxLocal);\n        sumQueue.FreeTensor(insumLocal);\n        meanQueue.FreeTensor(inmeanLocal);\n        inQueueSrc.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, height * width);\n        outQueueDst.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> meanQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> maxQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> sumQueue;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> expMaxQueue;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<T> srcGlobal, dstGlobal;\n    AscendC::GlobalTensor<U> meanGlobal, maxGlobal, sumGlobal;\n    uint32_t elementNumPerBlk1 = 0;\n    uint32_t elementNumPerBlk2 = 0;\n    uint32_t width = 1024;\n    uint32_t height = 8;\n    uint32_t loopCnt = 2;\n    uint32_t splitMeanCnt = 8;\n    float alpha = 0.9375;\n    SoftMaxTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void softmax_flashv3_kernel(__gm__ uint8_t *srcGm,\n    __gm__ uint8_t *inMaxGm, __gm__ uint8_t *inSumGm, __gm__ uint8_t *inMeanGm, __gm__ uint8_t *dstGm, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelSoftmaxFlashV3<half, float> op;\n    op.Init(srcGm, inMaxGm, inSumGm, inMeanGm, dstGm, tilingData.softmaxTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SoftmaxGrad",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0757.html",
    "功能说明": "将输入tensor[m 0 , m 1 , ...m t , n]（t大于等于0）的非尾轴长度相乘的结果看作m，则输入tensor的shape看作[m, n]。对输入tensor[m,n]按行做grad反向计算，计算公式如下： 当输入shape为ND格式时，内部的reduce过程按last轴进行；当输入shape为NZ格式时，内部的reduce过程按照last轴和first轴进行，reduce过程可以参考 SoftMax 中的图示说明。 为方便理解，通过Python脚本实现的方式，表达其计算公式如下，其中src、grad、isFront是源操作数（输入），dst为目的操作数（输出）。 def softmax_grad ( grad , src , isFront = None ): dst = grad * src dst = np . sum ( dst , axis =- 1 , keepdims = True ) if isFront : return dst dst = ( grad - dst ) * src return dst",
    "函数原型": "template <typename T, bool isReuseSource = false, bool isDataFormatNZ = false>\n__aicore__ inline void SoftmaxGrad(const LocalTensor<T>& dstTensor, const LocalTensor<T>& gradTensor, const LocalTensor<T>& srcTensor, const SoftMaxTiling& tiling, bool isFront = false, const SoftMaxShapeInfo& softmaxShapeInfo = {})",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 该参数预留，传入默认值false即可。 isDataFormatNZ 当前输入输出的数据格式是否为NZ格式，默认数据格式为ND，即默认取值为false。 针对 Atlas 200I/500 A2 推理产品 ，不支持配置为NZ格式。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T>\nclass KernelSoftmaxGrad {\npublic:\n    __aicore__ inline KernelSoftmaxGrad()\n    {}\n    __aicore__ inline void Init(\n        __gm__ uint8_t *src1Gm, __gm__ uint8_t *src2Gm, __gm__ uint8_t *dstGm, const SoftMaxTiling &tilingData)\n    {\n        elementNumPerBlk = 32 / sizeof(T);\n        src1Global.SetGlobalBuffer((__gm__ T *)src1Gm);\n        src2Global.SetGlobalBuffer((__gm__ T *)src2Gm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dstGm);\n        pipe.InitBuffer(inQueueSrc1, 1, height * width * sizeof(T));\n        pipe.InitBuffer(inQueueSrc2, 1, height * width * sizeof(T));\n        pipe.InitBuffer(outQueueDst, 1, height * width * sizeof(T));\n        tiling = tilingData;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal1 = inQueueSrc1.AllocTensor<T>();\n        AscendC::LocalTensor<T> srcLocal2 = inQueueSrc2.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal1, src1Global, height * width);\n        AscendC::DataCopy(srcLocal2, src2Global, height * width);\n        inQueueSrc1.EnQue(srcLocal1);\n        inQueueSrc2.EnQue(srcLocal2);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal1 = inQueueSrc1.DeQue<T>();\n        AscendC::LocalTensor<T> srcLocal2 = inQueueSrc2.DeQue<T>();\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.AllocTensor<T>();\n\n        AscendC::SoftMaxShapeInfo srcShape = {height, width, height, width};\n        AscendC::SoftmaxGrad<T>(dstLocal, srcLocal2, srcLocal1, tiling, false, srcShape);\n\n        outQueueDst.EnQue<T>(dstLocal);\n        inQueueSrc1.FreeTensor(srcLocal1);\n        inQueueSrc2.FreeTensor(srcLocal2);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, height * width);\n        outQueueDst.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc2;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n\n    AscendC::GlobalTensor<T> src1Global, src2Global, dstGlobal;\n    uint32_t elementNumPerBlk = 0;\n    uint32_t width = 64;\n    uint32_t height = 128;\n    SoftMaxTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void softmax_grad_kernel_half(\n    __gm__ uint8_t *src1Gm, __gm__ uint8_t *src2Gm, __gm__ uint8_t *dstGm, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelSoftmaxGrad<half> op;\n    op.Init(src1Gm, src2Gm, dstGm, tilingData.softmaxTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SoftmaxGradFront",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0759.html",
    "功能说明": "将输入tensor[m 0 , m 1 , ...m t , n]（t大于等于0）的非尾轴长度相乘的结果看作m，则输入tensor的shape看作[m, n]。对输入tensor[m,n]按行做gradfront反向计算，计算公式如下： 当输入shape为ND格式时，内部的reduce过程按last轴进行；当输入shape为NZ格式时，内部的reduce过程按照last轴和first轴进行，reduce过程可以参考 SoftMax 中的图示说明。 为方便理解，通过Python脚本实现的方式，表达其计算公式如下，其中dx、y是源操作数（输入），d为目的操作数（输出）。 def softmax_grad_front ( dx , y , is_fp16 = False ): dx = dx . astype ( np . float32 ) y = y . astype ( np . float32 ) d = ( dx * y ) . sum ( axis =- 1 , keepdims = True ) ###[1024,1] if is_fp16 : d = d . astype ( np . float16 ) return d",
    "函数原型": "template <typename T, bool isBasicBlock = false, bool isDataFormatNZ = false>\n__aicore__ inline void SoftmaxGradFront(const LocalTensor<T>& dstTensor, const LocalTensor<T>& gradTensor, const LocalTensor<T>& srcTensor, const SoftMaxTiling& tiling, const SoftMaxShapeInfo& softmaxShapeInfo = {})",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float Atlas 200I/500 A2 推理产品 ，支持的数据类型为：half/float isBasicBlock srcTensor和gradTensor的shape信息和Tiling切分策略满足基本块要求的情况下，可以使能该参数用于提升性能，默认不使能。是否满足基本块的要求，可以采用如下两种方式之一判断： srcTensor和dstTensor的shape信息[m,n]需要满足如下条件： 尾轴长度n小于2048并且大于等于256/sizeof(T)（即half场景下n最小为128，float场景下n最小为64），同时n是64的倍数； 非尾轴长度的乘积m为8的倍数。 在Tiling实现中，通过调用 IsBasicBlockInSoftMax 判断Tiling切分策略是否满足基本块的切分要求。 针对 Atlas 200I/500 A2 推理产品 ，该参数为预留参数，暂未启用，为后续的功能扩展做保留，保持默认值即可。 isDataFormatNZ 当前输入输出的数据格式是否为NZ格式，默认数据格式为ND，即默认取值为false。 针对 Atlas 200I/500 A2 推理产品 ，不支持配置为NZ格式。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T> class KernelSoftmaxGrad {\npublic:\n    __aicore__ inline KernelSoftmaxGrad() {}\n    __aicore__ inline void Init(__gm__ uint8_t* src1Gm, __gm__ uint8_t* src2Gm, __gm__ uint8_t* dstGm, const SoftMaxTiling& tilingData)\n    {\n        elementNumPerBlk = 32 / sizeof(T);\n        src1Global.SetGlobalBuffer((__gm__ T*)src1Gm);\n        src2Global.SetGlobalBuffer((__gm__ T*)src2Gm);\n        dstGlobal.SetGlobalBuffer((__gm__ T*)dstGm);\n        pipe.InitBuffer(inQueueSrc1, 1, height * width * sizeof(T));\n        pipe.InitBuffer(inQueueSrc2, 1, height * width * sizeof(T));\n        pipe.InitBuffer(outQueueDst, 1, height * elementNumPerBlk * sizeof(T));\n        tiling = tilingData;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal1 = inQueueSrc1.AllocTensor<T>();\n        AscendC::LocalTensor<T> srcLocal2 = inQueueSrc2.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal1, src1Global, height * width);\n        AscendC::DataCopy(srcLocal2, src2Global, height * width);\n        inQueueSrc1.EnQue(srcLocal1);\n        inQueueSrc2.EnQue(srcLocal2);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal1 = inQueueSrc1.DeQue<T>();\n        AscendC::LocalTensor<T> srcLocal2 = inQueueSrc2.DeQue<T>();\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.AllocTensor<T>();\n        AscendC::SoftMaxShapeInfo srcShape = { height, width, height, width };\n        AscendC::SoftmaxGradFront<T>(dstLocal, srcLocal2, srcLocal1, tiling, srcShape);\n        outQueueDst.EnQue<T>(dstLocal);\n        inQueueSrc1.FreeTensor(srcLocal1);\n        inQueueSrc2.FreeTensor(srcLocal2);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueueDst.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, height * elementNumPerBlk);\n        outQueueDst.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc1;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrc2;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueDst;\n    AscendC::GlobalTensor<T> src1Global, src2Global, dstGlobal;\n    uint32_t elementNumPerBlk = 0;\n    uint32_t width = 64;\n    uint32_t height = 128;\n    SoftMaxTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void softmax_grad_kernel_half(__gm__ uint8_t* src1Gm, __gm__ uint8_t* src2Gm, __gm__ uint8_t* dstGm, __gm__ uint8_t* tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelSoftmaxGrad<half> op;\n    op.Init(src1Gm, src2Gm, dstGm, tilingData.softmaxTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SwiGLU",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0776.html",
    "功能说明": "SwiGLU是采用Swish作为激活函数的GLU变体。具体计算公式如下： 其中Swish激活函数的计算公式如下（β为常量）：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void SwiGLU(LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor0, const LocalTensor<T>& srcTensor1, const float& scalarValue, const LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename srcType>\nclass KernelSwiGLU {\npublic:\n    __aicore__ inline KernelSwiGLU(){}\n    __aicore__ inline void Init(GM_ADDR src0Gm, GM_ADDR src1Gm, GM_ADDR dstGm, uint32_t srcSize, float beta)\n    {\n        betaValue = beta;\n        dataSize = srcSize;\n        src0Global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src0Gm), dataSize);\n        src1Global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(src1Gm), dataSize);\n        dst_global.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), dataSize);\n        pipe.InitBuffer(inQueueX, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(inQueueY, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, dataSize * sizeof(srcType));\n        if (sizeof(srcType) != sizeof(float)) {\n            pipe.InitBuffer(calcBufs, dataSize * (sizeof(float) / sizeof(uint8_t)) * 3);\n        }\n\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> src0Local = inQueueX.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> src1Local = inQueueY.AllocTensor<srcType>();\n        AscendC::DataCopy(src0Local, src0Global, dataSize);\n        AscendC::DataCopy(src1Local, src1Global, dataSize);\n        inQueueX.EnQue(src0Local);\n        inQueueY.EnQue(src1Local);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> src0Local = inQueueX.DeQue<srcType>();\n        AscendC::LocalTensor<srcType> src1Local = inQueueY.DeQue<srcType>();\n        AscendC::LocalTensor<uint8_t> tmpLocal;\n        if (sizeof(srcType) != sizeof(float)) {\n            tmpLocal = calcBufs.Get<uint8_t>();\n            AscendC::SwiGLU<srcType, false>(dstLocal, src0Local, src1Local, betaValue, tmpLocal, dataSize);\n        } else {\n            AscendC::SwiGLU<srcType, false>(dstLocal, src0Local, src1Local, betaValue, dataSize);\n        }\n\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(src0Local);\n        inQueueY.FreeTensor(src1Local);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dst_global, dstLocal, dataSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> src0Global;\n    AscendC::GlobalTensor<srcType> src1Global;\n    AscendC::GlobalTensor<srcType> dst_global;\n\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueY;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    AscendC::TBuf<AscendC::TPosition::VECCALC> calcBufs;\n    uint32_t dataSize = 0;\n    float betaValue = 0;\n};\n\ntemplate <typename dataType>\n__aicore__ void kernel_swiglu_operator(GM_ADDR src0Gm, GM_ADDR src1Gm, GM_ADDR dstGm, uint32_t srcSize)\n{\n    KernelSwiGLU<dataType> op;\n    float scalarValue = 1;\n    op.Init(src0Gm, src1Gm, dstGm, srcSize, scalarValue);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Swish",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0783.html",
    "功能说明": "在神经网络中，Swish是一个重要的激活函数。计算公式如下，其中β为常数：",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void Swish(const LocalTensor<T> &dstLocal, const LocalTensor<T> &srcLocal, uint32_t dataSize, const T &scalarValue)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\ntemplate <typename srcType>\nclass KernelSwish\n{\npublic:\n    __aicore__ inline KernelSwish() {}\n    __aicore__ inline void Init(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t inputSize, srcType scalar)\n    {\n        dataSize = inputSize;\n        scalarValue = scalar;\n        srcGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(srcGm), dataSize);\n        dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ srcType *>(dstGm), dataSize);\n        pipe.InitBuffer(inQueueX, 1, dataSize * sizeof(srcType));\n        pipe.InitBuffer(outQueue, 1, dataSize * sizeof(srcType));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.AllocTensor<srcType>();\n        AscendC::DataCopy(srcLocal, srcGlobal, dataSize);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.AllocTensor<srcType>();\n        AscendC::LocalTensor<srcType> srcLocal = inQueueX.DeQue<srcType>();\n        Swish(dstLocal, srcLocal, dataSize, scalarValue);\n        outQueue.EnQue<srcType>(dstLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<srcType> dstLocal = outQueue.DeQue<srcType>();\n        AscendC::DataCopy(dstGlobal, dstLocal, dataSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<srcType> srcGlobal;\n    AscendC::GlobalTensor<srcType> dstGlobal;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    uint32_t dataSize = 0;\n    srcType scalarValue = 0;\n};\ntemplate <typename dataType>\n__aicore__ void kernel_Swish_operator(GM_ADDR srcGm, GM_ADDR dstGm, uint32_t dataSize)\n{\n    KernelSwish<dataType> op;\n    dataType scalarValue = 1.702;\n    op.Init(srcGm, dstGm, dataSize, scalarValue);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Sum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0826.html",
    "功能说明": "获取最后一个维度的元素总和。 如果输入是向量，则在向量中对各元素相加；如果输入是矩阵，则沿最后一个维度对每行中元素求和。 本接口最多支持输入为二维数据，不支持更高维度的输入。 如下图所示，对shape为(2, 3)的二维矩阵进行运算，输出结果为[[ 6] [15]]。 为计算如上过程，引入一些必备概念：行数称之为 外轴长度（outter） ，每行实际的元素个数称之为 内轴的实际元素个数（n） ，存储n个元素所需的字节长度向上补齐到32整数倍后转换的元素个数称之为 补齐后的内轴元素个数 (inner) 。本接口要求输入的内轴长度为32字节的整数倍，所以当n占据的字节长度不是32的整数倍时，需要开发者将其向上补齐到32的整数倍。比如，如下的样例中，元素类型为half，每行的实际元素个数n为3，占据字节长度为6字节，不是32字节的整数倍，向上补齐后得到32字节，转换为元素个数为16。故outter = 2，n =3，inner=16。图中的padding代表补齐操作。n和inner的关系如下： inner = (n *sizeof(T) + 32 - 1) / 32 * 32 / sizeof(T) 。",
    "函数原型": "template <typename T, int32_t reduceDim = -1, bool isReuseSource = false, bool isBasicBlock = false>\n__aicore__ inline void Sum(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const SumParams &sumParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float reduceDim 用于指定按数据的哪一维度进行求和。本接口按最后一个维度实现，不支持reduceDim参数，传入默认值-1即可。 isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 isBasicBlock 预留参数，暂不支持。",
    "返回值": "",
    "调用示例": "AscendC::SumParams params;\nparams.inner = inner;\nparams.outter = outter;\nparams.n = n;\nT scalar(0);\nAscendC::Duplicate<T>(yLocal, scalar, out_inner);\nAscendC::Sum(yLocal, xLocal, sharedTmpBuffer, params);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Mean",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0829.html",
    "功能说明": "根据最后一轴的方向对各元素求平均值。 如果输入是向量，则在向量中对各元素相加求平均；如果输入是矩阵，则沿最后一个维度对元素求平均。 本接口最多支持输入为二维数据，不支持更高维度的输入。 如下图所示，对shape为(4, 5)的二维矩阵进行求平均操作，输出结果为[3， 8， 13， 18]。 在了解接口具体功能之前，需要了解一些必备概念：数据的行数称之为 外轴长度（outter） ，每行实际的元素个数称之为 内轴的实际元素个数（n） ，内轴实际元素个数n向上32字节对齐后的元素个数称之为 补齐后的内轴元素个数 (inner) 。本接口要求输入的内轴长度满足32字节对齐，所以当n占据的字节长度不是32字节的整数倍时，需要开发者将其向上补齐到32字节的整数倍。如下样例中，元素类型为float，每行的实际元素个数n为5，占据字节长度为20字节，不是32字节的整数倍，向上补齐后得到32字节，对应的元素个数为8。图中的padding代表补齐操作。n和inner的关系如下： inner = (n *sizeof(T) + 32 - 1) / 32 * 32 / sizeof(T) 。",
    "函数原型": "template <typename T, typename accType = T, bool isReuseSource = false, bool isBasicBlock = false, int32_t reduceDim = -1>\n__aicore__ inline void Mean(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const MeanParams &meanParams)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float accType 实际参与计算的数据类型，设置的accType精度高于输入T的情况下，在计算之前会将输入转换为accType，使用accType类型计算，计算完成后再转换为原来的数据类型。设置accType值升精度可以防止数据类型溢出。T为half时，您可以将accType设置为float，表示为输入half类型升精度至float进行计算。不支持accType精度低于输入T的情况。 isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。 isBasicBlock 预留参数，暂不支持。 reduceDim 用于指定按数据的哪一维度进行求和。本接口按最后一个维度实现，不支持reduceDim参数，传入默认值-1即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\ntemplate <typename T, typename accType>\nclass KernelMean\n{\npublic:\n    __aicore__ inline KernelMean() {}\n    __aicore__ inline void Init(__gm__ uint8_t *srcGm, __gm__ uint8_t *dstGm, uint32_t outter, uint32_t inner, uint32_t n, uint32_t Size)\n    {\n        meanParams.outter = outter;\n        meanParams.inner = inner;\n        meanParams.n = n;\n        tmpSize = Size;\n        srcGlobal.SetGlobalBuffer((__gm__ T *)srcGm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dstGm);\n        pipe.InitBuffer(inQueueX, 1, meanParams.outter * meanParams.inner * sizeof(T));\n        pipe.InitBuffer(outQueueY, 1, (meanParams.outter * sizeof(T) + AscendC::ONE_BLK_SIZE - 1) / AscendC::ONE_BLK_SIZE * AscendC::ONE_BLK_SIZE);\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueX.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, srcGlobal, meanParams.outter * meanParams.inner);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueX.DeQue<T>();\n        AscendC::LocalTensor<T> dstLocal = outQueueY.AllocTensor<T>();\n        if (tmpSize != 0) {\n            pipe.InitBuffer(tmplocalBuf, tmpSize);\n            AscendC::LocalTensor<uint8_t> tmplocalTensor = tmplocalBuf.Get<uint8_t>();\n            AscendC::Mean<T, accType>(dstLocal, srcLocal, tmplocalTensor, meanParams);\n        } else {\n            AscendC::Mean<T, accType>(dstLocal, srcLocal, meanParams);\n        }\n        outQueueY.EnQue<T>(dstLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueueY.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, (meanParams.outter * sizeof(T) + AscendC::ONE_BLK_SIZE - 1) / AscendC::ONE_BLK_SIZE * AscendC::ONE_BLK_SIZE / sizeof(T));\n        outQueueY.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<T> srcGlobal;\n    AscendC::GlobalTensor<T> dstGlobal;\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueY;\n    AscendC::TBuf<AscendC::TPosition::VECCALC> tmplocalBuf;\n    AscendC::MeanParams meanParams;\n    uint32_t tmpSize;\n};\n\nextern \"C\" __global__ __aicore__ void mean_custom(GM_ADDR x, GM_ADDR y, GM_ADDR workspace, GM_ADDR tiling)\n{\n    GET_TILING_DATA(tiling_data, tiling);\n    if (TILING_KEY_IS(1)) {\n        KernelMean<half, half> op;\n        op.Init(x, y, tiling_data.outter, tiling_data.inner, tiling_data.n, tiling_data.tmpSize);\n        op.Process();\n    } else if (TILING_KEY_IS(2)) {\n        KernelMean<float, float> op;\n        op.Init(x, y, tiling_data.outter, tiling_data.inner, tiling_data.n, tiling_data.tmpSize);\n        op.Process();\n    } else if (TILING_KEY_IS(3)) {\n        KernelMean<half, float> op;\n        op.Init(x, y, tiling_data.outter, tiling_data.inner, tiling_data.n, tiling_data.tmpSize);\n        op.Process();\n    }\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ReduceXorSum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0833.html",
    "功能说明": "按照元素执行Xor（按位异或）运算，并将计算结果ReduceSum求和。 注意： 当最终计算结果 超出int16范围[-32768，32767]后，将输出-32768 或者 32767。",
    "函数原型": "template <typename T, bool isReuseSource = false>\n__aicore__ inline void ReduceXorSum(LocalTensor<T>& dstTensor, const LocalTensor<T>& src0Tensor, const LocalTensor<T>& src1Tensor, LocalTensor<uint8_t>& sharedTmpBuffer, const uint32_t calCount)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 src0Tensor和src1Tensor的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 src0Tensor和src1Tensor的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::TPipe pipe;\nAscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\nAscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueY;\nAscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\nAscendC::TQue<AscendC::TPosition::VECCALC, 1> tmpQue;\n\npipe.InitBuffer(inQueueX, 1, 32 * sizeof(int16_t));\npipe.InitBuffer(inQueueY, 1, 32 * sizeof(int16_t));\npipe.InitBuffer(outQueue, 1, 32);\npipe.InitBuffer(tmpQue, 1, bufferSize);  // bufferSize 通过Host侧tiling参数获取\n\nAscendC::LocalTensor<int16_t> dstLocal = outQueue.AllocTensor<int16_t>();\nAscendC::LocalTensor<int16_t> src0Local = inQueueX.AllocTensor<int16_t>();\nAscendC::LocalTensor<int16_t> src1Local = inQueueY.AllocTensor<int16_t>();\nAscendC::LocalTensor<uint8_t> sharedTmpBuffer = tmpQue.AllocTensor<uint8_t>();\n\n// 不使用输入内存，输入shape信息为32, 算子输入的数据类型为int16_t, 实际计算个数为前32\nAscendC::ReduceXorSum<int16_t, false>(dstLocal, src0Local, src1Local, sharedTmpBuffer, 32);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ReduceSum",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10018.html",
    "功能说明": "对一个多维向量按照指定的维度进行数据累加。 定义指定计算的维度（Reduce轴）为R轴，非指定维度（Normal轴）为A轴。如下图所示，对shape为(2, 3)的二维矩阵进行运算，指定在第一维计算数据的累加，输出结果为[[5, 7, 9]]；指定在第二维计算数据的累加，输出结果为[[6] [15]]。 图1 ReduceSum按第一个维度计算示例 图2 ReduceSum按最后一个维度计算示例",
    "函数原型": "template <class T, class pattern, bool isReuseSource = false>\n__aicore__ inline void ReduceSum(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t srcShape[], bool srcInnerPad)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：float pattern 用于指定ReduceSum计算轴，包括Reduce轴和Normal轴。pattern由与向量维度数量相同的A、R字母组合形成，字母A表示Normal轴，R表示Reduce轴。例如，AR表示对二维向量进行ReduceSum计算：第一维是Normal轴，第二维是Reduce轴，即对第二维进行数据累加的计算。 pattern是定义在AscendC::Pattern::Reduce命名空间下的结构体，其成员变量用户无需关注。 pattern当前只支持取值为AR和RA。 isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 src的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 src的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<float> dstLocal = outQueue.AllocTensor<float>();\nAscendC::LocalTensor<float> srcLocal = inQueue.DeQue<float>();\nAscendC::LocalTensor<uint8_t> tmp = tbuf.Get<uint8_t>();\nuint32_t shape[] = { 2, 8 };\nconstexpr bool isReuse = true;\nAscendC::ReduceSum<float, AscendC::Pattern::Reduce::AR, isReuse>(dstLocal, srcLocal, tmp, shape, true);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ReduceMean",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10157.html",
    "功能说明": "对一个多维向量按照指定的维度求平均值。 定义指定计算的维度（Reduce轴）为R轴，非指定维度（Normal轴）为A轴。如下图所示，对shape为(2, 3)的二维矩阵进行运算，对第一维计算数据求平均值，输出结果为[[2.5, 3.5, 4.5]]；对第二维计算数据求平均值，输出结果为[[2] [5]]。 图1 ReduceMean按第一个维度计算示例 图2 ReduceMean最后一个维度计算示例",
    "函数原型": "template <class T, class pattern, bool isReuseSource = false>\n__aicore__ inline void ReduceMean(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t srcShape[], bool srcInnerPad)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：float pattern 用于指定ReduceMean计算轴，包括Reduce轴和Normal轴。pattern由与向量维度数量相同的A、R字母组合形成，字母A表示Normal轴，R表示Reduce轴。例如，AR表示对二维向量进行ReduceMean计算：第一维是Normal轴，第二维是Reduce轴，即对第二维数据计算求平均值。 pattern是定义在AscendC::Pattern::Reduce命名空间下的结构体，其成员变量用户无需关注。 pattern当前只支持取值为AR和RA，当前用户需要显式指定pattern为AscendC::Pattern::Reduce::AR或者AscendC::Pattern::Reduce::RA。 isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 src的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 src的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<float> dstLocal = outQueue.AllocTensor<float>();\nAscendC::LocalTensor<float> srcLocal = inQueue.DeQue<float>();\nAscendC::LocalTensor<uint8_t> tmp = tbuf.Get<uint8_t>();\nuint32_t shape[] = { 2, 8 };\nconstexpr bool isReuse = true;\nAscendC::ReduceMean<T, AscendC::Pattern::Reduce::AR, isReuse>(dstLocal, srcLocal, tmp, shape, true);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ReduceMax",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10055.html",
    "功能说明": "对一个多维向量在指定的维度求最大值。 定义指定计算的维度（Reduce轴）为R轴，非指定维度（Normal轴）为A轴。如下图所示，对shape为(2, 3)的二维矩阵进行运算，指定在第一维求最大值，输出结果为[[4, 5, 6]]；指定在第二维求最大值，输出结果为[[3] [6]]。 图1 ReduceMax按第一个维度计算示例 图2 ReduceMax按最后一个维度计算示例",
    "函数原型": "template <class T, class pattern, bool isReuseSource = false>\n__aicore__ inline void ReduceMax(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t srcShape[], bool srcInnerPad)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float pattern 用于指定ReduceMax计算轴，包括Reduce轴和Normal轴。pattern由与向量维度数量相同的A、R字母组合形成，字母A表示Normal轴，R表示Reduce轴。例如，AR表示对二维向量进行ReduceMax计算：第一维是Normal轴，第二维是Reduce轴，即对第二维数据求最大值。 pattern是定义在AscendC::Pattern::Reduce命名空间下的结构体，其成员变量用户无需关注。 pattern当前只支持取值为AR和RA。 isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 src的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 src的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<float> dstLocal = outQueue.AllocTensor<float>();\nAscendC::LocalTensor<float> srcLocal = inQueue.DeQue<float>();\nAscendC::LocalTensor<uint8_t> tmp = tbuf.Get<uint8_t>();\nuint32_t shape[] = { 2, 8 };\nconstexpr bool isReuse = true;\nAscendC::ReduceMax<float, AscendC::Pattern::Reduce::AR, isReuse>(dstLocal, srcLocal, tmp, shape, true);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ReduceMin",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10056.html",
    "功能说明": "对一个多维向量在指定的维度求最小值。 定义指定计算的维度（Reduce轴）为R轴，非指定维度（Normal轴）为A轴。如下图所示，对shape为(2, 3)的二维矩阵进行运算，指定在第一维求最小值，输出结果为[[1, 2, 3]]；指定在第二维求最小值，输出结果为[[1] [4]]。 图1 ReduceMin按第一个维度计算示例 图2 ReduceMin按最后一个维度计算示例",
    "函数原型": "template <class T, class pattern, bool isReuseSource = false>\n__aicore__ inline void ReduceMin(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t srcShape[], bool srcInnerPad)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float pattern 用于指定ReduceMin计算轴，包括Reduce轴和Normal轴。pattern由与向量维度数量相同的A、R字母组合形成，字母A表示Normal轴，R表示Reduce轴。例如，AR表示对二维向量进行ReduceMin计算：第一维是Normal轴，第二维是Reduce轴，即对第二维数据求最小值。 pattern是定义在AscendC::Pattern::Reduce命名空间下的结构体，其成员变量用户无需关注。 pattern当前只支持取值为AR和RA。 isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 src的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 src的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<float> dstLocal = outQueue.AllocTensor<float>();\nAscendC::LocalTensor<float> srcLocal = inQueue.DeQue<float>();\nAscendC::LocalTensor<uint8_t> tmp = tbuf.Get<uint8_t>();\nuint32_t shape[] = { 2, 8 };\nconstexpr bool isReuse = true;\nAscendC::ReduceMin<float, AscendC::Pattern::Reduce::AR, isReuse>(dstLocal, srcLocal, tmp, shape, true);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ReduceAny",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10142.html",
    "功能说明": "对一个多维向量在指定的维度求逻辑或。 定义指定计算的维度（Reduce轴）为R轴，非指定维度（Normal轴）为A轴。如下图所示，对shape为(2, 3)的二维矩阵进行运算，指定在第一维求逻辑或，输出结果为[[1, 0, 1]]；指定在第二维求逻辑或，输出结果为[[1] [1]]。 图1 ReduceAny按第一个维度计算示例 图2 ReduceAny按最后一个维度计算示例",
    "函数原型": "template <class T, class pattern, bool isReuseSource = false>\n__aicore__ inline void ReduceAny(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t srcShape[], bool srcInnerPad)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint8_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint8_t/float pattern 用于指定ReduceAny计算轴，包括Reduce轴和Normal轴。pattern由与向量维度数量相同的A、R字母组合形成，字母A表示Normal轴，R表示Reduce轴。例如，AR表示对二维向量进行ReduceAny计算：第一维是Normal轴，第二维是Reduce轴，即对第二维数据求逻辑或。 pattern是定义在AscendC::Pattern::Reduce命名空间下的结构体，其成员变量用户无需关注。 pattern当前只支持取值为AR和RA，当前用户需要显式指定pattern为AscendC::Pattern::Reduce::AR或者AscendC::Pattern::Reduce::RA。 isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 src的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 src的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<float> dstLocal = outQueue.AllocTensor<float>();\nAscendC::LocalTensor<float> srcLocal = inQueue.DeQue<float>();\nAscendC::LocalTensor<uint8_t> tmp = tbuf.Get<uint8_t>();\nuint32_t shape[] = { 2, 8 };\nconstexpr bool isReuse = true;\nAscendC::ReduceAny<float, AscendC::Pattern::Reduce::AR, isReuse>(dstLocal, srcLocal, tmp, shape, true);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ReduceAll",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10145.html",
    "功能说明": "对一个多维向量在指定的维度求逻辑与。 定义指定计算的维度（Reduce轴）为R轴，非指定维度（Normal轴）为A轴。如下图所示，对shape为(2, 3)的二维矩阵进行运算，指定在第一维求逻辑与，输出结果为[[1, 0, 0]]；指定在第二维求逻辑与，输出结果为[[0] [0]]。 图1 ReduceAll按第一个维度计算示例 图2 ReduceAll按最后一个维度计算示例",
    "函数原型": "template <class T, class pattern, bool isReuseSource = false>\n__aicore__ inline void ReduceAll(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t srcShape[], bool srcInnerPad)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint8_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint8_t/float pattern 用于指定ReduceAll计算轴，包括Reduce轴和Normal轴。pattern由与向量维度数量相同的A、R字母组合形成，字母A表示Normal轴，R表示Reduce轴。例如，AR表示对二维向量进行ReduceAll计算：第一维是Normal轴，第二维是Reduce轴，即对第二维数据求逻辑与。 pattern是定义在AscendC::Pattern::Reduce命名空间下的结构体，其成员变量用户无需关注。 pattern当前只支持取值为AR和RA，当前用户需要显式指定pattern为AscendC::Pattern::Reduce::AR或者AscendC::Pattern::Reduce::RA。 isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 src的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 src的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<float> dstLocal = outQueue.AllocTensor<float>();\nAscendC::LocalTensor<float> srcLocal = inQueue.DeQue<float>();\nAscendC::LocalTensor<uint8_t> tmp = tbuf.Get<uint8_t>();\nuint32_t shape[] = { 2, 8 };\nconstexpr bool isReuse = true;\nAscendC::ReduceAll<float, AscendC::Pattern::Reduce::AR, isReuse>(dstLocal, srcLocal, tmp, shape, true);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ReduceProd",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10150.html",
    "功能说明": "对一个多维向量在指定的维度求积。 定义指定计算的维度（Reduce轴）为R轴，非指定维度（Normal轴）为A轴。如下图所示，对shape为(2, 3)的二维矩阵进行运算，指定在第一维求乘积，输出结果为[[4, 10, 18]]；指定在第二维求乘积，输出结果为[[6] [120]]。 图1 ReduceProd按第一个维度计算示例 图2 ReduceProd按最后一个维度计算示例",
    "函数原型": "template <class T, class pattern, bool isReuseSource = false>\n__aicore__ inline void ReduceProd(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, const uint32_t srcShape[], bool srcInnerPad)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：float pattern 用于指定ReduceProd计算轴，包括Reduce轴和Normal轴。pattern由与向量维度数量相同的A、R字母组合形成，字母A表示Normal轴，R表示Reduce轴。例如，AR表示对二维向量进行ReduceProd计算：第一维是Normal轴，第二维是Reduce轴，即对第二维数据求积。 pattern是定义在AscendC::Pattern::Reduce命名空间下的结构体，其成员变量用户无需关注。 pattern当前只支持取值为AR和RA，当前用户需要显式指定pattern为AscendC::Pattern::Reduce::AR或者AscendC::Pattern::Reduce::RA。 isReuseSource 是否允许修改源操作数，默认值为false。如果开发者允许源操作数被改写，可以使能该参数，使能后能够节省部分内存空间。 设置为 true ，则本接口内部计算时 复用 src的内存空间，节省内存空间；设置为 false ，则本接口内部计算时 不复用 src的内存空间。 isReuseSource的使用样例请参考 更多样例 。",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<float> dstLocal = outQueue.AllocTensor<float>();\nAscendC::LocalTensor<float> srcLocal = inQueue.DeQue<float>();\nAscendC::LocalTensor<uint8_t> tmp = tbuf.Get<uint8_t>();\nuint32_t shape[] = { 2, 8 };\nconstexpr bool isReuse = true;\nAscendC::ReduceProd<float, AscendC::Pattern::Reduce::AR, isReuse>(dstLocal, srcLocal, tmp, shape, true);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "TopK",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0836.html",
    "功能说明": "获取最后一个维度的前k个最大值或最小值及其对应的索引。 如果输入是向量，则在向量中找到前k个最大值或最小值及其对应的索引；如果输入是矩阵，则沿最后一个维度计算每行中前k个最大值或最小值及其对应的索引。 本接口最多支持输入为二维数据，不支持更高维度的输入。 如下图所示，对shape为(4, 32)的二维矩阵进行排序，k设置为1，输出结果为[[32] [32] [32] [32]]。 必备概念 基于如上样例，我们引入一些必备概念：行数称之为 外轴长度（outter） ，每行实际的元素个数称之为 内轴的实际长度（n） 。本接口要求输入的内轴长度为32的整数倍，所以当n不是32的整数倍时，需要开发者将其向上补齐到32的整数倍，补齐后的长度称之为 内轴长度（inner） 。比如，如下的样例中，每行的实际长度n为31，不是32的整数倍，向上补齐后得到inner为32，图中的padding代表补齐操作。n和inner的关系如下：当n是32的整数倍时，inner=n；否则，inner > n。 接口模式 本接口支持两种模式： Normal模式 和 Small模式 。Normal模式是通用模式；Small模式是为内轴长度固定为32（单位：元素个数）的场景提供的高性能模式。因为Small模式inner固定为32，可以进行更有针对性的处理，所以相关的约束较少，性能较高。内轴长度inner为32时建议使用Small模式。 附加功能 ：本接口支持开发者指定某些行的排序是无效排序。通过传入finishLocal参数值来控制，finishLocal对应行的值为true时，表示该行排序无效，此时排序后输出的dstIndexLocal的k个索引值会全部被置为无效索引n。",
    "函数原型": "template <typename T, bool isInitIndex = false, bool isHasfinish = false, bool isReuseSrc = false, enum TopKMode topkMode = TopKMode::TOPK_NORMAL>\n__aicore__ inline void TopK(const LocalTensor<T> &dstValueLocal, const LocalTensor<int32_t> &dstIndexLocal, const LocalTensor<T> &srcLocal, const LocalTensor<int32_t> &srcIndexLocal, const LocalTensor<bool> &finishLocal, const int32_t k, const TopkTiling &tilling, const TopKInfo &topKInfo, const bool isLargest = true)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 待排序数据的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isInitIndex 是否传入输入数据的索引。 true表示传入，设置为true时，需要通过srcIndexLocal参数传入输入数据的索引，具体规则请参考 表2 中的srcIndexLocal参数说明。 false表示不传入，TopK API输出的索引不可用。 isHasfinish Topk接口支持开发者通过finishLocal参数来指定某些行的排序是无效排序。该模板参数用于控制是否启用上述功能，true表示启用，false表示不启用。 Normal模式支持的取值：true / false Small模式支持的取值：false isHasfinish参数和finishLocal的配套使用方法请参考 表2 中的finishLocal参数说明。 isReuseSrc 是否允许修改源操作数。该参数预留，传入默认值false即可。 topkMode Topk的模式选择，数据结构如下： enum class TopKMode { TOPK_NORMAL , // Normal模式 TOPK_NSMALL , // Small模式 };",
    "返回值": "",
    "调用示例": "if (!tmpLocal) {  // 是否通过tmpLocal入参传入临时空间\n    if (isSmallMode) { // Small模式\n        AscendC::TopK<T, isInitIndex, isHasfinish, isReuseSrc, AscendC::TopKMode::TOPK_NSMALL>(dstLocalValue,\n            dstLocalIndex, srcLocalValue, srcLocalIndex, srcLocalFinish, k, topKTilingData, topKInfo, isLargest);\n    } else {\n        AscendC::TopK<T, isInitIndex, isHasfinish, isReuseSrc, AscendC::TopKMode::TOPK_NORMAL>(dstLocalValue,\n            dstLocalIndex, srcLocalValue, srcLocalIndex, srcLocalFinish, k, topKTilingData, topKInfo, isLargest);\n    }\n} else {\n    if (tmplocalBytes % 32 != 0) {\n        tmplocalBytes = (tmplocalBytes + 31) / 32 * 32;\n    }\n    pipe.InitBuffer(tmplocalBuf, tmplocalBytes);\n    AscendC::LocalTensor<uint8_t> tmplocalTensor = tmplocalBuf.Get<uint8_t>();\n    if (isSmallMode) {\n        AscendC::TopK<T, isInitIndex, isHasfinish, isReuseSrc, AscendC::TopKMode::TOPK_NSMALL>(dstLocalValue,\n            dstLocalIndex, srcLocalValue, srcLocalIndex, srcLocalFinish, tmplocalTensor, k, topKTilingData, topKInfo, isLargest);\n    } else {\n        AscendC::TopK<T, isInitIndex, isHasfinish, isReuseSrc, AscendC::TopKMode::TOPK_NORMAL>(dstLocalValue,\n            dstLocalIndex, srcLocalValue, srcLocalIndex, srcLocalFinish, tmplocalTensor, k, topKTilingData, topKInfo, isLargest);\n    }\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Concat",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0839.html",
    "功能说明": "对数据进行预处理，将要排序的源操作数srcLocal一一对应的合入目标数据concatLocal中，数据预处理完后，可以进行 Sort 。",
    "函数原型": "template <typename T>\n__aicore__ inline void Concat(LocalTensor<T> &concatLocal, const LocalTensor<T> &srcLocal, const LocalTensor<T> &tmpLocal, const int32_t repeatTimes)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float\n\n表2 参数说明 参数名 输入/输出 描述 concatLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 srcLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 tmpLocal 输入 临时空间。接口内部复杂计算时用于存储中间变量，由开发者提供，临时空间大小的获取方式请参考 GetConcatTmpSize 。数据类型与源操作数保持一致。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 repeatTimes 输入 重复迭代次数，int32_t类型，每次迭代处理16个元素，下次迭代跳至相邻的下一组16个元素。取值范围：repeatTimes∈[0,255]。",
    "返回值": "",
    "调用示例": "请参见 MrgSort 的 调用示例 。 父主题： Sort 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Extract",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0841.html",
    "功能说明": "处理Sort的结果数据，输出排序后的value和index。",
    "函数原型": "template <typename T>\n__aicore__ inline void Extract(const LocalTensor<T> &dstValueLocal, const LocalTensor<uint32_t> &dstIndexLocal, const LocalTensor<T> &sortedLocal, const int32_t repeatTimes)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float\n\n表2 参数说明 参数名 输入/输出 含义 dstValueLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 dstIndexLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 此源操作数固定为uint32_t数据类型。 sortedLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 源操作数的数据类型需要与目的操作数保持一致。 repeatTimes 输入 重复迭代次数，int32_t类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，每次迭代处理64个float类型数据或128个half类型数据 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，每次迭代处理64个float类型数据或128个half类型数据 Atlas 推理系列产品 AI Core ，每次迭代完成16个Region Proposals的元素抽取并排布到16个元素里，下次迭代跳至相邻的下一组16个Region Proposals和下一组16个元素 取值范围：repeatTimes∈[0,255]。",
    "返回值": "",
    "调用示例": "请参见 MrgSort 的调用示例。 父主题： Sort 版权所有 © 2021-2025华为技术有限公司 保留一切权利 粤A2-20044005号 法律声明 隐私政策 Cookie协议 用户协议 联系我们",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Sort",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0842.html",
    "功能说明": "排序函数，按照数值大小进行降序排序。排序后的数据按照如下排布方式进行保存： Atlas A3 训练系列产品/Atlas A3 推理系列产品 采用方式一 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 采用方式一 Atlas 推理系列产品 AI Core 采用方式二 排布方式一： 一次迭代可以完成32个数的排序，排序好的score与其对应的index一起以（score, index）的结构存储在dstLocal中。不论score为half还是float类型，dstLocal中的（score, index）结构总是占据8Bytes空间。如下所示： 当score为float，index为uint32类型时，计算结果中index存储在高4Bytes，score存储在低4Bytes。 当score为half，index为uint32类型时，计算结果中index存储在高4Bytes，score存储在低2Bytes， 中间的2Bytes保留。 排布方式二：Region Proposal排布 输入输出数据均为Region Proposal，一次迭代可以完成16个region proposal的排序。每个Region Proposal占用连续8个half/float类型的元素，约定其格式： [ x1 , y1 , x2 , y2 , score , label , reserved_0 , reserved_1 ] 对于数据类型half，每一个Region Proposal占16Bytes，Byte[15:12]是无效数据，Byte[11:0]包含6个half类型的元素，其中Byte[11:10]定义为label，Byte[9:8]定义为score，Byte[7:6]定义为y2，Byte[5:4]定义为x2，Byte[3:2]定义为y1，Byte[1:0]定义为x1。 如下图所示，总共包含16个Region Proposals。 对于数据类型float，每一个Region Proposal占32Bytes，Byte[31:24]是无效数据，Byte[23:0]包含6个float类型的元素，其中Byte[23:20]定义为label，Byte[19:16]定义为score，Byte[15:12]定义为y2，Byte[11:8]定义为x2，Byte[7:4]定义为y1，Byte[3:0]定义为x1。 如下图所示，总共包含16个Region Proposals。",
    "函数原型": "template <typename T, bool isFullSort>\n__aicore__ inline void Sort(const LocalTensor<T> &dstLocal, const LocalTensor<T> &concatLocal, const LocalTensor<uint32_t> &indexLocal, LocalTensor<T> &tmpLocal, const int32_t repeatTimes)",
    "参数说明": "表1 模板参数说明 参数名 含义 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isFullSort 是否开启全排序模式。全排序模式指将全部输入降序排序，非全排序模式下，排序方式请参考 表2 中的repeatTimes说明。\n\n表2 参数说明 参数名称 输入/输出 含义 dstLocal 输出 目的操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 concatLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 此源操作数的数据类型需要与目的操作数保持一致。 indexLocal 输入 源操作数。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 此源操作数固定为uint32_t数据类型。 tmpLocal 输入 临时空间。接口内部复杂计算时用于存储中间变量，由开发者提供，临时空间大小BufferSize的获取方式请参考 GetSortTmpSize 。数据类型与源操作数保持一致。 类型为 LocalTensor ，支持的TPosition为VECIN/VECCALC/VECOUT。 LocalTensor的起始地址需要32字节对齐。 repeatTimes 输入 重复迭代次数，int32_t类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ：每次迭代完成32个元素的排序，下次迭代concatLocal和indexLocal各跳过32个elements，dstLocal跳过32*8 Byte空间。取值范围：repeatTimes∈[0,255]。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ：每次迭代完成32个元素的排序，下次迭代concatLocal和indexLocal各跳过32个elements，dstLocal跳过32*8 Byte空间。取值范围：repeatTimes∈[0,255]。 Atlas 推理系列产品 AI Core ：每次迭代完成16个region proposal的排序，下次迭代concatLocal和dstLocal各跳过16个region proposal。取值范围：repeatTimes∈[0,255]。",
    "返回值": "",
    "调用示例": "uint32_t elementCount = 128;\nuint32_t m_sortRepeatTimes = m_elementCount / 32;\nuint32_t m_extractRepeatTimes = m_elementCount / 32;\nAscendC::Concat(concatLocal, valueLocal, concatTmpLocal, m_concatRepeatTimes);\nAscendC::Sort<T, isFullSort>(sortedLocal, concatLocal, indexLocal, sortTmpLocal, m_sortRepeatTimes);\nAscendC::Extract(dstValueLocal, dstIndexLocal, sortedLocal, m_extractRepeatTimes);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "MrgSort",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0847.html",
    "功能说明": "将已经排好序的最多4条队列，合并排列成1条队列，结果按照score域由大到小排序，排布方式如下： Atlas A3 训练系列产品/Atlas A3 推理系列产品 采用方式一 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 采用方式一 Atlas 推理系列产品 AI Core 采用方式二 排布方式一： MrgSort处理的数据一般是经过Sort处理后的数据，也就是Sort接口的输出，队列的结构如下所示： 数据类型为float，每个结构占据8Bytes。 数据类型为half，每个结构也占据8Bytes，中间有2Bytes保留。 排布方式二：Region Proposal排布 输入输出数据均为Region Proposal，具体请参见 Sort 中的排布方式二。",
    "函数原型": "template <typename T, bool isExhaustedSuspension = false>\n__aicore__ inline void MrgSort(const LocalTensor<T> &dstLocal, const MrgSortSrcList<T> &sortList, const uint16_t elementCountList[4], uint32_t sortedNum[4], uint16_t validBit, const int32_t repeatTimes)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isExhaustedSuspension 某条队列耗尽（即该队列已经全部排序到目的操作数）后，是否需要停止合并。类型为bool，参数取值如下： false：直到所有队列耗尽完才停止合并。 true：某条队列耗尽后，停止合并。 默认值为false。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\ntemplate <typename T>\nclass FullSort\n{\npublic:\n    __aicore__ inline FullSort() {}\n    __aicore__ inline void Init(__gm__ uint8_t *srcValueGm, __gm__ uint8_t *srcIndexGm, __gm__ uint8_t *dstValueGm, __gm__ uint8_t *dstIndexGm)\n    {\n        concatRepeatTimes = elementCount / 16;\n        inBufferSize = elementCount * sizeof(uint32_t);\n        outBufferSize = elementCount * sizeof(uint32_t);\n        calcBufferSize = elementCount * 8;\n        tmpBufferSize = elementCount * 8;\n        sortedLocalSize = elementCount * 4;\n        sortRepeatTimes = elementCount / 32;\n        extractRepeatTimes = elementCount / 32;\n        sortTmpLocalSize = elementCount * 4;\n        valueGlobal.SetGlobalBuffer((__gm__ T *)srcValueGm);\n        indexGlobal.SetGlobalBuffer((__gm__ uint32_t *)srcIndexGm);\n        dstValueGlobal.SetGlobalBuffer((__gm__ T *)dstValueGm);\n        dstIndexGlobal.SetGlobalBuffer((__gm__ uint32_t *)dstIndexGm);\n        pipe.InitBuffer(queIn, 2, inBufferSize);\n        pipe.InitBuffer(queOut, 2, outBufferSize);\n        pipe.InitBuffer(queCalc, 1, calcBufferSize * sizeof(T));\n        pipe.InitBuffer(queTmp, 2, tmpBufferSize * sizeof(T));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> valueLocal = queIn.AllocTensor<T>();\n        AscendC::DataCopy(valueLocal, valueGlobal, elementCount);\n        queIn.EnQue(valueLocal);\n        AscendC::LocalTensor<uint32_t> indexLocal = queIn.AllocTensor<uint32_t>();\n        AscendC::DataCopy(indexLocal, indexGlobal, elementCount);\n        queIn.EnQue(indexLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> valueLocal = queIn.DeQue<T>();\n        AscendC::LocalTensor<uint32_t> indexLocal = queIn.DeQue<uint32_t>();\n        AscendC::LocalTensor<T> sortedLocal = queCalc.AllocTensor<T>();\n        AscendC::LocalTensor<T> concatTmpLocal = queTmp.AllocTensor<T>();\n        AscendC::LocalTensor<T> sortTmpLocal = queTmp.AllocTensor<T>();\n        AscendC::LocalTensor<T> dstValueLocal = queOut.AllocTensor<T>();\n        AscendC::LocalTensor<uint32_t> dstIndexLocal = queOut.AllocTensor<uint32_t>();\n        AscendC::LocalTensor<T> concatLocal;\n\n        AscendC::Concat(concatLocal, valueLocal, concatTmpLocal, concatRepeatTimes);\n        AscendC::Sort<T, false>(sortedLocal, concatLocal, indexLocal, sortTmpLocal, sortRepeatTimes);\n        uint32_t singleMergeTmpElementCount = elementCount / 4;\n        uint32_t baseOffset = AscendC::GetSortOffset<T>(singleMergeTmpElementCount);\n        AscendC::MrgSortSrcList sortList = AscendC::MrgSortSrcList(sortedLocal[0], sortedLocal[baseOffset], sortedLocal[2 * baseOffset], sortedLocal[3 * baseOffset]);\n        uint16_t singleDataSize = elementCount / 4;\n        const uint16_t elementCountList[4] = {singleDataSize, singleDataSize, singleDataSize, singleDataSize};\n        uint32_t sortedNum[4];\n        AscendC::MrgSort<T, false>(sortTmpLocal, sortList, elementCountList, sortedNum, 0b1111, 1);\n        AscendC::Extract(dstValueLocal, dstIndexLocal, sortTmpLocal, extractRepeatTimes);\n\n        queTmp.FreeTensor(concatTmpLocal);\n        queTmp.FreeTensor(sortTmpLocal);\n        queIn.FreeTensor(valueLocal);\n        queIn.FreeTensor(indexLocal);\n        queCalc.FreeTensor(sortedLocal);\n        queOut.EnQue(dstValueLocal);\n        queOut.EnQue(dstIndexLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstValueLocal = queOut.DeQue<T>();\n        AscendC::LocalTensor<uint32_t> dstIndexLocal = queOut.DeQue<uint32_t>();\n        AscendC::DataCopy(dstValueGlobal, dstValueLocal, elementCount);\n        AscendC::DataCopy(dstIndexGlobal, dstIndexLocal, elementCount);\n        queOut.FreeTensor(dstValueLocal);\n        queOut.FreeTensor(dstIndexLocal);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 2> queIn;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 2> queOut;\n    AscendC::TQue<AscendC::TPosition::VECIN, 2> queTmp;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> queCalc;\n    AscendC::GlobalTensor<T> valueGlobal;\n    AscendC::GlobalTensor<uint32_t> indexGlobal;\n    AscendC::GlobalTensor<T> dstValueGlobal;\n    AscendC::GlobalTensor<uint32_t> dstIndexGlobal;\n    uint32_t elementCount = 128;\n    uint32_t concatRepeatTimes;\n    uint32_t inBufferSize;\n    uint32_t outBufferSize;\n    uint32_t calcBufferSize;\n    uint32_t tmpBufferSize;\n    uint32_t sortedLocalSize;\n    uint32_t sortTmpLocalSize;\n    uint32_t sortRepeatTimes;\n    uint32_t extractRepeatTimes;\n};\n\nextern \"C\" __global__ __aicore__ void sort_operator(__gm__ uint8_t *src0Gm, __gm__ uint8_t *src1Gm, __gm__ uint8_t *dst0Gm, __gm__ uint8_t *dst1Gm)\n{\n    FullSort<half> op;\n    op.Init(src0Gm, src1Gm, dst0Gm, dst1Gm);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Broadcast",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0853.html",
    "功能说明": "将输入按照输出shape进行广播。 比如A的shape为(2,1)，广播的目标shape为(2,16)，则会将原来的一列扩展为相同的16列。 输入数据： [[ 1 ] [ 2 ]] 输出数据： [[ 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ] [ 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ]]",
    "函数原型": "template <typename T, int32_t dim, int32_t axis, bool isReuseSource = false>\n__aicore__ inline void Broadcast(const LocalTensor<T> &dstLocal, const LocalTensor<T> &srcLocal, const uint32_t dstShape[dim], const uint32_t srcShape[dim], LocalTensor<uint8_t> &sharedTmpBuffer)",
    "参数说明": "表1 模板参数说明 参数名称 功能 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint8_t/int8_t/half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint8_t/int8_t/half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：uint8_t/int8_t/half/float dim 输入/输出tensor的维度，目前仅支持1维和2维。 axis 要广播的维度，目前仅支持0和1。 isReuseSource 是否允许修改源操作数。该参数预留，传入默认值false即可。",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T, int32_t dim, int32_t axis>\nclass KernelBroadcast {\npublic:\n    __aicore__ inline KernelBroadcast()\n    {}\n    __aicore__ inline void Init(\n        GM_ADDR srcGm, GM_ADDR dstGm, const uint32_t dstShape[dim], const uint32_t srcShape[dim])\n    {\n        for (uint32_t i = 0; i < dim; i++) {\n            srcSize *= srcShape[i];\n            dstSize *= dstShape[i];\n        }\n        srcGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ T *>(srcGm), srcSize);\n        dstGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ T *>(dstGm), dstSize);\n\n        pipe.InitBuffer(inQueueX, 1, srcSize * sizeof(T));\n        pipe.InitBuffer(outQueue, 1, dstSize * sizeof(T));\n        dstShape_ = dstShape;\n        srcShape_ = srcShape;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueX.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, srcGlobal, srcSize);\n        inQueueX.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueue.AllocTensor<T>();\n        AscendC::LocalTensor<T> srcLocal = inQueueX.DeQue<T>();\n        AscendC::Broadcast<T, dim, axis>(dstLocal, srcLocal, dstShape_, srcShape_);\n\n        outQueue.EnQue<T>(dstLocal);\n        inQueueX.FreeTensor(srcLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> dstLocal = outQueue.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, dstLocal, dstSize);\n        outQueue.FreeTensor(dstLocal);\n    }\n\nprivate:\n    AscendC::GlobalTensor<T> srcGlobal;\n    AscendC::GlobalTensor<T> dstGlobal;\n\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueue;\n    const uint32_t *dstShape_{nullptr};\n    const uint32_t *srcShape_{nullptr};\n    int32_t srcSize{1};\n    int32_t dstSize{1};\n};\n\ntemplate <typename T, int32_t dim, int32_t axis>\n__aicore__ void kernel_broadcast_operator(\n    GM_ADDR srcGm, GM_ADDR dstGm, const uint32_t dstShape[dim], const uint32_t srcShape[dim])\n{\n    KernelBroadcast<T, dim, axis> op;\n    op.Init(srcGm, dstGm, dstShape, srcShape);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Pad",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0849.html",
    "功能说明": "对height * width的二维Tensor在width方向上pad到32B对齐，如果Tensor的width已32B对齐，且全部为有效数据，则不支持调用本接口对齐。本接口具体功能场景如下： 场景1 Tensor的width非32B对齐，以half为例，如16*15，进行Pad，右边补1列，变成16*16。 场景2 Tensor的width已32B对齐，但是有部分冗余数据，以half为例，如16*16（最后两列为冗余数据），进行Pad，仍为16*16，但是最后两列冗余数据可以被填充成设定的值。",
    "函数原型": "template <typename T>\n__aicore__ inline void Pad(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, PadParams &padParams, const LocalTensor<uint8_t> &sharedTmpBuffer, PadTiling &tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T>\nclass KernelPad {\npublic:\n    __aicore__ inline KernelPad()\n    {}\n    __aicore__ inline void Init(GM_ADDR dstGm, GM_ADDR srcGm, uint32_t heightIn, uint32_t widthIn, uint32_t oriWidthIn,\n        AscendC::PadParams &padParamsIn, const PadTiling &tilingData)\n    {\n        height = heightIn;\n        width = widthIn;\n        oriWidth = oriWidthIn;\n        padParams = padParamsIn;\n        srcGlobal.SetGlobalBuffer((__gm__ T *)srcGm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dstGm);\n        pipe.InitBuffer(inQueueSrcVecIn, 1, height * width * sizeof(T));\n        alignedWidth = ((width * sizeof(T) - 1) / 32 + 1) * 32 / sizeof(T);\n        pipe.InitBuffer(inQueueSrcVecOut, 1, height * alignedWidth * sizeof(T));\n        tiling = tilingData;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrcVecIn.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, srcGlobal, height * width);\n        inQueueSrcVecIn.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> dstLocal = inQueueSrcVecIn.DeQue<T>();\n        AscendC::LocalTensor<T> srcOutLocal = inQueueSrcVecOut.AllocTensor<T>();\n        AscendC::Pad(srcOutLocal, dstLocal, padParams, tiling);\n        inQueueSrcVecOut.EnQue(srcOutLocal);\n        inQueueSrcVecIn.FreeTensor(dstLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> srcOutLocalDe = inQueueSrcVecOut.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, srcOutLocalDe, height * alignedWidth);\n        inQueueSrcVecOut.FreeTensor(srcOutLocalDe);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrcVecIn;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> inQueueSrcVecOut;\n    AscendC::GlobalTensor<T> srcGlobal;\n    AscendC::GlobalTensor<T> dstGlobal;\n    uint32_t height;\n    uint32_t width;\n    uint32_t oriWidth;\n    uint32_t alignedWidth;\n    AscendC::PadParams padParams;\n    PadTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void kernel_pad_half_16_15_15(GM_ADDR src_gm, GM_ADDR dst_gm, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelPad<half> op;\n    AscendC::PadParams padParams{0, 1, 321};\n    op.Init(dst_gm, src_gm, 16, 15, 15, padParams, tilingData.padTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "UnPad",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0851.html",
    "功能说明": "对height * width的二维Tensor在width方向上进行unpad，如果Tensor的width非32B对齐，则不支持调用本接口unpad。本接口具体功能场景如下：Tensor的width已32B对齐，以half为例，如16*16，进行UnPad，变成16*15。",
    "函数原型": "template <typename T>\n__aicore__ inline void UnPad(const LocalTensor<T> &dstTensor, const LocalTensor<T> &srcTensor, UnPadParams &unPadParams, LocalTensor<uint8_t> &sharedTmpBuffer, UnPadTiling &tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\ntemplate <typename T>\nclass KernelUnPad {\npublic:\n    __aicore__ inline KernelUnPad()\n    {}\n    __aicore__ inline void Init(GM_ADDR dstGm, GM_ADDR srcGm, uint16_t heightIn, uint16_t widthIn, uint16_t oriWidthIn,\n        AscendC::UnPadParams &unPadParamsIn, const UnPadTiling &tilingData)\n    {\n        height = heightIn;\n        width = widthIn;\n        oriWidth = oriWidthIn;\n        unPadParams = unPadParamsIn;\n        srcGlobal.SetGlobalBuffer((__gm__ T *)srcGm);\n        dstGlobal.SetGlobalBuffer((__gm__ T *)dstGm);\n        pipe.InitBuffer(inQueueSrcVecIn, 1, height * width * sizeof(T));\n        pipe.InitBuffer(inQueueSrcVecOut, 1, height * (width - unPadParams.leftPad - unPadParams.rightPad) * sizeof(T));\n        tiling = tilingData;\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\n\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<T> srcLocal = inQueueSrcVecIn.AllocTensor<T>();\n        AscendC::DataCopy(srcLocal, srcGlobal, height * width);\n        inQueueSrcVecIn.EnQue(srcLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<T> dstLocal = inQueueSrcVecIn.DeQue<T>();\n        AscendC::LocalTensor<T> srcOutLocal = inQueueSrcVecOut.AllocTensor<T>();\n        AscendC::UnPad(srcOutLocal, dstLocal, unPadParams, tiling);\n        inQueueSrcVecOut.EnQue(srcOutLocal);\n        inQueueSrcVecIn.FreeTensor(dstLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<T> srcOutLocalDe = inQueueSrcVecOut.DeQue<T>();\n        AscendC::DataCopy(dstGlobal, srcOutLocalDe, height * (width - unPadParams.leftPad - unPadParams.rightPad));\n        inQueueSrcVecOut.FreeTensor(srcOutLocalDe);\n    }\n\nprivate:\n    AscendC::TPipe pipe;\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrcVecIn;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> inQueueSrcVecOut;\n    AscendC::GlobalTensor<T> srcGlobal;\n    AscendC::GlobalTensor<T> dstGlobal;\n    uint16_t height;\n    uint16_t width;\n    uint16_t oriWidth;\n    AscendC::UnPadParams unPadParams;\n    UnPadTiling tiling;\n};\n\nextern \"C\" __global__ __aicore__ void\n    kernel_unpad_half_16_16_16(GM_ADDR src_gm, GM_ADDR dst_gm, __gm__ uint8_t *tiling)\n{\n    GET_TILING_DATA(tilingData, tiling);\n    KernelUnPad<half> op;\n    AscendC::UnPadParams unPadParams{0, 1};\n    op.Init(dst_gm, src_gm, 16, 16, 16, unPadParams, tilingData.unpadTilingData);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "DropOut",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0862.html",
    "功能说明": "提供根据MaskTensor对SrcTensor（源操作数，输入Tensor）进行过滤的功能，得到DstTensor（目的操作数、输出Tensor）。仅支持输入shape为ND格式。 该过滤功能包括两种模式， 字节模式 和 比特模式 。 字节模式 MaskTensor中存储的数值为布尔类型，每个布尔数值代表是否取用SrcTensor对应位置的数值：如果是，则选取SrcTensor中的数值存入DstTensor；否则，对DstTensor中的对应位置赋值为零。DstTensor，SrcTensor和MaskTensor的shape相同。示例如下： SrcTensor=[1，2，3，4，5，6，7，8，9，10] MaskTensor=[1，0，1，0，1，0，0，1，1，0]（每个数的数据类型为uint8_t） DstTensor=[1，0，3，0，5，0，0，8，9，0] 比特模式 MaskTensor的每个bit数值，代表是否取用SrcTensor对应位置的数值：如果是，则选取SrcTensor中的数值存入DstTensor；否则，对DstTensor中的对应位置赋值为零。SrcTensor和DstTensor的shape相同，假设均为[height ， width]，MaskTensor的shape为[height ， (width / 8)]。示例如下： SrcTensor=[1，2，3，4，5，6，7，8] MaskTensor=[169]（转换为二进制表示为1010 1001） DstTensor=[1，0，3，0，5，0，0，8] 特殊情况1：当MaskTensor有效数据非连续存放时，MaskTensor的width轴，为了满足32B对齐，需要填充无效数值，SrcTensor的width轴，需满足32Byte对齐。示例如下： SrcTensor=[1，2，3，4，5，6，7，8，11，12，13，14，15，16，17，18] MaskTensor=[1，0，1，0，1，0，0，1，X，X，1，0，1，0，1，0，0，1，X，X]（X为无效数值，假设数据已满足对齐要求，示例数值为二进制形式表示） DstTensor=[1，0，3，0，5，0，0，8，11，0， 13， 0， 15， 0， 0，18] 特殊情况2：当MaskTensor有效数据连续存放，maskTensor_size不满足32B对齐时，需要在MaskTensor的尾部补齐32B对齐时，对应SrcTensor的尾部也需要补充无效数据，使得srcTensor_size满足32B对齐。示例如下： SrcTensor=[1，2，3，4，5，6，7，8，11，12，13，14，15，16，17，18] MaskTensor=[1，0，1，0，1，0，0，1， 1， 0， 1， 0， 1， 0， 0， 1，X，X，X，X]（X为无效数值，假设数据已满足对齐要求，示例数值为二进制形式表示） DstTensor= [1，0，3，0，5，0，0，8， 11， 0， 13， 0， 15， 0， 0， 18]",
    "函数原型": "template <typename T, bool isInitBitMode = false, uint32_t dropOutMode = 0>\n__aicore__ inline void DropOut(const LocalTensor<T>& dstLocal, const LocalTensor<T>& srcLocal, const LocalTensor<uint8_t>& maskLocal, const float keepProb, const DropOutShapeInfo& info)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float isInitBitMode 在比特模式下，是否需要在接口内部初始化（默认false）。 dropOutMode 选择执行何种输入场景： 0：默认值，由接口根据输入shape推断运行模式，注意，推断不符合预期的场景，需设置对应模式 1：执行字节模式，且maskLocal含有脏数据 2：执行字节模式，且maskLocal不含有脏数据 3：执行比特模式，且maskLocal不含有脏数据 4：执行比特模式，且maskLocal含有脏数据",
    "返回值": "",
    "调用示例": "AscendC::DropOutShapeInfo info;\nfloat probValue = 0.8;\ninfo.firstAxis = tilingData.firstAxis / tilingData.tileNum;\ninfo.srcLastAxis = tileLength;\ninfo.maskLastAxis = tileLength;\nAscendC::DropOut(yLocal, xLocal, maskLocal, sharedTmpBuffer, probValue, info)",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "SelectWithBytesMask",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0859.html",
    "功能说明": "给定两个源操作数src0和src1，根据maskTensor相应位置的值（非bit位）选取元素，得到目的操作数dst。选择的规则为：当Mask的值为0时，从src0中选取，否则从src1选取。 该接口支持多维Shape，需满足maskTensor和源操作数Tensor的前轴（非尾轴）元素个数相同，且maskTensor尾轴元素个数大于等于源操作数尾轴元素个数，maskTensor多余部分丢弃不参与计算。 maskTensor尾轴需32字节对齐且元素个数为16的倍数。 源操作数Tensor尾轴需32字节对齐。 如下图样例，源操作数src0为Tensor，shape为(2,16)，数据类型为half，尾轴长度满足32字节对齐；源操作数src1为scalar，数据类型为half；maskTensor的数据类型为bool，为满足对齐要求shape为(2,32)，仅有图中蓝色部分的mask掩码生效，灰色部分不参与计算。输出目的操作数dstTensor如下图所示。",
    "函数原型": "template <typename T, typename U, bool isReuseMask = true>\n__aicore__ inline void SelectWithBytesMask(const LocalTensor<T> &dst, const LocalTensor<T> &src0, T src1, const LocalTensor<U> &mask, const LocalTensor<uint8_t> &sharedTmpBuffer, const SelectWithBytesMaskShapeInfo &info)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float U 掩码Tensor mask的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：bool/uint8_t/int8_t/uint16_t/int16_t/uint32_t/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：bool/uint8_t/int8_t/uint16_t/int16_t/uint32_t/int32_t Atlas 推理系列产品 AI Core ，支持的数据类型为：bool/uint8_t/int8_t/uint16_t/int16_t/uint32_t/int32_t isReuseMask 是否允许修改maskTensor。默认为true。 取值为true时，仅在maskTensor尾轴元素个数和srcTensor尾轴元素个数不同的情况下，maskTensor可能会被修改；其余场景，maskTensor不会修改。 取值为false时，任意场景下，maskTensor均不会修改，但可能会需要更多的临时空间。",
    "返回值": "",
    "调用示例": "AscendC::SelectWithBytesMaskShapeInfo info;\nsrcLocal1 = inQueueX1.DeQue<srcType>();\nmaskLocal = maskQueue.DeQue<maskType>();\nAscendC::LocalTensor<uint8_t> tmpBuffer = sharedTmpBuffer.Get<uint8_t>();\ndstLocal = outQueue.AllocTensor<srcType>();\nAscendC::SelectWithBytesMask(dstLocal, srcLocal1, scalar, maskLocal, tmpBuffer, info);\noutQueue.EnQue<srcType>(dstLocal);\nmaskQueue.FreeTensor(maskLocal);\ninQueueX1.FreeTensor(srcLocal1);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ConfusionTranspose",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0865.html",
    "功能说明": "对输入数据进行数据排布及Reshape操作，具体功能如下： 【场景1：NZ2ND，1、2轴互换】 输入Tensor { shape:[B, N, H/N/16, S/16, 16, 16], origin_shape:[B, N, S, H/N], format:\"NZ\", origin_format:\"ND\"} 输出Tensor { shape:[B, S, N, H/N], origin_shape:[B, S, N, H/N], format:\"ND\", origin_format:\"ND\"} 图1 场景1数据排布变换 【场景2：NZ2NZ，1、2轴互换】 输入Tensor { shape:[B, N, H/N/16, S/16, 16, 16], origin_shape:[B, N, S, H/N], format:\"NZ\", origin_format:\"ND\"} 输出Tensor { shape:[B, S, H/N/16, N/16, 16, 16], origin_shape:[B, S, N, H/N], format:\"NZ\", origin_format:\"ND\"} 图2 场景2数据排布变换 【场景3：NZ2NZ，尾轴切分】 输入Tensor { shape:[B, H / 16, S / 16, 16, 16], origin_shape：[B, S, H], format:\"NZ\", origin_format:\"ND\"} 输出Tensor { shape:[B, N, H/N/16, S / 16, 16, 16], origin_shape:[B, N, S, H/N], format:\"NZ\", origin_format:\"ND\"} 图3 场景3数据排布变换 【场景4：NZ2ND，尾轴切分】 输入Tensor { shape:[B, H / 16, S / 16, 16, 16], origin_shape:[B, S, H], format:\"NZ\", origin_format:\"ND\"} 输出Tensor { shape:[B, N, S, H/N], origin_shape:[B, N, S, H/N], format:\"ND\", origin_format:\"ND\"} 图4 场景4数据排布变换 【场景5：NZ2ND，尾轴合并】 输入Tensor { shape:[B, N, H/N/16, S/16, 16, 16], origin_shape:[B, N, S, H/N], format:\"NZ\", origin_format:\"ND\"} 输出Tensor { shape:[B, S, H], origin_shape:[B, S, H], format:\"ND\", origin_format:\"ND\"} 图5 场景5数据排布变换 【场景6：NZ2NZ，尾轴合并】 输入Tensor { shape:[B, N, H/N/16, S/16, 16, 16], origin_shape:[B, N, S, H/N], format:\"NZ\", origin_format:\"ND\"} 输出Tensor { shape:[B, H/16, S/16, 16, 16], origin_shape:[B, S, H], format:\"NZ\", origin_format:\"ND\"} 图6 场景6数据排布变换 【场景7：二维转置】 支持在UB上对二维Tensor进行转置，其中srcShape中的H、W均是16的整倍。 图7 场景7数据排布变换",
    "函数原型": "template <typename T>\n__aicore__ inline void ConfusionTranspose(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t> &sharedTmpBuffer, TransposeType transposeType, ConfusionTransposeTiling& tiling)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为：int16_t/uint16_t/half/int32_t/uint32_t/float",
    "返回值": "",
    "调用示例": "AscendC::TPipe *pipe = pipeIn;\nAscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueSrcVecIn;\nAscendC::TQue<AscendC::TPosition::VECOUT, 1> inQueueSrcVecOut;\npipe->InitBuffer(inQueueSrcVecIn, 1, b * n * s * hnDiv * sizeof(T));\npipe->InitBuffer(inQueueSrcVecOut, 1, b * n * s * hnDiv * sizeof(T));\nAscendC::ConfusionTranspose(dstLocal, srcLocal, AscendC::TransposeType::TRANSPOSE_NZ2ND_0213, this->tiling);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "TransData",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10181.html",
    "功能说明": "将输入数据的排布格式转换为目标排布格式。 本接口支持的数据格式转换场景包括以下四种，除维度顺序变换外，其中涉及到C轴和N轴的拆分，具体转换方式为，C轴拆分为C1轴、C0轴，N轴拆分为N1轴、N0轴。对于位宽为16的数据类型的数据，C0和N0固定为16，C1和N1的计算公式如下。 场景1：NCDHW -> NDC1HWC0 输入Tensor {shape:[N, C, D, H, W]}，输出Tensor {shape:[N, D, C/16, H, W, 16]}。请注意，C0实际上等于16，为便于展示，下图中C0被设定为2。 图1 NCDHW格式转为NDC1HWC0格式示意图 场景2：NDC1HWC0 -> NCDHW 输入Tensor {shape:[N, D, C/16, H, W, 16]}，输出Tensor {shape:[N, C, D, H, W]}。请注意，C0实际上等于16，为便于展示，下图中C0被设定为2。 图2 NDC1HWC0格式转为NCDHW格式示意图 场景3：NCDHW -> FRACTAL_Z_3D 输入Tensor {shape:[N, C, D, H, W]}，输出Tensor {shape:[D, C/16, H, W, N/16, 16, 16]}。请注意，C0和N0实际上等于16，为便于展示，下图中C0和N0被设定为2。 图3 NCDHW格式转为FRACTAL_Z_3D格式示意图 场景4：FRACTAL_Z_3D -> NCDHW 输入Tensor {shape:[D, C/16, H, W, N/16, 16, 16]}，输出Tensor {shape:[N, C, D, H, W]}。请注意，C0和N0实际上等于16，为便于展示，下图中C0和N0被设定为2。 图4 FRACTAL_Z_3D格式转为NCDHW格式示意图",
    "函数原型": "template <const TransDataConfig& config, typename T, typename U, typename S>\n__aicore__ inline void TransData(const LocalTensor<T>& dstTensor, const LocalTensor<T>& srcTensor, const LocalTensor<uint8_t>& sharedTmpBuffer, const TransDataParams<U, S>& params)",
    "参数说明": "表1 模板参数说明 参数名 描述 config 指定数据格式转换的场景。当前支持的转换场景有如下四种：NCDHW -> NDC1HWC0、NDC1HWC0 -> NCDHW、NCDHW -> FRACTAL_Z_3D、FRACTAL_Z_3D -> NCDHW。该参数为TransDataConfig类型，具体定义如下。 struct TransDataConfig { DataFormat srcFormat ; DataFormat dstFormat ; }; enum class DataFormat : uint8_t { ND = 0 , NZ , NCHW , NC1HWC0 , NHWC , NCDHW , NDC1HWC0 , FRACTAL_Z_3D , };",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<half> dstLocal = outQueue.AllocTensor<half>();\nAscendC::LocalTensor<half> srcLocal = inQueue.DeQue<half>();\nAscendC::LocalTensor<uint8_t> tmp = tbuf.Get<uint8_t>();\n// 构造Layout方式\nAscendC::Layout ncdhwLayout = AscendC::MakeLayout(AscendC::MakeShape(1, 32, 2, 2, 8), AscendC::MakeStride());\nAscendC::Layout ndc1hwc0Layout = AscendC::MakeLayout(AscendC::MakeShape(1, 2, 2, 2, 8, 16), AscendC::MakeStride());\nstatic constexpr AscendC::TransDataConfig config = {DataFormat::NCDHW, DataFormat::NDC1HWC0};\nAscendC::TransDataParams<decltype(ncdhwLayout), decltype(ndc1hwc0Layout)> params = {ncdhwLayout, ndc1hwc0Layout};\nAscendC::TransData<config>(dstLocal, srcLocal, tmp, params);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ArithProgression",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0856.html",
    "功能说明": "给定起始值，等差值和长度，返回一个等差数列。",
    "函数原型": "template <typename T>\n__aicore__ inline void ArithProgression(const LocalTensor<T> &dstLocal, const T firstValue, const T diffValue, const int32_t count)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：half/float/int16_t/int32_t Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：half/float/int16_t/int32_t Atlas 推理系列产品 AI Core ，支持的数据类型为：half/float/int16_t/int32_t",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<T> dstLocal = outDst.AllocTensor<T>();\nAscendC::ArithProgression<T>(dstLocal, static_cast<T>(firstValue_), static_cast<T>(diffValue_), count_);\noutDst.EnQue<T>(dstLocal);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "使用说明",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0613.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "使用说明",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0868.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "InitGlobalMemory",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0891.html",
    "功能说明": "将Global Memory上的数据初始化为指定值。该接口可用于对workspace地址或输出数据进行清零。",
    "函数原型": "template <typename T>\n__aicore__ inline void InitGlobalMemory(GlobalTensor<T>& gmWorkspaceAddr, const uint64_t size, const T value)",
    "参数说明": "表1 模板参数说明 参数名 含义 T 操作数的数据类型。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：uint16_t/int16_t/half/uint32_t/int32_t/float Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：uint16_t/int16_t/half/uint32_t/int32_t/float Atlas 推理系列产品 AI Core ，支持的数据类型为：uint16_t/int16_t/half/uint32_t/int32_t/float",
    "返回值": "",
    "调用示例": "#include \"kernel_operator.h\"\n\nconstexpr int32_t INIT_SIZE = 65536;\n\nclass KernelInitGlobalMemory {\npublic:\n    __aicore__ inline KernelInitGlobalMemory() {}\n    __aicore__ inline void Init(GM_ADDR x, GM_ADDR y, GM_ADDR z, TPipe* pipe)\n    {\n        xGm.SetGlobalBuffer((__gm__ half*)x + INIT_SIZE * AscendC::GetBlockIdx(), INIT_SIZE);\n        yGm.SetGlobalBuffer((__gm__ half*)y + INIT_SIZE * AscendC::GetBlockIdx(), INIT_SIZE);\n        zGm.SetGlobalBuffer((__gm__ half*)z + INIT_SIZE * AscendC::GetBlockIdx(), INIT_SIZE);\n        // init zGm value\n        AscendC::InitGlobalMemory(zGm, INIT_SIZE, (half)(AscendC::GetBlockIdx()));\n\n        AscendC::TEventID eventIdMTE3ToMTE2 = GetTPipePtr()->FetchEventID(AscendC::HardEvent::MTE3_MTE2);\n        AscendC::SetFlag<AscendC::HardEvent::MTE3_MTE2>(eventIdMTE3ToMTE2);\n        AscendC::WaitFlag<AscendC::HardEvent::MTE3_MTE2>(eventIdMTE3ToMTE2);\n\n        pipe->InitBuffer(inQueueX, 1, INIT_SIZE * sizeof(half));\n        pipe->InitBuffer(inQueueY, 1, INIT_SIZE * sizeof(half));\n        pipe->InitBuffer(outQueueZ, 1, INIT_SIZE * sizeof(half));\n    }\n    __aicore__ inline void Process()\n    {\n        CopyIn();\n        Compute();\n        CopyOut();\n    }\nprivate:\n    __aicore__ inline void CopyIn()\n    {\n        AscendC::LocalTensor<half> xLocal = inQueueX.AllocTensor<half>();\n        AscendC::LocalTensor<half> yLocal = inQueueY.AllocTensor<half>();\n        AscendC::DataCopy(xLocal, xGm, INIT_SIZE);\n        AscendC::DataCopy(yLocal, yGm, INIT_SIZE);\n        inQueueX.EnQue(xLocal);\n        inQueueY.EnQue(yLocal);\n    }\n    __aicore__ inline void Compute()\n    {\n        AscendC::LocalTensor<half> xLocal = inQueueX.DeQue<half>();\n        AscendC::LocalTensor<half> yLocal = inQueueY.DeQue<half>();\n        AscendC::LocalTensor<half> zLocal = outQueueZ.AllocTensor<half>();\n        AscendC::Add(zLocal, xLocal, yLocal, INIT_SIZE);\n        outQueueZ.EnQue<half>(zLocal);\n        inQueueX.FreeTensor(xLocal);\n        inQueueY.FreeTensor(yLocal);\n    }\n    __aicore__ inline void CopyOut()\n    {\n        AscendC::LocalTensor<half> zLocal = outQueueZ.DeQue<half>();\n        // add result to zGm\n        AscendC::SetAtomicAdd<half>();\n        AscendC::DataCopy(zGm, zLocal, INIT_SIZE);\n        AscendC::SetAtomicNone();\n        outQueueZ.FreeTensor(zLocal);\n    }\nprivate:\n    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX, inQueueY;\n    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueZ;\n    AscendC::GlobalTensor<half> xGm;\n    AscendC::GlobalTensor<half> yGm;\n    AscendC::GlobalTensor<half> zGm;\n};\n\nextern \"C\" __global__ __aicore__ void init_global_memory_custom(GM_ADDR x, GM_ADDR y, GM_ADDR z)\n{\n    KernelInitGlobalMemory op;\n    TPipe pipe;\n    op.Init(x, y, z, &pipe);\n    op.Process();\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "使用说明",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10005.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "使用说明",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0918.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "使用说明",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0893.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "max",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10053.html",
    "功能说明": "比较相同数据类型的两个数，返回最大值。",
    "函数原型": "template <typename T, typename U>\n__aicore__ inline T max(const T src0, const U src1)",
    "参数说明": "表1 模板参数说明 参数名 含义 T 输入数据src0的数据类型。当前支持的数据类型为int8_t/uint8_t/int16_t/uint16_t/int32_t/uint32_t/float/int64_t/uint64_t。 U 输入数据src1的数据类型。当前支持的数据类型为int8_t/uint8_t/int16_t/uint16_t/int32_t/uint32_t/float/int64_t/uint64_t。 预留类型，当前必须与T保持一致。",
    "返回值": "",
    "调用示例": "int64_t src0 = 1;\nint64_t src1 = 2;\n \nint64_t result = AscendC::Std::max(src0, src1); \n// result: 2",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "min",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10054.html",
    "功能说明": "比较相同数据类型的两个数，返回最小值。",
    "函数原型": "template <typename T, typename U>\n__aicore__ inline T min(const T src0, const U src1)",
    "参数说明": "表1 模板参数说明 参数名 含义 T 输入数据src0的数据类型。当前支持的数据类型为int8_t/uint8_t/int16_t/uint16_t/int32_t/uint32_t/float/int64_t/uint64_t。 U 输入数据src1的数据类型。当前支持的数据类型为int8_t/uint8_t/int16_t/uint16_t/int32_t/uint32_t/float/int64_t/uint64_t。 预留类型，当前必须与T保持一致。",
    "返回值": "",
    "调用示例": "int64_t src0 = 1;\nint64_t src1 = 2;\n \nint64_t result = AscendC::Std::min(src0, src1); \n// result: 1",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "index_sequence",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10106.html",
    "功能说明": "index_sequence是Ascend C提供的一个类模板，用于生成一个编译时的整数序列，适用于模板元编程。 make_index_sequence是Ascend C提供的一个模板，通常使用make_index_sequence创建一个index_sequence类型的对象，用于生成一个从0到N-1的整数序列。",
    "函数原型": "template<size_t... Idx>\nusing index_sequence = IntegerSequence<size_t, Idx...>;",
    "参数说明": "表1 模板参数说明 参数名 含义 ...Idx 表示序列的形参包。 size_t，在64位系统中为long unsigned int，非64位系统中为unsigned int。 N 生成的整数序列的大小。 size_t，在64位系统中为long unsigned int，非64位系统中为unsigned int。",
    "返回值": "",
    "调用示例": "template<size_t... Is> \n__aicore__  inline void PrintIndexSequence(AscendC::Std::index_sequence<Is...>) {\n   ((AscendC::printf(\" Is:%lu\", Is)), ...);\n}\n__aicore__ inline void Process()\n{\n    PrintIndexSequence(AscendC::Std::make_index_sequence<5>{}); // 打印结果: 0，1，2，3，4\n    PrintIndexSequence(AscendC::Std::index_sequence<0,1,2,10,8000>{}); // 打印结果: 0，1，2，10, 8000\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "tuple",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10108.html",
    "功能说明": "在C++中，tuple是一个功能强大的容器，它允许存储多个不同类型的元素。具体使用场景如下： 当一个函数需要返回多个不同类型的值时，使用tuple是一个很好的选择。它避免了创建结构体或类来封装多个返回值，尤其是在不需要为这些返回值创建单独的类型时。 当需要存储不同类型的数据，可以使用tuple来存储异构元素。例如，存储数据的查询结果，其中包含不同类型的字段。 在函数调用中，当需要传递多个不同类型的参数，但又不想为它们创建结构体时，可以使用tuple对这些参数分组。 在模板元编程中，tuple可以作为类型列表，存储多个类型信息。 当程序需要在不同阶段存储和传递多个状态信息时，可以使用tuple将这些状态统一存储，便于管理。 在一些泛型算法中，可以使用tuple存储计算结果或中间结果。 在模板元编程中，可以使用tuple存储和展开参数包。 以下是tuple的构造函数说明： 默认构造函数：创建一个空的元组。 初始化列表构造函数：直接在创建对象时提供元素的值。 复制构造函数：用来复制一个已有的元组。 另外，Ascend C提供辅助函数 make_tuple ，用于创建元组，它可以自动推断元素的类型，使代码更简洁，也可以使用make_tuple来构造元素列表。",
    "函数原型": "template <typename Tp, typename ...Tps>\nclass tuple<Tp, Tps...> : public tuple<Tps...> \n{\npublic:\n    __aicore__ inline tuple();\n\n    __aicore__ inline tuple(const Tp& val, const Tps& ...params);\n\n    __aicore__ inline tuple(Tp&& val, Tps&& ...params);\n\n    template <typename Head, typename ...Args>\n    __aicore__ inline tuple<Tp, Tps...>& operator=(const tuple<Head, Args...>& t);\n}",
    "参数说明": "表1 模板参数说明 参数名 含义 Tps... 表示输入类型的形参包，参数个数范围为[0，64]。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor",
    "返回值": "",
    "调用示例": "AscendC::LocalTensor<T> src0Local = inQueueX.AllocTensor<T>();\nAscendC::LocalTensor<T> src1Local = inQueueX2.AllocTensor<T>();\n\n// make_tuple聚合Tensor类结构\nauto testMakeTensor = AscendC::Std::make_tuple(src0Local, src1Local, src0_global, src1_global);\n\nAscendC::PRINTF(\"tuple size is --> %d\\n\", AscendC::Std::tuple_size<decltype(testMakeTensor)>::value);\n\n//初始化列表构造聚合\nAscendC::Std::tuple<AscendC::LocalTensor<T>, AscendC::LocalTensor<T>, AscendC::GlobalTensor<T>, AscendC::GlobalTensor<T>> testTensor{src0Local, src1Local, src0_global, src1_global};\n\n// 复制构造方式\nAscendC::Std::tuple<AscendC::LocalTensor<T>, AscendC::LocalTensor<T>, AscendC::GlobalTensor<T>, AscendC::GlobalTensor<T>> test2Tensor = testTensor;\n\nAscendC::Std::tuple<AscendC::LocalTensor<T>, AscendC::LocalTensor<T>, AscendC::GlobalTensor<T>, AscendC::GlobalTensor<T>> test3Tensor;\n\n// 运算符重载\ntest3Tensor = test2Tensor;\n\nAscendC::PRINTF(\"tuple size is --> %d\\n\", AscendC::Std::tuple_size<decltype(test3Tensor)>::value);\n\n// get方法获取对应元素\nAscendC::LocalTensor<T> src0LocalTuple = AscendC::Std::get<0>(test3Tensor);\nAscendC::LocalTensor<T> src1LocalTuple = AscendC::Std::get<1>(test3Tensor);\n\nAscendC::GlobalTensor<T> src0_globalTuple = AscendC::Std::get<2>(test3Tensor);\nAscendC::GlobalTensor<T> src1_globalTuple = AscendC::Std::get<3>(test3Tensor);        \n\n// 多种数据类型初始化列表聚合\nAscendC::Std::tuple<AscendC::int4b_t, int8_t, uint8_t, int16_t, uint16_t, int32_t, uint32_t, uint64_t, int64_t, half, float, \\\nbfloat16_t, float8_e8m0_t, bool> test1 = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10.0, 11.0, 12.0, 13.0, true};\n\nAscendC::PRINTF(\"tuple size is --> %d\\n\", AscendC::Std::tuple_size<decltype(test1)>::value);\n\n// get方法获取多种数据类型元素\nAscendC::int4b_t        number_int4b_t =        AscendC::Std::get<0>(test1);\nint8_t                  number_int8_t =         AscendC::Std::get<1>(test1);\nuint8_t                 number_uint8_t =        AscendC::Std::get<2>(test1);\nint16_t                 number_int16_t =        AscendC::Std::get<3>(test1);\nuint16_t                number_uint16_t =       AscendC::Std::get<4>(test1);\nint32_t                 number_int32_t =        AscendC::Std::get<5>(test1);\nuint32_t                number_uint32_t =       AscendC::Std::get<6>(test1);\nuint64_t                number_uint64_t =       AscendC::Std::get<7>(test1);\nint64_t                 number_int64_t =        AscendC::Std::get<8>(test1);\nhalf                    number_half =           AscendC::Std::get<9>(test1);\nfloat                   number_float =          AscendC::Std::get<10>(test1);\nbfloat16_t              number_bfloat16_t =     AscendC::Std::get<11>(test1);\nfloat8_e8m0_t           number_float8_e8m0_t =  AscendC::Std::get<12>(test1);\nbool                    number_bool =           AscendC::Std::get<13>(test1);\n\n// get方法获取元素引用接续运算\nAscendC::Std::get<1>(test1)+= 1 ;\nAscendC::Std::get<2>(test1)+= 1 ;\nAscendC::Std::get<3>(test1)+= 1 ;\nAscendC::Std::get<4>(test1)+= 1 ;\nAscendC::Std::get<5>(test1)+= 1 ;\nAscendC::Std::get<6>(test1)+= 1 ;\nAscendC::Std::get<7>(test1)+= 1 ;\nAscendC::Std::get<8>(test1)+= 1 ;\nAscendC::Std::get<10>(test1) += (float)1.0 ;\n\n// make_tuple初始化列表固定元素数据类型\nauto test2 = AscendC::Std::make_tuple(AscendC::int4b_t (1) ,int8_t (2) ,uint8_t (3) ,int16_t (4) ,uint16_t (5) ,int32_t (6) , \\\n    uint32_t (7) ,uint64_t (8) ,int64_t (9) ,half (10) ,float (11) ,bfloat16_t (12) ,float8_e8m0_t (13) , bool (true));\n\nAscendC::PRINTF(\"tuple size is --> %d\\n\", AscendC::Std::tuple_size<decltype(test2)>::value);\n\n// get方法获取多种数据类型元素\nnumber_int4b_t =        AscendC::Std::get<0>(test2);\nnumber_int8_t =         AscendC::Std::get<1>(test2);\nnumber_uint8_t =        AscendC::Std::get<2>(test2);\nnumber_int16_t =        AscendC::Std::get<3>(test2);\nnumber_uint16_t =       AscendC::Std::get<4>(test2);\nnumber_int32_t =        AscendC::Std::get<5>(test2);\nnumber_uint32_t =       AscendC::Std::get<6>(test2);\nnumber_uint64_t =       AscendC::Std::get<7>(test2);\nnumber_int64_t =        AscendC::Std::get<8>(test2);\nnumber_half =           AscendC::Std::get<9>(test2);\nnumber_float =          AscendC::Std::get<10>(test2);\nnumber_bfloat16_t =     AscendC::Std::get<11>(test2);\nnumber_float8_e8m0_t =  AscendC::Std::get<12>(test2);\nnumber_bool =           AscendC::Std::get<13>(test2);\n\n// get方法获取元素引用接续运算\nAscendC::Std::get<1>(test2)+= 1 ;\nAscendC::Std::get<2>(test2)+= 1 ;\nAscendC::Std::get<3>(test2)+= 1 ;\nAscendC::Std::get<4>(test2)+= 1 ;\nAscendC::Std::get<5>(test2)+= 1 ;\nAscendC::Std::get<6>(test2)+= 1 ;\nAscendC::Std::get<7>(test2)+= 1 ;\nAscendC::Std::get<8>(test2)+= 1 ;\nAscendC::Std::get<10>(test2) += (float)1.0 ;\n\n// 变量初始化列表聚合\nAscendC::Std::tuple<AscendC::int4b_t, int8_t, uint8_t, int16_t, uint16_t, int32_t, uint32_t, uint64_t, int64_t, half, float, \\\nbfloat16_t, float8_e8m0_t, bool> test3 = {\n    number_int4b_t, number_int8_t, number_uint8_t, number_int16_t, number_uint16_t, number_int32_t, number_uint32_t, \\\n    number_uint64_t, number_int64_t, number_half, number_float, number_bfloat16_t, number_float8_e8m0_t, number_bool, \n};\n\nAscendC::PRINTF(\"tuple size is --> %d\\n\", AscendC::Std::tuple_size<decltype(test3)>::value);\n\nuint32_t const_uint32_t = 0;\nfloat const_float = 0.0;\nbool const_bool = false;\n\n// const常量类型\nconst AscendC::Std::tuple<uint32_t, float, bool> test4{11, 2.2, true};\n\n// get方法获取const常量类型\nconst_uint32_t = AscendC::Std::get<0>(test4);\nconst_float = AscendC::Std::get<1>(test4);\nconst_bool = AscendC::Std::get<2>(test4);\n\nAscendC::Std::tuple_element<0,decltype(test4)>::type first = 77;\nAscendC::Std::tuple_element<1,decltype(test4)>::type second = 7.7;\nAscendC::Std::tuple_element<2,decltype(test4)>::type third = false;\n\nAscendC::PRINTF(\"The value of the test element is: %d, %f, %d\\n\", first, second, third);\n\nAscendC::Std::tie(const_uint32_t, const_float, const_bool) = test4;\n\nAscendC::PRINTF(\"The value of the test element is: %d, %f, %d\\n\", const_uint32_t, const_float, const_bool);\n\n// const元素聚合\nAscendC::Std::tuple<const uint32_t, const float, const bool> test5{33, 4.4, true};\n\n// get方法获取const元素\nconst_uint32_t = AscendC::Std::get<0>(test5);\nconst_float = AscendC::Std::get<1>(test5);\nconst_bool = AscendC::Std::get<2>(test5);\n\nconst AscendC::Std::tuple<const uint32_t, const float, const bool> test6{33, 4.4, true};\n\nconst_uint32_t = AscendC::Std::get<0>(test6);\nconst_float = AscendC::Std::get<1>(test6);\nconst_bool = AscendC::Std::get<2>(test6);\n\n// 默认构造初始化\nAscendC::Std::tuple<\\\nuint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, \\\nuint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, \\\nuint32_t, uint32_t, uint32_t, uint8_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t,\\\nuint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, \\\nuint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, \\\nuint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, \\\nuint32_t, uint32_t, uint32_t, uint32_t> test7;\n\n// 默认元素初始化聚合\nauto test8 = AscendC::Std::make_tuple(\\\n    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \\\n    11, 12, 13, 14, 15, 16, 17, 18, 19, 20, \\\n    21, 22, 23, 24, 25, 26, 27, 28, 29, 30, \\\n    31, 32, 33, 34, 35, 36, 37, 38, 39, 40, \\\n    41, 42, 43, 44, 45, 46, 47, 48, 49, 50, \\\n    51, 52, 53, 54, 55, 56, 57, 58, 59, 60, \\\n    61, 62, 63, 64);\n\n// 运算符重载赋值\ntest7 = test8;\n\nAscendC::PRINTF(\"tuple size is --> %d\\n\", AscendC::Std::tuple_size<decltype(test7)>::value);\nAscendC::PRINTF(\"tuple size is --> %d\\n\", AscendC::Std::tuple_size<decltype(test8)>::value);\n\n// make_tuple聚合初始化\nAscendC::Std::tuple<uint32_t, float, bool> test9 = AscendC::Std::make_tuple(const_uint32_t, const_float, const_bool);\n\nconst_uint32_t = AscendC::Std::get<0>(test9);\nconst_float = AscendC::Std::get<1>(test9);\nconst_bool = AscendC::Std::get<2>(test9);\n\nAscendC::PRINTF(\"tuple size is --> %d\\n\", AscendC::Std::tuple_size<decltype(test9)>::value);\n\nusing Element0Type = AscendC::Std::tuple_element<0, decltype(test9)>::type;\nElement0Type element0 = 88;\n\nusing Element1Type = AscendC::Std::tuple_element<1, decltype(test9)>::type;\nElement1Type element1 = 8.8;\n\nusing Element2Type = AscendC::Std::tuple_element<2, decltype(test9)>::type;\nElement2Type element2 = true;\n\nAscendC::PRINTF(\"The value of the test element is: %d, %f, %d\\n\", element0, element1, element2);\n\nAscendC::Std::tie(const_uint32_t, const_float, const_bool) = test9;\n\nAscendC::PRINTF(\"The value of the test element is: %d, %f, %d\\n\", const_uint32_t, const_float, const_bool);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "get",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10109.html",
    "功能说明": "get的作用是从tuple容器中提取指定位置的元素。",
    "函数原型": "template <size_t N, typename ...Tps>\n__aicore__ inline typename tuple_element<N, tuple<Tps...> >::type& get(tuple<Tps...>& t) noexcept;\n\ntemplate <size_t N, typename ...Tps>\n__aicore__ inline const typename tuple_element<N, tuple<Tps...> >::type& get(const tuple<Tps...>& t) noexcept;\n\ntemplate <size_t N, typename ...Tps>\n__aicore__ inline typename tuple_element<N, tuple<Tps...> >::type&& get(tuple<Tps...>&& t) noexcept;\n\ntemplate <size_t N, typename ...Tps>\n__aicore__ inline const typename tuple_element<N, tuple<Tps...> >::type&& get(const tuple<Tps...>&& t) noexcept;",
    "参数说明": "表1 模板参数说明 参数名 含义 N N是一个编译时常量，代表要提取元素的索引。索引从0开始，取值范围为[0, 64)。 Tps... Tps...为传入tuple的模板参数包，tuple参数个数范围为(0, 64]。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor t t是tuple对象，可以是左值引用、常量左值引用或右值引用。",
    "返回值": "",
    "调用示例": "AscendC::Std::tuple<uint32_t, float, bool> test{11, 2.2, true};\nuint32_t const_uint32_t = AscendC::Std::get<0>(test);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "make_tuple",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10110.html",
    "功能说明": "make_tuple是一个实用的函数模板，其作用在于便捷地创建tuple对象。它可以自动推断元素的类型，使代码更简洁，也可以构造元素列表。",
    "函数原型": "template <typename ...Tps>\n__aicore__ inline constexpr tuple<unwrap_decay_t<Tps>...> make_tuple(Tps&& ...args);",
    "参数说明": "表1 模板参数说明 参数名 含义 Tps... Tps...为传入tuple的模板参数包，代表传递给make_tuple的参数类型，参数个数范围为[0, 64]。 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 ，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor Atlas A3 训练系列产品/Atlas A3 推理系列产品 ，支持的数据类型为：int4b_t，int8_t，uint8_t，int16_t，uint16_t，int32_t，uint32_t，uint64_t，int64_t，half，float，bfloat16_t，bool，LocalTensor，GlobalTensor args args...是函数参数包，代表传递给make_tuple的实际参数，参数个数范围为[0, 64]。",
    "返回值": "",
    "调用示例": "AscendC::Std::tuple<uint32_t, float, bool> test = AscendC::Std::make_tuple(22, 3.3, true);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "is_convertible",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10114.html",
    "功能说明": "is_convertible是定义于<type_traits>头文件的一个类型转换检查工具，它提供了一种在程序编译时进行类型转换检查的机制：判断两个类型之间是否可以进行隐式转换并返回结果布尔值。本接口可应用在模板元编程、函数重载决议以及静态断言等场景，用于在程序编译阶段捕获潜在的类型转换错误，避免发生运行时错误。",
    "函数原型": "template <typename From, typename To>\nstruct is_convertible;",
    "参数说明": "表1 模板参数说明 参数名 含义 From 源类型，即需要进行转换的原始类型。 To 目标类型，即需要转换到的目标类型。",
    "返回值": "",
    "调用示例": "class Base {};\nclass Derived : public Base {};\nclass Unrelated {};\n\n// 检查 int 是否可以隐式转换为 double\nAscendC::PRINTF(\"Is int convertible to double? %d\\n\", AscendC::Std::is_convertible<int, double>::value);\n\n// 检查 double 是否可以隐式转换为 int\nAscendC::PRINTF(\"Is double convertible to int? %d\\n\", AscendC::Std::is_convertible<double, int>::value);\n\n// 检查 Derived 是否可以转换为 Base\nAscendC::PRINTF(\"Is Derived callable with Base? %d\\n\", AscendC::Std::is_convertible<Derived, Base>::value);\n// 检查 Base 是否可以转换为 Derived\nAscendC::PRINTF(\"Is Base callable with Derived? %d\\n\", AscendC::Std::is_convertible<Base, Derived>::value);\n// 检查 Derived 是否可以转换为 Unrelated\nAscendC::PRINTF(\"Is Derived callable with Unrelated? %d\\n\", AscendC::Std::is_convertible<Derived, Unrelated>::value);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "is_base_of",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10115.html",
    "功能说明": "is_base_of是定义于<type_traits>头文件的一个类型特征工具，它能够在程序编译时检查一个类型是否为另一个类型的基类。本接口可应用在模板元编程、类型检查和条件编译等场景，用于在编译阶段捕获潜在的类型错误，提高代码的鲁棒性。",
    "函数原型": "template <typename Base, typename Derived>\nstruct is_base_of;",
    "参数说明": "表1 模板参数说明 参数名 含义 Base 待检查的基类类型，即Base类型是否为Derived类型的基类。 Derived 待检查的派生类类型，即Base类型是否为Derived类型的基类。",
    "返回值": "",
    "调用示例": "class Base {};\nclass Derived : public Base {};\nclass Unrelated {};\n\n// 虚继承的派生类\nclass Derived2 : virtual public Base {};\n\n// 定义虚继承的派生类\nclass VirtualDerived : virtual public Base {};\n\n// 定义多重继承的派生类\nclass MultiDerived : public Base, public VirtualDerived {};\n\n// 模板基类\ntemplate <typename T>\nclass BaseTemplate {\npublic:\n    T value;\n};\n\n// 模板派生类\ntemplate <typename T>\nclass DerivedTemplate : public BaseTemplate<T> {};\n\n// 检查 Base 是否是 Derived 的基类\nAscendC::PRINTF(\"Is Base a base of Derived? %d\\n\" , AscendC::Std::is_base_of<Base, Derived>::value);\n\n// 检查 Derived 是否是 Base 的基类（应该为 false）\nAscendC::PRINTF(\"Is Derived a base of Base? %d\\n\" , AscendC::Std::is_base_of<Derived, Base>::value);\n\n// 检查 Base 是否是 Unrelated 的基类（应该为 false）\nAscendC::PRINTF(\"Is Base a base of Unrelated? %d\\n\" , AscendC::Std::is_base_of<Base, Unrelated>::value);\n\nAscendC::PRINTF(\"Is Base a base of Derived (virtual inheritance)? %d\\n\", AscendC::Std::is_base_of<Base, Derived2>::value);\n\nAscendC::PRINTF(\"Is BaseTemplate<int> a base of DerivedTemplate<int>? %d\\n\", AscendC::Std::is_base_of<BaseTemplate<int>, DerivedTemplate<int>>::value);\n\n// 测试 Base 是否为 VirtualDerived 的基类（虚继承情况）\nAscendC::PRINTF(\"Is Base a base of VirtualDerived? %d\\n\" , AscendC::Std::is_base_of<Base, VirtualDerived>::value);\n// 测试 Base 是否为 MultiDerived 的基类（多重继承情况）\nAscendC::PRINTF(\"Is Base a base of MultiDerived? %d\\n\" , AscendC::Std::is_base_of<Base, MultiDerived>::value);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "is_same",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10116.html",
    "功能说明": "is_same是定义在<type_traits>头文件里的一个类型特征工具，它能够在程序编译时判断两个类型是否完全相同。本接口可应用在模板元编程、类型检查、条件编译等场景，用于在编译阶段确定类型信息，避免运行时可能出现的类型不匹配问题。",
    "函数原型": "template <typename Tp, typename Up>\nstruct is_same;",
    "参数说明": "表1 模板参数说明 参数名 含义 Tp 需要比较两个类型是否完全相同的第一个类型。 Up 需要比较两个类型是否完全相同的第二个类型。",
    "返回值": "",
    "调用示例": "// 定义两个不同的类\nclass ClassA {};\nclass ClassB {};\n\n// 定义相同的类两次\nclass ClassC {};\nusing ClassC_alias = ClassC;\n\n// 定义一个简单的模板类\ntemplate <typename T>\nclass TemplateClass {};\n\n// 比较相同的基本类型\nAscendC::PRINTF(\"Is int the same as int? %d\\n\", AscendC::Std::is_same<int, int>::value);\n\n// 比较不同的基本类型\nAscendC::PRINTF(\"Is int the same as double? %d\\n\", AscendC::Std::is_same<int, double>::value);\n\n// 比较不同的类类型\nAscendC::PRINTF(\"Is ClassA the same as ClassB? %d\\n\", AscendC::Std::is_same<ClassA, ClassB>::value);\n\n// 比较相同的类类型\nAscendC::PRINTF(\"Is ClassC the same as ClassC_alias? %d\\n\", AscendC::Std::is_same<ClassC, ClassC_alias>::value);\n\n// 比较相同模板实例化类型\nAscendC::PRINTF(\"Is TemplateClass<int> the same as TemplateClass<int>? %d\\n\", AscendC::Std::is_same<TemplateClass<int>, TemplateClass<int>>::value);\n\n// 比较不同模板实例化类型\nAscendC::PRINTF(\"Is TemplateClass<int> the same as TemplateClass<double>? %d\\n\", AscendC::Std::is_same<TemplateClass<int>, TemplateClass<double>>::value);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "enable_if",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10117.html",
    "功能说明": "enable_if是定义于<type_traits>头文件的一个模板元编程工具，它能够在程序编译时根据某个条件启用或禁用特定的函数模板、类模板或模板特化，以此实现更精细的模板重载和类型选择，增强代码的灵活性和安全性。 enable_if是一个模板结构体，有两个模板参数：模板参数Bp是一个布尔值，表示条件；模板参数Tp是一个类型，默认值为void。当Bp为false时，enable_if没有嵌套的type成员。当Bp为true时，enable_if有一个嵌套的type成员，其类型为Tp。",
    "函数原型": "template <bool Bp, typename Tp>\nstruct enable_if;",
    "参数说明": "表1 模板参数说明 参数名 含义 Bp 布尔值，表示条件。 Tp 类型，默认值为void。",
    "返回值": "",
    "调用示例": "template <typename T>\nclass Calculator {\npublic:\n    // 当 T 是整数类型时启用此成员函数\n    template <typename U = T>\n    typename AscendC::Std::enable_if<AscendC::Std::is_integral<U>::value, U>::type\n    __aicore__ inline multiply(U a, U b) {\n        AscendC::PRINTF(\"Integral type multiplication\");\n        return a * b;\n    }\n\n    // 当 T 不是整数类型时启用此成员函数\n    template <typename U = T>\n    typename AscendC::Std::enable_if<!AscendC::Std::is_integral<U>::value, U>::type\n    __aicore__ inline multiply(U a, U b) {\n        AscendC::PRINTF(\"Non-integral type multiplication\");\n        return a * b;\n    }\n};\n\n// 通用模板类\ntemplate <typename T, typename Enable = void>\nclass Container {\npublic:\n    __aicore__ inline Container() {\n        AscendC::PRINTF(\"Generic container.\\n\");\n    }\n};\n\n// 特化版本，当 T 是整数类型时启用\ntemplate <typename T>\nclass Container<T, typename AscendC::Std::enable_if<AscendC::Std::is_integral<T>::value>::type> {\npublic:\n    __aicore__ inline Container() {\n        AscendC::PRINTF(\"Integral container.\\n\");\n    }\n};\n\n// 当 T 是整数类型时启用该函数\ntemplate <typename T> \n__aicore__ inline typename AscendC::Std::enable_if<AscendC::Std::is_integral<T>::value, T>::type add(T a, T b) {\n    AscendC::PRINTF(\"Integral type addition.\");\n    return a + b;\n}\n\n// 当 T 不是整数类型时启用该函数\ntemplate <typename T> \n__aicore__ inline typename AscendC::Std::enable_if<!AscendC::Std::is_integral<T>::value, T>::type add(T a, T b) {\n    AscendC::PRINTF(\"Non-integral type addition.\");\n    return a + (-b);\n}\n\nCalculator<int> intCalculator;\nint intResult = intCalculator.multiply((int)2, (int)3);\nAscendC::PRINTF(\"Result of integral multiplication: %d\\n\", intResult);\n\nCalculator<float> doubleCalculator;\nfloat doubleResult = doubleCalculator.multiply((float)2.5, (float)3.5);\nAscendC::PRINTF(\"Result of non-integral multiplication: %f\\n\", doubleResult);\n\nContainer<float> genericContainer;\nContainer<int> integralContainer;\n\nintResult = add(1, 2);\nAscendC::PRINTF(\"Integer result: %d\\n\", intResult);\n\ndoubleResult = add((float)1.5, (float)2.5);\nAscendC::PRINTF(\"float result: %f\\n\", doubleResult);",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "conditional",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_10118.html",
    "功能说明": "conditional是定义在<type_traits>头文件里的一个类型特征工具，它在程序编译时根据一个布尔条件从两个类型中选择一个类型。本接口可应用在模板元编程中，用于根据不同的条件来灵活选择合适的类型，增强代码的通用性和灵活性。 conditional有一个嵌套的type成员，它的值取决于Bp的值：如果Bp为true，则conditional<Bp, If, Then>::type为If。如果Bp为false，则conditional<Bp, If, Then>::type为Then。",
    "函数原型": "template <bool Bp, typename If, typename Then>\nstruct conditional;",
    "参数说明": "表1 模板参数说明 参数名 含义 Bp 一个布尔常量表达式，作为选择类型的条件。 If 当Bp为true时选择的类型。 Then 当Bp为false时选择的类型。",
    "返回值": "",
    "调用示例": "// 定义两个不同的类型\nstruct TypeA {\n    __aicore__ inline static void print() {\n        AscendC::PRINTF(\"This is TypeA..\\n\");\n    }\n};\n\nstruct TypeB {\n    __aicore__ inline static void print() {\n        AscendC::PRINTF(\"This is TypeB..\\n\");\n    }\n};\n\n// 根据条件选择类型\ntemplate <bool Condition>\n__aicore__ inline void selectType() {\n    using SelectedType = typename AscendC::Std::conditional<Condition, TypeA, TypeB>::type;\n    SelectedType::print();\n}\n\n// 定义一个模板函数，根据条件选择不同的类型\ntemplate <bool Condition>\n__aicore__ inline void selectOtherType() {\n    using SelectedType = typename std::conditional<Condition, int, float>::type;\n    if constexpr (std::is_same_v<SelectedType, int>) {\n        AscendC::PRINTF(\"Selected type is int.\\n\");\n    } else {\n        AscendC::PRINTF(\"Selected type is float.\\n\");\n    }\n}\n\n// 条件为 true，选择 TypeA\nselectType<true>();\n// 条件为 false，选择 TypeB\nselectType<false>();\n\n// 测试条件为 true 的情况\nselectOtherType<true>();\n// 测试条件为 false 的情况\nselectOtherType<false>();",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "原型注册接口（OP_ADD）",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0945.html",
    "功能说明": "注册算子的原型定义，从而确保算子能够被框架正确识别、编译和执行 。 算子原型主要描述了算子的输入输出、属性等信息以及算子在AI处理器上相关实现信息，并关联 tiling实现 等函数。算子原型通过自定义的算子类来承载，该算子类继承自 OpDef类 。完成算子的原型定义等操作后，需要调用 OP_ADD 接口，传入算子类型（自定义算子类的类名），进行算子原型注册。详细内容请参考 算子原型定义 。",
    "函数原型": "OP_ADD(opType)",
    "参数说明": "参数 输入/输出 说明 opType 输入 算子类型名称",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Input",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0946.html",
    "功能说明": "注册算子输入，调用该接口后会返回一个OpParamDef结构，后续可通过该结构配置算子输入信息。",
    "函数原型": "OpParamDef &Input(const char *name)",
    "参数说明": "参数 输入/输出 说明 name 输入 算子输入名称。",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ParamType",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0957.html",
    "功能说明": "定义算子参数类型。",
    "函数原型": "OpParamDef &ParamType(Option param_type)",
    "参数说明": "参数 输入/输出 说明 param_type 输入 参数类型，Option取值为：OPTIONAL（可选）、REQUIRED（必选）、DYNAMIC（动态输入）。",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "OpAttrDef",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0976.html",
    "功能说明": "定义算子属性。",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 函数原型,参数说明,返回值"
  },
  {
    "API名称": "SetTiling",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0978.html",
    "功能说明": "注册Tiling函数。Tiling函数的原型是固定的，接受一个 TilingContext 作为输入，在此context上可以获取到输入、输出的Shape指针等内容。注册的Tiling函数由框架调用，调用时会传入TilingContext参数。",
    "函数原型": "OpAICoreDef &SetTiling(gert::OpImplRegisterV2::TilingKernelFunc func)",
    "参数说明": "参数 输入/输出 说明 func 输入 Tiling函数。TilingKernelFunc类型定义如下： using TilingKernelFunc = UINT32 ( * )( TilingContext * );",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "Input",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0988.html",
    "功能说明": "某些场景下，同一个算子在不同的AI处理器型号上，其支持的原型输入不同。 通过该接口，可针对不同的AI处理器型号 注册差异化的算子输入 。调用该接口后会返回一个OpParamDef结构，后续可通过该结构配置算子输入信息。",
    "函数原型": "OpParamDef &Input(const char *name)",
    "参数说明": "参数 输入/输出 说明 name 输入 算子输入名称。",
    "返回值": "",
    "调用示例": "class AddCustom : public OpDef {\npublic:\n    AddCustom(const char* name) : OpDef(name)\n    {\n        this->Input(\"x\").DataType({ ge::DT_FLOAT16 }).ParamType(OPTIONAL);\n        this->Output(\"y\").DataType({ ge::DT_FLOAT16 });\n        OpAICoreConfig aicConfig1;\n        OpAICoreConfig aicConfig2;\n        aicConfig1.Input(\"x\")\n            .ParamType(OPTIONAL)\n            .DataType({ ge::DT_FLOAT })\n            .Format({ ge::FORMAT_ND });\n        aicConfig2.Input(\"x\")\n            .ParamType(REQUIRED)\n            .DataType({ ge::DT_INT32 })\n            .Format({ ge::FORMAT_ND });\n        this->AICore().AddConfig(\"ascendxxx1\", aicConfig1);\n        this->AICore().AddConfig(\"ascendxxx2\", aicConfig2);\n    }\n};",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "简介",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0999.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "TilingData结构定义",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1005.html",
    "功能说明": "定义一个TilingData的类，添加所需的成员变量（TilingData字段），用于保存所需TilingData参数。完成该TilingData类的定义后，该类通过继承TilingDef类（用来存放、处理用户自定义Tiling结构体成员变量的基类）提供以下接口： set_{field_name}接口：用于设置TilingData类的字段值，field_name为定义TilingData类时添加的字段名。 SaveToBuffer接口：完成TilingData的序列化和保存。 GetDataSize接口：获取TilingData的长度。 CheckAlignAndGenPlaceHolder：该接口是内部关联接口，用于框架侧检查Tiling结构体中成员变量是否满足字节对齐要求，并对不对齐的变量进行补齐，开发者无需关注。 SetDataPtr接口：该接口为预留接口，开发者无需关注。",
    "函数原型": "BEGIN_TILING_DATA_DEF(class_name)",
    "参数说明": "表1 BEGIN_TILING_DATA_DEF 参数说明 参数 输入/输出 说明 class_name 输入 用户定义tiling结构体名，与c++变量命名要求一致 表2 TILING_DATA_FIELD_DEF 参数说明 参数 输入/输出 说明 data_type 输入 字段的数据类型 field_name 输入 字段名，与c++变量命名要求一致 表3 TILING_DATA_FIELD_DEF_ARR 参数说明 参数 输入/输出 说明 arr_type 输入 数组元素数据类型 arr_size 输入 数组元素个数 field_name 输入 字段名，与c++变量命名要求一致 表4 TILING_DATA_FIELD_DEF_STRUCT 参数说明 参数 输入/输出 说明 struct_type 输入 结构体类型 field_name 输入 字段名，与c++变量命名要求一致",
    "返回值": "",
    "调用示例": "#include \"register/tilingdata_base.h\"\n\n// 定义tilingdata类\nnamespace optiling {\nBEGIN_TILING_DATA_DEF(Matmul)\n  TILING_DATA_FIELD_DEF(uint16_t, mmVar);\n  TILING_DATA_FIELD_DEF_ARR(uint16_t, 3, mmArr);\nEND_TILING_DATA_DEF;\n//注册中间结构体，第一个参数固定为struct_name#Op，第二个参数即struct_name, 如struct_name为Matmul，第一参数为MatmulOp，第二个参数为Matmul\nREGISTER_TILING_DATA_CLASS(MatmulOp, Matmul)      //注册中间结构体\n\nBEGIN_TILING_DATA_DEF(AddCustomTilingData)        // 注册一个tiling类，以tiling的名字作为入参\n  TILING_DATA_FIELD_DEF(uint32_t, blkDim);        // 添加tiling变量类型字段，参与计算核数\n  TILING_DATA_FIELD_DEF(uint32_t, totalSize);     // 添加tiling变量类型字段，总计算数据量\n  TILING_DATA_FIELD_DEF(uint32_t, splitTile);     // 添加tiling变量类型字段，每个core处理的数据分块计算\n  TILING_DATA_FIELD_DEF_ARR(uint16_t, 3, arrSample);    // 添加tiling数组类型字段\n  TILING_DATA_FIELD_DEF_STRUCT(Matmul, mm);             // 添加tiling结构体类型字段\nEND_TILING_DATA_DEF;                                    // 定义结束\n// 注册算子tilingdata类到对应的AddCustom算子\nREGISTER_TILING_DATA_CLASS(AddCustom, AddCustomTilingData) \n}\n\n// host侧设置参数值和使用tiling参数\nstatic void TilingAddInit(AddCustomTilingData *tiling, uint32_t blockDim)\n{\n  // 设置参数值\n  tiling->set_blkDim(blockDim);                  // 置值通用数据类型变量blockDim\n  uint16_t arr[] = {10,2,8,2,3,4,5,2,1,2,4,4,5,};\n  tiling->set_arrSample(arr);                    // 置值通用数据类型数组变量arrSample，仅会复制arr数据的前三个数据，与TILING_DATA_FIELD_DEF_ARR中arr_size一致\n  tiling->mm.set_mmVar(1);                       // 置值嵌套结构体通用数据类型变量mmVar\n  tiling->mm.set_mmArr(arr);                     // 置值嵌套结构体通用数据类型数组mmArr\n  \n  // 使用参数值\n  uint32_t useBlockDim = tiling->get_blkDim();    // 获取通用数据类型变量blockDim\n  uint32_t* arrPoint = tiling->get_arrSample();   // 获取通用数据类型数组变量arrSample\n  useBlockDim = tiling->mm.get_mmVar();           // 获取嵌套结构体通用数据类型变量mmVar\n  arrPoint = tiling->mm.get_mmArr();              // 获取嵌套结构体通用数据类型数组mmArr\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "TilingData结构注册",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1006.html",
    "功能说明": "注册定义的TilingData结构体并和自定义算子绑定。具体使用说明请参考 调用示例 。",
    "函数原型": "#define REGISTER_TILING_DATA_CLASS(op_type, class_name)\n  class op_type##class_name##Helper {\n  public:\n    op_type##class_name##Helper() {\n      CTilingDataClassFactory::RegisterTilingData(#op_type, op_type##class_name##Helper::CreateTilingDataInstance);\n    }\n    static std::shared_ptr<TilingDef> CreateTilingDataInstance() {\n      return std::make_shared<class_name>();\n    }\n  };\n  op_type##class_name##Helper g_tilingdata_##op_type##class_name##helper;",
    "参数说明": "表1 参数说明 参数 输入/输出 说明 op_type 输入 注册的算子名 struct_name 输入 tiling结构体名，与c++变量命名要求一致",
    "返回值": "",
    "调用示例": "#include \"register/tilingdata_base.h\"\n\n// 定义tilingdata类\nnamespace optiling {\nBEGIN_TILING_DATA_DEF(AddCustomTilingData)    // 注册一个tiling的类，以tiling的名字作为入参\n  TILING_DATA_FIELD_DEF(uint32_t, blkDim);    // 添加tiling字段，参与计算核数\n  TILING_DATA_FIELD_DEF(uint32_t, totalSize); // 添加tiling字段，总计算数据量-输入shape大小\n  TILING_DATA_FIELD_DEF(uint32_t, splitTile); // 添加tiling字段，每个core处理的数据分块计算\nEND_TILING_DATA_DEF;                          // 定义结束\n// 注册算子tilingdata类到对应的AddCustom算子\nREGISTER_TILING_DATA_CLASS(AddCustom, AddCustomTilingData) \n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "简介",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1007.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "// 构造KernelContext\nauto kernelContextHolder = context_ascendc::ContextBuilder()\n    .Inputs(...)\n    .Outputs(...)\n    .BuildKernelRunContext();\ngert::KernelContext* tilingParseContext = kernelContextHolder->GetContext<gert::KernelContext>();\n\n// 构造TilingContext\nauto tilingContextHolder = context_ascendc::ContextBuilder()\n    .SetOpNameType(...,...)\n    .NodeIoNum(...)\n    .IrInstanceNum(...)\n    .AddInputTd(...)\n    .AddOutputTd(...)\n    .AddAttr(...)\n    .BuildTilingContext(...);\ngert::TilingContext* tilingContext = tilingContextHolder->GetContext<gert::TilingContext>();",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "模板参数定义",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00011.html",
    "功能说明": "通过以下函数原型进行模板参数ASCENDC_TPL_ARGS_DECL和模板参数组合ASCENDC_TPL_ARGS_SEL（即可使用的模板）的定义。详细内容请参考 Tiling模板编程 。",
    "函数原型": "// ParamStruct是存放用户设置的模板参数ASCENDC_TPL_ARGS_DECL和模板参数组合ASCENDC_TPL_ARGS_SEL的结构体，用作后续的Tilingkey与模板参数之间的编解码，用户无需关注\nstruct ParamStruct {\n    const char* name;\n    uint32_t paramType;\n    uint8_t bitWidth;\n    std::vector<uint64_t> vals;\n    const char* macroType;\n    ParamStruct(const char* inName, uint32_t inParamType, uint8_t inBitWidth, std::vector<uint64_t> inVals,\n        const char* inMacroType):\n        name(inName), paramType(inParamType), bitWidth(inBitWidth), vals(std::move(inVals)),\n        macroType(inMacroType) {}\n};\nusing TilingDeclareParams = std::vector<ParamStruct>;\nusing TilingSelectParams = std::vector<std::vector<ParamStruct>>;\n\n// 模板参数定义相关接口\n#define ASCENDC_TPL_DTYPE_DECL(x, ...) ParamStruct{#x, ASCENDC_TPL_DTYPE, ASCENDC_TPL_8_BW, {__VA_ARGS__}, \"DECL\"}\n#define ASCENDC_TPL_FORMAT_DECL(x, ...) ParamStruct{#x, ASCENDC_TPL_FORMAT, ASCENDC_TPL_8_BW, {__VA_ARGS__}, \"DECL\"}\n#define ASCENDC_TPL_UINT_DECL(x, bw, ...) ParamStruct{#x, ASCENDC_TPL_UINT, bw, {__VA_ARGS__}, \"DECL\"}\n#define ASCENDC_TPL_BOOL_DECL(x, ...) ParamStruct{#x, ASCENDC_TPL_BOOL, ASCENDC_TPL_1_BW, {__VA_ARGS__}, \"DECL\"}\n\n#define ASCENDC_TPL_DTYPE_SEL(x, ...) ParamStruct{#x, ASCENDC_TPL_DTYPE, ASCENDC_TPL_8_BW, {__VA_ARGS__}, \"SEL\"}\n#define ASCENDC_TPL_FORMAT_SEL(x, ...) ParamStruct{#x, ASCENDC_TPL_FORMAT, ASCENDC_TPL_8_BW, {__VA_ARGS__}, \"SEL\"}\n#define ASCENDC_TPL_UINT_SEL(x, ...) ParamStruct{#x, ASCENDC_TPL_UINT, 0, {__VA_ARGS__}, \"SEL\"}\n#define ASCENDC_TPL_BOOL_SEL(x, ...) ParamStruct{#x, ASCENDC_TPL_BOOL, ASCENDC_TPL_1_BW, {__VA_ARGS__}, \"SEL\"}\n\n#define ASCENDC_TPL_ARGS_DECL(x, ...) static TilingDeclareParams g_tilingDeclareParams{ __VA_ARGS__ }\n#define ASCENDC_TPL_ARGS_SEL(...) { __VA_ARGS__}\n#define ASCENDC_TPL_SEL(...) static TilingSelectParams g_tilingSelectParams{ __VA_ARGS__ }",
    "参数说明": "表1 Tiling模板参数定义说明 宏 功能描述 参数解释 ASCENDC_TPL_ARGS_DECL(args0, ...) 用于定义算子的模板参数。 args0：表示算子Optype。 args1-argsn：后续为若干个DTYPE、FORMAT、UINT、BOOL的模板参数定义，分别通过ASCENDC_TPL_DTYPE_DECL、ASCENDC_TPL_FORMAT_DECL、ASCENDC_TPL_UINT_DECL、ASCENDC_TPL_BOOL_DECL进行定义。 ASCENDC_TPL_DTYPE_DECL(args0, ...) DataType 类型的模板参数定义。 args0：参数名。 args1-argsn：后续若干个参数为穷举的 DataType 枚举值。 ASCENDC_TPL_FORMAT_DECL(args0, ...) Format 类型的模板参数定义。 args0：参数名。 args1-argsn：后续若干个参数为穷举的 Format 枚举值。 ASCENDC_TPL_UINT_DECL(args0, args1, args2, ...) 自定义UINT类型（无符号整形）的模板参数定义。 args0：参数名。 args1：最大位宽，模板参数的个数不能超过最大位宽。 args2：参数定义的模式。支持以下三种模式： ASCENDC_TPL_UI_RANGE：范围模式，设置该模式，后续紧跟着第一个值表示范围个数，第一个值后面的每两个数值为一组分别表示该范围的起、终位置；注意定义的范围个数要和后续的组数保持一致。 举例： ASCENDC_TPL_UINT_DECL(args0, args1,ASCENDC_TPL_UI_RANGE,2,0,2,3,5)表示2组参数，这2组参数范围为{0, 2}，{3, 5}，因此该参数定义的UINT参数合法值为{0, 1, 2, 3, 4, 5}。 ASCENDC_TPL_UI_LIST：穷举模式，设置该模式，则表示后续将穷举出所有的参数值。 举例： ASCENDC_TPL_UINT_DECL(args0, args1,ASCENDC_TPL_UI_LIST,10,12,13,9,8,7,6)表示1组穷举参数，[10, 12, 13, 9, 8, 7, 6]为穷举值，因此该参数定义的UINT参数合法值为{10, 12, 13, 9, 8, 7, 6}。 ASCENDC_TPL_UI_MIX：混合模式，设置该模式，则表示前n个数值为范围模式的参数定义，后m个数值为穷举模式的参数定义。 举例 ： ASCENDC_TPL_UINT_DECL(args0, args1,ASCENDC_TPL_UI_MIX,2,0,2,3, 5, 10, 12, 13, 9, 8)表示2组穷举参数，这2组范围为{0, 2}, {3, 5}，[10, 12, 13, 9, 8]为穷举值，因此该参数定义的UINT参数合法值为{0, 1, 2, 3, 4, 5, 10, 12, 13, 9, 8}。 args3-argsn：对应不同范围模式的参数数值。 ASCENDC_TPL_BOOL_DECL(args0, ...) 自定义bool类型的模板参数定义。 args0：参数名。 args1-args2：取值范围0，1。 表2 Tiling模板参数组合定义 宏 功能描述 参数解释 ASCENDC_TPL_SEL(...) 算子的模板参数整体组合。 包含多个算子的模板参数组合。 ASCENDC_TPL_ARGS_DSEL(...) 算子的模板参数组合。 一个算子的模板参数组合。 ASCENDC_TPL_DTYPE_SEL(args0, ...) DataType类型的模板参数组合。 args0：表示参数名。 args1-argsn ：后续若干个参数为ASCENDC_TPL_DTYPE_DECL中定义的参数范围子集。 ASCENDC_TPL_FORMAT_SEL(args0, ...) Format类型的模板参数组合。 args0：表示参数名。 args1-argsn：后续若干个参数为ASCENDC_TPL_FORMAT_DECL中定义的参数范围子集。 ASCENDC_TPL_UINT_SEL(args0, args1, args2, ...) UINT类型的模板参数组合。 args0：表示参数名。 args1：参数定义的模式。支持如下取值： ASCENDC_TPL_UI_RANGE：范围模式。 ASCENDC_TPL_UI_LIST：穷举模式。 ASCENDC_TPL_UI_MIX：混合模式。 args2-argsn：后续若干个参数为ASCENDC_TPL_UINT_DECL中定义的参数范围子集。 模式和参数的配置方式参考ASCENDC_TPL_UINT_DECL(args0, args1, args2, ...)。 ASCENDC_TPL_BOOL_SEL(args0, ...) bool类型的模板参数组合。 args0：表示参数名。 args1-args2 ：后续若干个参数为ASCENDC_TPL_BOOL_DECL定义的参数范围子集。",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ASCENDC_TPL_SEL_PARAM",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00057.html",
    "功能说明": "Tiling模板编程时，开发者通过调用此接口自动生成并配置TilingKey。 使用该接口需要包含定义模板参数和模板参数组合的头文件。详细内容请参考 Tiling模板编程 。",
    "函数原型": "#define ASCENDC_TPL_SEL_PARAM(context, ...)           \\\ndo {                                                  \\\n    uint64_t key = GET_TPL_TILING_KEY({__VA_ARGS__}); \\\n    context->SetTilingKey(key);                       \\\n} while(0)\n// context指代TilingFunc(gert::TilingContext *context)中的context",
    "参数说明": "参数 输入/输出 说明 context 输入 TilingFunc注册上下文。 ... 输入 可变长参数，模板参数的具体值，传入时需要与定义模板参数和模板参数组合的头文件中的模板参数顺序保持一致。",
    "返回值": "",
    "调用示例": "#include \"tiling_key_add_custom.h\"\nstatic ge::graphStatus TilingFunc(gert::TilingContext *context)\n{\n    TilingData tiling;\n    uint32_t totalLength = context->GetInputShape(0)->GetOriginShape().GetShapeSize();\n    ge::DataType dtype_x = context->GetInputDesc(0)->GetDataType();\n    ge::DataType dtype_y = context->GetInputDesc(1)->GetDataType();\n    ge::DataType dtype_z = context->GetOutputDesc(1)->GetDataType();\n    uint32_t D_T_X = ADD_TPL_FP32, D_T_Y=ADD_TPL_FP32, D_T_Z=ADD_TPL_FP32, TILE_NUM=1, IS_SPLIT=0;\n    if(dtype_x == ge::DataType::DT_FLOAT){\n        D_T_X = ADD_TPL_FP32;\n    }else if(dtype_x == ge::DataType::DT_FLOAT16){\n        D_T_X = ADD_TPL_FP16;\n    }\n    if(dtype_y == ge::DataType::DT_FLOAT){\n        D_T_Y = ADD_TPL_FP32;\n    }else if(dtype_y == ge::DataType::DT_FLOAT16){\n        D_T_Y = ADD_TPL_FP16;\n    }\n    if(dtype_z == ge::DataType::DT_FLOAT){\n        D_T_Z = ADD_TPL_FP32;\n    }else if(dtype_z == ge::DataType::DT_FLOAT16){\n        D_T_Z = ADD_TPL_FP16;\n    }\n    if(totalLength< MIN_LENGTH_FOR_SPLIT){\n        IS_SPLIT = 0;\n        TILE_NUM = 1;\n    }else{\n        IS_SPLIT = 1;\n        TILE_NUM = DEFAULT_TILE_NUM;\n    }\n    context->SetBlockDim(BLOCK_DIM);\n    tiling.set_totalLength(totalLength);\n    tiling.SaveToBuffer(context->GetRawTilingData()->GetData(), context->GetRawTilingData()->GetCapacity());\n    context->GetRawTilingData()->SetDataSize(tiling.GetDataSize());\n    ASCENDC_TPL_SEL_PARAM(context, D_T_X, D_T_Y, D_T_Z, TILE_NUM, IS_SPLIT);\n    size_t *currentWorkspace = context->GetWorkspaceSizes(1);\n    currentWorkspace[0] = 0;\n    return ge::GRAPH_SUCCESS;\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "DEVICE_IMPL_OP_OPTILING",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_00060.html",
    "功能说明": "在 Tiling下沉 场景中，该宏定义用于生成Tiling下沉的注册类，再通过调用注册类的成员函数来注册需要下沉的Tiling函数。",
    "函数原型": "namespace optiling {\nusing SinkTilingFunc = std::function<ge::graphStatus(gert::TilingContext *context)>;\n\nclass DeviceOpImplRegisterImpl;\n// 开发者仅关注Tiling成员函数\nclass DeviceOpImplRegister {\npublic:\n  DeviceOpImplRegister(const char *opType);\n  ~DeviceOpImplRegister();\n  DeviceOpImplRegister(DeviceOpImplRegister &&other) noexcept;\n  DeviceOpImplRegister(const DeviceOpImplRegister &other);\n  DeviceOpImplRegister &operator=(const DeviceOpImplRegister &) = delete;\n  DeviceOpImplRegister &operator=(DeviceOpImplRegister &&) = delete;\n  DeviceOpImplRegister &Tiling(SinkTilingFunc func);\n\n// ...\n};\n}  // namespace optiling\n\n#define DEVICE_IMPL_OP_OPTILING(optype)                                                                      \\\n  static optiling::DeviceOpImplRegister VAR_UNUSED g_deviceOpImplRegister##optype =                                    \\\n      optiling::DeviceOpImplRegister(#optype)\n#endif",
    "参数说明": "表1 DEVICE_IMPL_OP_OPTILING参数说明 参数 输入/输出 说明 optype 输入 需要注册Tiling函数的OpType（算子类型）。 表2 Tiling成员函数参数说明 参数 输入/输出 说明 func 输入 需要注册的Tiling函数，该函数接受一个 TilingContext 作为输入，以 ge::graphStatus 为返回值。",
    "返回值": "",
    "调用示例": "DEVICE_IMPL_OP_OPTILING(TestOptype).Tiling(TestTilingFunc); // 将Tiling函数以及其OpType注册到Tiling下沉",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "简介",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1026.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "",
    "返回值": "",
    "调用示例": "",
    "错误": "缺失字段: 功能说明,函数原型,参数说明,返回值"
  },
  {
    "API名称": "PlatformAscendCManager",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1039.html",
    "功能说明": "基于Kernel Launch算子工程，通过Kernel直调（Kernel Launch）方式调用算子的场景下，可能需要获取硬件平台相关信息，比如获取硬件平台的核数。PlatformAscendCManager类提供获取平台信息的功能：通过该类的GetInstance方法可以获取一个PlatformAscendC类的指针，再通过该指针获取硬件平台相关信息，支持获取的信息可参考 PlatformAscendC 。 使用该功能需要包含\"tiling/platform/platform_ascendc.h\"头文件，并在编译脚本中链接tiling_api、platform动态库。 包含头文件的样例如下： #include \"tiling/platform/platform_ascendc.h\" 链接动态库的样例如下: add_executable(main main.cpp) target_link_libraries(main PRIVATE kernels tiling_api platform ) 当前该类仅支持如下型号： Atlas 推理系列产品 Atlas 训练系列产品 Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品",
    "函数原型": "class PlatformAscendCManager {\npublic:\n    static PlatformAscendC* GetInstance();\n    // 在仅有CPU环境、无对应的NPU硬件环境时，需要传入customSocVersion来指定对应的AI处理器型号。注意：因为GetInstance实现属于单例模式，仅在第一次调用时传入的customSocVersion生效。\n    static PlatformAscendC* GetInstance(const char *customSocVersion);\nprivate:\n...\n}",
    "参数说明": "参数 输入/输出 说明 customSocVersion 输入 AI处理器型号。 非 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ：在安装 昇腾AI处理器 的服务器执行 npu-smi info 命令进行查询，获取 Name 信息。实际配置值为AscendName，例如 Name 取值为 xxxyy ，实际配置值为Ascend xxxyy 。 Atlas A3 训练系列产品/Atlas A3 推理系列产品 ：在安装 昇腾AI处理器 的服务器执行 npu-smi info -t board -i id -c chip_id 命令进行查询，获取 Chip Name 和 NPU Name 信息，实际配置值为Chip Name_NPU Name。例如 Chip Name 取值为Ascend xxx ， NPU Name 取值为1234，实际配置值为Ascend xxx _ 1234。 其中： id：设备id，通过 npu-smi info -l 命令查出的NPU ID即为设备id。 chip_id：芯片id，通过 npu-smi info -m 命令查出的Chip ID即为芯片id。",
    "返回值": "",
    "调用示例": "GetInfoFun() {\n    ...\n    auto coreNum = platform_ascendc::PlatformAscendCManager::GetInstance()->GetCoreNum();\n    ...\n    return;\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "ADD_TO_LAUNCHER_LIST_AICORE",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1043.html",
    "功能说明": "",
    "函数原型": "",
    "参数说明": "参数 输入/输出 说明 KERNEL_NAME 输入 算子名，例如Add。 op_args... 输入 算子的参数，包括输入 OP_INPUT 、输出 OP_OUTPUT 、属性 OP_ATTR 等参数。",
    "返回值": "",
    "调用示例": "// 调用ADD_TO_LAUNCHER_LIST_AICORE创建add算子的执行任务，其中Add是算子名，self和other是算子输入参数，addOut是算子输出参数\nADD_TO_LAUNCHER_LIST_AICORE(Add, OP_INPUT(self, other), OP_OUTPUT(addOut));",
    "错误": "缺失字段: 功能说明,函数原型,返回值"
  },
  {
    "API名称": "Cast",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1193.html",
    "功能说明": "将输入tensor转换为指定的数据类型。",
    "函数原型": "// 固定写法，创建OpExecutor\nauto uniqueExecutor = CREATE_EXECUTOR();\n\nauto selfCasted = self;\n// 当self为布尔类型时，利用Cast接口转换为uint8类型后可进行整型计算；\nif (self->GetDataType() == op::DataType::DT_BOOL) {\n  selfCasted = l0op::Cast(self, op::DataType::DT_UINT8, uniqueExecutor.get());\n  CHECK_RET(selfCasted != nullptr, ACLNN_ERR_PARAM_NULLPTR);\n}",
    "参数说明": "参数 输入/输出 说明 self 输入 待转换的输入tensor，数据类型支持FLOAT16、FLOAT、DOUBLE、BFLOAT16、INT8、UINT8、INT16、UINT16、INT32、UINT32、INT64、UINT64、BOOL、COMPLEX64、COMPLEX128。数据格式支持ND。 说明： BFLOAT16适用于如下产品型号： Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 dstDtype 输入 转换后的目标dtype，数据类型支持FLOAT16、FLOAT、DOUBLE、BFLOAT16、INT8、UINT8、INT16、UINT16、INT32、UINT32、INT64、UINT64、BOOL、COMPLEX64、COMPLEX128。 说明： BFLOAT16适用于如下产品型号： Atlas A2 训练系列产品/Atlas 800I A2 推理产品/A200I A2 Box 异构组件 Atlas A3 训练系列产品/Atlas A3 推理系列产品 executor 输入 op执行器，包含了算子计算流程。",
    "返回值": "",
    "调用示例": "// 固定写法，创建OpExecutor\nauto uniqueExecutor = CREATE_EXECUTOR();\n\nauto selfCasted = self;\n// 当self为布尔类型时，利用Cast接口转换为uint8类型后可进行整型计算；\nif (self->GetDataType() == op::DataType::DT_BOOL) {\n  selfCasted = l0op::Cast(self, op::DataType::DT_UINT8, uniqueExecutor.get());\n  CHECK_RET(selfCasted != nullptr, ACLNN_ERR_PARAM_NULLPTR);\n}",
    "错误": "缺失字段: 返回值"
  },
  {
    "API名称": "DumpTensor",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0192.html",
    "功能说明": "基于算子工程开发的算子，可以使用该接口Dump指定Tensor的内容。同时支持打印自定义的附加信息（仅支持uint32_t数据类型的信息），比如打印当前行号等。 在算子kernel侧实现代码中需要打印Tensor数据的地方调用DumpTensor接口打印相关内容。样例如下： AscendC :: DumpTensor ( srcLocal , 5 , dataLen ); DumpTensor接口打印功能会对算子实际运行的性能带来一定影响，通常在调测阶段使用。开发者可以按需通过如下方式关闭打印功能。 自定义算子工程 修改算子工程op_kernel目录下的CMakeLists.txt文件，首行增加编译选项-DASCENDC_DUMP=0，关闭ASCENDC_DUMP开关，示例如下： // 关闭所有算子的printf打印功能 add_ops_compile_options ( ALL OPTIONS - DASCENDC_DUMP = 0 ) Kernel直调工程 修改cmake目录下的npu_lib.cmake文件，在ascendc_compile_definitions命令中增加-DASCENDC_DUMP=0宏定义来关闭ASCENDC_DUMP开关。示例如下： // 关闭所有算子的printf打印功能 ascendc_compile_definitions ( ascendc_kernels_$ { RUN_MODE } PRIVATE - DASCENDC_DUMP = 0 ) Dump时，每个block核的dump信息前会增加对应信息头DumpHead（32字节大小），用于记录核号和资源使用信息；每次Dump的Tensor数据前也会添加信息头DumpTensorHead（32字节大小），用于记录Tensor的相关信息。如下图所示，展示了多核打印场景下的打印信息结构。 DumpHead的具体信息如下： opType：当前运行的算子类型； CoreType：当前运行的核的类型； block dim：开发者设置的算子执行核数； total_block_num：参与dump的核数； block_remain_len：当前核剩余可用的dump的空间； block_initial_space：当前核初始分配的dump空间； rsv：保留字段； magic：内存校验魔术字。 DumpHead打印时，除了上述打印还会自动打印当前所运行核的类型及对应的该类型下的核索引，如：AIV-0。 DumpTensorHead的具体信息如下： desc：用户自定义附加信息； addr：Tensor的地址； data_type：Tensor的数据类型； position：表示Tensor所在的物理存储位置，当前仅支持 Unified Buffer / L1 Buffer / L0C Buffer / Global Memory 。 DumpTensor打印结果的最前面会自动打印CANN_VERSION_STR值与CANN_TIMESTAMP值。其中，CANN_VERSION_STR与CANN_TIMESTAMP为宏定义，CANN_VERSION_STR代表CANN软件包的版本号信息，形式为字符串，CANN_TIMESTAMP为CANN软件包发布时的时间戳，形式为数值（uint64_t）。开发者也可在代码中直接使用这两个宏。 打印示例如下： opType = AddCustom , DumpHead : AIV - 0 , CoreType = AIV , block dim = 8 , total_block_num = 8 , block_remain_len = 1046912 , block_initial_space = 1048576 , rsv = 0 , magic = 5 aa5bccd CANN Version : XX.XX , TimeStamp : XXXXXXXXXXXXXXXXX DumpTensor : desc = 5 , addr = 0 , data_type = float16 , position = UB [ 19 . 000000 , 4 . 000000 , 38 . 000000 , 50 . 000000 , 39 . 000000 , 67 . 000000 , 84 . 000000 , 98 . 000000 , 21 . 000000 , 36 . 000000 , 18 . 000000 , 46 . 000000 , 10 . 000000 , 92 . 000000 , 26 . 000000 , 38 . 000000 , 39 . 000000 , 9 . 000000 , 82 . 000000 , 37 . 000000 , 35 . 000000 , 65 . 000000 , 97 . 000000 , 59 . 000000 , 89 . 000000 , 63 . 000000 , 70 . 000000 , 57 . 000000 , 35 . 000000 , 3 . 000000 , 16 . 000000 , 42 . 000000 ] DumpTensor : desc = 5 , addr = 100 , data_type = float16 , position = UB [ 6 . 000000 , 34 . 000000 , 52 . 000000 , 38 . 000000 , 73 . 000000 , 38 . 000000 , 35 . 000000 , 14 . 000000 , 67 . 000000 , 62 . 000000 , 30 . 000000 , 49 . 000000 , 86 . 000000 , 37 . 000000 , 84 . 000000 , 18 . 000000 , 38 . 000000 , 18 . 000000 , 44 . 000000 , 21 . 000000 , 86 . 000000 , 99 . 000000 , 13 . 000000 , 79 . 000000 , 84 . 000000 , 9 . 000000 , 48 . 000000 , 74 . 000000 , 52 . 000000 , 99 . 000000 , 80 . 000000 , 53 . 000000 ] ... DumpTensor : desc = 5 , addr = 0 , data_type = float16 , position = UB [ 35 . 000000 , 41 . 000000 , 41 . 000000 , 22 . 000000 , 84 . 000000 , 49 . 000000 , 60 . 000000 , 0 . 000000 , 90 . 000000 , 14 . 000000 , 67 . 000000 , 80 . 000000 , 16 . 000000 , 46 . 000000 , 16 . 000000 , 83 . 000000 , 6 . 000000 , 70 . 000000 , 97 . 000000 , 28 . 000000 , 97 . 000000 , 62 . 000000 , 80 . 000000 , 22 . 000000 , 53 . 000000 , 37 . 000000 , 23 . 000000 , 58 . 000000 , 65 . 000000 , 28 . 000000 , 4 . 000000 , 29 . 000000 ]",
    "函数原型": "template <typename T>\n__aicore__ inline void DumpTensor(const LocalTensor<T> &tensor, uint32_t desc, uint32_t dumpSize)\ntemplate <typename T>\n__aicore__ inline void DumpTensor(const GlobalTensor<T>& tensor, uint32_t desc, uint32_t dumpSize)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 需要dump的Tensor的数据类型。支持的数据类型为uint8_t/int8_t/int16_t/uint16_t/int32_t/uint32_t/int64_t/uint64_t/float/half/bfloat16_t。\n\n表2 参数说明 参数名 输入/输出 描述 tensor 输入 需要dump的Tensor。 待dump的tensor位于 Unified Buffer / L1 Buffer / L0C Buffer 时使用LocalTensor类型的tensor参数输入。 待dump的tensor位于 Global Memory 时使用GlobalTensor类型的tensor参数输入。 desc 输入 用户自定义附加信息（行号或其他自定义数字）。 在使用DumpTensor功能时，用户可通过desc参数附加自定义信息，以便在不同调用场景下区分Dump内容的来源。此功能有助于精准定位具体DumpTensor的输出，提升调试与分析效率。 dumpSize 输入 需要dump的元素个数。 dump的元素总长度需要32字节对齐。 shapeInfo 输入 传入Tensor的shape信息，可按照shape信息进行打印。",
    "返回值": "无",
    "调用示例": "AscendC::DumpTensor(srcLocal,5, dataLen);",
    "错误": null
  },
  {
    "API名称": "printf",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0193.html",
    "功能说明": "该接口提供CPU域/NPU域调试场景下的格式化输出功能。 在算子kernel侧实现代码中需要输出日志信息的地方调用printf接口打印相关内容。样例如下： #include \"kernel_operator.h\" AscendC :: printf ( \"fmt string %d \\n \" , 0x123 ); AscendC :: PRINTF ( \"fmt string %d \\n \" , 0x123 ); printf（PRINTF）接口打印功能会对算子实际运行的性能带来一定影响，通常在调测阶段使用。开发者可以按需通过如下方式关闭打印功能。 自定义算子工程 修改算子工程op_kernel目录下的CMakeLists.txt文件，首行增加编译选项-DASCENDC_DUMP=0，关闭ASCENDC_DUMP开关，示例如下： // 关闭所有算子的printf打印功能 add_ops_compile_options ( ALL OPTIONS - DASCENDC_DUMP = 0 ) Kernel直调工程 修改cmake目录下的npu_lib.cmake文件，在ascendc_compile_definitions命令中增加-DASCENDC_DUMP=0宏定义来关闭NPU侧ASCENDC_DUMP开关。示例如下： // 关闭所有算子的printf打印功能 ascendc_compile_definitions ( ascendc_kernels_$ { RUN_MODE } PRIVATE - DASCENDC_DUMP = 0 ) 修改cmake目录下的cpu_lib.cmake文件，在target_compile_definitions命令中增加-DASCENDC_DUMP=0宏定义来关闭CPU侧ASCENDC_DUMP开关。示例如下： target_compile_definitions ( ascendc_kernels_$ { RUN_MODE } PRIVATE - DASCENDC_DUMP = 0 ) 需要注意的是，关闭CPU侧的打印开关时，只对PRINTF接口生效，对printf不生效。 NPU模式下，printf打印结果的最前面会自动打印CANN_VERSION_STR值与CANN_TIMESTAMP值。其中，CANN_VERSION_STR与CANN_TIMESTAMP为宏定义，CANN_VERSION_STR代表CANN软件包的版本号信息，形式为字符串，CANN_TIMESTAMP为CANN软件包发布时的时间戳，形式为数值(uint64_t)。开发者也可在代码中直接使用这两个宏。prinf打印结果示例如下： CANN Version : XXX.XX , TimeStamp : 20240807140556417 fmt string 291 fmt string 291 根据算子执行方式的不同，printf的打印结果输出方式不同。动态图或者单算子直调场景下，待输出内容会被解析并打印在屏幕上；静态图场景下，整图算子需要全下沉到NPU侧执行，无法直接调用接口打印出单个算子的信息，因此需要在模型执行完毕后，将待输出内容落盘在dump文件中，dump文件需要通过工具解析为可读内容。 dump文件落盘路径按照优先级排列如下: 如果开启了Data Dump功能，dump文件落盘到开发者配置的dump_path路径下。如何开启Dump功能依赖于具体的网络运行方式。以TensorFlow在线推理为例，通过enable_dump、dump_path、dump_mode等参数进行配置。配置方式可参考 《 TensorFlow 2.6.5模型迁移指南 》 中的API参考 > TF Adapter 接口（2.x）> npu.global_options > 配置参数说明章节。 如果未开启Data Dump功能，但配置了ASCEND_WORK_PATH环境变量，dump文件落盘到ASCEND_WORK_PATH下的printf目录下。ASCEND_WORK_PATH环境变量的配置方式可参考 ASCEND_WORK_PATH 。 如果未开启Data Dump功能也没有配置ASCEND_WORK_PATH环境变量，dump文件落盘到当前程序执行目录下的printf路径下。 落盘dump文件需要使用工具解析为用户可读内容： 使用show_kernel_debug_data工具将dump二进制文件解析为用户可读内容，命令格式如下。show_kernel_debug_data的具体使用方法请参考 show_kernel_debug_data工具 。 show_kernel_debug_data bin_file output_dir",
    "函数原型": "void printf(__gm__ const char* fmt, Args&&... args)\nvoid PRINTF(__gm__ const char* fmt, Args&&... args)",
    "参数说明": "参数名 输入/输出 描述 fmt 输入 格式控制字符串，包含两种类型的对象：普通字符和转换说明。 普通字符将原样不动地打印输出。 转换说明并不直接输出而是用于控制printf中参数的转换和打印。每个转换说明都由一个百分号字符（%）开始，以转换说明结束，从而说明输出数据的类型 。 支持的转换类型包括： %d / %i：输出十进制数，支持打印的数据类型：bool/int8_t/int16_t/int32_t/int64_t %f：输出实数，支持打印的数据类型：float/half/bfloat16_t %x：输出十六进制整数，支持打印的数据类型：int8_t/int16_t/int32_t/int64_t/uint8_t/uint16_t/uint32_t/uint64_t %s：输出字符串 %u：输出unsigned类型数据，支持打印的数据类型：bool/uint8_t/uint16_t/uint32_t/uint64_t %p：输出指针地址 注意 ：上文列出的数据类型是NPU域调试支持的数据类型，CPU域调试时，支持的数据类型和C/C++规范保持一致。 args 输入 附加参数，个数和类型可变的参数列表：根据不同的fmt字符串，函数可能需要一系列的附加参数，每个参数包含了一个要被插入的值，替换了fmt参数中指定的每个%标签。参数的个数应与%标签的个数相同。",
    "返回值": "无",
    "调用示例": "#include \"kernel_operator.h\"\n\n// 整型打印：\nAscendC::printf(\"fmt string %d\\n\", 0x123);\nAscendC::PRINTF(\"fmt string %d\\n\", 0x123);\n\n// 浮点型打印：\nfloat a = 3.14;\nAscendC::printf(\"fmt string %f\\n\", a);\nAscendC::PRINTF(\"fmt string %f\\n\", a);\n\n// 指针打印：\nint *b;\nAscendC::printf(\"TEST %p\\n\", b);\nAscendC::PRINTF(\"TEST %p\\n\", b);",
    "错误": null
  },
  {
    "API名称": "assert",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0194.html",
    "功能说明": "基于算子工程开发的算子，可以使用该接口实现CPU/NPU域assert断言功能。算子执行中，如果assert内部条件判断不为真，则输出assert条件并将输入的信息格式化打印在屏幕上。 在算子kernel侧实现代码中需要增加断言的地方使用assert检查代码，并格式化输出一些调测信息。示例如下： int assertFlag = 10 ; assert ( assertFlag == 10 ); assert ( assertFlag == 10 , \"The assertFlag value is 10. \\n \" ); assert ( assertFlag == 10 , \"The assertFlag value is %d. \\n \" , assertFlag ); assert接口打印功能会对算子实际运行的性能带来一定影响（每一条assert，系统会额外增加一条逻辑判断，具体性能影响取决于代码中assert的使用数量），通常在调测阶段使用。开发者可以按需通过如下方式关闭打印功能。 自定义算子工程 修改算子工程op_kernel目录下的CMakeLists.txt文件，首行增加编译选项-DASCENDC_DUMP=0，关闭ASCENDC_DUMP开关，示例如下： // 关闭所有算子的printf打印功能 add_ops_compile_options ( ALL OPTIONS - DASCENDC_DUMP = 0 ) Kernel直调工程 修改cmake目录下的npu_lib.cmake文件，在ascendc_compile_definitions命令中增加-DASCENDC_DUMP=0宏定义来关闭ASCENDC_DUMP开关；关闭CPU侧的断言打印，则修改cpu_lib.cmake文件。示例如下： // 关闭所有算子的printf打印功能 ascendc_compile_definitions ( ascendc_kernels_$ { RUN_MODE } PRIVATE - DASCENDC_DUMP = 0 ) 在assert条件被触发时，在断言信息前面会自动打印CANN_VERSION_STR值与CANN_TIMESTAMP值。其中，CANN_VERSION_STR与CANN_TIMESTAMP为宏定义，CANN_VERSION_STR代表CANN软件包的版本号信息，形式为字符串，CANN_TIMESTAMP为CANN软件包发布时的时间戳，形式为数值(uint64_t)。开发者也可在代码中直接使用这两个宏。assert打印信息示例如下： [ ASSERT ][ CANN_VERSION : XXX.XX ][ TimeStamp : 20240807140556417 ] / home / ... / add_custom.cpp : 44 : Assertion ` assertFlag != 10 ' The assertFlag value is 10 .",
    "函数原型": "assert(expr)\nassert(expr, __gm__ const char *fmt, Args&&... args)",
    "参数说明": "参数名 输入/输出 描述 expr 输入 assert断言是否终止程序的条件。为true则程序继续执行，为false则终止程序。 fmt 输入 格式控制字符串，包含两种类型的对象：普通字符和转换说明。 普通字符将原样不动地打印输出。 转换说明并不直接输出而是用于控制printf中参数的转换和打印。每个转换说明都由一个百分号字符（%）开始，以转换说明结束，从而说明输出数据的类型 。 支持的转换类型包括： %d / %i：输出十进制数 %f：输出实数 %x：输出十六进制整数 %s：输出字符串 %u：输出unsigned类型数据 %p：输出指针地址 当前支持的数据类型为uint8_t/int8_t/int16_t/uint16_t/int32_t/uint32_t/int64_t/uint64_t/float/half。 args 输入 附加参数，个数和类型可变的参数列表：根据不同的fmt字符串，函数可能需要一系列的附加参数，每个参数包含了一个要被插入的值，替换了fmt参数中指定的每个%标签。参数的个数应与%标签的个数相同。",
    "返回值": "无",
    "调用示例": "int assertFlag = 10;\n\n// 断言条件\nassert(assertFlag == 10);\n\n// 打印消息\nassert(assertFlag == 10, \"The assertFlag value is 10.\\n\");\n\n// 格式化打印\nassert(assertFlag == 10, \"The assertFlag value is %d.\\n\", assertFlag);\nassert(assertFlag != 10, \"The assertFlag value is %d.\\n\", assertFlag);",
    "错误": null
  },
  {
    "API名称": "DumpAccChkPoint",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0195.html",
    "功能说明": "基于算子工程开发的算子，可以使用该接口Dump指定Tensor的内容。同时支持打印自定义的附加信息（仅支持uint32_t数据类型的信息），比如打印当前行号等。区别于 DumpTensor ，使用该接口可以支持指定偏移位置的Tensor打印。 在算子kernel侧实现代码中需要打印偏移后Tensor数据的地方调用DumpAccChkPoint接口打印相关内容。样例如下： AscendC :: DumpAccChkPoint ( srcLocal , 5 , 32 , dataLen ); DumpAccChkPoint接口打印功能会对算子实际运行的性能带来一定影响，通常在调测阶段使用。开发者可以按需通过如下方式关闭打印功能。 自定义算子工程 修改算子工程op_kernel目录下的CMakeLists.txt文件，首行增加编译选项-DASCENDC_DUMP=0，关闭ASCENDC_DUMP开关，示例如下： // 关闭所有算子的printf打印功能 add_ops_compile_options ( ALL OPTIONS - DASCENDC_DUMP = 0 ) Kernel直调工程 修改cmake目录下的npu_lib.cmake文件，在ascendc_compile_definitions命令中增加-DASCENDC_DUMP=0宏定义来关闭ASCENDC_DUMP开关。示例如下： // 关闭所有算子的printf打印功能 ascendc_compile_definitions ( ascendc_kernels_$ { RUN_MODE } PRIVATE - DASCENDC_DUMP = 0 ) Dump时，每个block核的dump信息前会增加对应信息头DumpHead（32字节大小），用于记录核号和资源使用信息；每次Dump的Tensor数据前也会添加信息头DumpTensorHead（32字节大小），用于记录Tensor的相关信息。如下图所示，展示了多核打印场景下的打印信息结构。 DumpHead的具体信息如下： opType：当前运行的算子类型； CoreType：当前运行的核的类型； block dim：开发者设置的算子执行核数； total_block_num：参与dump的核数； block_remain_len：当前核剩余可用的dump的空间； block_initial_space：当前核初始分配的dump空间； rsv：保留字段； magic：内存校验魔术字。 DumpHead打印时，除了上述打印还会自动打印当前所运行核的类型及对应的该类型下的核索引，如：AIV-0。 DumpTensorHead的具体信息如下： desc：用户自定义附加信息； addr：Tensor的地址； data_type：Tensor的数据类型； position：表示Tensor所在的物理存储位置，当前仅支持 Unified Buffer / L1 Buffer / L0C Buffer / Global Memory 。 DumpAccChkPoint打印结果的最前面会自动打印CANN_VERSION_STR值与CANN_TIMESTAMP值。其中，CANN_VERSION_STR与CANN_TIMESTAMP为宏定义，CANN_VERSION_STR代表CANN软件包的版本号信息，形式为字符串，CANN_TIMESTAMP为CANN软件包发布时的时间戳，形式为数值（uint64_t）。开发者也可在代码中直接使用这两个宏。 打印结果的样例如下： opType = AddCustom , DumpHead : AIV - 0 , CoreType = AIV , block dim = 8 , total_block_num = 8 , block_remain_len = 1046912 , block_initial_space = 1048576 , rsv = 0 , magic = 5 aa5bccd CANN Version : XX.XX , TimeStamp : XXXXXXXXXXXXXXXXX DumpTensor : desc = 5 , addr = 40 , data_type = float16 , position = UB [ 16 . 000000 , 22 . 000000 , 2 . 000000 , 3 . 000000 , 58 . 000000 , 62 . 000000 , 33 . 000000 , 74 . 000000 , 51 . 000000 , 69 . 000000 , 61 . 000000 , 9 . 000000 , 53 . 000000 , 35 . 000000 , 14 . 000000 , 43 . 000000 , 20 . 000000 , 43 . 000000 , 92 . 000000 , 84 . 000000 , 9 . 000000 , 6 . 000000 , 78 . 000000 , 53 . 000000 , 52 . 000000 , 33 . 000000 , 51 . 000000 , 61 . 000000 , 92 . 000000 , 45 . 000000 , 39 . 000000 , 34 . 000000 ] ... DumpTensor : desc = 5 , addr = 140 , data_type = float16 , position = UB [ 41 . 000000 , 91 . 000000 , 12 . 000000 , 32 . 000000 , 28 . 000000 , 49 . 000000 , 2 . 000000 , 75 . 000000 , 11 . 000000 , 32 . 000000 , 17 . 000000 , 31 . 000000 , 70 . 000000 , 38 . 000000 , 76 . 000000 , 87 . 000000 , 61 . 000000 , 8 . 000000 , 55 . 000000 , 70 . 000000 , 17 . 000000 , 37 . 000000 , 35 . 000000 , 58 . 000000 , 94 . 000000 , 31 . 000000 , 50 . 000000 , 29 . 000000 , 13 . 000000 , 37 . 000000 , 79 . 000000 , 29 . 000000 ]",
    "函数原型": "template <typename T>\n__aicore__ inline void DumpAccChkPoint(const LocalTensor<T> &tensor, uint32_t index, uint32_t countOff, uint32_t dumpSize)\ntemplate <typename T>\n__aicore__ inline void DumpAccChkPoint(const GlobalTensor<T> &tensor, uint32_t index, uint32_t countOff, uint32_t dumpSize)",
    "参数说明": "表1 模板参数说明 参数名 描述 T 需要dump的Tensor的数据类型。支持的数据类型为uint8_t/int8_t/int16_t/uint16_t/int32_t/uint32_t/int64_t/uint64_t/float/half/bfloat16_t。\n\n表2 参数说明 参数名 输入/输出 描述 tensor 输入 需要dump的Tensor。 待dump的tensor位于 Unified Buffer / L1 Buffer / L0C Buffer 时使用LocalTensor类型的tensor参数输入。 待dump的tensor位于 Global Memory 时使用GlobalTensor类型的tensor参数输入。 index 输入 用户自定义附加信息（行号或其他自定义数字）。 countOff 输入 偏移元素个数。 dumpSize 输入 需要dump的元素个数。",
    "返回值": "无",
    "调用示例": "AscendC::DumpAccChkPoint(srcLocal, 7, 32 , 128);",
    "错误": null
  },
  {
    "API名称": "Trap",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_0196.html",
    "功能说明": "在kernel侧调用，NPU模式下会中断AI Core的运行，CPU模式下等同于assert。可用于kernel侧异常场景的调试。",
    "函数原型": "__aicore__ inline void Trap()",
    "参数说明": "无",
    "返回值": "无",
    "调用示例": "AscendC::Trap();",
    "错误": null
  },
  {
    "API名称": "GmAlloc",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1207.html",
    "功能说明": "进行核函数的CPU侧运行验证时，用于创建共享内存：在/tmp目录下创建一个共享文件，并返回该文件的映射指针。",
    "函数原型": "void *GmAlloc(size_t size)",
    "参数说明": "参数名 输入/输出 描述 size 输入 用户想要申请的共享内存大小",
    "返回值": "返回该共享内存空间的首地址。",
    "调用示例": "constexpr size_t len = 8 * 32 * 1024 * 8;\nhalf* x = (half*) GmAlloc(len*sizeof(half));",
    "错误": null
  },
  {
    "API名称": "ICPU_RUN_KF",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1208.html",
    "功能说明": "进行核函数的CPU侧运行验证时，CPU调测总入口，完成CPU侧的算子程序调用。",
    "函数原型": "#define ICPU_RUN_KF(func, blkdim, ...)",
    "参数说明": "参数名 输入/输出 描述 func 输入 算子的kernel函数指针。 blkdim 输入 算子的核心数，corenum。 ... 输入 所有的入参和出参，依次填入，当前参数个数限制为32个，超出32时会出现编译错误。",
    "返回值": "无",
    "调用示例": "ICPU_RUN_KF(sort_kernel0, coreNum, (uint8_t*)x, (uint8_t*)y);",
    "错误": null
  },
  {
    "API名称": "ICPU_SET_TILING_KEY",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1209.html",
    "功能说明": "用于指定本次CPU调测使用的tilingKey。调测执行时，将只执行算子核函数中该tilingKey对应的分支。",
    "函数原型": "ICPU_SET_TILING_KEY(tilingKey)",
    "参数说明": "参数名 输入/输出 描述 tilingKey 输入 指定本次CPU调测使用的tilingKey，参数类型为int32_t。",
    "返回值": "无",
    "调用示例": "ICPU_SET_TILING_KEY(10086);\nICPU_RUN_KF(sort_kernel0, coreNum, (uint8_t*)x, (uint8_t*)y);",
    "错误": null
  },
  {
    "API名称": "GmFree",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1210.html",
    "功能说明": "进行核函数的CPU侧运行验证时，用于释放通过 GmAlloc 申请的共享内存。",
    "函数原型": "void GmFree(void *ptr)",
    "参数说明": "参数名 输入/输出 描述 ptr 输入 需要释放的共享内存的指针。",
    "返回值": "无",
    "调用示例": "AscendC::GmFree((void*)x);",
    "错误": null
  },
  {
    "API名称": "SetKernelMode",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1211.html",
    "功能说明": "针对分离架构，CPU调测时，设置内核模式为单AIV模式，单AIC模式或者MIX模式，以分别支持单AIV矢量算子，单AIC矩阵算子，MIX混合算子的CPU调试。不调用该接口的情况下，默认为MIX模式。为保证算子代码在多个硬件平台兼容，耦合架构下也可以调用，该场景下接口不会生效，不影响正常调试。",
    "函数原型": "void SetKernelMode(KernelMode mode)",
    "参数说明": "参数名 输入/输出 描述 mode 输入 内核模式，针对AIC，AIV，MIX算子的CPU调试，参数取值分别为AIC_MODE，AIV_MODE，MIX_MODE。 enum class KernelMode { MIX_MODE = 0 , AIC_MODE , AIV_MODE };",
    "返回值": "无",
    "调用示例": "int32_t main(int32_t argc, char* argv[])\n{\n    ...\n#ifdef ASCENDC_CPU_DEBUG\n    ...\n    AscendC::SetKernelMode(KernelMode::AIV_MODE);\n    ICPU_RUN_KF(add_custom, blockDim, x, y, z); // use this macro for cpu debug\n    ...\n    AscendC::GmFree((void *)x);\n    AscendC::GmFree((void *)y);\n    AscendC::GmFree((void *)z);\n#else\n    ...\n#endif\n    return 0;\n}",
    "错误": null
  },
  {
    "API名称": "TRACE_START",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1212.html",
    "功能说明": "通过CAModel进行算子性能仿真时，可对算子任意运行阶段打点，从而分析不同指令的流水图，以便进一步性能调优。 用于表示起始位置打点，一般与 TRACE_STOP 配套使用。",
    "函数原型": "#define TRACE_START(apid)",
    "参数说明": "参数名 输入/输出 描述 apid 输入 当前预留了十个用户自定义的类型： 0x0：USER_DEFINE_0 0x1：USER_DEFINE_1 0x2：USER_DEFINE_2 0x3：USER_DEFINE_3 0x4：USER_DEFINE_4 0x5：USER_DEFINE_5 0x6：USER_DEFINE_6 0x7：USER_DEFINE_7 0x8：USER_DEFINE_8 0x9：USER_DEFINE_9",
    "返回值": "无",
    "调用示例": "TRACE_START(0x2);\nAdd(zLocal, xLocal, yLocal, dataSize);\nTRACE_STOP(0x2);",
    "错误": null
  },
  {
    "API名称": "TRACE_STOP",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1213.html",
    "功能说明": "通过CAModel进行算子性能仿真时，可对算子任意运行阶段打点，从而分析不同指令的流水图，以便进一步性能调优。 用于表示终止位置打点，一般与 TRACE_START 配套使用。",
    "函数原型": "#define TRACE_STOP(apid)",
    "参数说明": "参数名 输入/输出 描述 apid 输入 取值需与 TRACE_START 参数取值保持一致，否则影响打点结果。",
    "返回值": "无",
    "调用示例": "TRACE_START(0x1);\nDataCopy(zGm, zLocal, this->totalLength);\nTRACE_STOP(0x1);",
    "错误": null
  },
  {
    "API名称": "MetricsProfStart",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1214.html",
    "功能说明": "用于设置性能数据采集信号启动，和MetricsProfStop配合使用。使用 msProf 工具进行算子上板调优时，可在kernel侧代码段前后分别调用MetricsProfStart和MetricsProfStop来指定需要调优的代码段范围。",
    "函数原型": "__aicore__ inline void MetricsProfStart()",
    "参数说明": "无",
    "返回值": "无",
    "调用示例": "MetricsProfStart();",
    "错误": null
  },
  {
    "API名称": "MetricsProfStop",
    "API文档URL": "https://www.hiascend.com/document/detail/zh/canncommercial/82RC1/API/ascendcopapi/atlasascendc_api_07_1215.html",
    "功能说明": "设置性能数据采集信号停止，和MetricsProfStart配合使用。使用 msProf 工具进行算子上板调优时，可在kernel侧代码段前后分别调用MetricsProfStart和MetricsProfStop来指定需要调优的代码段范围。",
    "函数原型": "__aicore__ inline void MetricsProfStop()",
    "参数说明": "无",
    "返回值": "无",
    "调用示例": "MetricsProfStop();",
    "错误": null
  }
]